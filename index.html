<html><head><meta charset='utf-8'><title>Keyword Plot</title></head><body><div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script>                <div id="64f5ff55-fcba-4259-8ffc-833f741d398e" class="plotly-graph-div" style="height:800px; width:2500px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("64f5ff55-fcba-4259-8ffc-833f741d398e")) {                    Plotly.newPlot(                        "64f5ff55-fcba-4259-8ffc-833f741d398e",                        [{"hoverinfo":"text","marker":{"line":{"width":0}},"text":["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs\u003cbr\u003eEvaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection\u003cbr\u003eBlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering\u003cbr\u003eLookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps\u003cbr\u003eAligning Language Models to Explicitly Handle Ambiguity\u003cbr\u003eSelf-Refine Instruction-Tuning for Aligning Reasoning in Language Models\u003cbr\u003eSeemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?\u003cbr\u003eQUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios\u003cbr\u003ePhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study\u003cbr\u003eSEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation\u003cbr\u003eLearn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism\u003cbr\u003eVGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation\u003cbr\u003eWhere is the signal in tokenization space?\u003cbr\u003eEstimating Knowledge in Large Language Models Without Generating a Single Token\u003cbr\u003eWhen Context Leads but Parametric Memory Follows in Large Language Models\u003cbr\u003e... and 150 more","On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices\u003cbr\u003ePerformance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale\u003cbr\u003eText Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification\u003cbr\u003eIncubating Text Classifiers Following User Instruction with Nothing but LLM\u003cbr\u003eAdaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks\u003cbr\u003eThe Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse\u003cbr\u003eFine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates\u003cbr\u003ePERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts\u003cbr\u003eThe Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples\u003cbr\u003eStablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models\u003cbr\u003eIntegrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation\u003cbr\u003eUniversal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning\u003cbr\u003eMARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction\u003cbr\u003eTowards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs\u003cbr\u003eRationalizing Transformer Predictions via End-To-End Differentiable Self-Training\u003cbr\u003e... and 53 more","Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNS\u003cbr\u003eRethinking Token Reduction for State Space Models\u003cbr\u003eInstruction Pre-Training: Language Models are Supervised Multitask Learners\u003cbr\u003eLeading Whitespaces of Language Models' Subword Vocabulary Pose a Confound for Calculating Word Probabilities\u003cbr\u003eWhen Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages\u003cbr\u003eKidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions\u003cbr\u003eContext-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models\u003cbr\u003eCItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling\u003cbr\u003eMitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing\u003cbr\u003eCan Large Language Models Learn Independent Causal Mechanisms?\u003cbr\u003eExtending Context Window of Large Language Models from a Distributional Perspective\u003cbr\u003eVPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models\u003cbr\u003eBirdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives\u003cbr\u003eCan Transformers Learn n-gram Language Models?\u003cbr\u003ePREALIGN: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment\u003cbr\u003e... and 49 more","A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers\u003cbr\u003eOvercome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue\u003cbr\u003eCryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading\u003cbr\u003eDA\u00b3: A Distribution-Aware Adversarial Attack against Language Models\u003cbr\u003eAdaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eFine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates\u003cbr\u003eDoes Large Language Model Contain Task-Specific Neurons?\u003cbr\u003eGetting More from Less: Large Language Models are Good Spontaneous Multilingual Learners\u003cbr\u003eMOSEL: Inference Serving Using Dynamic Modality Selection\u003cbr\u003eThe Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification\u003cbr\u003eParaphrase Types Elicit Prompt Engineering Capabilities\u003cbr\u003eMitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment\u003cbr\u003eUniversal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning\u003cbr\u003eDo LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models\u003cbr\u003e... and 48 more","Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors\u003cbr\u003eMAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering\u003cbr\u003eSelf-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering\u003cbr\u003eTag-grounded Visual Instruction Tuning with Retrieval Augmentation\u003cbr\u003eDocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models\u003cbr\u003eWorld to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering\u003cbr\u003eFrom the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis\u003cbr\u003eConcept-skill Transferability-based Data Selection for Large Vision-Language Models\u003cbr\u003eHow Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?\u003cbr\u003eBenchmarking Vision Language Models for Cultural Understanding\u003cbr\u003eUOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models\u003cbr\u003eMMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model\u003cbr\u003eBeyond Embeddings: The Promise of Visual Table in Visual Reasoning\u003cbr\u003eTowards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\u003cbr\u003ePelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification\u003cbr\u003e... and 42 more","LONGEMBED: Extending Embedding Models for Long Context Retrieval\u003cbr\u003eReuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment\u003cbr\u003eLookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps\u003cbr\u003eDancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models\u003cbr\u003eBayesian Calibration of Win Rate Estimation with LLM Evaluators\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eOptimized Speculative Sampling for GPU Hardware Accelerators\u003cbr\u003eA Survey of AMR Applications\u003cbr\u003eEAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees\u003cbr\u003eEvaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works\u003cbr\u003eAttribute or Abstain: Large Language Models as Long Document Assistants\u003cbr\u003eA Thorough Examination of Decoding Methods in the Era of LLMs\u003cbr\u003eMiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents\u003cbr\u003eSynchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation\u003cbr\u003eUnlocking Memorization in Large Language Models with Dynamic Soft Prompting\u003cbr\u003e... and 40 more","Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process\u003cbr\u003eLogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models\u003cbr\u003eFuseGen: PLM Fusion for Data-generation based Zero-shot Learning\u003cbr\u003eIn Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search\u003cbr\u003eQUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios\u003cbr\u003eVerification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving\u003cbr\u003eHow Hard is this Test Set?\nNLI Characterization by Exploiting Training Dynamics\u003cbr\u003eScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws\u003cbr\u003eAdaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks\u003cbr\u003eHow Do Humans Write Code? Large Models Do It the Same Way Too\u003cbr\u003eScaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars\u003cbr\u003eRevealing the Parallel Multilingual Learning within Large Language Models\u003cbr\u003eGetting More from Less: Large Language Models are Good Spontaneous Multilingual Learners\u003cbr\u003eAttribute or Abstain: Large Language Models as Long Document Assistants\u003cbr\u003eEnhancing Systematic Decompositional Natural Language Inference Using Informal Logic\u003cbr\u003e... and 39 more","Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks\u003cbr\u003eRoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eAdvancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003eSelf-Refine Instruction-Tuning for Aligning Reasoning in Language Models\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eTeaching Small Language Models Reasoning through Counterfactual Distillation\u003cbr\u003eInvestigating Mysteries of CoT-Augmented Distillation\u003cbr\u003eFocused Large Language Models are Stable Many-Shot Learners\u003cbr\u003eMixture-of-Subspaces in Low-Rank Adaptation\u003cbr\u003eRetrieved In-Context Principles from Previous Mistakes\u003cbr\u003eA Thorough Examination of Decoding Methods in the Era of LLMs\u003cbr\u003eSusu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S.\u003cbr\u003eI Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses\u003cbr\u003eLarge Language Models Can Self-Correct with Key Condition Verification\u003cbr\u003e... and 38 more","Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?\u003cbr\u003eChain-of-Dictionary Prompting Elicits Translation in Large Language Models\u003cbr\u003eWord Alignment as Preference for Machine Translation\u003cbr\u003eVoices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects\u003cbr\u003eAligning Translation-Specific Understanding to General Understanding in Large Language Models\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eAn Audit on the Perspectives and Challenges of Hallucinations in NLP\u003cbr\u003eA Survey of AMR Applications\u003cbr\u003eRevealing the Parallel Multilingual Learning within Large Language Models\u003cbr\u003eLexically Grounded Subword Segmentation\u003cbr\u003eIs It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?\u003cbr\u003eSCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation\u003cbr\u003eDistributional Properties of Subword Regularization\u003cbr\u003eUnveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism\u003cbr\u003eOuroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding\u003cbr\u003e... and 33 more","Prompts have evil twins\u003cbr\u003ePromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval\u003cbr\u003eKidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions\u003cbr\u003ePERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts\u003cbr\u003e\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models\u003cbr\u003eLLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives\u003cbr\u003ePrecise Model Benchmarking with Only a Few Observations\u003cbr\u003eIs It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?\u003cbr\u003eUnlocking Memorization in Large Language Models with Dynamic Soft Prompting\u003cbr\u003eIf CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions\u003cbr\u003eStablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models\u003cbr\u003eAnalysis of Plan-based Retrieval for Grounded Text Generation\u003cbr\u003eOuroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding\u003cbr\u003eEvaluating n-Gram Novelty of Language Models Using RUSTY-DAWG\u003cbr\u003eA Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors\u003cbr\u003e... and 24 more","Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections\u003cbr\u003eRoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning\u003cbr\u003eDirect Multi-Turn Preference Optimization for Language Agents\u003cbr\u003eInstruction Pre-Training: Language Models are Supervised Multitask Learners\u003cbr\u003eDancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models\u003cbr\u003eBayesian Calibration of Win Rate Estimation with LLM Evaluators\u003cbr\u003eNLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian\u003cbr\u003eGAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities\u003cbr\u003eAutomatic Instruction Evolving for Large Language Models\u003cbr\u003eEAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees\u003cbr\u003eGold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs\u003cbr\u003eWPO: Enhancing RLHF with Weighted Preference Optimization\u003cbr\u003eA Thorough Examination of Decoding Methods in the Era of LLMs\u003cbr\u003eAmbigNLG: Addressing Task Ambiguity in Instruction for NLG\u003cbr\u003eMAIR: A Massive Benchmark for Evaluating Instructed Retrieval\u003cbr\u003e... and 24 more","Learning Planning-based Reasoning via Trajectories Collection and Process Reward Synthesizing\u003cbr\u003eFrom Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning\u003cbr\u003eHow Do Humans Write Code? Large Models Do It the Same Way Too\u003cbr\u003eMuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning\u003cbr\u003eRevealing the Parallel Multilingual Learning within Large Language Models\u003cbr\u003eAutomatic Instruction Evolving for Large Language Models\u003cbr\u003eFROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models\u003cbr\u003eEAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees\u003cbr\u003eADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning\u003cbr\u003eRetrieved In-Context Principles from Previous Mistakes\u003cbr\u003eFine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together\u003cbr\u003eEmpowering Multi-step Reasoning across Languages via Program-Aided Language Models\u003cbr\u003eControlMath: Controllable Data Generation Promotes Math Generalist Models\u003cbr\u003eLearn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning\u003cbr\u003eNot Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment\u003cbr\u003e... and 18 more","Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\u003cbr\u003eTake Off the Training Wheels! Progressive In-Context Learning for Effective Alignment\u003cbr\u003eHow do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning\u003cbr\u003eInterpretability-based Tailored Knowledge Editing in Transformers\u003cbr\u003eEXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning\u003cbr\u003eSynergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems\u003cbr\u003eFocused Large Language Models are Stable Many-Shot Learners\u003cbr\u003eLearning to Retrieve Iteratively for In-Context Learning\u003cbr\u003ePosition Engineering: Boosting Large Language Models through Positional Information Manipulation\u003cbr\u003eStrategic Demonstration Selection for Improved Fairness in LLM In-Context Learning\u003cbr\u003eBridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning\u003cbr\u003eImproving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning\u003cbr\u003eSCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation\u003cbr\u003eOn the In-context Generation of Language Models\u003cbr\u003eBreaking the Curse of Multilinguality with Cross-lingual Expert Language Models\u003cbr\u003e... and 18 more","AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation\u003cbr\u003eAutomatic Instruction Evolving for Large Language Models\u003cbr\u003eEAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees\u003cbr\u003eUnlocking Memorization in Large Language Models with Dynamic Soft Prompting\u003cbr\u003eI Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses\u003cbr\u003eOuroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding\u003cbr\u003eHow Do Your Code LLMs Perform? Empowering Code Instruction Tuning with Really Good Data\u003cbr\u003eSmall Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector\u003cbr\u003eLearn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning\u003cbr\u003eECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?\u003cbr\u003eRe-ReST: Reflection-Reinforced Self-Training for Language Agents\u003cbr\u003eFree your mouse! Command Large Language Models to Generate Code to Format Word Documents\u003cbr\u003eCoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing\u003cbr\u003eRAR: Retrieval-augmented retrieval for code generation in low-resource languages\u003cbr\u003eEHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records\u003cbr\u003e... and 17 more","MTLS: Making Texts into Linguistic Symbols\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eADELIE: Aligning Large Language Models on Information Extraction\u003cbr\u003eBio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints\u003cbr\u003eParaphrase Types Elicit Prompt Engineering Capabilities\u003cbr\u003eNuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data\u003cbr\u003eSciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents\u003cbr\u003eZero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages\u003cbr\u003eLarge Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark\u003cbr\u003eA Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives\u003cbr\u003eModel Editing Harms General Abilities of Large Language Models: Regularization to the Rescue\u003cbr\u003eFill In The Gaps: Model Calibration and Generalization with Synthetic Data\u003cbr\u003eEmbedded Named Entity Recognition using Probing Classifiers\u003cbr\u003eNOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition\u003cbr\u003eAre Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?\u003cbr\u003e... and 17 more","PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study\u003cbr\u003eTo Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models\u003cbr\u003eMAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration\u003cbr\u003eMore Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs\u003cbr\u003eLearning to Correct for QA Reasoning with Black-box LLMs\u003cbr\u003eText-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction\u003cbr\u003eSelf-AMPLIFY : Improving Small Language Models with Self Post Hoc Explanations\u003cbr\u003eExperimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently\u003cbr\u003eDynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models\u003cbr\u003eImprove Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation\u003cbr\u003eCan LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators\u003cbr\u003eModel Editing Harms General Abilities of Large Language Models: Regularization to the Rescue\u003cbr\u003eOne Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models\u003cbr\u003eReasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality\u003cbr\u003e... and 16 more","Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs\u003cbr\u003eKnowledge Verification to Nip Hallucination in the Bud\u003cbr\u003eEfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u003cbr\u003eCrafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs\u003cbr\u003eModel Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation\u003cbr\u003ePosition Engineering: Boosting Large Language Models through Positional Information Manipulation\u003cbr\u003eImproving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning\u003cbr\u003eAGRAME: Any-Granularity Ranking with Multi-Vector Embeddings\u003cbr\u003eMiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents\u003cbr\u003eAssessing \"Implicit\" Retrieval Robustness of Large Language Models\u003cbr\u003eATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR\u003cbr\u003eImprove Dense Passage Retrieval with Entailment Tuning\u003cbr\u003eRA2FD: Distilling Faithfulness into Efficient Dialogue Systems\u003cbr\u003eAnalysis of Plan-based Retrieval for Grounded Text Generation\u003cbr\u003eSearching for Best Practices in Retrieval-Augmented Generation\u003cbr\u003e... and 15 more","Do Large Language Models Know How Much They Know?\u003cbr\u003eGENRA: Enhancing Zero-shot Retrieval with Rank Aggregation\u003cbr\u003eFIRST: Faster Improved Listwise Reranking with Single Token Decoding\u003cbr\u003eOmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer\u003cbr\u003eMatryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions\u003cbr\u003eExploring the Practicality of Generative Retrieval on Dynamic Corpora\u003cbr\u003eMAIR: A Massive Benchmark for Evaluating Instructed Retrieval\u003cbr\u003ePcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity\u003cbr\u003eBridging Local Details and Global Context in Text-Attributed Graphs\u003cbr\u003eLitSearch: A Retrieval Benchmark for Scientific Literature Search\u003cbr\u003eScaling Laws for Linear Complexity Language Models\u003cbr\u003eOne Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models\u003cbr\u003eClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures\u003cbr\u003eLLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement\u003cbr\u003eLink, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval\u003cbr\u003e... and 15 more","ImageInWords: Unlocking Hyper-Detailed Image Descriptions\u003cbr\u003eUniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation\u003cbr\u003eHELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding\u003cbr\u003eTag-grounded Visual Instruction Tuning with Retrieval Augmentation\u003cbr\u003eDoes Object Grounding Really Reduce Hallucination of Large Vision-Language Models?\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eHow Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?\u003cbr\u003eFiner: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models\u003cbr\u003eUOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models\u003cbr\u003eA Survey of AMR Applications\u003cbr\u003eTowards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\u003cbr\u003eResampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes\u003cbr\u003ePrecise Model Benchmarking with Only a Few Observations\u003cbr\u003eLeveraging Large Language Models for NLG Evaluation: Advances and Challenges\u003cbr\u003eThe Instinctive Bias: Spurious Images lead to Illusion in MLLMs\u003cbr\u003e... and 14 more","A Survey on In-context Learning\u003cbr\u003eModel Balancing Helps Low-data Training and Fine-tuning\u003cbr\u003eDo We Need Language-Specific Fact-Checking Models? The Case of Chinese\u003cbr\u003eA Generic Method for Fine-grained Category Discovery in Natural Language Texts\u003cbr\u003eChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context\u003cbr\u003eKnowledge-Centric Hallucination Detection\u003cbr\u003eToward Compositional Behavior in Neural Models: A Survey of Current Views\u003cbr\u003eIntegrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation\u003cbr\u003ePragmatic Norms Are All You Need \u2013 Why The Symbol Grounding Problem Does Not Apply to LLMs\u003cbr\u003eUnraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications\u003cbr\u003eTowards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models\u003cbr\u003eHeterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models\u003cbr\u003eIM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method\u003cbr\u003eInterpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions\u003cbr\u003eFill In The Gaps: Model Calibration and Generalization with Synthetic Data\u003cbr\u003e... and 13 more","Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments\u003cbr\u003eA User-Centric Multi-Intent Benchmark for Evaluating Large Language Models\u003cbr\u003eEvaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts\u003cbr\u003eChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context\u003cbr\u003eMAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration\u003cbr\u003ePARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data\u003cbr\u003eSplit and Merge: Aligning Position Biases in LLM-based Evaluators\u003cbr\u003eA Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations\u003cbr\u003eTowards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey\u003cbr\u003eFinding Blind Spots in Evaluator LLMs with Interpretable Checklists\u003cbr\u003eIs this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs\u003cbr\u003eAssessing and Verifying Task Utility in LLM-Powered Applications\u003cbr\u003eAn Open-Source Data Contamination Report for Large Language Models\u003cbr\u003eCan AI Relate: Testing Large Language Model Response for Mental Health Support\u003cbr\u003eA Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios\u003cbr\u003e... and 11 more","A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers\u003cbr\u003eDo We Need Language-Specific Fact-Checking Models? The Case of Chinese\u003cbr\u003eSTOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions\u003cbr\u003eNLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian\u003cbr\u003eChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context\u003cbr\u003eTowards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights\u003cbr\u003eVoices in a Crowd: Searching for Clusters of Unique Perspectives\u003cbr\u003eTowards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey\u003cbr\u003eMoral Foundations of Large Language Models\u003cbr\u003eDiscovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation\u003cbr\u003eThe Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models\u003cbr\u003eCan AI Relate: Testing Large Language Model Response for Mental Health Support\u003cbr\u003eJobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models\u003cbr\u003eDivine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models\u003cbr\u003eEvaluating Biases in Context-Dependent Sexual and Reproductive Health Questions\u003cbr\u003e... and 6 more","Mitigating the Alignment Tax of RLHF\u003cbr\u003eSeemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?\u003cbr\u003eRevealing the Parallel Multilingual Learning within Large Language Models\u003cbr\u003eLawBench: Benchmarking Legal Knowledge of Large Language Models\u003cbr\u003eMore Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation\u003cbr\u003eFAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition\u003cbr\u003eNull-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination\u003cbr\u003eShaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling\u003cbr\u003eDistractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation\u003cbr\u003eLayer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models\u003cbr\u003eLLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training\u003cbr\u003eAdaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations\u003cbr\u003eA linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks\u003cbr\u003eAMPO: Automatic Multi-Branched Prompt Optimization\u003cbr\u003eSCIDQA: A Deep Reading Comprehension Dataset over Scientific Papers\u003cbr\u003e... and 6 more","Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process\u003cbr\u003eSURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information\u003cbr\u003eAttribute or Abstain: Large Language Models as Long Document Assistants\u003cbr\u003eIs It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?\u003cbr\u003eUnveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism\u003cbr\u003ePcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity\u003cbr\u003eHiFT: A Hierarchical Full Parameter Fine-Tuning Strategy\u003cbr\u003eFuse to Forget: Bias Reduction and Selective Memorization through Model Fusion\u003cbr\u003eComputational Meme Understanding: A Survey\u003cbr\u003eAdversarial Text Generation using Large Language Models for Dementia Detection\u003cbr\u003eReformatted Alignment\u003cbr\u003eCategorial Grammar Supertagging via Large Language Models\u003cbr\u003eA Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios\u003cbr\u003eMMedAgent: Learning to Use Medical Tools with Multi-modal Agent\u003cbr\u003eRethinking Code Refinement: Learning to Judge Code Efficiency\u003cbr\u003e... and 6 more","ImageInWords: Unlocking Hyper-Detailed Image Descriptions\u003cbr\u003eExploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors\u003cbr\u003eAn Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification\u003cbr\u003eMuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning\u003cbr\u003eAn Audit on the Perspectives and Challenges of Hallucinations in NLP\u003cbr\u003eCareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation\u003cbr\u003eControlMath: Controllable Data Generation Promotes Math Generalist Models\u003cbr\u003eCross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing\u003cbr\u003eGeneralizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4\u003cbr\u003eSMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support\u003cbr\u003eTranslation of Multifaceted Data without Re-Training of Machine Translation Systems\u003cbr\u003eEvaluation of Question Answer Generation for Portuguese: Insights and Datasets\u003cbr\u003eA Study of Implicit Ranking Unfairness in Large Language Models\u003cbr\u003eREADME: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP\u003cbr\u003eAll You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification\u003cbr\u003e... and 5 more","Aligning Large Language Models with Diverse Political Viewpoints\u003cbr\u003eEnhancing Reinforcement Learning with Dense Rewards from Language Model Critic\u003cbr\u003eDetecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors\u003cbr\u003eOuroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding\u003cbr\u003eLeveraging Large Language Models for NLG Evaluation: Advances and Challenges\u003cbr\u003eCan We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?\u003cbr\u003eFFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping\u003cbr\u003eSemformer: Transformer Language Models with Semantic Planning\u003cbr\u003eDisordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts\u003cbr\u003eWalia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets\u003cbr\u003eExploring the Relationship between In-Context Learning and Instruction Tuning\u003cbr\u003eDivide and Conquer: Legal Concept-guided Criminal Court View Generation\u003cbr\u003eRoQLlama: A Lightweight Romanian Adapted Language Model\u003cbr\u003eALIGNSUM: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference\u003cbr\u003eLaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation\u003cbr\u003e... and 5 more","Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks\u003cbr\u003eExploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights\u003cbr\u003eFast Forwarding Low-Rank Training\u003cbr\u003eIs It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?\u003cbr\u003eCommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions\u003cbr\u003eText2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback\u003cbr\u003eCurriculum Consistency Learning for Conditional Sentence Generation\u003cbr\u003eHow Susceptible are Large Language Models to Ideological Manipulation?\u003cbr\u003eInstruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks\u003cbr\u003eSymbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization\u003cbr\u003eOptimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search\u003cbr\u003eData Diversity Matters for Robust Instruction Tuning\u003cbr\u003eScalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach\u003cbr\u003eDistilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning\u003cbr\u003eCantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues\u003cbr\u003e... and 4 more","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eRoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eAdvancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eEmpowering Multi-step Reasoning across Languages via Program-Aided Language Models\u003cbr\u003eTowards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models\u003cbr\u003eLarge Language Models Can Self-Correct with Key Condition Verification\u003cbr\u003eNull-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination\u003cbr\u003eOuroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding\u003cbr\u003eFirst Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning\u003cbr\u003eRe-Reading Improves Reasoning in Large Language Models\u003cbr\u003eMentor-KD: Making Small Language Models Better Multi-step Reasoners\u003cbr\u003eIs C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning\u003cbr\u003eApiQ: Finetuning of 2-Bit Quantized Large Language Model\u003cbr\u003e... and 4 more","RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning\u003cbr\u003eOn Training Data Influence of GPT Models\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eNLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian\u003cbr\u003eFROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models\u003cbr\u003ePerceptions of Linguistic Uncertainty by Language Models and Humans\u003cbr\u003eMediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations\u003cbr\u003eEncouraging Divergent Thinking in Large Language Models through Multi-Agent Debate\u003cbr\u003eApiQ: Finetuning of 2-Bit Quantized Large Language Model\u003cbr\u003eFAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding\u003cbr\u003eHead-wise Shareable Attention for Large Language Models\u003cbr\u003eBiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks\u003cbr\u003eLeveraging Grammar Induction for Language Understanding and Generation\u003cbr\u003eSelf-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages\u003cbr\u003eLaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation\u003cbr\u003e... and 4 more","Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection\u003cbr\u003eWhen Context Leads but Parametric Memory Follows in Large Language Models\u003cbr\u003eKnowledge-Centric Hallucination Detection\u003cbr\u003ePelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification\u003cbr\u003eCliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios\u003cbr\u003eDetecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors\u003cbr\u003eNull-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination\u003cbr\u003eSmall Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector\u003cbr\u003eCan LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators\u003cbr\u003eOn the Universal Truthfulness Hyperplane Inside LLMS\u003cbr\u003eEnhanced Hallucination Detection in Neural Machine Translation through Simple Detector Aggregation\u003cbr\u003eFactuality of Large Language Models: A Survey\u003cbr\u003eReference-free Hallucination Detection for Large Vision-Language Models\u003cbr\u003eDiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models\u003cbr\u003eMachine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models\u003cbr\u003e... and 4 more","Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models\u003cbr\u003eIs LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment\u003cbr\u003eExploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights\u003cbr\u003eInstruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks\u003cbr\u003eLink, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval\u003cbr\u003eEfficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models\u003cbr\u003eIFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning\u003cbr\u003eRetrieval-enriched zero-shot image classification in low-resource domains\u003cbr\u003eDiversity, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA\u003cbr\u003eTROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning\u003cbr\u003eDisentangling Questions from Query Generation for Task-Adaptive Retrieval\u003cbr\u003eInstance-Level Dynamic LoRAs Composition for Cross-Task Generalization\u003cbr\u003eVideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs\u003cbr\u003eNavigating Hallucinations for Reasoning of Unintentional Activities\u003cbr\u003eOptimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs\u003cbr\u003e... and 4 more","Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training\u003cbr\u003eADELIE: Aligning Large Language Models on Information Extraction\u003cbr\u003eBio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints\u003cbr\u003eSciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents\u003cbr\u003eGrasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction\u003cbr\u003eLarge Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark\u003cbr\u003eTopic-Oriented Open Relation Extraction with A Priori Seed Generation\u003cbr\u003eSRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework\u003cbr\u003eFAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding\u003cbr\u003eA Survey on Natural Language Counterfactual Generation\u003cbr\u003eA Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction\u003cbr\u003eEntity or Relation Embeddings? An Analysis of Encoding Strategies for Relation Extraction\u003cbr\u003eMedINST: Meta Dataset of Biomedical Instructions\u003cbr\u003eC-ICL: Contrastive In-context Learning for Information Extraction\u003cbr\u003eIs There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases\u003cbr\u003e... and 4 more","A Survey on In-context Learning\u003cbr\u003eTowards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models\u003cbr\u003eINDUCT-LEARN: Short Phrase Prompting with Instruction Induction\u003cbr\u003eLearning to Retrieve Iteratively for In-Context Learning\u003cbr\u003eBridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning\u003cbr\u003eExploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights\u003cbr\u003eStrengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations\u003cbr\u003eNuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data\u003cbr\u003eOpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation\u003cbr\u003eFewer is More: Boosting Math Reasoning with Reinforced Context Pruning\u003cbr\u003eShortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning\u003cbr\u003eInfiniPot: Infinite Context Processing on Memory-Constrained LLMs\u003cbr\u003eAttention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters\u003cbr\u003eKV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches\u003cbr\u003eDisentangling Questions from Query Generation for Task-Adaptive Retrieval\u003cbr\u003e... and 3 more","Hateful Word in Context Classification\u003cbr\u003eEyes Don't Lie: Subjective Hate Annotation and Detection with Gaze\u003cbr\u003eA Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers\u003cbr\u003eBridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning\u003cbr\u003eThe Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification\u003cbr\u003eUnlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization\u003cbr\u003eMitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment\u003cbr\u003eUnveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism\u003cbr\u003eRevisiting Supervised Contrastive Learning for Microblog Classification\u003cbr\u003eHate Personified: Investigating the role of LLMs in content moderation\u003cbr\u003eAnnotator-Centric Active Learning for Subjective NLP Tasks\u003cbr\u003eDelving into Qualitative Implications of Synthetic Data for Hate Speech Detection\u003cbr\u003ePREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection\u003cbr\u003eCost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation\u003cbr\u003eHateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models\u003cbr\u003e... and 2 more","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eAdvancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003eMODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning\u003cbr\u003eFrom Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning\u003cbr\u003eMentor-KD: Making Small Language Models Better Multi-step Reasoners\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality\u003cbr\u003eTask Oriented In-Domain Data Augmentation\u003cbr\u003eCan LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks\u003cbr\u003eMirror-Consistency: Harnessing Inconsistency in Majority Voting\u003cbr\u003eLaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation\u003cbr\u003eLLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement\u003cbr\u003eLoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning\u003cbr\u003e... and 2 more","\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models\u003cbr\u003eRSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework\u003cbr\u003eThe Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention\u003cbr\u003eLLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives\u003cbr\u003eSplit and Merge: Aligning Position Biases in LLM-based Evaluators\u003cbr\u003eBiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs\u003cbr\u003eApplying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation\u003cbr\u003eLocal Contrastive Editing of Gender Stereotypes\u003cbr\u003eOffsetBias: Leveraging Debiased Data for Tuning Evaluators\u003cbr\u003eCan AI Relate: Testing Large Language Model Response for Mental Health Support\u003cbr\u003eGiving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases\u003cbr\u003eCan LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric\u003cbr\u003eTowards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions\u003cbr\u003ePlatform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias\u003cbr\u003eCognitive Bias in Decision-Making with LLMs\u003cbr\u003e... and 1 more","Uncertainty in Language Models: Assessment through Rank-Calibration\u003cbr\u003eOn Training Data Influence of GPT Models\u003cbr\u003eIs Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering\u003cbr\u003eStyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eNLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian\u003cbr\u003eGenerative Models for Automatic Medical Decision Rule Extraction from Text\u003cbr\u003eOntologically Faithful Generation of Non-Player Character Dialogues\u003cbr\u003eContextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation\u003cbr\u003eMediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations\u003cbr\u003eEncouraging Divergent Thinking in Large Language Models through Multi-Agent Debate\u003cbr\u003eEvaluating Diversity in Automatic Poetry Generation\u003cbr\u003eConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees\u003cbr\u003eLaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation\u003cbr\u003eSODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs\u003cbr\u003e... and 1 more","Learning Planning-based Reasoning via Trajectories Collection and Process Reward Synthesizing\u003cbr\u003eLogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models\u003cbr\u003eScaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars\u003cbr\u003eRetrieved In-Context Principles from Previous Mistakes\u003cbr\u003eMETAREFLECTION: Learning Instructions for Language Agents using Past Reflections\u003cbr\u003ePuzzle Solving using Reasoning of Large Language Models: A Survey\u003cbr\u003eExploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems\u003cbr\u003eSymbolic Working Memory Enhances Language Models for Complex Rule Application\u003cbr\u003eMentor-KD: Making Small Language Models Better Multi-step Reasoners\u003cbr\u003eStep-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?\u003cbr\u003eMulti-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models\u003cbr\u003eMIBench: Evaluating Multimodal Large Language Models over Multiple Images\u003cbr\u003eAbstraction-of-Thought Makes Language Models Better Reasoners\u003cbr\u003eEconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning\u003cbr\u003eLearning to Plan by Updating Natural Language\u003cbr\u003e... and 1 more","Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence\u003cbr\u003eWPO: Enhancing RLHF with Weighted Preference Optimization\u003cbr\u003eOptimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning\u003cbr\u003eA Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors\u003cbr\u003eImproving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning\u003cbr\u003eDogeRM: Equipping Reward Models with Domain Knowledge through Model Merging\u003cbr\u003eGlobal Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents\u003cbr\u003eRethinking the Role of Proxy Rewards in Language Model Alignment\u003cbr\u003eFiltered Direct Preference Optimization\u003cbr\u003eReward Modeling Requires Automatic Adjustment Based on Data Quality\u003cbr\u003eSemi-Supervised Reward Modeling via Iterative Self-Training\u003cbr\u003eStep-level Value Preference Optimization for Mathematical Reasoning\u003cbr\u003eInverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models without Preference Data\u003cbr\u003eMargin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback\u003cbr\u003eDEFT: Distribution-guided Efficient Fine-Tuning for Human Alignment\u003cbr\u003e... and 1 more","Evaluating Readability and Faithfulness of Concept-based Explanations\u003cbr\u003eQUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models\u003cbr\u003ePTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL\u003cbr\u003eCOEVOL: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation\u003cbr\u003eUNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models\u003cbr\u003eCommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions\u003cbr\u003eOpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation\u003cbr\u003eA Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models\u003cbr\u003eIn-Context Former: Lightning-fast Compressing Context for Large Language Model\u003cbr\u003eEvaluating Moral Beliefs across LLMs through a Pluralistic Framework\u003cbr\u003eLlama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection\u003cbr\u003eLaCo: Large Language Model Pruning via Layer Collapse\u003cbr\u003eThink Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection\u003cbr\u003eBetter Alignment with Instruction Back-and-Forth Translation\u003cbr\u003eATQ: Activation Transformation for Weight-Activation Quantization of Large Language Models","RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning\u003cbr\u003eInterpretability-based Tailored Knowledge Editing in Transformers\u003cbr\u003eEVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation\u003cbr\u003e\u003eWhy Does New Knowledge Create Messy Ripple Effects in LLMs?\u003cbr\u003eCommonsense Knowledge Editing Based on Free-Text in LLMs\u003cbr\u003eAKEW: Assessing Knowledge Editing in the Wild\u003cbr\u003eRebuilding ROME : Resolving Model Collapse during Sequential Model Editing\u003cbr\u003eEditing Conceptual Knowledge for Large Language Models\u003cbr\u003eKnowledge Editing in Language Models via Adapted Direct Preference Optimization\u003cbr\u003eRIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning\u003cbr\u003eEditing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models\u003cbr\u003eAdaptive Token Biaser: Knowledge Editing via Biasing Key Entities\u003cbr\u003eCross-Lingual Multi-Hop Knowledge Editing\u003cbr\u003eUpdating Large Language Models' Memories with Time Constraints\u003cbr\u003eLLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments","Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems\u003cbr\u003eOntologically Faithful Generation of Non-Player Character Dialogues\u003cbr\u003eOptimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning\u003cbr\u003eParaphrase Types Elicit Prompt Engineering Capabilities\u003cbr\u003eBeyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models\u003cbr\u003eTransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities\u003cbr\u003eHow to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective\u003cbr\u003eLeveraging Large Language Models for NLG Evaluation: Advances and Challenges\u003cbr\u003eGDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets\u003cbr\u003eSMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support\u003cbr\u003eDiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models\u003cbr\u003eMixed-Session Conversation with Egocentric Memory\u003cbr\u003eSecuring Multi-turn Conversational Language Models From Distributed Backdoor Triggers\u003cbr\u003eCACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory\u003cbr\u003eTRIP NEGOTIATOR: A Travel Persona-aware Reinforced Dialogue Generation Model for Personalized Integrative Negotiation in Tourism","NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning\u003cbr\u003eAutoregressive Pre-Training on Pixels and Texts\u003cbr\u003eUnraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications\u003cbr\u003eLarge Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark\u003cbr\u003eLLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks\u003cbr\u003eConnecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game\u003cbr\u003eMalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language\u003cbr\u003eThe Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance\u003cbr\u003eEnhancing Agent Learning through World Dynamics Modeling\u003cbr\u003eMUSCLE: A Model Update Strategy for Compatible LLM Evolution\u003cbr\u003eLarge Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation\u003cbr\u003eChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline\u003cbr\u003eMoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition\u003cbr\u003eSQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models","BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering\u003cbr\u003eREAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering\u003cbr\u003eLarge Language Models Can Self-Correct with Key Condition Verification\u003cbr\u003eWhere am I? Large Language Models Wandering between Semantics and Structures in Long Contexts\u003cbr\u003eModel Editing Harms General Abilities of Large Language Models: Regularization to the Rescue\u003cbr\u003eImproving Zero-shot LLM Re-Ranker with Risk Minimization\u003cbr\u003eRE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation\u003cbr\u003eRaFe: Ranking Feedback Improves Query Rewriting for RAG\u003cbr\u003eChain-of-Rewrite: Aligning Question and Documents for Open-Domain Question Answering\u003cbr\u003eAdaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts\u003cbr\u003eEvidence Retrieval for Fact Verification using Multi-stage Reranking\u003cbr\u003eMechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations\u003cbr\u003eQPaug: Question and Passage Augmentation for Open-Domain Question Answering of LLMs\u003cbr\u003eExploring Hint Generation Approaches in Open-Domain Question Answering","AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation\u003cbr\u003ePerformance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale\u003cbr\u003eMTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval\u003cbr\u003eKnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server\u003cbr\u003eFIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation\u003cbr\u003eOptimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach\u003cbr\u003eImprove Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation\u003cbr\u003eDual-Space Knowledge Distillation for Large Language Models\u003cbr\u003ePAIRDISTILL: Pairwise Relevance Distillation for Dense Retrieval\u003cbr\u003exCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics\u003cbr\u003eMulti-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation\u003cbr\u003eDistilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning\u003cbr\u003ePromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning\u003cbr\u003eTemperature-Centric Investigation of Speculative Decoding with Knowledge Distillation","Take Off the Training Wheels! Progressive In-Context Learning for Effective Alignment\u003cbr\u003eContrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion\u003cbr\u003eNegating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization\u003cbr\u003eReward Difference Optimization For Sample Reweighting In Offline RLHF\u003cbr\u003eSelf-Evolution Fine-Tuning for Policy Optimization\u003cbr\u003ePURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness\u003cbr\u003eTS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models\u003cbr\u003eOn Diversified Preferences of Large Language Model Alignment\u003cbr\u003eChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline\u003cbr\u003eEnhancing Alignment using Curriculum Learning & Ranked Preferences\u003cbr\u003eModel Merging and Safety Alignment: One Bad Model Spoils the Bunch\u003cbr\u003eAligners: Decoupling LLMs and Alignment\u003cbr\u003eBeyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks\u003cbr\u003eOn the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization","Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects\u003cbr\u003eSEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eOn Mitigating Performance Disparities in Multilingual Speech Recognition\u003cbr\u003eOptimized Speculative Sampling for GPU Hardware Accelerators\u003cbr\u003eAdvancing Test-Time Adaptation in Wild Acoustic Test Settings\u003cbr\u003eMuting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models\u003cbr\u003eTask Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition\u003cbr\u003eUnveiling the Role of Pretraining in Direct Speech Translation\u003cbr\u003eInterventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding\u003cbr\u003eAre Modern Neural ASR Architectures Robust for Polysynthetic Languages?\u003cbr\u003eWavLLM: Towards Robust and Adaptive Speech Large Language Model\u003cbr\u003eBeyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models\u003cbr\u003eModeling Gender and Dialect Bias in Automatic Speech Recognition\u003cbr\u003eFast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper","SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eUniversal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning\u003cbr\u003eRevisiting Supervised Contrastive Learning for Microblog Classification\u003cbr\u003eCorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs\u003cbr\u003eSYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation\u003cbr\u003eMultilingual Topic Classification in X: Dataset and Analysis\u003cbr\u003eCoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage\u003cbr\u003eTransfer Learning for Text Classification via Model Risk Analysis\u003cbr\u003eGeneralists vs. Specialists: Evaluating Large Language Models for Urdu\u003cbr\u003eIn-Context Learning with Iterative Demonstration Selection\u003cbr\u003eDual-Phase Accelerated Prompt Optimization\u003cbr\u003ePrompt-Based Bias Calibration for Better Zero\u002fFew-Shot Learning of Language Models\u003cbr\u003eLexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons\u003cbr\u003eInference and Verbalization Functions During In-Context Learning","Prompts have evil twins\u003cbr\u003eTracking the perspectives of interacting language models\u003cbr\u003ePersonas as a Way to Model Truthfulness in Language Models\u003cbr\u003eToken Erasure as a Footprint of Implicit Vocabulary Items in LLMs\u003cbr\u003eBreaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models\u003cbr\u003eEncourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective\u003cbr\u003eFIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation\u003cbr\u003eCONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models\u003cbr\u003eLearning to Route for Dynamic Adapter Composition in Continual Learning with Language Models\u003cbr\u003eImproving LLM Attributions with Randomized Path-Integration\u003cbr\u003eMobileQuant: Mobile-friendly Quantization for On-device Language Models\u003cbr\u003eA Recipe to Train Powerful Romanian LLMs with English Instructions\u003cbr\u003eCapturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data","Mitigating the Alignment Tax of RLHF\u003cbr\u003eNLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian\u003cbr\u003eA Thorough Examination of Decoding Methods in the Era of LLMs\u003cbr\u003eUnlocking Memorization in Large Language Models with Dynamic Soft Prompting\u003cbr\u003eAn Analysis and Mitigation of the Reversal Curse\u003cbr\u003eLayer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models\u003cbr\u003eLongAlign: A Recipe for Long Context Alignment of Large Language Models\u003cbr\u003eAC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models\u003cbr\u003eGeneralists vs. Specialists: Evaluating Large Language Models for Urdu\u003cbr\u003eMedINST: Meta Dataset of Biomedical Instructions\u003cbr\u003eA Recipe to Train Powerful Romanian LLMs with English Instructions\u003cbr\u003eHop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models","Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\u003cbr\u003eFast Forwarding Low-Rank Training\u003cbr\u003eBreaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models\u003cbr\u003eLarge Language Models Can Be Contextual Privacy Protection Learners\u003cbr\u003eMIXTURE-OF-SKILLS: Learning to Optimize Data Usage for Fine-Tuning Large Language Models\u003cbr\u003eGRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients\u003cbr\u003eOn the Empirical Complexity of Reasoning and Planning in LLMs\u003cbr\u003ePrivate prediction for large-scale synthetic text generation\u003cbr\u003eStep-level Value Preference Optimization for Mathematical Reasoning\u003cbr\u003eLeveraging Web-Crawled Data for High-Quality Fine-Tuning\u003cbr\u003eTuringQ: Benchmarking AI Comprehension in Theory of Computation\u003cbr\u003eQEFT: Quantization for Efficient Fine-Tuning of LLMs","Instruction Pre-Training: Language Models are Supervised Multitask Learners\u003cbr\u003eControlMath: Controllable Data Generation Promotes Math Generalist Models\u003cbr\u003eMAIR: A Massive Benchmark for Evaluating Instructed Retrieval\u003cbr\u003eData Contamination Can Cross Language Barriers\u003cbr\u003eInstruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks\u003cbr\u003eInvestigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks\u003cbr\u003ePREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection\u003cbr\u003eKnowledge Graph Enhanced Large Language Model Editing\u003cbr\u003eCan LLM Graph Reasoning Generalize beyond Pattern Memorization?\u003cbr\u003eEditing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models\u003cbr\u003eFrom Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models\u003cbr\u003eVarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation","Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models\u003cbr\u003eOmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer\u003cbr\u003eFineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension\u003cbr\u003eMultimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model\u003cbr\u003eWhiteboard-of-Thought: Thinking Step-by-Step Across Modalities\u003cbr\u003eTraining-free Deep Concept Injection Enables Language Models for Video Question Answering\u003cbr\u003eMMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems\u003cbr\u003eCONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models\u003cbr\u003ePlot Twist: Multimodal Models Don't Comprehend Simple Chart Details\u003cbr\u003eLarge Language Models Are Challenged by Habitat-Centered Reasoning\u003cbr\u003eKnowledge-Aware Reasoning over Multimodal Semi-structured Tables\u003cbr\u003eTowards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks","Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?\u003cbr\u003eLM\u00b2: A Simple Society of Language Models Solves Complex Reasoning\u003cbr\u003eCasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures\u003cbr\u003eAMPO: Automatic Multi-Branched Prompt Optimization\u003cbr\u003eFew shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering\u003cbr\u003eAugmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering\u003cbr\u003eEnhancing Healthcare LLM Trust with Atypical Presentations Recalibration\u003cbr\u003eMultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate\u003cbr\u003eMEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation\u003cbr\u003eLanguage Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks\u003cbr\u003eLarge Language Models are In-context Teachers for Knowledge Reasoning\u003cbr\u003eMedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures","ImageInWords: Unlocking Hyper-Detailed Image Descriptions\u003cbr\u003ePre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation\u003cbr\u003eWords Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation\u003cbr\u003eEmpowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training\u003cbr\u003eThe Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention\u003cbr\u003eRe-ReST: Reflection-Reinforced Self-Training for Language Agents\u003cbr\u003eAltogether: Image Captioning via Re-aligning Alt-text\u003cbr\u003eLearning from Mistakes: Iterative Prompt Relabeling for Text-to-Image Diffusion Model Training\u003cbr\u003ePrecision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model\u003cbr\u003eRepairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement\u003cbr\u003eAdversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation","Scaling Properties of Speech Language Models\u003cbr\u003eEH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning\u003cbr\u003eMulti-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges\u003cbr\u003eMOSEL: Inference Serving Using Dynamic Modality Selection\u003cbr\u003eWhat is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations\u003cbr\u003e950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages\u003cbr\u003eVHASR: A Multimodal Speech Recognition System With Vision Hotwords\u003cbr\u003eBayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities\u003cbr\u003eTwists, Humps, and Pebbles: Multilingual Speech Recognition Models Exhibit Gender Performance Gaps\u003cbr\u003eCasablanca: Data and Models for Multidialectal Arabic Speech Recognition\u003cbr\u003ePolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition","LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models\u003cbr\u003eWhat is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations\u003cbr\u003eAKEW: Assessing Knowledge Editing in the Wild\u003cbr\u003eTowards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis\u003cbr\u003eCreative and Context-Aware Translation of East Asian Idioms with GPT-4\u003cbr\u003eA LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation\u003cbr\u003eNot (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition\u003cbr\u003eTuringQ: Benchmarking AI Comprehension in Theory of Computation\u003cbr\u003eBLADE: Benchmarking Language Model Agents for Data-Driven Science\u003cbr\u003eFactcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers\u003cbr\u003eKnowledge-Centric Templatic Views of Documents","Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training\u003cbr\u003eADELIE: Aligning Large Language Models on Information Extraction\u003cbr\u003eExplicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments\u003cbr\u003eSPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness\u003cbr\u003eGeneral Collaborative Framework between Large Language Model and Experts for Universal Information Extraction\u003cbr\u003eDocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction\u003cbr\u003eEmploying Glyphic Information for Chinese Event Extraction with Vision-Language Model\u003cbr\u003eAC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models\u003cbr\u003eEvent-Keyed Summarization\u003cbr\u003eMedINST: Meta Dataset of Biomedical Instructions\u003cbr\u003eDebate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction","FuseGen: PLM Fusion for Data-generation based Zero-shot Learning\u003cbr\u003eSafely Learning with Private Data: A Federated Learning Framework for Large Language Model\u003cbr\u003eUnveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism\u003cbr\u003eCOGEN: Learning from Feedback with Coupled Comprehension and Generation\u003cbr\u003eHiFT: A Hierarchical Full Parameter Fine-Tuning Strategy\u003cbr\u003eFuse to Forget: Bias Reduction and Selective Memorization through Model Fusion\u003cbr\u003eDynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models\u003cbr\u003eReformatted Alignment\u003cbr\u003eBSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain\u003cbr\u003eAre LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues\u003cbr\u003eModeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas","A Survey of AMR Applications\u003cbr\u003eExploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights\u003cbr\u003eText-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction\u003cbr\u003eModeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding\u003cbr\u003eParaphrase Types Elicit Prompt Engineering Capabilities\u003cbr\u003eFINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents\u003cbr\u003eTKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs\u003cbr\u003eDe-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP\u003cbr\u003eWhen and Where Did It Happen? An Encoder-Decoder Model to Identify Scenario Context\u003cbr\u003eSchema-Driven Information Extraction from Heterogeneous Tables\u003cbr\u003eSciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement","A Thorough Examination of Decoding Methods in the Era of LLMs\u003cbr\u003eI Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses\u003cbr\u003eUnraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications\u003cbr\u003eAn Analysis and Mitigation of the Reversal Curse\u003cbr\u003eTools Fail: Detecting Silent Errors in Faulty Tools\u003cbr\u003eSmall Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector\u003cbr\u003eLLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks\u003cbr\u003eAssessing and Verifying Task Utility in LLM-Powered Applications\u003cbr\u003eMulti-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision\u003cbr\u003eChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline\u003cbr\u003eSolving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?","LIONS: An Empirically Optimized Approach to Align Language Models\u003cbr\u003eReverse-Engineering the Reader\u003cbr\u003eImproving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning\u003cbr\u003eCOMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities\u003cbr\u003eRethinking the Role of Proxy Rewards in Language Model Alignment\u003cbr\u003eEnhancing Language Model Alignment: A Confidence-Based Approach to Label Smoothing\u003cbr\u003eFiltered Direct Preference Optimization\u003cbr\u003eOptimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search\u003cbr\u003eKnowledge Editing in Language Models via Adapted Direct Preference Optimization\u003cbr\u003eEvolutionary Contrastive Distillation for Language Model Alignment\u003cbr\u003eFACTALIGN: Long-form Factuality Alignment of Large Language Models","Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eAdvancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003ePython is Not Always the Best Choice: Embracing Multilingual Program of Thoughts\u003cbr\u003eNash CoT: Multi-Path Inference with Preference Equilibrium\u003cbr\u003eReasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies\u003cbr\u003eCan LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks\u003cbr\u003eAGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories\u003cbr\u003eDivide-or-Conquer? Which Part Should You Distill Your LLM?\u003cbr\u003eSkills-in-Context: Unlocking Compositionality in Large Language Models","AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning\u003cbr\u003eOn Training Data Influence of GPT Models\u003cbr\u003eUnveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement\u003cbr\u003eWhen Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models\u003cbr\u003eFisher Information-based Efficient Curriculum Federated Learning with Large Language Models\u003cbr\u003eWhich Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?\u003cbr\u003eInitialization of Large Language Models via Reparameterization to Mitigate Loss Spikes\u003cbr\u003eIntermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models\u003cbr\u003eSkills-in-Context: Unlocking Compositionality in Large Language Models\u003cbr\u003eA Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune","Model Balancing Helps Low-data Training and Fine-tuning\u003cbr\u003ePixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models\u003cbr\u003eUnveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement\u003cbr\u003eSparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers\u003cbr\u003eIM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality\u003cbr\u003eMixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules\u003cbr\u003eLeveraging Grammar Induction for Language Understanding and Generation\u003cbr\u003eIntermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models\u003cbr\u003eBIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models","HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding\u003cbr\u003eWhispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models\u003cbr\u003eWord Alignment as Preference for Machine Translation\u003cbr\u003eAnalysis of Plan-based Retrieval for Grounded Text Generation\u003cbr\u003eMitigating Open-Vocabulary Caption Hallucinations\u003cbr\u003eSH2: Self-Highlighted Hesitation Helps You Decode More Truthfully\u003cbr\u003eMechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations\u003cbr\u003eWhat if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models\u003cbr\u003eStructured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations\u003cbr\u003eDial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning","Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models\u003cbr\u003eStepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors\u003cbr\u003eFewer is More: Boosting Math Reasoning with Reinforced Context Pruning\u003cbr\u003eSCIAGENT: Tool-augmented Language Models for Scientific Reasoning\u003cbr\u003eCoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage\u003cbr\u003eCan LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks\u003cbr\u003eMUSCLE: A Model Update Strategy for Compatible LLM Evolution\u003cbr\u003eUnlocking the Potential of Model Merging for Low-Resource Languages\u003cbr\u003eSQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models\u003cbr\u003eMiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning","Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?\u003cbr\u003eFirst Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning\u003cbr\u003eAdaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations\u003cbr\u003eReasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies\u003cbr\u003eAn Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models\u003cbr\u003eDetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?\u003cbr\u003eTRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation\u003cbr\u003eCross-Lingual Multi-Hop Knowledge Editing\u003cbr\u003eGraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models\u003cbr\u003eQuantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective","Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese\u003cbr\u003eAdvancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss\u003cbr\u003ePcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity\u003cbr\u003eScaling Sentence Embeddings with Large Language Models\u003cbr\u003eVariational Language Concepts for Interpreting Foundation Language Models\u003cbr\u003eHit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention\u003cbr\u003eAre ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity\u003cbr\u003eMEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation\u003cbr\u003eRegression-aware Inference with LLMs\u003cbr\u003eRepresentational Isomorphism and Alignment of Multilingual Large Language Models","PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study\u003cbr\u003eNoise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature\u003cbr\u003eAutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments\u003cbr\u003eLLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement\u003cbr\u003eLLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement\u003cbr\u003eUnsupervised Hierarchical Topic Modeling via Anchor Word Clustering and Path Guidance\u003cbr\u003eNeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization\u003cbr\u003ePlatform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias\u003cbr\u003eTopic Modeling: Contextual Token Embeddings Are All You Need\u003cbr\u003eEnhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs","QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models\u003cbr\u003eVPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models\u003cbr\u003exCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics\u003cbr\u003eMobileQuant: Mobile-friendly Quantization for On-device Language Models\u003cbr\u003ePromoting Data and Model Privacy in Federated Learning through Quantized LoRA\u003cbr\u003eOptimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs\u003cbr\u003eExploring Quantization for Efficient Pre-Training of Transformer Language Models\u003cbr\u003eQEFT: Quantization for Efficient Fine-Tuning of LLMs\u003cbr\u003eHow Does Quantization Affect Multilingual LLMs?\u003cbr\u003eATQ: Activation Transformation for Weight-Activation Quantization of Large Language Models","Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting\u003cbr\u003eVideo-LLaVA: Learning United Visual Representation by Alignment Before Projection\u003cbr\u003eEncoding and Controlling Global Semantics for Long-form Video Question Answering\u003cbr\u003eTraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering\u003cbr\u003eEfficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge\u003cbr\u003eTV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning\u003cbr\u003eTraining-free Deep Concept Injection Enables Language Models for Video Question Answering\u003cbr\u003eEnhancing Temporal Modeling of Video LLMs via Time Gating\u003cbr\u003eExploring Question Guidance and Answer Calibration for Visually Grounded Video Question Answering\u003cbr\u003eALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding","MQuinE: a Cure for \"Z-paradox\" in Knowledge Graph Embedding\u003cbr\u003eMoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion\u003cbr\u003eATAP: Automatic Template-Augmented Commonsense Knowledge Graph Completion via Pre-Trained Language Models\u003cbr\u003eCan Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction\u003cbr\u003ePredictive Multiplicity of Knowledge Graph Embeddings in Link Prediction\u003cbr\u003eTemporal Fact Reasoning over Hyper-Relational Knowledge Graphs\u003cbr\u003eLet's Ask GNN: Empowering Large Language Model for Graph In-Context Learning\u003cbr\u003eOpenGraph: Towards Open Graph Foundation Models\u003cbr\u003eLlamipa: An Incremental Discourse Parser\u003cbr\u003eBlock-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding","Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding\u003cbr\u003eFIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation\u003cbr\u003eCONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models\u003cbr\u003eCalibrating Language Models with Adaptive Temperature Scaling\u003cbr\u003eReconfidencing LLMs from the Grouping Loss Perspective\u003cbr\u003eEnhancing Healthcare LLM Trust with Atypical Presentations Recalibration\u003cbr\u003eSelf-Consistency Boosts Calibration for Math Reasoning\u003cbr\u003eDistance-aware Calibration for Pre-trained Language Models\u003cbr\u003eCalibrating Long-form Generations from Large Language Models\u003cbr\u003eUncertainty Calibration for Tool-Using Language Agents","A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers\u003cbr\u003eVisual Prompting in LLMs for Enhancing Emotion Recognition\u003cbr\u003eTowards Robust Speech Representation Learning for Thousands of Languages\u003cbr\u003eSelf-Powered LLM Modality Expansion for Large Speech-Text Models\u003cbr\u003eRevisiting Supervised Contrastive Learning for Microblog Classification\u003cbr\u003ePALM: Few-Shot Prompt Learning for Audio Language Models\u003cbr\u003eEmotion Granularity from Text: An Aggregate-Level Indicator of Mental Health\u003cbr\u003eEmosical: An Emotion-Annotated Musical Theatre Dataset\u003cbr\u003eWavLLM: Towards Robust and Adaptive Speech Large Language Model","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eFrom Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning\u003cbr\u003eMentor-KD: Making Small Language Models Better Multi-step Reasoners\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality\u003cbr\u003eTask Oriented In-Domain Data Augmentation\u003cbr\u003eMirror-Consistency: Harnessing Inconsistency in Majority Voting","QUDSELECT: Selective Decoding for Questions Under Discussion Parsing\u003cbr\u003eParaphrase Types Elicit Prompt Engineering Capabilities\u003cbr\u003eMeasuring the Robustness of NLP Models to Domain Shifts\u003cbr\u003eTranslation of Multifaceted Data without Re-Training of Machine Translation Systems\u003cbr\u003eLearning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain\u003cbr\u003eEvaluation of Question Answer Generation for Portuguese: Insights and Datasets\u003cbr\u003eLearning to Ask Denotative and Connotative Questions for Knowledge-based VQA\u003cbr\u003eEnable Fast Sampling for Seq2Seq Text Diffusion\u003cbr\u003eReference-based Metrics Disprove Themselves in Question Generation","DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models\u003cbr\u003eEnhancing Systematic Decompositional Natural Language Inference Using Informal Logic\u003cbr\u003eParaphrase Types Elicit Prompt Engineering Capabilities\u003cbr\u003eRepMatch: Quantifying Cross-Instance Similarities in Representation Space\u003cbr\u003eOpen-world Multi-label Text Classification with Extremely Weak Supervision\u003cbr\u003eMitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging\u003cbr\u003eMedINST: Meta Dataset of Biomedical Instructions\u003cbr\u003eVariational Language Concepts for Interpreting Foundation Language Models\u003cbr\u003eAre ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity","Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method\u003cbr\u003eNLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian\u003cbr\u003eCan LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric\u003cbr\u003eModeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas\u003cbr\u003eBadFair: Backdoored Fairness Attacks with Group-conditioned Triggers\u003cbr\u003eHow to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models\u003cbr\u003eAttribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification\u003cbr\u003eBeyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression\u003cbr\u003eCROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack","\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models\u003cbr\u003eNormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization\u003cbr\u003eMolecular Facts: Desiderata for Decontextualization in LLM Fact Verification\u003cbr\u003ePROTRIX: Building Models for Planning and Reasoning over Tables with Sentence Context\u003cbr\u003eEvidence Retrieval for Fact Verification using Multi-stage Reranking\u003cbr\u003eDyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs\u003cbr\u003eHow Entangled is Factuality and Deception in German?\u003cbr\u003eClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs\u003cbr\u003eZero-Shot Fact Verification via Natural Logic and Large Language Models","UNIGEN: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation\u003cbr\u003eAn Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification\u003cbr\u003eLLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History\u003cbr\u003eAMPO: Automatic Multi-Branched Prompt Optimization\u003cbr\u003eRevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference\u003cbr\u003eSCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models\u003cbr\u003eBadFair: Backdoored Fairness Attacks with Group-conditioned Triggers\u003cbr\u003eDual-Phase Accelerated Prompt Optimization","COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds\u003cbr\u003eClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures\u003cbr\u003eEmosical: An Emotion-Annotated Musical Theatre Dataset\u003cbr\u003eForecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling\u003cbr\u003eFrom Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues\u003cbr\u003eCACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory\u003cbr\u003eARTS: Assessing Readability & Text Simplicity\u003cbr\u003eCoCoHD: Congress Committee Hearing Dataset","Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment\u003cbr\u003eMetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic\u003cbr\u003eSelf-Refine Instruction-Tuning for Aligning Reasoning in Language Models\u003cbr\u003eNLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian\u003cbr\u003eGetting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection\u003cbr\u003eHit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention\u003cbr\u003eWhere Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing\u003cbr\u003eFine-Tuning Language Models on Multiple Datasets for Citation Intention Classification","ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws\u003cbr\u003eParaphrase Types Elicit Prompt Engineering Capabilities\u003cbr\u003eMajor Entity Identification: A Generalizable Alternative to Coreference Resolution\u003cbr\u003eLayer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models\u003cbr\u003eAre LLMs Good Annotators for Discourse-level Event Relation Extraction?\u003cbr\u003eMedINST: Meta Dataset of Biomedical Instructions\u003cbr\u003eHit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention\u003cbr\u003eEvaluating Differentially Private Synthetic Data Generation in High-Stakes Domains","SEEKR: Selective Attention-Guided Knowledge Retention for Continual Learning of Large Language Models\u003cbr\u003eEmpowering Large Language Model for Continual Video Question Answering with Collaborative Prompting\u003cbr\u003eLearning to Route for Dynamic Adapter Composition in Continual Learning with Language Models\u003cbr\u003eRevisiting Catastrophic Forgetting in Large Language Model Tuning\u003cbr\u003eUnlocking Continual Learning Abilities in Language Models\u003cbr\u003eICL: Iterative Continual Learning for Multi-domain Neural Machine Translation\u003cbr\u003eGradient Localization Improves Lifelong Pretraining of Language Models\u003cbr\u003eMitigating Catastrophic Forgetting in Language Transfer via Model Merging","PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL\u003cbr\u003eMiddleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments\u003cbr\u003eBayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities\u003cbr\u003eImproving Demonstration Diversity by Human-Free Fusing for Text-to-SQL\u003cbr\u003eSYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA\u003cbr\u003eLearning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL\u003cbr\u003eDTS-SQL: Decomposed Text-to-SQL with Small Large Language Models\u003cbr\u003eTAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning","Bayesian Calibration of Win Rate Estimation with LLM Evaluators\u003cbr\u003eThemis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability\u003cbr\u003eLeveraging Large Language Models for NLG Evaluation: Advances and Challenges\u003cbr\u003eMeasuring Psychological Depth in Language Models\u003cbr\u003eWalia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets\u003cbr\u003eBeyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models\u003cbr\u003eSWAG: Storytelling With Action Guidance\u003cbr\u003eExtrinsic Evaluation of Cultural Competence in Large Language Models","Advancing Test-Time Adaptation in Wild Acoustic Test Settings\u003cbr\u003eTask Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition\u003cbr\u003eDomain adapted machine translation: What does catastrophic forgetting forget and why?\u003cbr\u003eGeneration with Dynamic Vocabulary\u003cbr\u003eAdaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?\u003cbr\u003eUnsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts\u003cbr\u003eA Survey on Natural Language Counterfactual Generation\u003cbr\u003eTogether We Can: Multilingual Automatic Post-Editing for Low-Resource Languages","Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners\u003cbr\u003eCoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage\u003cbr\u003eALVIN: Active Learning Via INterpolation\u003cbr\u003eMeasuring the Robustness of NLP Models to Domain Shifts\u003cbr\u003eA Survey on Natural Language Counterfactual Generation\u003cbr\u003eStablePT: Towards Stable Prompting for Few-shot Learning via Input Separation\u003cbr\u003eThink Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection\u003cbr\u003eLLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study","Consecutive Batch Model Editing with HooK Layers\u003cbr\u003eOn the Robustness of Editing Large Language Models\u003cbr\u003eLocal Contrastive Editing of Gender Stereotypes\u003cbr\u003eRebuilding ROME : Resolving Model Collapse during Sequential Model Editing\u003cbr\u003eKnowledge Graph Enhanced Large Language Model Editing\u003cbr\u003eThe Fall of ROME: Understanding the Collapse of LLMs in Model Editing\u003cbr\u003eBetter Call SAUL: Fluent and Consistent Language Model Editing with Generation Regularization\u003cbr\u003eA Unified Framework for Model Editing","An Experimental Analysis on Evaluating Patent Citations\u003cbr\u003eTROTR: A Framework for Evaluating the Recontextualization of Text\u003cbr\u003eStill Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis\u003cbr\u003eMulti-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models\u003cbr\u003eGraph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification\u003cbr\u003eESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases\u003cbr\u003eThe Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eAdvancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eMentor-KD: Making Small Language Models Better Multi-step Reasoners\u003cbr\u003eMirror-Consistency: Harnessing Inconsistency in Majority Voting\u003cbr\u003eMaking Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning","What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs\u003cbr\u003eLayer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models\u003cbr\u003eRevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference\u003cbr\u003eALVIN: Active Learning Via INterpolation\u003cbr\u003eMeasuring and Improving Attentiveness to Partial Inputs with Counterfactuals\u003cbr\u003eHit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention\u003cbr\u003eLoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters","AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning\u003cbr\u003eUnveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement\u003cbr\u003eFisher Information-based Efficient Curriculum Federated Learning with Large Language Models\u003cbr\u003eWhich Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?\u003cbr\u003eIntermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models\u003cbr\u003eFine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation\u003cbr\u003eA Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune","AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning\u003cbr\u003eUnveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement\u003cbr\u003eWhen Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models\u003cbr\u003eWhich Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?\u003cbr\u003eIntermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models\u003cbr\u003eFine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation\u003cbr\u003eA Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune","AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning\u003cbr\u003eOn Training Data Influence of GPT Models\u003cbr\u003eWhen Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models\u003cbr\u003eFisher Information-based Efficient Curriculum Federated Learning with Large Language Models\u003cbr\u003eCHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification\u003cbr\u003eInitialization of Large Language Models via Reparameterization to Mitigate Loss Spikes\u003cbr\u003eDLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model","A Survey on In-context Learning\u003cbr\u003eMoral Foundations of Large Language Models\u003cbr\u003eAMPO: Automatic Multi-Branched Prompt Optimization\u003cbr\u003eThe Death and Life of Great Prompts: Analyzing the Evolution of LLM Prompts from the Structural Perspective\u003cbr\u003eFew shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering\u003cbr\u003eCreative and Context-Aware Translation of East Asian Idioms with GPT-4\u003cbr\u003eCan't Remember Details in Long Documents? You Need Some R&R","AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents\u003cbr\u003eHumans or LLMs as the Judge? A Study on Judgement Bias\u003cbr\u003eStatistical Uncertainty in Word Embeddings: GloVe-V\u003cbr\u003eHate Personified: Investigating the role of LLMs in content moderation\u003cbr\u003eFrom Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment\u003cbr\u003eWho is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models\u003cbr\u003eModeling Gender and Dialect Bias in Automatic Speech Recognition","Model Balancing Helps Low-data Training and Fine-tuning\u003cbr\u003eSafely Learning with Private Data: A Federated Learning Framework for Large Language Model\u003cbr\u003eTEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models\u003cbr\u003eTurn Waste into Worth: Rectifying Top-k Router of MoE\u003cbr\u003eInitialization of Large Language Models via Reparameterization to Mitigate Loss Spikes\u003cbr\u003eBIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models\u003cbr\u003eLoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning","CMD: a framework for Context-aware Model self-Detoxification\u003cbr\u003eLarge Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark\u003cbr\u003eIntrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis\u003cbr\u003eMake Large Language Model a Better Ranker\u003cbr\u003eBreaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling\u003cbr\u003eMoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition\u003cbr\u003eEigen Attention: Attention in Low-Rank Space for KV Cache Compression","GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eAdvancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003eLarge Language Models Can Self-Correct with Key Condition Verification\u003cbr\u003eNull-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination\u003cbr\u003eRe-Reading Improves Reasoning in Large Language Models\u003cbr\u003eApiQ: Finetuning of 2-Bit Quantized Large Language Model\u003cbr\u003eMirror-Consistency: Harnessing Inconsistency in Majority Voting","Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models\u003cbr\u003eIf CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions\u003cbr\u003eVision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification\u003cbr\u003eRetrieval-enriched zero-shot image classification in low-resource domains\u003cbr\u003eUnveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories\u003cbr\u003eText2Model: Text-based Model Induction for Zero-shot Image Classification\u003cbr\u003eMed-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models","Advancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003eVLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment\u003cbr\u003eWhat are the Generator Preferences for End-to-end Task-Oriented Dialog System?\u003cbr\u003eModeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation\u003cbr\u003eStep-level Value Preference Optimization for Mathematical Reasoning\u003cbr\u003eTS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models\u003cbr\u003eInterpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts","QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios\u003cbr\u003eLearning to Retrieve Iteratively for In-Context Learning\u003cbr\u003eLanguage-to-Code Translation with a Single Labeled Example\u003cbr\u003eStrengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations\u003cbr\u003eCross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing\u003cbr\u003eScope-enhanced Compositional Semantic Parsing for DRT\u003cbr\u003ePredicting generalization performance with correctness discriminators","MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning\u003cbr\u003eUnveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement\u003cbr\u003eTurn Waste into Worth: Rectifying Top-k Router of MoE\u003cbr\u003eThe Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance\u003cbr\u003eRoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization\u003cbr\u003eLLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement\u003cbr\u003eMiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning","Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving\u003cbr\u003eLearn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning\u003cbr\u003eEHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records\u003cbr\u003eBi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check\u003cbr\u003eBeyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models\u003cbr\u003eE2CL: Exploration-based Error Correction Learning for Embodied Agents\u003cbr\u003eResilience of Large Language Models for Noisy Instructions","CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering\u003cbr\u003eRight for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering\u003cbr\u003eGenerate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering\u003cbr\u003eRetrieval and Reasoning on KGs: Integrate Knowledge Graphs into Large Language Models for Complex Question Answering\u003cbr\u003eQuestion-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering\u003cbr\u003eA Framework of Knowledge Graph-Enhanced Large Language Model Based on Question Decomposition and Atomic Retrieval\u003cbr\u003eLess is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA","MTLS: Making Texts into Linguistic Symbols\u003cbr\u003eLexically Grounded Subword Segmentation\u003cbr\u003eA Morphology-Based Investigation of Positional Encodings\u003cbr\u003eGeneralists vs. Specialists: Evaluating Large Language Models for Urdu\u003cbr\u003ePredicting generalization performance with correctness discriminators\u003cbr\u003eAFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks\u003cbr\u003eTargeted Multilingual Adaptation for Low-resource Language Families","When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives\u003cbr\u003eOneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting\u003cbr\u003eUnsupervised Named Entity Disambiguation for Low Resource Domains\u003cbr\u003eVisual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant\u003cbr\u003eBMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers\u003cbr\u003eComparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval\u003cbr\u003eOneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs","Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks\u003cbr\u003eIs LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment\u003cbr\u003eReasoning Robustness of LLMs to Adversarial Typographical Errors\u003cbr\u003eRAFT: Realistic Attacks to Fool Text Detectors\u003cbr\u003eRAt: Injecting Implicit Bias for Text-To-Image Prompt Refinement Models\u003cbr\u003eRobust Text Classification: Analyzing Prototype-Based Networks\u003cbr\u003eAttacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions","Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation\u003cbr\u003eTowards Verifiable Text Generation with Evolving Memory and Self-Reflection\u003cbr\u003eFine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together\u003cbr\u003eFAME: Towards Factual Multi-Task Model Editing\u003cbr\u003eOneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs\u003cbr\u003eRefiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities\u003cbr\u003eStyle-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles","Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval\u003cbr\u003eDistilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP\u003cbr\u003eFrom Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models\u003cbr\u003eFineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension\u003cbr\u003ePreserving Multi-Modal Capabilities of Pre-trained VLMS for Improving Vision-Linguistic Compositionality\u003cbr\u003eInfrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models\u003cbr\u003eTransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling","Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates\u003cbr\u003eUniversal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning\u003cbr\u003eRethinking the Evaluation of In-Context Learning for LLMs\u003cbr\u003eQuantum Recurrent Architectures for Text Classification\u003cbr\u003eBayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities\u003cbr\u003eNavigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models\u003cbr\u003eTransfer Learning for Text Classification via Model Risk Analysis","Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts\u003cbr\u003eRevealing the Parallel Multilingual Learning within Large Language Models\u003cbr\u003eDEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing\u003cbr\u003eImproving Minimum Bayes Risk Decoding with Multi-Prompt\u003cbr\u003eEnable Fast Sampling for Seq2Seq Text Diffusion\u003cbr\u003eExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models\u003cbr\u003eREADME: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP","GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities\u003cbr\u003eADELIE: Aligning Large Language Models on Information Extraction\u003cbr\u003eLawBench: Benchmarking Legal Knowledge of Large Language Models\u003cbr\u003eExplicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments\u003cbr\u003eGeneral Collaborative Framework between Large Language Model and Experts for Universal Information Extraction\u003cbr\u003eBeyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models\u003cbr\u003eDebate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction","EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning\u003cbr\u003eTowards Robust Speech Representation Learning for Thousands of Languages\u003cbr\u003eSelf-Powered LLM Modality Expansion for Large Speech-Text Models\u003cbr\u003eLLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement\u003cbr\u003eMulti-dimensional Evaluation of Empathetic Dialogue Responses\u003cbr\u003eLinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization\u003cbr\u003eClass Name Guided Out-of-Scope Intent Classification","EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning\u003cbr\u003eTowards Robust Speech Representation Learning for Thousands of Languages\u003cbr\u003eTransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities\u003cbr\u003eDC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding\u003cbr\u003eFlee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling\u003cbr\u003eMELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science\u003cbr\u003eDesigning Logic Pattern Templates for Counter-Argument Logical Structure Analysis","EPO: Hierarchical LLM Agents with Environment Preference Optimization\u003cbr\u003eAligning Large Language Models with Diverse Political Viewpoints\u003cbr\u003eRLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs\u003cbr\u003eModel-based Preference Optimization in Abstractive Summarization without Human Feedback\u003cbr\u003eBAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization\u003cbr\u003eEnhancing Alignment using Curriculum Learning & Ranked Preferences\u003cbr\u003eMargin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback","A Survey of AMR Applications\u003cbr\u003eMulti-pass Decoding for Grammatical Error Correction\u003cbr\u003eLLM-based Code-Switched Text Generation for Grammatical Error Correction\u003cbr\u003eTo Err Is Human, but Llamas Can Learn It Too\u003cbr\u003eTo Ask LLMs about English Grammaticality, Prompt Them in a Different Language\u003cbr\u003eGazelle: An Instruction Dataset for Arabic Writing Assistance\u003cbr\u003eEfficient and Interpretable Grammatical Error Correction with Mixture of Experts","ADELIE: Aligning Large Language Models on Information Extraction\u003cbr\u003eExplicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments\u003cbr\u003eDocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction\u003cbr\u003eOEE-CFC: A Dataset for Open Event Extraction from Chinese Financial Commentary\u003cbr\u003eMMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling\u003cbr\u003eMELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science\u003cbr\u003eDebate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction","Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners\u003cbr\u003eDo LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models\u003cbr\u003eFAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding\u003cbr\u003eVariational Language Concepts for Interpreting Foundation Language Models\u003cbr\u003eAre ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity\u003cbr\u003eFunctionality learning through specification instructions\u003cbr\u003eUnlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization","ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?\u003cbr\u003eNOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition\u003cbr\u003eDISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers\u003cbr\u003eError Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation\u003cbr\u003eStep-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?\u003cbr\u003eWhat's under the hood: Investigating Automatic Metrics on Meeting Summarization\u003cbr\u003eDifficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs","The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification\u003cbr\u003eDiversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets\u003cbr\u003eEnhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research\u003cbr\u003eI love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining\u003cbr\u003eStanceformer: Target-Aware Transformer for Stance Detection\u003cbr\u003eToeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter\u003cbr\u003eHow to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models","Improving Knowledge Graph Completion with Structure-Aware Supervised Contrastive Learning\u003cbr\u003eMoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion\u003cbr\u003eJoint Pre-Encoding Representation and Sturcture Embedding for Efficient and Low-Resource Knowledge Graph Completion\u003cbr\u003eVarying Sentence Representations via Condition-Specified Routers\u003cbr\u003eContext-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs\u003cbr\u003eTemporal Fact Reasoning over Hyper-Relational Knowledge Graphs\u003cbr\u003eSALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning","Prompts have evil twins\u003cbr\u003eFairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments\u003cbr\u003eOptimizing Instructions and Demonstrations for Multi-Stage Language Model Programs\u003cbr\u003eFewer is More: Boosting Math Reasoning with Reinforced Context Pruning\u003cbr\u003eSelf-Renewal Prompt Optimizing with Implicit Reasoning\u003cbr\u003eLLM as a metric critic for low resource relation identification","LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay\u003cbr\u003eAn LLM Feature-based Framework for Dialogue Constructiveness Assessment\u003cbr\u003eIntegrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation\u003cbr\u003eAutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments\u003cbr\u003eBeyond Persuasion: Towards Conversational Recommender System with Credible Explanations\u003cbr\u003eZero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval","When LLMs Meet Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection\u003cbr\u003eTowards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\u003cbr\u003eMEANT: Multimodal Encoder for Antecedent Information\u003cbr\u003eMatryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions\u003cbr\u003eMMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems\u003cbr\u003eDifficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs","Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs\u003cbr\u003eLEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models\u003cbr\u003eTowards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\u003cbr\u003eLarge Language Models Can Be Contextual Privacy Protection Learners\u003cbr\u003eSynthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models\u003cbr\u003eLlama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection","MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making\u003cbr\u003eRetrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation\u003cbr\u003eMAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration\u003cbr\u003eMathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models\u003cbr\u003eOn the Empirical Complexity of Reasoning and Planning in LLMs\u003cbr\u003eAn Evaluation Mechanism of LLM-based Agents on Manipulating APIs","LONGEMBED: Extending Embedding Models for Long Context Retrieval\u003cbr\u003eDancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models\u003cbr\u003eXplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs\u003cbr\u003eFAME: Towards Factual Multi-Task Model Editing\u003cbr\u003eA Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios\u003cbr\u003eA Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models","Integrating Plutchik's Theory with Mixture of Experts for Enhancing Emotion Classification\u003cbr\u003eMessage Passing on Semantic-Anchor-Graphs for Fine-grained Emotion Representation Learning and Classification\u003cbr\u003eDoes Large Language Model Contain Task-Specific Neurons?\u003cbr\u003eUnveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism\u003cbr\u003eUnderstanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing\u003cbr\u003eTUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance","Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process\u003cbr\u003eSafely Learning with Private Data: A Federated Learning Framework for Large Language Model\u003cbr\u003eAn Audit on the Perspectives and Challenges of Hallucinations in NLP\u003cbr\u003eRevealing the Parallel Multilingual Learning within Large Language Models\u003cbr\u003eModel-based Preference Optimization in Abstractive Summarization without Human Feedback\u003cbr\u003eMeasuring the Robustness of NLP Models to Domain Shifts","Model Balancing Helps Low-data Training and Fine-tuning\u003cbr\u003eARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback\u003cbr\u003eOn Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality\u003cbr\u003eAdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models\u003cbr\u003eTowards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks","Do We Need Language-Specific Fact-Checking Models? The Case of Chinese\u003cbr\u003eMiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents\u003cbr\u003eUnknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data\u003cbr\u003eM\u00b3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection\u003cbr\u003eHow to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models\u003cbr\u003eFactcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers","VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation\u003cbr\u003eTeaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use\u003cbr\u003eText2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback\u003cbr\u003eWeak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems\u003cbr\u003eCOFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code\u003cbr\u003eNavigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models","EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u003cbr\u003eFrom RAG to RICHES: Retrieval Interlaced with Sequence Generation\u003cbr\u003eRe-ReST: Reflection-Reinforced Self-Training for Language Agents\u003cbr\u003eRIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning\u003cbr\u003eAdaptive Token Biaser: Knowledge Editing via Biasing Key Entities\u003cbr\u003eLLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments","What do Large Language Models Need for Machine Translation Evaluation?\u003cbr\u003eBeyond Reference: Evaluating High Quality Translations Better than Human References\u003cbr\u003eMMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language\u003cbr\u003ePrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation\u003cbr\u003eCan Automatic Metrics Assess High-Quality Translations?\u003cbr\u003eBLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation","Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping\u003cbr\u003eUnsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel\u003cbr\u003eWhat are the Generator Preferences for End-to-end Task-Oriented Dialog System?\u003cbr\u003eTransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities\u003cbr\u003eLearning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues\u003cbr\u003eRewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue","World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering\u003cbr\u003eUOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models\u003cbr\u003eShaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling\u003cbr\u003eInvestigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models\u003cbr\u003ePropTest: Automatic Property Testing for Improved Visual Programming\u003cbr\u003eVDebugger: Harnessing Execution Feedback for Debugging Visual Programs","Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation\u003cbr\u003eSynchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation\u003cbr\u003eAnalysis of Plan-based Retrieval for Grounded Text Generation\u003cbr\u003eMulti-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models\u003cbr\u003eCalibrating Long-form Generations from Large Language Models\u003cbr\u003eDownstream Trade-offs of a Family of Text Watermarks","A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners\u003cbr\u003eLLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives\u003cbr\u003eSynthetic Multimodal Question Generation\u003cbr\u003eBetter Alignment with Instruction Back-and-Forth Translation\u003cbr\u003eAligners: Decoupling LLMs and Alignment\u003cbr\u003eToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information","Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement\u003cbr\u003eWhen Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models\u003cbr\u003eWhich Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?\u003cbr\u003eIntermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models\u003cbr\u003eFine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation\u003cbr\u003eA Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune","SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\u003cbr\u003eUniversal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning\u003cbr\u003eCorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs\u003cbr\u003ePrompt-Based Bias Calibration for Better Zero\u002fFew-Shot Learning of Language Models\u003cbr\u003eLexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons\u003cbr\u003eInference and Verbalization Functions During In-Context Learning","Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System\u003cbr\u003eWhat are the Generator Preferences for End-to-end Task-Oriented Dialog System?\u003cbr\u003eIntegrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation\u003cbr\u003eThoughts to Target: Enhance Planning for Target-driven Conversation\u003cbr\u003eRewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue\u003cbr\u003eSARCAT: Generative Span-Act Guided Response Generation Using Copy-Enhanced Target Augmentation","Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model\u003cbr\u003eEncourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective\u003cbr\u003eORPO: Monolithic Preference Optimization without Reference Model\u003cbr\u003eFlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization\u003cbr\u003eSelf-Renewal Prompt Optimizing with Implicit Reasoning\u003cbr\u003eSelf-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness","RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework\u003cbr\u003eUnlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding\u003cbr\u003eIntrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis\u003cbr\u003eTowards Aligning Language Models with Textual Feedback\u003cbr\u003eMulti-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models\u003cbr\u003ePromoting Constructive Deliberation: Reframing for Receptiveness","A Survey of AMR Applications\u003cbr\u003eSynchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation\u003cbr\u003eLongAlign: A Recipe for Long Context Alignment of Large Language Models\u003cbr\u003eSH2: Self-Highlighted Hesitation Helps You Decode More Truthfully\u003cbr\u003eGeneralists vs. Specialists: Evaluating Large Language Models for Urdu\u003cbr\u003eCalibrating Long-form Generations from Large Language Models","Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models\u003cbr\u003eNuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data\u003cbr\u003eData Contamination Can Cross Language Barriers\u003cbr\u003eScaling Sentence Embeddings with Large Language Models\u003cbr\u003eTrain Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation\u003cbr\u003eMitigating Catastrophic Forgetting in Language Transfer via Model Merging","SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information\u003cbr\u003eCommVQA: Situating Visual Question Answering in Communicative Contexts\u003cbr\u003eVGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning\u003cbr\u003eMMedAgent: Learning to Use Medical Tools with Multi-modal Agent\u003cbr\u003eMobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding\u003cbr\u003eImproving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design","CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models\u003cbr\u003eIntroducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly\u003cbr\u003eKV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches\u003cbr\u003eAda-Instruct: Adapting Instruction Generators for Complex Reasoning\u003cbr\u003eLength Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding\u003cbr\u003eFrom Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression","Towards Verifiable Text Generation with Evolving Memory and Self-Reflection\u003cbr\u003eAGRAME: Any-Granularity Ranking with Multi-Vector Embeddings\u003cbr\u003eImprove Dense Passage Retrieval with Entailment Tuning\u003cbr\u003eDense X Retrieval: What Retrieval Granularity Should We Use?\u003cbr\u003eNot All Contexts Are Equal: Teaching LLMs Credibility-aware Generation\u003cbr\u003eLearning to Paraphrase for Alignment with LLM Preference","MisinfoEval: Generative AI in the Era of \u201cAlternative Facts\"\u003cbr\u003eEnhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research\u003cbr\u003eSPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness\u003cbr\u003eDecoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach\u003cbr\u003eHow to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models\u003cbr\u003eMisinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation","A Thorough Examination of Decoding Methods in the Era of LLMs\u003cbr\u003eHow to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective\u003cbr\u003eLongAlign: A Recipe for Long Context Alignment of Large Language Models\u003cbr\u003eAUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models\u003cbr\u003eLLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement\u003cbr\u003eMerge to Learn: Efficiently Adding Skills to Language Models with Model Merging","MOSEL: Inference Serving Using Dynamic Modality Selection\u003cbr\u003eA Closer Look at Multidimensional Online Political Incivility\u003cbr\u003eStill Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis\u003cbr\u003eGraph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification\u003cbr\u003eRandom Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems\u003cbr\u003eCHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models","Assessing \"Implicit\" Retrieval Robustness of Large Language Models\u003cbr\u003eATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR\u003cbr\u003eSearching for Best Practices in Retrieval-Augmented Generation\u003cbr\u003eRetrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation\u003cbr\u003eR2AG: Incorporating Retrieval Information into Retrieval Augmented Generation\u003cbr\u003eFrom Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression","Efficient Sequential Decision Making with Large Language Models\u003cbr\u003ePepRec: Progressive Enhancement of Prompting for Recommendation\u003cbr\u003eJump Starting Bandits with LLM-Generated Prior Knowledge\u003cbr\u003eI-AM-G: Interest Augmented Multimodal Generator for Item Personalization\u003cbr\u003eQUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware\u003cbr\u003eZero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval","RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs\u003cbr\u003eAKEW: Assessing Knowledge Editing in the Wild\u003cbr\u003eThe Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning\u003cbr\u003eForecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling\u003cbr\u003eFactcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers\u003cbr\u003eVarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation","Bio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints\u003cbr\u003eSciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents\u003cbr\u003eLarge Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark\u003cbr\u003eA Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction\u003cbr\u003eC-ICL: Contrastive In-context Learning for Information Extraction\u003cbr\u003eIs There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases","Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models\u003cbr\u003eREADME++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment\u003cbr\u003e\u003eWhy Does New Knowledge Create Messy Ripple Effects in LLMs?\u003cbr\u003eCross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing\u003cbr\u003eEfficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models\u003cbr\u003eSelf-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages","Structured Optimal Brain Pruning for Large Language Models\u003cbr\u003ePruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging\u003cbr\u003ePromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning\u003cbr\u003eChange Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy\u003cbr\u003eOptimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs\u003cbr\u003eWhen Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models","Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning\u003cbr\u003eDogeRM: Equipping Reward Models with Domain Knowledge through Model Merging\u003cbr\u003eReward Modeling Requires Automatic Adjustment Based on Data Quality\u003cbr\u003eSemi-Supervised Reward Modeling via Iterative Self-Training\u003cbr\u003eOn Diversified Preferences of Large Language Model Alignment\u003cbr\u003eInterpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts","Temporally Consistent Factuality Probing for Large Language Models\u003cbr\u003eCAT-BENCH: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans\u003cbr\u003eMIBench: Evaluating Multimodal Large Language Models over Multiple Images\u003cbr\u003eDyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs\u003cbr\u003eRemember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models\u003cbr\u003eNARRATIVE-OF-THOUGHT: Improving Temporal Reasoning of Large Language Models via Recounted Narratives","ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures\u003cbr\u003eNOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition\u003cbr\u003eFlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents\u003cbr\u003eA Recipe to Train Powerful Romanian LLMs with English Instructions\u003cbr\u003eTowards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks\u003cbr\u003eBLADE: Benchmarking Language Model Agents for Data-Driven Science","CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality\u003cbr\u003eZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering\u003cbr\u003eAdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models\u003cbr\u003eDLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model\u003cbr\u003eMaking Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning","MULTI-NEWS+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation\u003cbr\u003eLarge Language Models for Data Annotation and Synthesis: A Survey\u003cbr\u003eOATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants\u003cbr\u003eNeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries\u003cbr\u003eSelective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model","Table Question Answering for Low-resourced Indic Languages\u003cbr\u003eLeveraging pre-trained language models for linguistic analysis: A case of argument structure constructions\u003cbr\u003eEfficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts\u003cbr\u003eCreative and Context-Aware Translation of East Asian Idioms with GPT-4\u003cbr\u003eDiverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking","Hateful Word in Context Classification\u003cbr\u003eFOOL ME IF YOU CAN! An Adversarial Dataset to Investigate the Robustness of LMs in Word Sense Disambiguation\u003cbr\u003eMore DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages\u003cbr\u003eAC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models\u003cbr\u003eHit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention","\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models\u003cbr\u003eMitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing\u003cbr\u003eTarget-Aware Language Modeling via Granular Data Sampling\u003cbr\u003eCultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies\u003cbr\u003eLPZero: Language Model Zero-cost Proxy Search from Zero","RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning\u003cbr\u003eAssessing \"Implicit\" Retrieval Robustness of Large Language Models\u003cbr\u003eOn the Robustness of Editing Large Language Models\u003cbr\u003eA Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios\u003cbr\u003eLanguage Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks","Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing\u003cbr\u003eAGRAME: Any-Granularity Ranking with Multi-Vector Embeddings\u003cbr\u003eTROTR: A Framework for Evaluating the Recontextualization of Text\u003cbr\u003eMake Large Language Model a Better Ranker\u003cbr\u003eA Study of Implicit Ranking Unfairness in Large Language Models","Tokenization Is More Than Compression\u003cbr\u003eCHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification\u003cbr\u003eZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering\u003cbr\u003eInstruction Fine-Tuning: Does Prompt Loss Matter?\u003cbr\u003eDLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model","FLIRT: Feedback Loop In-context Red Teaming\u003cbr\u003eHolistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction\u003cbr\u003eCoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference\u003cbr\u003eSTAR: SocioTechnical Approach to Red Teaming Language Models\u003cbr\u003eBe a Multitude to Itself: A Prompt Evolution Framework for Red Teaming","Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections\u003cbr\u003eOn Evaluating Explanation Utility for Human-AI Decision Making in NLP\u003cbr\u003eAsk the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration\u003cbr\u003eREADME: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP\u003cbr\u003eSocratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation","DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities\u003cbr\u003eUnifying Multimodal Retrieval via Document Screenshot Embedding\u003cbr\u003eMixGR: Enhancing Retriever Generalization for Scientific Domain through Complementary Granularity\u003cbr\u003eThreshold-driven Pruning with Segmented Maximum Term Weights for Approximate Cluster-based Sparse Retrieval\u003cbr\u003eSeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation","Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models\u003cbr\u003eLearning to Route for Dynamic Adapter Composition in Continual Learning with Language Models\u003cbr\u003eLayer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models\u003cbr\u003eBIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models\u003cbr\u003ePromoting Data and Model Privacy in Federated Learning through Quantized LoRA","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eFrom Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eGLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eFrom Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eBeyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eAdvancing Process Verification for Large Language Models via Tree-Based Preference Learning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering\u003cbr\u003eCan LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks","Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\u003cbr\u003eWorking Memory Identifies Reasoning Limits in Language Models\u003cbr\u003eMentor-KD: Making Small Language Models Better Multi-step Reasoners\u003cbr\u003eMirror-Consistency: Harnessing Inconsistency in Majority Voting\u003cbr\u003eAuto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework","AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning\u003cbr\u003eOn Training Data Influence of GPT Models\u003cbr\u003eFisher Information-based Efficient Curriculum Federated Learning with Large Language Models\u003cbr\u003eIntermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models\u003cbr\u003eA Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune","RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models\u003cbr\u003eMedCoT: Medical Chain of Thought via Hierarchical Expert\u003cbr\u003eSelf-Training Large Language and Vision Assistant for Medical Question-Answering\u003cbr\u003eMed-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models\u003cbr\u003eLight-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models","CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading\u003cbr\u003eVerification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving\u003cbr\u003eXplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs\u003cbr\u003eEnhancing High-order Interaction Awareness in LLM-based Recommender Model\u003cbr\u003eBeyond Persuasion: Towards Conversational Recommender System with Credible Explanations","Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\u003cbr\u003eThe Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention\u003cbr\u003eMalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language\u003cbr\u003eCONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules\u003cbr\u003eSedarEval: Automated Evaluation using Self-Adaptive Rubrics","Tag-grounded Visual Instruction Tuning with Retrieval Augmentation\u003cbr\u003eUOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models\u003cbr\u003eTowards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\u003cbr\u003eTraining-free Deep Concept Injection Enables Language Models for Video Question Answering\u003cbr\u003eInfrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models","GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models\u003cbr\u003eFrom Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning\u003cbr\u003eAdaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning\u003cbr\u003eADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning\u003cbr\u003eAlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality","Backward Lens: Projecting Language Model Gradients into the Vocabulary Space\u003cbr\u003eBeyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning\u003cbr\u003eAxis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings\u003cbr\u003eVariational Language Concepts for Interpreting Foundation Language Models\u003cbr\u003eSeeing Through VisualBERT: A Causal Adventure on Memetic Landscapes","Reusing Transferable Weight Increments for Low-resource Style Generation\u003cbr\u003eStyle-Specific Neurons for Steering LLMs in Text Style Transfer\u003cbr\u003eTowards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout\u003cbr\u003eMORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization\u003cbr\u003eTINYSTYLER: Efficient Few-Shot Text Style Transfer with Authorship Embeddings","Calibrating the Confidence of Large Language Models by Eliciting Fidelity\u003cbr\u003eScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws\u003cbr\u003eGPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning\u003cbr\u003eIn-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models\u003cbr\u003eBiMediX: Bilingual Medical Mixture of Experts LLM","DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models\u003cbr\u003eUnlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization\u003cbr\u003eLarge Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark\u003cbr\u003eDe-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP\u003cbr\u003eVE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models","Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models\u003cbr\u003eCSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free-Word-Ordered and Morphologically-Rich Low-Resource Languages\u003cbr\u003eContribution of Linguistic Typology to Universal Dependency Parsing: An Empirical Investigation\u003cbr\u003eA Morphology-Based Investigation of Positional Encodings\u003cbr\u003eRepresentation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing","Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale\u003cbr\u003eSelf-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models\u003cbr\u003eAnnotator-Centric Active Learning for Subjective NLP Tasks\u003cbr\u003eOn the Fragility of Active Learners for Text Classification\u003cbr\u003eActive Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization","Estimating Knowledge in Large Language Models Without Generating a Single Token\u003cbr\u003eRSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework\u003cbr\u003eRLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs\u003cbr\u003eFactuality of Large Language Models: A Survey\u003cbr\u003eAdaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation","PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models\u003cbr\u003eFirst Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning\u003cbr\u003eA Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles\u003cbr\u003eEfficiently Computing Susceptibility to Context in Language Models\u003cbr\u003eVarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation","Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset\u003cbr\u003eToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations\u003cbr\u003eEnhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research\u003cbr\u003eGiving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases\u003cbr\u003eBanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla","Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement\u003cbr\u003eFisher Information-based Efficient Curriculum Federated Learning with Large Language Models\u003cbr\u003eWhich Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?\u003cbr\u003eIntermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models\u003cbr\u003eA Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune","How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?\u003cbr\u003eThe Instinctive Bias: Spurious Images lead to Illusion in MLLMs\u003cbr\u003eInvestigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models\u003cbr\u003eNearest Neighbor Normalization Improves Multimodal Retrieval\u003cbr\u003ePreserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models","VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment\u003cbr\u003eMDPO: Conditional Preference Optimization for Multimodal Large Language Models\u003cbr\u003eSYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization\u003cbr\u003eSnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM\u003cbr\u003eSelf-training Large Language Models through Knowledge Detection","Can Large Language Models Learn Independent Causal Mechanisms?\u003cbr\u003eANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies\u003cbr\u003eConnecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game\u003cbr\u003eInference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs\u003cbr\u003eCELLO: Causal Evaluation of Large Vision-Language Models","Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale\u003cbr\u003eA Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models\u003cbr\u003eCMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models\u003cbr\u003eImproving Referring Ability for Biomedical Language Models\u003cbr\u003eUnlocking Continual Learning Abilities in Language Models","POSTMARK: A Robust Blackbox Watermark for Large Language Models\u003cbr\u003eWhere Am I From? Identifying Origin of LLM-generated Content\u003cbr\u003eContext-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models\u003cbr\u003eGuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack\u003cbr\u003eCODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code","Efficient Sequential Decision Making with Large Language Models\u003cbr\u003eIntegrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation\u003cbr\u003ePcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity\u003cbr\u003eFrom Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues\u003cbr\u003eCantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues","OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer\u003cbr\u003eSmall LLMs Are Weak Tool Learners: A Multi-LLM Agent\u003cbr\u003eE2CL: Exploration-based Error Correction Learning for Embodied Agents\u003cbr\u003eTrustAgent: Towards Safe and Trustworthy LLM-based Agents\u003cbr\u003eLearning to Use Tools via Cooperative and Interactive Agents with Large Language Models","Towards Robust Speech Representation Learning for Thousands of Languages\u003cbr\u003eSelf-Powered LLM Modality Expansion for Large Speech-Text Models\u003cbr\u003eContinual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech\u003cbr\u003eTokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR\u003cbr\u003eSTTATTS: Unified Speech-To-Text And Text-To-Speech Model","Domain adapted machine translation: What does catastrophic forgetting forget and why?\u003cbr\u003eGranularity is crucial when applying differential privacy to text: An investigation for neural machine translation\u003cbr\u003eDICTDIS: Dictionary Constrained Disambiguation for Improved NMT\u003cbr\u003eFinding the Optimal Byte-Pair Encoding Merge Operations for Neural Machine Translation in a Low-Resource Setting\u003cbr\u003eDoes Context Help Mitigate Gender Bias in Neural Machine Translation?","How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective\u003cbr\u003eMitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging\u003cbr\u003eEvolutionary Contrastive Distillation for Language Model Alignment\u003cbr\u003ePromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning\u003cbr\u003eAUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models","BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs\u003cbr\u003eMetrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP\\\u003cbr\u003eA Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models\u003cbr\u003eGender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts\u003cbr\u003eBeyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression","HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy\u003cbr\u003eWalia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets\u003cbr\u003eLongAlign: A Recipe for Long Context Alignment of Large Language Models\u003cbr\u003eRevisiting Catastrophic Forgetting in Large Language Model Tuning\u003cbr\u003eLexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation","TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning\u003cbr\u003eCONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models\u003cbr\u003eImproving Multi-Agent Debate with Sparse Communication Topology\u003cbr\u003eLarge Language Models Are Challenged by Habitat-Centered Reasoning\u003cbr\u003eKnowledge-Aware Reasoning over Multimodal Semi-structured Tables","Grounding Language in Multi-Perspective Referential Communication\u003cbr\u003eWhiteboard-of-Thought: Thinking Step-by-Step Across Modalities\u003cbr\u003eBeyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models\u003cbr\u003eIntroducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation\u003cbr\u003eALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"],"textposition":"none","x":["question answering","text classification","language modeling","sentiment analysis","visual question answering","summarization","natural language inference","commonsense reasoning","machine translation","text generation","instruction following","mathematical reasoning","in-context learning","code generation","named entity recognition","reasoning","RAG","information retrieval","image captioning","natural language processing","LLM evaluation","bias detection","reading comprehension","classification","data augmentation","text summarization","instruction tuning","arithmetic reasoning","natural language understanding","hallucination detection","zero-shot learning","relation extraction","few-shot learning","hate speech detection","gsm8k","bias mitigation","natural language generation","logical reasoning","reinforcement learning from human feedback","LLMs","knowledge editing","dialogue generation","language understanding","open-domain question answering","knowledge distillation","LLM alignment","automatic speech recognition","topic classification","language models","translation","fine-tuning","generalization","visual reasoning","medical question answering","text-to-image generation","speech recognition","evaluation","event extraction","generation","information extraction","math problem solving","language model alignment","math","rte","glue","hallucination mitigation","math reasoning","multi-hop reasoning","semantic textual similarity","topic modeling","quantization","video question answering","link prediction","calibration","emotion recognition","svamp","question generation","textual entailment","toxicity detection","fact verification","sentiment classification","dataset creation","multi-task learning","coreference resolution","continual learning","text-to-sql","story generation","domain adaptation","sentiment analysis natural language inference","model editing","binary classification","strategyqa","paraphrase detection","qnli","mnli","boolq","prompt engineering","bias analysis","superglue","language generation","arithmetic reasoning commonsense reasoning","image classification","preference learning","semantic parsing","mMLu","error correction","knowledge graph question answering","part-of-speech tagging","entity linking","adversarial attack","multi-hop qa","image-text retrieval","text classification sentiment analysis","text simplification","event detection","intent classification","slot filling","preference optimization","grammatical error correction","event argument extraction","paraphrase identification","error analysis","stance detection","knowledge graph completion","prompt optimization","persuasion","multimodal learning","knowledge injection","planning","qa","emotion classification","abstractive summarization","scienceqa","fact-checking","reinforcement learning","multi-hop question answering","machine translation evaluation","task-oriented dialogue","visual grounding","long-form generation","synthetic data generation","qqp","sentiment analysis topic classification","response generation","preference alignment","toxicity reduction","question answering summarization","transfer learning","vqa","code completion","open-domain qa","misinformation detection","coding","multi-label classification","question answering RAG","recommendation systems","benchmark","named entity recognition relation extraction","cross-lingual transfer","model compression","reward modeling","temporal reasoning","benchmarking","openbookqa","data annotation","data generation","word sense disambiguation","downstream task performance","robustness evaluation","ranking","piqa","red teaming","human-ai collaboration","document retrieval","parameter-efficient fine-tuning","addsub","aqua","csqa","date understanding","sst-2","medical visual question answering","explanation generation","benchmark creation","visual question answering image captioning","multiarith","interpretability","text style transfer","multiple-choice question answering","document classification","dependency parsing","active learning","open-ended generation","language model evaluation","offensive language detection","mrpc","image captioning visual question answering","hallucination reduction","abstract reasoning","continual pre-training","watermarking","dialogue systems","task planning","asr","neural machine translation","instruction-following","bias evaluation","instruction fine-tuning","multimodal reasoning","spatial reasoning"],"y":[165,68,64,63,57,55,54,53,48,39,39,33,33,32,32,31,30,30,29,28,26,21,21,21,20,20,19,19,19,19,19,19,18,17,17,16,16,16,16,15,15,15,14,14,14,14,14,14,13,12,12,12,12,12,11,11,11,11,11,11,11,11,10,10,10,10,10,10,10,10,10,10,10,10,9,9,9,9,9,9,8,8,8,8,8,8,8,8,8,8,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5],"type":"bar"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"title":{"text":"Keyword"},"tickangle":-45},"margin":{"l":60,"r":60,"t":80,"b":300},"font":{"size":16},"title":{"text":"EMNLP2024 Keyword"},"yaxis":{"title":{"text":"Frequency"}},"height":800,"width":2500,"bargap":0.1},                        {"responsive": true}                    )                };            </script>        </div>
    <script>
    const ngramMap = {"sentiment classification": ["UNIGEN: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation", "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification", "LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History", "AMPO: Automatic Multi-Branched Prompt Optimization", "RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference", "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models", "BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers", "Dual-Phase Accelerated Prompt Optimization"], "dataset cleansing": ["MULTI-NEWS+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation"], "data annotation": ["MULTI-NEWS+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation", "Large Language Models for Data Annotation and Synthesis: A Survey", "OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants", "NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries", "Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model"], "multi-document summarization": ["MULTI-NEWS+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation", "GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "dataset cleansing data annotation": ["MULTI-NEWS+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation"], "data annotation multi-document summarization": ["MULTI-NEWS+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation"], "dataset cleansing data annotation multi-document summarization": ["MULTI-NEWS+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation"], "factual inconsistency detection": ["FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"], "summarization evaluation": ["FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document", "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation", "Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics"], "factual inconsistency detection summarization evaluation": ["FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"], "prompt optimization": ["Prompts have evil twins", "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments", "Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs", "Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning", "Self-Renewal Prompt Optimizing with Implicit Reasoning", "LLM as a metric critic for low resource relation identification"], "adversarial attacks": ["Prompts have evil twins", "Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models", "Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming", "Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation"], "language models": ["Prompts have evil twins", "Tracking the perspectives of interacting language models", "Personas as a Way to Model Truthfulness in Language Models", "Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs", "Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models", "Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective", "FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation", "CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models", "Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models", "Improving LLM Attributions with Randomized Path-Integration", "MobileQuant: Mobile-friendly Quantization for On-device Language Models", "A Recipe to Train Powerful Romanian LLMs with English Instructions", "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "text generation": ["Prompts have evil twins", "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval", "KidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions", "PERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts", "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models", "LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives", "Precise Model Benchmarking with Only a Few Observations", "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?", "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions", "StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models", "Analysis of Plan-based Retrieval for Grounded Text Generation", "Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding", "Evaluating n-Gram Novelty of Language Models Using RUSTY-DAWG", "A Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors", "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists", "Scaling Laws for Linear Complexity Language Models", "Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions", "Transformers are Multi-State RNNS", "An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs", "Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?", "Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules", "Adversarial Text Generation using Large Language Models for Dementia Detection", "Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models", "Filtered Direct Preference Optimization", "Are LLMs Aware that Some Questions are not Open-ended?", "BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks", "LongForm: Effective Instruction Tuning with Reverse Instructions", "Achieving Stronger Generation via Simple Contrastive Tuning", "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning", "Promoting Data and Model Privacy in Federated Learning through Quantized LoRA", "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models", "Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation", "Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification", "Empirical Prior for Text Autoencoders", "Local and Global Decoding in Text Generation", "Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation", "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains", "Extrinsic Evaluation of Cultural Competence in Large Language Models"], "jailbreaks": ["Prompts have evil twins"], "prompt optimization adversarial attacks": ["Prompts have evil twins"], "adversarial attacks language models": ["Prompts have evil twins"], "language models text generation": ["Prompts have evil twins"], "text generation jailbreaks": ["Prompts have evil twins"], "prompt optimization adversarial attacks language models": ["Prompts have evil twins"], "adversarial attacks language models text generation": ["Prompts have evil twins"], "language models text generation jailbreaks": ["Prompts have evil twins"], "prompt optimization adversarial attacks language models text generation": ["Prompts have evil twins"], "adversarial attacks language models text generation jailbreaks": ["Prompts have evil twins"], "prompt optimization adversarial attacks language models text generation jailbreaks": ["Prompts have evil twins"], "tableqa": ["Table Question Answering for Low-resourced Indic Languages"], "low-resource languages": ["Table Question Answering for Low-resourced Indic Languages", "RAR: Retrieval-augmented retrieval for code generation in low-resource languages"], "data generation": ["Table Question Answering for Low-resourced Indic Languages", "Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions", "Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts", "Creative and Context-Aware Translation of East Asian Idioms with GPT-4", "Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking"], "tableqa low-resource languages": ["Table Question Answering for Low-resourced Indic Languages"], "low-resource languages data generation": ["Table Question Answering for Low-resourced Indic Languages"], "tableqa low-resource languages data generation": ["Table Question Answering for Low-resourced Indic Languages"], "image captioning": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions", "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation", "HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding", "Tag-grounded Visual Instruction Tuning with Retrieval Augmentation", "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?", "Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models", "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models", "A Survey of AMR Applications", "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes", "Precise Model Benchmarking with Only a Few Observations", "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges", "The Instinctive Bias: Spurious Images lead to Illusion in MLLMs", "From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment", "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "Altogether: Image Captioning via Re-aligning Alt-text", "IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning", "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "Nearest Neighbor Normalization Improves Multimodal Retrieval", "Mitigating Open-Vocabulary Caption Hallucinations", "Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models", "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning", "M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks", "CAPEEN: Image Captioning with Early Exits and Knowledge Distillation", "Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models", "TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling", "Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design"], "data augmentation": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions", "Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors", "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification", "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "An Audit on the Perspectives and Challenges of Hallucinations in NLP", "CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation", "ControlMath: Controllable Data Generation Promotes Math Generalist Models", "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing", "Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4", "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support", "Translation of Multifaceted Data without Re-Training of Machine Translation Systems", "Evaluation of Question Answer Generation for Portuguese: Insights and Datasets", "A Study of Implicit Ranking Unfairness in Large Language Models", "README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP", "All You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification", "Generate then Refine: Data Augmentation for Zero-shot Intent Detection", "LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification", "Controlled Transformation of Text-Attributed Graphs", "Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing", "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "text-to-image generation": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions", "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation", "Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation", "Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training", "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention", "Re-ReST: Reflection-Reinforced Self-Training for Language Agents", "Altogether: Image Captioning via Re-aligning Alt-text", "Learning from Mistakes: Iterative Prompt Relabeling for Text-to-Image Diffusion Model Training", "Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model", "Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement", "Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation"], "vision-language reasoning": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions"], "image captioning data augmentation": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions"], "data augmentation text-to-image generation": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions"], "text-to-image generation vision-language reasoning": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions"], "image captioning data augmentation text-to-image generation": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions"], "data augmentation text-to-image generation vision-language reasoning": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions"], "image captioning data augmentation text-to-image generation vision-language reasoning": ["ImageInWords: Unlocking Hyper-Detailed Image Descriptions"], "social behavior analysis": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "collaboration": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay", "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "confrontation": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "teamwork": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "leadership": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "persuasion": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay", "An LLM Feature-based Framework for Dialogue Constructiveness Assessment", "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation", "AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments", "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations", "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "camouflage": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "social behavior analysis collaboration": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "collaboration confrontation": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "confrontation teamwork": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "teamwork leadership": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "leadership persuasion": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "persuasion camouflage": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "social behavior analysis collaboration confrontation": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "collaboration confrontation teamwork": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "confrontation teamwork leadership": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "teamwork leadership persuasion": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "leadership persuasion camouflage": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "social behavior analysis collaboration confrontation teamwork": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "collaboration confrontation teamwork leadership": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "confrontation teamwork leadership persuasion": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "teamwork leadership persuasion camouflage": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "social behavior analysis collaboration confrontation teamwork leadership": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "collaboration confrontation teamwork leadership persuasion": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "confrontation teamwork leadership persuasion camouflage": ["LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"], "depression detection": ["When LLMs Meet Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection"], "multimodal learning": ["When LLMs Meet Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection", "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "MEANT: Multimodal Encoder for Antecedent Information", "Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions", "MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems", "Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "speech analysis": ["When LLMs Meet Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection", "Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "depression detection multimodal learning": ["When LLMs Meet Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection"], "multimodal learning speech analysis": ["When LLMs Meet Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection"], "depression detection multimodal learning speech analysis": ["When LLMs Meet Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection"], "speech synthesis": ["Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model", "Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control", "Emosical: An Emotion-Annotated Musical Theatre Dataset"], "speech enhancement": ["Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model"], "speech synthesis speech enhancement": ["Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model"], "hate speech detection": ["Hateful Word in Context Classification", "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze", "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers", "Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning", "The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification", "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization", "Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment", "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "Revisiting Supervised Contrastive Learning for Microblog Classification", "Hate Personified: Investigating the role of LLMs in content moderation", "Annotator-Centric Active Learning for Subjective NLP Tasks", "Delving into Qualitative Implications of Synthetic Data for Hate Speech Detection", "PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection", "Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation", "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models", "Functionality learning through specification instructions", "Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "word sense disambiguation": ["Hateful Word in Context Classification", "FOOL ME IF YOU CAN! An Adversarial Dataset to Investigate the Robustness of LMs in Word Sense Disambiguation", "More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages", "AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "hate speech detection word sense disambiguation": ["Hateful Word in Context Classification"], "subjective hate annotation": ["Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"], "gaze prediction": ["Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"], "hate speech detection subjective hate annotation": ["Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"], "subjective hate annotation gaze prediction": ["Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"], "hate speech detection subjective hate annotation gaze prediction": ["Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"], "arithmetic tasks": ["NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning", "Regression-aware Inference with LLMs"], "language understanding": ["NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning", "Autoregressive Pre-Training on Pixels and Texts", "Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "LLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks", "Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game", "MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language", "The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance", "Enhancing Agent Learning through World Dynamics Modeling", "MUSCLE: A Model Update Strategy for Compatible LLM Evolution", "Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation", "ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline", "MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition", "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "arithmetic tasks language understanding": ["NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"], "bias mitigation": ["\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework", "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention", "LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives", "Split and Merge: Aligning Position Biases in LLM-based Evaluators", "BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs", "Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation", "Local Contrastive Editing of Gender Stereotypes", "OffsetBias: Leveraging Debiased Data for Tuning Evaluators", "Can AI Relate: Testing Large Language Model Response for Mental Health Support", "Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases", "Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric", "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias", "Cognitive Bias in Decision-Making with LLMs", "Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "fair text generation": ["\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"], "downstream task performance": ["\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing", "Target-Aware Language Modeling via Granular Data Sampling", "CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies", "LPZero: Language Model Zero-cost Proxy Search from Zero"], "bias mitigation fair text generation": ["\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"], "fair text generation downstream task performance": ["\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"], "bias mitigation fair text generation downstream task performance": ["\u201cThinking\u201d Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"], "product recommendation": ["A Usage-centric Take on Intent Understanding in E-Commerce"], "intent understanding": ["A Usage-centric Take on Intent Understanding in E-Commerce"], "e-commerce": ["A Usage-centric Take on Intent Understanding in E-Commerce"], "product recommendation intent understanding": ["A Usage-centric Take on Intent Understanding in E-Commerce"], "intent understanding e-commerce": ["A Usage-centric Take on Intent Understanding in E-Commerce"], "product recommendation intent understanding e-commerce": ["A Usage-centric Take on Intent Understanding in E-Commerce"], "knowledge injection": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs", "LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models", "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "Large Language Models Can Be Contextual Privacy Protection Learners", "Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models", "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "question answering": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs", "Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection", "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering", "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps", "Aligning Language Models to Explicitly Handle Ambiguity", "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?", "QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios", "PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study", "SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation", "Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism", "VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation", "Where is the signal in tokenization space?", "Estimating Knowledge in Large Language Models Without Generating a Single Token", "When Context Leads but Parametric Memory Follows in Large Language Models", "I Could've Asked That: Reformulating Unanswerable Questions", "Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs", "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation", "Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning", "Teaching Small Language Models Reasoning through Counterfactual Distillation", "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation", "Investigating Mysteries of CoT-Augmented Distillation", "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities", "A Survey of AMR Applications", "Does Large Language Model Contain Task-Specific Neurons?", "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?", "\u201cImage, Tell me your story!\" Predicting the original meta-context of visual misinformation", "Language-to-Code Translation with a Single Labeled Example", "Attribute or Abstain: Large Language Models as Long Document Assistants", "Learning to Correct for QA Reasoning with Black-box LLMs", "Assessing \"Implicit\" Retrieval Robustness of Large Language Models", "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation", "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic", "Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding", "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?", "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models", "OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer", "Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning", "Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation", "MixGR: Enhancing Retriever Generalization for Scientific Domain through Complementary Granularity", "Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding", "Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering", "ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR", "Paraphrase Types Elicit Prompt Engineering Capabilities", "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMS", "TroL: Traversal of Layers for Large Language and Vision Models", "Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs", "Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "Self-Powered LLM Modality Expansion for Large Speech-Text Models", "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities", "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "Rethinking the Evaluation of In-Context Learning for LLMs", "Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries", "Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling", "The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis", "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation", "KnowTuning: Knowledge-aware Fine-tuning for Large Language Models", "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "RepMatch: Quantifying Cross-Instance Similarities in Representation Space", "Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models", "Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment", "LONGAGENT: Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration", "Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models", "Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations", "Searching for Best Practices in Retrieval-Augmented Generation", "Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition", "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs", "HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy", "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks", "Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering", "Generation with Dynamic Vocabulary", "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models", "You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions", "Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models", "SCIDQA: A Deep Reading Comprehension Dataset over Scientific Papers", "Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models", "Do great minds think alike? Investigating Human-AI Complementarity in Question Answering with CAIMIRA", "Memory-Efficient Fine-Tuning of Transformers via Token Selection", "Can LLMs Learn Uncertainty on Their Own? Expressing Uncertainty Effectively in A Self-Training Manner", "BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers", "Measuring the Robustness of NLP Models to Domain Shifts", "DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?", "CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "RAG-Studio: Towards In-Domain Adaptation of Retrieval Augmented Generation Through Self-Alignment", "API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access", "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models", "Large Language Model-based Human-Agent Collaboration for Complex Task Solving", "LongAlign: A Recipe for Long Context Alignment of Large Language Models", "The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models", "AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses", "Abstraction-of-Thought Makes Language Models Better Reasoners", "LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering", "Are LLMs Aware that Some Questions are not Open-ended?", "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature", "EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning", "Divide-or-Conquer? Which Part Should You Distill Your LLM?", "Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations", "A Notion of Complexity for Theory of Mind via Discrete World Models", "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation", "HoneyComb: A Flexible LLM-Based Agent System for Materials Science", "Characterizing LLM Abstention Behavior in Science QA with Context Perturbations", "Language Models Still Struggle to Zero-shot Reason about Time Series", "InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration", "Self-Contradictory Reasoning Evaluation and Detection", "MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension", "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully", "RoQLlama: A Lightweight Romanian Adapted Language Model", "A Survey on Natural Language Counterfactual Generation", "Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs", "From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items", "Plot Twist: Multimodal Models Don't Comprehend Simple Chart Details", "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection", "M2QA: Multi-domain Multilingual Question Answering", "LumberChunker: Long-Form Narrative Document Segmentation", "VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs", "Learning Semantic Structure through First-Order-Logic Translation", "TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "In-Context Learning with Iterative Demonstration Selection", "BERGEN: A Benchmarking Library for Retrieval-Augmented Generation", "MACAROON: Training Vision-Language Models To Be Your Engaged Partners", "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs", "MedINST: Meta Dataset of Biomedical Instructions", "TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation", "Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention", "Datasets for Multilingual Answer Sentence Selection", "LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters", "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation", "Detecting Temporal Ambiguity in Questions", "Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding", "Who's Who: Large Language Models Meet Knowledge Conflicts in Practice", "Query Routing for Homogeneous Tools: An Instantiation in the RAG Scenario", "Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation", "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation", "MDCR: A Dataset for Multi-Document Conditional Reasoning", "R2AG: Incorporating Retrieval Information into Retrieval Augmented Generation", "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity", "Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning", "Dual-Phase Accelerated Prompt Optimization", "TuringQ: Benchmarking AI Comprehension in Theory of Computation", "Can't Remember Details in Long Documents? You Need Some R&R", "More Bang for your Context: Virtual Documents for Question Answering over Long Documents", "Synthetic Multimodal Question Generation", "Calibrating Long-form Generations from Large Language Models", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model", "DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression", "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization", "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models", "XC-CACHE: Cross-Attending to Cached Context for Efficient LLM Inference", "ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning", "M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models", "To Ask LLMs about English Grammaticality, Prompt Them in a Different Language", "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation", "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations", "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation", "Zero-Shot Fact Verification via Natural Logic and Large Language Models"], "unsupervised fine-tuning": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"], "RAG": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs", "Knowledge Verification to Nip Hallucination in the Bud", "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering", "Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs", "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation", "Position Engineering: Boosting Large Language Models through Positional Information Manipulation", "Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning", "AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings", "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents", "Assessing \"Implicit\" Retrieval Robustness of Large Language Models", "ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR", "Improve Dense Passage Retrieval with Entailment Tuning", "RA2FD: Distilling Faithfulness into Efficient Dialogue Systems", "Analysis of Plan-based Retrieval for Grounded Text Generation", "Searching for Best Practices in Retrieval-Augmented Generation", "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs", "IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning", "COMPACT: Compressing Retrieved Documents Actively for Question Answering", "RAR: Retrieval-augmented retrieval for code generation in low-resource languages", "SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation", "Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts", "EvOR: Evolving Retrieval for Code Generation", "LumberChunker: Long-Form Narrative Document Segmentation", "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent", "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation", "R2AG: Incorporating Retrieval Information into Retrieval Augmented Generation", "Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression", "Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA", "Unified Active Retrieval for Retrieval Augmented Generation"], "knowledge injection question answering": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"], "question answering unsupervised fine-tuning": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"], "unsupervised fine-tuning RAG": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"], "knowledge injection question answering unsupervised fine-tuning": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"], "question answering unsupervised fine-tuning RAG": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"], "knowledge injection question answering unsupervised fine-tuning RAG": ["Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"], "political debate simulation": ["Systematic Biases in LLM Simulations of Debates"], "isolated sign language recognition": ["Studying and Mitigating Biases in Sign Language Understanding Models", "SignCLIP: Connecting Text and Sign Language by Contrastive Learning", "Towards Online Continuous Sign Language Recognition and Translation"], "dictionary retrieval": ["Studying and Mitigating Biases in Sign Language Understanding Models"], "isolated sign language recognition dictionary retrieval": ["Studying and Mitigating Biases in Sign Language Understanding Models"], "natural language generation": ["Uncertainty in Language Models: Assessment through Rank-Calibration", "On Training Data Influence of GPT Models", "Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering", "StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "Generative Models for Automatic Medical Decision Rule Extraction from Text", "Ontologically Faithful Generation of Non-Player Character Dialogues", "Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation", "MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations", "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate", "Evaluating Diversity in Automatic Poetry Generation", "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees", "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation", "SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs", "Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts"], "uncertainty quantification": ["Uncertainty in Language Models: Assessment through Rank-Calibration", "Perceptions of Linguistic Uncertainty by Language Models and Humans", "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees"], "natural language generation uncertainty quantification": ["Uncertainty in Language Models: Assessment through Rank-Calibration"], "tool learning": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning", "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models", "Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "robustness evaluation": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning", "Assessing \"Implicit\" Retrieval Robustness of Large Language Models", "On the Robustness of Editing Large Language Models", "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios", "Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks"], "tool selection": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning", "An Evaluation Mechanism of LLM-based Agents on Manipulating APIs", "TOOLVERIFIER: Generalization to New Tools via Self-Verification", "Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option"], "parameter identification": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "content filling": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "tool learning robustness evaluation": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "robustness evaluation tool selection": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "tool selection parameter identification": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "parameter identification content filling": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "tool learning robustness evaluation tool selection": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "robustness evaluation tool selection parameter identification": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "tool selection parameter identification content filling": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "tool learning robustness evaluation tool selection parameter identification": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "robustness evaluation tool selection parameter identification content filling": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "tool learning robustness evaluation tool selection parameter identification content filling": ["RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning"], "logical reasoning": ["Learning Planning-based Reasoning via Trajectories Collection and Process Reward Synthesizing", "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models", "Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars", "Retrieved In-Context Principles from Previous Mistakes", "METAREFLECTION: Learning Instructions for Language Agents using Past Reflections", "Puzzle Solving using Reasoning of Large Language Models: A Survey", "Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems", "Symbolic Working Memory Enhances Language Models for Complex Rule Application", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?", "Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models", "MIBench: Evaluating Multimodal Large Language Models over Multiple Images", "Abstraction-of-Thought Makes Language Models Better Reasoners", "EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning", "Learning to Plan by Updating Natural Language", "P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "mathematical reasoning": ["Learning Planning-based Reasoning via Trajectories Collection and Process Reward Synthesizing", "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "How Do Humans Write Code? Large Models Do It the Same Way Too", "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "Revealing the Parallel Multilingual Learning within Large Language Models", "Automatic Instruction Evolving for Large Language Models", "FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models", "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "Retrieved In-Context Principles from Previous Mistakes", "Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together", "Empowering Multi-step Reasoning across Languages via Program-Aided Language Models", "ControlMath: Controllable Data Generation Promotes Math Generalist Models", "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment", "Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging", "Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems", "LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning", "Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models", "SELF-EXPLORE: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards", "Mixed Distillation Helps Smaller Language Models Reason Better", "AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations", "Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts", "Self-Consistency Boosts Calibration for Math Reasoning", "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information", "Step-level Value Preference Optimization for Mathematical Reasoning", "Weak-to-Strong Reasoning", "Learning to Plan by Updating Natural Language", "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement", "Leveraging Web-Crawled Data for High-Quality Fine-Tuning", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning", "Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS", "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "logical reasoning mathematical reasoning": ["Learning Planning-based Reasoning via Trajectories Collection and Process Reward Synthesizing"], "generative spoken language modeling": ["Scaling Properties of Speech Language Models"], "speech recognition": ["Scaling Properties of Speech Language Models", "EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning", "Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges", "MOSEL: Inference Serving Using Dynamic Modality Selection", "What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations", "950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages", "VHASR: A Multimodal Speech Recognition System With Vision Hotwords", "Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities", "Twists, Humps, and Pebbles: Multilingual Speech Recognition Models Exhibit Gender Performance Gaps", "Casablanca: Data and Models for Multidialectal Arabic Speech Recognition", "PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition"], "semantic understanding": ["Scaling Properties of Speech Language Models"], "syntactic understanding": ["Scaling Properties of Speech Language Models"], "generative spoken language modeling speech recognition": ["Scaling Properties of Speech Language Models"], "speech recognition semantic understanding": ["Scaling Properties of Speech Language Models"], "semantic understanding syntactic understanding": ["Scaling Properties of Speech Language Models"], "generative spoken language modeling speech recognition semantic understanding": ["Scaling Properties of Speech Language Models"], "speech recognition semantic understanding syntactic understanding": ["Scaling Properties of Speech Language Models"], "generative spoken language modeling speech recognition semantic understanding syntactic understanding": ["Scaling Properties of Speech Language Models"], "target entity and sentiment detection": ["\u201cWe Demand Justice!\u201d: Towards Social Context Grounding of Political Texts"], "vague text disambiguation": ["\u201cWe Demand Justice!\u201d: Towards Social Context Grounding of Political Texts"], "target entity and sentiment detection vague text disambiguation": ["\u201cWe Demand Justice!\u201d: Towards Social Context Grounding of Political Texts"], "patent citation prediction": ["An Experimental Analysis on Evaluating Patent Citations"], "binary classification": ["An Experimental Analysis on Evaluating Patent Citations", "TROTR: A Framework for Evaluating the Recontextualization of Text", "Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis", "Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models", "Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification", "ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases", "The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "patent citation prediction binary classification": ["An Experimental Analysis on Evaluating Patent Citations"], "machine translation": ["Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?", "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models", "Word Alignment as Preference for Machine Translation", "Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects", "Aligning Translation-Specific Understanding to General Understanding in Large Language Models", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "An Audit on the Perspectives and Challenges of Hallucinations in NLP", "A Survey of AMR Applications", "Revealing the Parallel Multilingual Learning within Large Language Models", "Lexically Grounded Subword Segmentation", "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?", "SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation", "Distributional Properties of Subword Regularization", "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding", "The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis", "Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation", "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks", "Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation", "Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level", "Mitigating the Language Mismatch and Repetition Issues in LLM-based Machine Translation via Model Editing", "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges", "BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training", "What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study", "Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization", "Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation", "Back to School: Translation Using Grammar Books", "Improving Minimum Bayes Risk Decoding with Multi-Prompt", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "Translation of Multifaceted Data without Re-Training of Machine Translation Systems", "Evaluating Automatic Metrics with Incremental Machine Translation Systems", "Exploring the Relationship between In-Context Learning and Instruction Tuning", "Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation", "Leveraging Grammar Induction for Language Understanding and Generation", "Dual-teacher Knowledge Distillation for Low-frequency Word Translation", "Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs", "On Creating an English-Thai Code-switched Machine Translation in Medical Domain", "Cross-lingual Contextualized Phrase Retrieval", "Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages", "MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization", "Exploring Design Choices for Building Language-Specific LLMs", "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages", "Benchmarking Machine Translation with Cultural Awareness", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks", "Representational Isomorphism and Alignment of Multilingual Large Language Models", "LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation", "Analyzing Context Contributions in LLM-based Machine Translation", "Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "ranking": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing", "AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings", "TROTR: A Framework for Evaluating the Recontextualization of Text", "Make Large Language Model a Better Ranker", "A Study of Implicit Ranking Unfairness in Large Language Models"], "relevance prediction": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "post-processing": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "pseudo-rater": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "ranking relevance prediction": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "relevance prediction post-processing": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "post-processing pseudo-rater": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "ranking relevance prediction post-processing": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "relevance prediction post-processing pseudo-rater": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "ranking relevance prediction post-processing pseudo-rater": ["Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"], "non-collaborative dialogue agent": ["Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"], "strategic conversation": ["Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"], "user agreement": ["Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"], "non-collaborative dialogue agent strategic conversation": ["Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"], "strategic conversation user agreement": ["Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"], "non-collaborative dialogue agent strategic conversation user agreement": ["Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"], "LLM-assisted cheating prevention in introductory programming assignments": ["Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation"], "instruction tuning data selection": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation", "Data Diversity Matters for Robust Instruction Tuning"], "quality estimation": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation", "Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages", "BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "diversity preservation": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "language model training": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "instruction tuning data selection quality estimation": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "quality estimation diversity preservation": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "diversity preservation language model training": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "instruction tuning data selection quality estimation diversity preservation": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "quality estimation diversity preservation language model training": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "instruction tuning data selection quality estimation diversity preservation language model training": ["Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"], "relationship prediction": ["On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models"], "speech resynthesis": ["EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models", "Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach", "Towards Robust Speech Representation Learning for Thousands of Languages"], "speech-to-speech translation": ["EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models", "Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects", "TRANSLLAMA: LLM-based Simultaneous Translation System", "Textless Speech-to-Speech Translation With Limited Parallel Data"], "emphasis classification": ["EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"], "speech resynthesis speech-to-speech translation": ["EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"], "speech-to-speech translation emphasis classification": ["EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"], "speech resynthesis speech-to-speech translation emphasis classification": ["EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"], "fake news detection": ["On Fake News Detection with LLM Enhanced Semantics Mining", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation"], "text classification": ["On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices", "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale", "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification", "Incubating Text Classifiers Following User Instruction with Nothing but LLM", "Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks", "The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse", "Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates", "PERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts", "The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples", "StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models", "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation", "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning", "MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction", "Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs", "Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training", "Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models", "A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution", "Rethinking the Evaluation of In-Context Learning for LLMs", "Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning", "Are Large Language Models Good Classifiers? A Study on Edit Intent Classification in Scientific Document Revisions", "Revisiting Supervised Contrastive Learning for Microblog Classification", "Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging", "CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs", "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data", "Quantum Recurrent Architectures for Text Classification", "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion", "Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models", "SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation", "DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers", "AMPO: Automatic Multi-Branched Prompt Optimization", "Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities", "A Morphology-Based Investigation of Positional Encodings", "ADAPTERS MIXUP: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers", "GottBERT: a pure German Language Model", "Memory-Efficient Fine-Tuning of Transformers via Token Selection", "On the Fragility of Active Learners for Text Classification", " 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated Peer Reviews ", "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models", "Transfer Learning for Text Classification via Model Risk Analysis", "LoRAN: Improved Low-Rank Adaptation by a Non-Linear Transformation", "BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks", "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation", "Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles", "Rethinking Evaluation Methods for Machine Unlearning", "A Survey on Natural Language Counterfactual Generation", "Enhancing Byzantine-Resistant Aggregations with Client Embedding", "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models", "An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference", "On the Generalization of Training-based ChatGPT Detection Methods", "MedINST: Meta Dataset of Biomedical Instructions", "Unlocking the Potential of Model Merging for Low-Resource Languages", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention", "CERT-ED: Certifiably Robust Text Classification for Edit Distance", "Fighting Randomness with Randomness: Mitigating Optimisation Instability of Fine-Tuning using Delayed Ensemble and Noisy Interpolation", "Logits Reranking via Semantic Labels for Hard Samples in Text Classification", "Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment", "Distance-aware Calibration for Pre-trained Language Models", "Textual Dataset Distillation via Language Model Embedding", "Robust Text Classification: Analyzing Prototype-Based Networks", "All You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification", "Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems", "Efficient Active Learning with Adapters", "CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text", "Characterizing Text Datasets with Psycholinguistic Features", "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression", "Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs", "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation", "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "meta-learning": ["On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices", "A Survey on In-context Learning", "Characterizing Text Datasets with Psycholinguistic Features"], "text classification meta-learning": ["On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices", "Characterizing Text Datasets with Psycholinguistic Features"], "sentiment analysis": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers", "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue", "CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading", "DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models", "Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates", "Does Large Language Model Contain Task-Specific Neurons?", "Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners", "MOSEL: Inference Serving Using Dynamic Modality Selection", "The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification", "Paraphrase Types Elicit Prompt Engineering Capabilities", "Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment", "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning", "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models", "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "Latent Concept-based Explanation of NLP Models", "Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research", "Rethinking the Evaluation of In-Context Learning for LLMs", "The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis", "RepMatch: Quantifying Cross-Instance Similarities in Representation Space", "Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "Revisiting Supervised Contrastive Learning for Microblog Classification", "A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives", "CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs", "Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data", "Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training", "Quantum Recurrent Architectures for Text Classification", "Semantics and Sentiment: Cross-lingual Variations in Emoji Use", "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion", "SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation", "Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage", "ALVIN: Active Learning Via INterpolation", "Measuring the Robustness of NLP Models to Domain Shifts", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models", "Transfer Learning for Text Classification via Model Risk Analysis", "Exploring the Relationship between In-Context Learning and Instruction Tuning", "A Survey on Natural Language Counterfactual Generation", "DADEE: Unsupervised Domain Adaptation in Early Exit PLMS", "SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists", "Crisis counselor language and perceived genuine concern in crisis conversations", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters", "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation", "Do LLMs Think Fast and Slow? A Causal Study on Sentiment Analysis", "BiasDora: Exploring Hidden Biased Associations in Vision-Language Models", "Exploring Design Choices for Building Language-Specific LLMs", "Functionality learning through specification instructions", "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection", "Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks", "Regression-aware Inference with LLMs", "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons", "BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla", "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study", "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization", "The Overlooked Repetitive Lengthening Form in Sentiment Analysis", "Inference and Verbalization Functions During In-Context Learning", "CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack"], "emotion recognition": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers", "Visual Prompting in LLMs for Enhancing Emotion Recognition", "Towards Robust Speech Representation Learning for Thousands of Languages", "Self-Powered LLM Modality Expansion for Large Speech-Text Models", "Revisiting Supervised Contrastive Learning for Microblog Classification", "PALM: Few-Shot Prompt Learning for Audio Language Models", "Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health", "Emosical: An Emotion-Annotated Musical Theatre Dataset", "WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "offensive text detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "bias detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers", "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese", "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions", "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context", "Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights", "Voices in a Crowd: Searching for Clusters of Unique Perspectives", "Towards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey", "Moral Foundations of Large Language Models", "Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation", "The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models", "Can AI Relate: Testing Large Language Model Response for Mental Health Support", "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models", "Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models", "Evaluating Biases in Context-Dependent Sexual and Reproductive Health Questions", "PclGPT: A Large Language Model for Patronizing and Condescending Language Detection", "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "BiasDora: Exploring Hidden Biased Associations in Vision-Language Models", "Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing", "Cognitive Bias in Decision-Making with LLMs", "Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "sentiment analysis emotion recognition": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "emotion recognition hate speech detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "hate speech detection offensive text detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "offensive text detection bias detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "sentiment analysis emotion recognition hate speech detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "emotion recognition hate speech detection offensive text detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "hate speech detection offensive text detection bias detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "sentiment analysis emotion recognition hate speech detection offensive text detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "emotion recognition hate speech detection offensive text detection bias detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "sentiment analysis emotion recognition hate speech detection offensive text detection bias detection": ["A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"], "nlp tasks": ["Mitigating the Alignment Tax of RLHF"], "common sense qa": ["Mitigating the Alignment Tax of RLHF"], "reading comprehension": ["Mitigating the Alignment Tax of RLHF", "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?", "Revealing the Parallel Multilingual Learning within Large Language Models", "LawBench: Benchmarking Legal Knowledge of Large Language Models", "More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation", "FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition", "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling", "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training", "Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations", "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks", "AMPO: Automatic Multi-Branched Prompt Optimization", "SCIDQA: A Deep Reading Comprehension Dataset over Scientific Papers", "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios", "Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals", "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models", "Functionality learning through specification instructions", "FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models", "InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "translation": ["Mitigating the Alignment Tax of RLHF", "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "A Thorough Examination of Decoding Methods in the Era of LLMs", "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "An Analysis and Mitigation of the Reversal Curse", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "LongAlign: A Recipe for Long Context Alignment of Large Language Models", "AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "MedINST: Meta Dataset of Biomedical Instructions", "A Recipe to Train Powerful Romanian LLMs with English Instructions", "Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models"], "nlp tasks common sense qa": ["Mitigating the Alignment Tax of RLHF"], "common sense qa reading comprehension": ["Mitigating the Alignment Tax of RLHF"], "reading comprehension translation": ["Mitigating the Alignment Tax of RLHF"], "nlp tasks common sense qa reading comprehension": ["Mitigating the Alignment Tax of RLHF"], "common sense qa reading comprehension translation": ["Mitigating the Alignment Tax of RLHF"], "nlp tasks common sense qa reading comprehension translation": ["Mitigating the Alignment Tax of RLHF"], "explanation evaluation": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "readability assessment": ["Evaluating Readability and Faithfulness of Concept-based Explanations", "README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment", "ARTS: Assessing Readability & Text Simplicity"], "faithfulness measurement": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "concept-based explanations": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "LLMs": ["Evaluating Readability and Faithfulness of Concept-based Explanations", "QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models", "PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL", "COEVOL: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation", "UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models", "CommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions", "OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation", "A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models", "In-Context Former: Lightning-fast Compressing Context for Large Language Model", "Evaluating Moral Beliefs across LLMs through a Pluralistic Framework", "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection", "LaCo: Large Language Model Pruning via Layer Collapse", "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection", "Better Alignment with Instruction Back-and-Forth Translation", "ATQ: Activation Transformation for Weight-Activation Quantization of Large Language Models"], "explanation evaluation readability assessment": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "readability assessment faithfulness measurement": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "faithfulness measurement concept-based explanations": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "concept-based explanations LLMs": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "explanation evaluation readability assessment faithfulness measurement": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "readability assessment faithfulness measurement concept-based explanations": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "faithfulness measurement concept-based explanations LLMs": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "explanation evaluation readability assessment faithfulness measurement concept-based explanations": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "readability assessment faithfulness measurement concept-based explanations LLMs": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "explanation evaluation readability assessment faithfulness measurement concept-based explanations LLMs": ["Evaluating Readability and Faithfulness of Concept-based Explanations"], "student simulation": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems", "Using LLMs to Simulate Students' Responses to Exam Questions"], "conversational its": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "personalized learning": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "language learning": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems", "Communicating with Speakers and Listeners of Different Pragmatic Levels"], "image description": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "student simulation conversational its": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "conversational its personalized learning": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "personalized learning language learning": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "language learning image description": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "student simulation conversational its personalized learning": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "conversational its personalized learning language learning": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "personalized learning language learning image description": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "student simulation conversational its personalized learning language learning": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "conversational its personalized learning language learning image description": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "student simulation conversational its personalized learning language learning image description": ["Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems"], "embodied ai": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "long-term memory": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "planning": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making", "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation", "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models", "On the Empirical Complexity of Reasoning and Planning in LLMs", "An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "decision-making": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making", "On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "task execution": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making", "SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "embodied ai long-term memory": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "long-term memory planning": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "planning decision-making": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "decision-making task execution": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "embodied ai long-term memory planning": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "long-term memory planning decision-making": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "planning decision-making task execution": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "embodied ai long-term memory planning decision-making": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "long-term memory planning decision-making task execution": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "embodied ai long-term memory planning decision-making task execution": ["MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"], "logical fallacy detection": ["COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"], "logical fallacy classification": ["COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"], "dataset creation": ["COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds", "ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures", "Emosical: An Emotion-Annotated Musical Theatre Dataset", "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling", "From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues", "CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory", "ARTS: Assessing Readability & Text Simplicity", "CoCoHD: Congress Committee Hearing Dataset"], "logical fallacy detection logical fallacy classification": ["COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"], "logical fallacy classification dataset creation": ["COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"], "logical fallacy detection logical fallacy classification dataset creation": ["COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"], "arc_easy": ["Tokenization Is More Than Compression"], "copa": ["Tokenization Is More Than Compression", "AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "hendryckstests-marketing": ["Tokenization Is More Than Compression"], "hendryckstests-sociology": ["Tokenization Is More Than Compression"], "mathqa": ["Tokenization Is More Than Compression", "MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "piqa": ["Tokenization Is More Than Compression", "CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "Instruction Fine-Tuning: Does Prompt Loss Matter?", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "qa4mre_2013": ["Tokenization Is More Than Compression"], "race": ["Tokenization Is More Than Compression", "Unleashing the Potential of Large Language Models through Spectral Modulation"], "sciq": ["Tokenization Is More Than Compression"], "wsc273": ["Tokenization Is More Than Compression"], "arc_easy copa": ["Tokenization Is More Than Compression"], "copa hendryckstests-marketing": ["Tokenization Is More Than Compression"], "hendryckstests-marketing hendryckstests-sociology": ["Tokenization Is More Than Compression"], "hendryckstests-sociology mathqa": ["Tokenization Is More Than Compression"], "mathqa piqa": ["Tokenization Is More Than Compression"], "piqa qa4mre_2013": ["Tokenization Is More Than Compression"], "qa4mre_2013 race": ["Tokenization Is More Than Compression"], "race sciq": ["Tokenization Is More Than Compression"], "sciq wsc273": ["Tokenization Is More Than Compression"], "arc_easy copa hendryckstests-marketing": ["Tokenization Is More Than Compression"], "copa hendryckstests-marketing hendryckstests-sociology": ["Tokenization Is More Than Compression"], "hendryckstests-marketing hendryckstests-sociology mathqa": ["Tokenization Is More Than Compression"], "hendryckstests-sociology mathqa piqa": ["Tokenization Is More Than Compression"], "mathqa piqa qa4mre_2013": ["Tokenization Is More Than Compression"], "piqa qa4mre_2013 race": ["Tokenization Is More Than Compression"], "qa4mre_2013 race sciq": ["Tokenization Is More Than Compression"], "race sciq wsc273": ["Tokenization Is More Than Compression"], "arc_easy copa hendryckstests-marketing hendryckstests-sociology": ["Tokenization Is More Than Compression"], "copa hendryckstests-marketing hendryckstests-sociology mathqa": ["Tokenization Is More Than Compression"], "hendryckstests-marketing hendryckstests-sociology mathqa piqa": ["Tokenization Is More Than Compression"], "hendryckstests-sociology mathqa piqa qa4mre_2013": ["Tokenization Is More Than Compression"], "mathqa piqa qa4mre_2013 race": ["Tokenization Is More Than Compression"], "piqa qa4mre_2013 race sciq": ["Tokenization Is More Than Compression"], "qa4mre_2013 race sciq wsc273": ["Tokenization Is More Than Compression"], "arc_easy copa hendryckstests-marketing hendryckstests-sociology mathqa": ["Tokenization Is More Than Compression"], "copa hendryckstests-marketing hendryckstests-sociology mathqa piqa": ["Tokenization Is More Than Compression"], "hendryckstests-marketing hendryckstests-sociology mathqa piqa qa4mre_2013": ["Tokenization Is More Than Compression"], "hendryckstests-sociology mathqa piqa qa4mre_2013 race": ["Tokenization Is More Than Compression"], "mathqa piqa qa4mre_2013 race sciq": ["Tokenization Is More Than Compression"], "piqa qa4mre_2013 race sciq wsc273": ["Tokenization Is More Than Compression"], "red teaming": ["FLIRT: Feedback Loop In-context Red Teaming", "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction", "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference", "STAR: SocioTechnical Approach to Red Teaming Language Models", "Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "vulnerabilities evaluation": ["FLIRT: Feedback Loop In-context Red Teaming"], "inappropriate content generation": ["FLIRT: Feedback Loop In-context Red Teaming"], "red teaming vulnerabilities evaluation": ["FLIRT: Feedback Loop In-context Red Teaming"], "vulnerabilities evaluation inappropriate content generation": ["FLIRT: Feedback Loop In-context Red Teaming"], "red teaming vulnerabilities evaluation inappropriate content generation": ["FLIRT: Feedback Loop In-context Red Teaming"], "vision-language navigation": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections", "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation\\"], "instruction following": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections", "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning", "Direct Multi-Turn Preference Optimization for Language Agents", "Instruction Pre-Training: Language Models are Supervised Multitask Learners", "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "Bayesian Calibration of Win Rate Estimation with LLM Evaluators", "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities", "Automatic Instruction Evolving for Large Language Models", "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs", "WPO: Enhancing RLHF with Weighted Preference Optimization", "A Thorough Examination of Decoding Methods in the Era of LLMs", "AmbigNLG: Addressing Task Ambiguity in Instruction for NLG", "MAIR: A Massive Benchmark for Evaluating Instructed Retrieval", "Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment", "Dual-Space Knowledge Distillation for Large Language Models", "BLSP-Emo: Towards Empathetic Large Speech-Language Models", "DEM: Distribution Edited Model for Training with Mixed Data Distributions", "Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks", "Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?", "Preference-Guided Reflective Sampling for Aligning Language Models", "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "Suri: Multi-constraint Instruction Following for Long-form Text Generation", "Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation", "Self-Renewal Prompt Optimizing with Implicit Reasoning", "Inference-Time Language Model Alignment via Integrated Value Guidance", "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation\\", "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models", "LongForm: Effective Instruction Tuning with Reverse Instructions", "LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints", "Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models", "How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment", "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models", "Achieving Stronger Generation via Simple Contrastive Tuning", "From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models", "A Recipe to Train Powerful Romanian LLMs with English Instructions", "Resilience of Large Language Models for Noisy Instructions", "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "error detection": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections", "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors", "Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing", "Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check"], "correction suggestion": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "human-ai collaboration": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections", "On Evaluating Explanation Utility for Human-AI Decision Making in NLP", "Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration", "README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP", "Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "vision-language navigation instruction following": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections", "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation\\"], "instruction following error detection": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "error detection correction suggestion": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "correction suggestion human-ai collaboration": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "vision-language navigation instruction following error detection": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "instruction following error detection correction suggestion": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "error detection correction suggestion human-ai collaboration": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "vision-language navigation instruction following error detection correction suggestion": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "instruction following error detection correction suggestion human-ai collaboration": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "vision-language navigation instruction following error detection correction suggestion human-ai collaboration": ["Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections"], "instruction tuning": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks", "Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights", "Fast Forwarding Low-Rank Training", "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?", "CommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions", "Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback", "Curriculum Consistency Learning for Conditional Sentence Generation", "How Susceptible are Large Language Models to Ideological Manipulation?", "Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks", "Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization", "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search", "Data Diversity Matters for Robust Instruction Tuning", "Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach", "Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning", "CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues", "Better Alignment with Instruction Back-and-Forth Translation", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks", "Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging", "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "general nlp tasks": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "math": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts", "Nash CoT: Multi-Path Inference with Preference Equilibrium", "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks", "AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories", "Divide-or-Conquer? Which Part Should You Distill Your LLM?", "Skills-in-Context: Unlocking Compositionality in Large Language Models"], "code": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks", "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters", "Reformatted Alignment"], "commonsense reasoning": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks", "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "Teaching Small Language Models Reasoning through Counterfactual Distillation", "Investigating Mysteries of CoT-Augmented Distillation", "Focused Large Language Models are Stable Many-Shot Learners", "Mixture-of-Subspaces in Low-Rank Adaptation", "Retrieved In-Context Principles from Previous Mistakes", "A Thorough Examination of Decoding Methods in the Era of LLMs", "Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S.", "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses", "Large Language Models Can Self-Correct with Key Condition Verification", "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective", "Commonsense Knowledge Editing Based on Free-Text in LLMs", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "Re-Reading Improves Reasoning in Large Language Models", "LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training", "Scaling Laws for Linear Complexity Language Models", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning", "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies", "ApiQ: Finetuning of 2-Bit Quantized Large Language Model", "Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game", "DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks", "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models", "Learning to Paraphrase for Alignment with LLM Preference", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting", "AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations", "Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning", "From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items", "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information", "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning", "MUSCLE: A Model Update Strategy for Compatible LLM Evolution", "RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization", "The Mystery of Compositional Generalization in Graph-based Generative Commonsense Reasoning", "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning", "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation", "Exploring Design Choices for Building Language-Specific LLMs", "Zero-shot Commonsense Reasoning over Machine Imagination", "PizzaCommonSense: Learning to Model Commonsense Reasoning about Intermediate Steps in Cooking Recipes", "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models", "InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States", "Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning", "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation", "Large Language Models are In-context Teachers for Knowledge Reasoning", "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "world knowledge": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks", "LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training", "ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "instruction tuning general nlp tasks": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "general nlp tasks math": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "math code": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "code commonsense reasoning": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "commonsense reasoning world knowledge": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "instruction tuning general nlp tasks math": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "general nlp tasks math code": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "math code commonsense reasoning": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "code commonsense reasoning world knowledge": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "instruction tuning general nlp tasks math code": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "general nlp tasks math code commonsense reasoning": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "math code commonsense reasoning world knowledge": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "instruction tuning general nlp tasks math code commonsense reasoning": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "general nlp tasks math code commonsense reasoning world knowledge": ["Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"], "geometry problem solving": ["GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation", "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "multi-modal learning": ["GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"], "image generation": ["GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation", "Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP", "A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models", "TextLap: Customizing Language Models for Text-to-Layout Planning"], "geometry problem solving multi-modal learning": ["GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"], "multi-modal learning image generation": ["GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"], "geometry problem solving multi-modal learning image generation": ["GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"], "document retrieval": ["DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities", "Unifying Multimodal Retrieval via Document Screenshot Embedding", "MixGR: Enhancing Retriever Generalization for Scientific Domain through Complementary Granularity", "Threshold-driven Pruning with Segmented Maximum Term Weights for Approximate Cluster-based Sparse Retrieval", "SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation"], "entity ranking": ["DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"], "query expansion": ["DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities", "Exploring the Best Practices of Query Expansion with Large Language Models"], "document retrieval entity ranking": ["DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"], "entity ranking query expansion": ["DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"], "document retrieval entity ranking query expansion": ["DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"], "parameter-efficient fine-tuning": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models", "Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models", "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models", "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models", "Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "moe LLMs": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "expert selection": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "task specialization": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "parameter-efficient fine-tuning moe LLMs": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "moe LLMs expert selection": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "expert selection task specialization": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "parameter-efficient fine-tuning moe LLMs expert selection": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "moe LLMs expert selection task specialization": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "parameter-efficient fine-tuning moe LLMs expert selection task specialization": ["Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models"], "qa": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval", "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs", "FAME: Towards Factual Multi-Task Model Editing", "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios", "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "summarization": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval", "Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment", "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps", "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "Bayesian Calibration of Win Rate Estimation with LLM Evaluators", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "Optimized Speculative Sampling for GPU Hardware Accelerators", "A Survey of AMR Applications", "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works", "Attribute or Abstain: Large Language Models as Long Document Assistants", "A Thorough Examination of Decoding Methods in the Era of LLMs", "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents", "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation", "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "Paraphrase Types Elicit Prompt Engineering Capabilities", "RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs", "How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective", "LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability", "InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!", "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets", "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration", "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization", "Re-Evaluating Evaluation for Multilingual Summarization", "Towards Aligning Language Models with Textual Feedback", "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage", "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion", "Reformatted Alignment", "LongAlign: A Recipe for Long Context Alignment of Large Language Models", "Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning", "LoRAN: Improved Low-Rank Adaptation by a Non-Linear Transformation", "Inference-Time Language Model Alignment via Integrated Value Guidance", "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully", "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches", "An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "Event-Keyed Summarization", "MedINST: Meta Dataset of Biomedical Instructions", "Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding", "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity", "Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts", "Calibrating Long-form Generations from Large Language Models", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks", "Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness", "Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression", "A Critical Look at Meta-evaluating Summarisation Evaluation Metrics", "AXCEL: Automated eXplainable Consistency Evaluation using LLMS", "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression", "Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "passkey retrieval": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval", "PSC: Extending Context Window of Large Language Models via Phase Shift Calibration", "A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression", "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "needle-in-a-haystack retrieval": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval"], "qa summarization": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval", "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"], "summarization passkey retrieval": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval"], "passkey retrieval needle-in-a-haystack retrieval": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval"], "qa summarization passkey retrieval": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval"], "summarization passkey retrieval needle-in-a-haystack retrieval": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval"], "qa summarization passkey retrieval needle-in-a-haystack retrieval": ["LONGEMBED: Extending Embedding Models for Long Context Retrieval"], "arithmetic reasoning": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "Empowering Multi-step Reasoning across Languages via Program-Aided Language Models", "Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models", "Large Language Models Can Self-Correct with Key Condition Verification", "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding", "First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning", "Re-Reading Improves Reasoning in Large Language Models", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning", "ApiQ: Finetuning of 2-Bit Quantized Large Language Model", "Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark", "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting", "Self-training Language Models for Arithmetic Reasoning"], "common sense reasoning": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "Inference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs", "Mixed Distillation Helps Smaller Language Models Reason Better"], "addsub": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "aqua": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "gsm8k": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning", "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "Task Oriented In-Domain Data Augmentation", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting", "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation", "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement", "LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning", "Skills-in-Context: Unlocking Compositionality in Large Language Models", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "singleeq": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "singleop": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "svamp": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "Task Oriented In-Domain Data Augmentation", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "csqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "strategyqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "date understanding": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "Working Memory Identifies Reasoning Limits in Language Models", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting", "Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "arithmetic reasoning common sense reasoning": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "common sense reasoning addsub": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "addsub aqua": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "aqua gsm8k": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "gsm8k singleeq": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleeq singleop": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleop svamp": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "svamp csqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "csqa strategyqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "strategyqa date understanding": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "arithmetic reasoning common sense reasoning addsub": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "common sense reasoning addsub aqua": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "addsub aqua gsm8k": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "aqua gsm8k singleeq": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "gsm8k singleeq singleop": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleeq singleop svamp": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleop svamp csqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "svamp csqa strategyqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "csqa strategyqa date understanding": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "arithmetic reasoning common sense reasoning addsub aqua": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "common sense reasoning addsub aqua gsm8k": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "addsub aqua gsm8k singleeq": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "aqua gsm8k singleeq singleop": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "gsm8k singleeq singleop svamp": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleeq singleop svamp csqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleop svamp csqa strategyqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "svamp csqa strategyqa date understanding": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "arithmetic reasoning common sense reasoning addsub aqua gsm8k": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "common sense reasoning addsub aqua gsm8k singleeq": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "addsub aqua gsm8k singleeq singleop": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "aqua gsm8k singleeq singleop svamp": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "gsm8k singleeq singleop svamp csqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleeq singleop svamp csqa strategyqa": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "singleop svamp csqa strategyqa date understanding": ["Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"], "dialogue aspect-based sentiment quadruple analysis": ["Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"], "quadruple extraction": ["Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"], "dialogue aspect-based sentiment quadruple analysis quadruple extraction": ["Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"], "quadruple extraction sentiment analysis": ["Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"], "dialogue aspect-based sentiment quadruple analysis quadruple extraction sentiment analysis": ["Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"], "emotion classification": ["Integrating Plutchik's Theory with Mixture of Experts for Enhancing Emotion Classification", "Message Passing on Semantic-Anchor-Graphs for Fine-grained Emotion Representation Learning and Classification", "Does Large Language Model Contain Task-Specific Neurons?", "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing", "TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "event causality identification": ["In-context Contrastive Learning for Event Causality Identification", "Advancing Event Causality Identification via Heuristic Semantic Dependency Inquiry Network", "Event Causality Identification with Synthetic Control", "Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering"], "paraphrase detection": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference", "ALVIN: Active Learning Via INterpolation", "Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention", "LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "context-dependent paraphrase identification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "dialog paraphrase classification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "span identification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "paraphrase detection context-dependent paraphrase identification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "context-dependent paraphrase identification dialog paraphrase classification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "dialog paraphrase classification span identification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "paraphrase detection context-dependent paraphrase identification dialog paraphrase classification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "context-dependent paraphrase identification dialog paraphrase classification span identification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "paraphrase detection context-dependent paraphrase identification dialog paraphrase classification span identification": ["What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"], "language modeling": ["Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNS", "Rethinking Token Reduction for State Space Models", "Instruction Pre-Training: Language Models are Supervised Multitask Learners", "Leading Whitespaces of Language Models' Subword Vocabulary Pose a Confound for Calculating Word Probabilities", "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages", "KidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions", "Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models", "CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling", "Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing", "Can Large Language Models Learn Independent Causal Mechanisms?", "Extending Context Window of Large Language Models from a Distributional Perspective", "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models", "Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives", "Can Transformers Learn n-gram Language Models?", "PREALIGN: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment", "Demystifying Verbatim Memorization in Large Language Models", "Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models", "Stable Language Model Pre-training by Reducing Embedding Variability", "Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "Target-Aware Language Modeling via Granular Data Sampling", "Chain and Causal Attention for Efficient Entity Tracking", "Turn Waste into Worth: Rectifying Top-k Router of MoE", "Evaluating n-Gram Novelty of Language Models Using RUSTY-DAWG", "Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention", "A Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors", "GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients", "LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training", "Scaling Laws for Linear Complexity Language Models", "Do LLMs learn a true syntactic universal?", "Calibrating Language Models with Adaptive Temperature Scaling", "How to Compute the Probability of a Word", "Language models and brains align due to more than next-word prediction and word-level information", "Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models", "Semformer: Transformer Language Models with Semantic Planning", "Transformers are Multi-State RNNS", "Generation with Dynamic Vocabulary", "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models", "Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?", "Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules", "ApiQ: Finetuning of 2-Bit Quantized Large Language Model", "Scalable Data Ablation Approximations for Language Models through Modular Training and Merging", "T-FREE: Subword Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings", "Is Child-Directed Speech Effective Training Data for Language Models?", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes", "Tending Towards Stability: Convergence Challenges in Small Language Models", "Taking a Deep Breath: Enhancing Language Modeling of Large Language Models with Sentinel Tokens", "On the token distance modeling ability of higher RoPE attention dimension", "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models", "LONGHEADS: Multi-Head Attention is Secretly a Long Context Processor", "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models", "Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding", "Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts", "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs", "Generalized Measures of Anticipation and Responsivity in Online Language Processing", "Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers", "Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation", "Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification", "Exploring Quantization for Efficient Pre-Training of Transformer Language Models", "Empirical Prior for Text Autoencoders", "Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning", "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression", "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression", "Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models", "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models"], "syntactic generalization": ["Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNS"], "language modeling syntactic generalization": ["Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNS"], "data synthesis": ["Large Language Models for Data Annotation and Synthesis: A Survey", "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search"], "LLM application": ["Large Language Models for Data Annotation and Synthesis: A Survey"], "data annotation data synthesis": ["Large Language Models for Data Annotation and Synthesis: A Survey"], "data synthesis LLM application": ["Large Language Models for Data Annotation and Synthesis: A Survey"], "data annotation data synthesis LLM application": ["Large Language Models for Data Annotation and Synthesis: A Survey"], "rte": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "On Training Data Influence of GPT Models", "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models", "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "Skills-in-Context: Unlocking Compositionality in Large Language Models", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "sst-2": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "On Training Data Influence of GPT Models", "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "sst-5": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "qnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "snli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mr": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "cb": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "boolq": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "On Training Data Influence of GPT Models", "When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models", "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models", "CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "wsc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "multirc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "record": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "squad": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Model Balancing Helps Low-data Training and Fine-tuning", "LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "rte sst-2": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "On Training Data Influence of GPT Models"], "sst-2 sst-5": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "sst-5 qnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "qnli mnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", "Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation"], "mnli snli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "snli mr": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mr cb": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "cb boolq": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "boolq wsc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "wsc multirc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "multirc copa": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "copa record": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "record squad": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "rte sst-2 sst-5": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "sst-2 sst-5 qnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "sst-5 qnli mnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "qnli mnli snli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mnli snli mr": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "snli mr cb": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mr cb boolq": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "cb boolq wsc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "boolq wsc multirc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "wsc multirc copa": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "multirc copa record": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "copa record squad": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "rte sst-2 sst-5 qnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "sst-2 sst-5 qnli mnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "sst-5 qnli mnli snli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "qnli mnli snli mr": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mnli snli mr cb": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "snli mr cb boolq": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mr cb boolq wsc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "cb boolq wsc multirc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "boolq wsc multirc copa": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "wsc multirc copa record": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "multirc copa record squad": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "rte sst-2 sst-5 qnli mnli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "sst-2 sst-5 qnli mnli snli": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "sst-5 qnli mnli snli mr": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "qnli mnli snli mr cb": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mnli snli mr cb boolq": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "snli mr cb boolq wsc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "mr cb boolq wsc multirc": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "cb boolq wsc multirc copa": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "boolq wsc multirc copa record": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "wsc multirc copa record squad": ["AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning"], "knowledge editing": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning", "Interpretability-based Tailored Knowledge Editing in Transformers", "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation", ">Why Does New Knowledge Create Messy Ripple Effects in LLMs?", "Commonsense Knowledge Editing Based on Free-Text in LLMs", "AKEW: Assessing Knowledge Editing in the Wild", "Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing", "Editing Conceptual Knowledge for Large Language Models", "Knowledge Editing in Language Models via Adapted Direct Preference Optimization", "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning", "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models", "Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities", "Cross-Lingual Multi-Hop Knowledge Editing", "Updating Large Language Models' Memories with Time Constraints", "LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments"], "natural language understanding": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning", "On Training Data Influence of GPT Models", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models", "Perceptions of Linguistic Uncertainty by Language Models and Humans", "MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations", "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate", "ApiQ: Finetuning of 2-Bit Quantized Large Language Model", "FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding", "Head-wise Shareable Attention for Large Language Models", "BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks", "Leveraging Grammar Induction for Language Understanding and Generation", "Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages", "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation", "StraGo: Harnessing Strategic Guidance for Prompt Optimization", "Zero-shot Commonsense Reasoning over Machine Imagination", "ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning", "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "knowledge editing commonsense reasoning": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning", "Commonsense Knowledge Editing Based on Free-Text in LLMs"], "commonsense reasoning arithmetic reasoning": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models"], "arithmetic reasoning instruction following": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "instruction following natural language understanding": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "knowledge editing commonsense reasoning arithmetic reasoning": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "commonsense reasoning arithmetic reasoning instruction following": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "arithmetic reasoning instruction following natural language understanding": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "knowledge editing commonsense reasoning arithmetic reasoning instruction following": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "commonsense reasoning arithmetic reasoning instruction following natural language understanding": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "knowledge editing commonsense reasoning arithmetic reasoning instruction following natural language understanding": ["RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"], "open-domain question answering": ["BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering", "REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering", "Large Language Models Can Self-Correct with Key Condition Verification", "Where am I? Large Language Models Wandering between Semantics and Structures in Long Contexts", "Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "Improving Zero-shot LLM Re-Ranker with Risk Minimization", "RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation", "RaFe: Ranking Feedback Improves Query Rewriting for RAG", "Chain-of-Rewrite: Aligning Question and Documents for Open-Domain Question Answering", "Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts", "Evidence Retrieval for Fact Verification using Multi-stage Reranking", "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations", "QPaug: Question and Passage Augmentation for Open-Domain Question Answering of LLMs", "Exploring Hint Generation Approaches in Open-Domain Question Answering"], "question answering open-domain question answering": ["BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"], "narrative analysis": ["HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs", "Are Large Language Models Capable of Generating Human-Level Narratives?"], "empathy prediction": ["HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"], "style extraction": ["HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"], "narrative analysis empathy prediction": ["HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"], "empathy prediction style extraction": ["HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"], "narrative analysis empathy prediction style extraction": ["HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"], "reinforcement learning from human feedback": ["Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence", "WPO: Enhancing RLHF with Weighted Preference Optimization", "Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning", "A Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors", "Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging", "Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents", "Rethinking the Role of Proxy Rewards in Language Model Alignment", "Filtered Direct Preference Optimization", "Reward Modeling Requires Automatic Adjustment Based on Data Quality", "Semi-Supervised Reward Modeling via Iterative Self-Training", "Step-level Value Preference Optimization for Mathematical Reasoning", "Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models without Preference Data", "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback", "DEFT: Distribution-guided Efficient Fine-Tuning for Human Alignment", "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "conditional benchmarks": ["Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"], "open-ended benchmarks": ["Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"], "reinforcement learning from human feedback conditional benchmarks": ["Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"], "conditional benchmarks open-ended benchmarks": ["Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"], "reinforcement learning from human feedback conditional benchmarks open-ended benchmarks": ["Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"], "cross-cultural recipe retrieval": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"], "query rewriting": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval", "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search", "Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers", "RaFe: Ranking Feedback Improves Query Rewriting for RAG"], "re-ranking": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval", "Improving Zero-shot LLM Re-Ranker with Risk Minimization"], "cultural adaptation": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval", "Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S.", "Implicit Personalization in Language Models: A Systematic Study"], "cross-cultural recipe retrieval query rewriting": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"], "query rewriting re-ranking": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"], "re-ranking cultural adaptation": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"], "cross-cultural recipe retrieval query rewriting re-ranking": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"], "query rewriting re-ranking cultural adaptation": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"], "cross-cultural recipe retrieval query rewriting re-ranking cultural adaptation": ["Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"], "medical visual question answering": ["RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models", "MedCoT: Medical Chain of Thought via Hierarchical Expert", "Self-Training Large Language and Vision Assistant for Medical Question-Answering", "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models", "Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models"], "report generation": ["RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models", "SATYRN: A Platform for Analytics Augmented Generation", "Holistic Evaluation for Interleaved Text-and-Image Generation", "MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical visual question answering report generation": ["RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models"], "cryptocurrency trading": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "financial decision-making": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "explanation generation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading", "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving", "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs", "Enhancing High-order Interaction Awareness in LLM-based Recommender Model", "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "market trend analysis": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "news impact interpretation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "investment strategy deliberation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "performance reflection": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "market volatility navigation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "data-driven strategy establishment": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "cryptocurrency trading financial decision-making": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "financial decision-making sentiment analysis": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "sentiment analysis explanation generation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "explanation generation market trend analysis": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "market trend analysis news impact interpretation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "news impact interpretation investment strategy deliberation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "investment strategy deliberation performance reflection": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "performance reflection market volatility navigation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "market volatility navigation data-driven strategy establishment": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "cryptocurrency trading financial decision-making sentiment analysis": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "financial decision-making sentiment analysis explanation generation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "sentiment analysis explanation generation market trend analysis": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "explanation generation market trend analysis news impact interpretation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "market trend analysis news impact interpretation investment strategy deliberation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "news impact interpretation investment strategy deliberation performance reflection": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "investment strategy deliberation performance reflection market volatility navigation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "performance reflection market volatility navigation data-driven strategy establishment": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "cryptocurrency trading financial decision-making sentiment analysis explanation generation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "financial decision-making sentiment analysis explanation generation market trend analysis": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "sentiment analysis explanation generation market trend analysis news impact interpretation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "explanation generation market trend analysis news impact interpretation investment strategy deliberation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "market trend analysis news impact interpretation investment strategy deliberation performance reflection": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "news impact interpretation investment strategy deliberation performance reflection market volatility navigation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "investment strategy deliberation performance reflection market volatility navigation data-driven strategy establishment": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "cryptocurrency trading financial decision-making sentiment analysis explanation generation market trend analysis": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "financial decision-making sentiment analysis explanation generation market trend analysis news impact interpretation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "sentiment analysis explanation generation market trend analysis news impact interpretation investment strategy deliberation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "explanation generation market trend analysis news impact interpretation investment strategy deliberation performance reflection": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "market trend analysis news impact interpretation investment strategy deliberation performance reflection market volatility navigation": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "news impact interpretation investment strategy deliberation performance reflection market volatility navigation data-driven strategy establishment": ["CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading"], "natural language processing": ["A Survey on In-context Learning", "Model Balancing Helps Low-data Training and Fine-tuning", "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese", "A Generic Method for Fine-grained Category Discovery in Natural Language Texts", "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context", "Knowledge-Centric Hallucination Detection", "Toward Compositional Behavior in Neural Models: A Survey of Current Views", "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation", "Pragmatic Norms Are All You Need \u2013 Why The Symbol Grounding Problem Does Not Apply to LLMs", "Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models", "Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models", "IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method", "Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions", "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data", "Calibrating Language Models with Adaptive Temperature Scaling", "RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference", "InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem", "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models", "Self-Renewal Prompt Optimizing with Implicit Reasoning", "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation", "Enhancing Byzantine-Resistant Aggregations with Client Embedding", "Crisis counselor language and perceived genuine concern in crisis conversations", "Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation", "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling", "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection", "Resilience of Large Language Models for Noisy Instructions", "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "few-shot learning": ["A Survey on In-context Learning", "Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models", "INDUCT-LEARN: Short Phrase Prompting with Instruction Induction", "Learning to Retrieve Iteratively for In-Context Learning", "Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning", "Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights", "Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations", "NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data", "OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation", "Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning", "Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning", "InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters", "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches", "Disentangling Questions from Query Generation for Task-Adaptive Retrieval", "Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting", "Scalable and Domain-General Abstractive Proposition Segmentation", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "prompt engineering": ["A Survey on In-context Learning", "Moral Foundations of Large Language Models", "AMPO: Automatic Multi-Branched Prompt Optimization", "The Death and Life of Great Prompts: Analyzing the Evolution of LLM Prompts from the Structural Perspective", "Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering", "Creative and Context-Aware Translation of East Asian Idioms with GPT-4", "Can't Remember Details in Long Documents? You Need Some R&R"], "model pre-training": ["A Survey on In-context Learning"], "demonstration selection": ["A Survey on In-context Learning", "LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "knowledge updating": ["A Survey on In-context Learning", "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "data engineering": ["A Survey on In-context Learning", "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "model augmentation": ["A Survey on In-context Learning"], "natural language processing few-shot learning": ["A Survey on In-context Learning"], "few-shot learning meta-learning": ["A Survey on In-context Learning"], "meta-learning prompt engineering": ["A Survey on In-context Learning"], "prompt engineering model pre-training": ["A Survey on In-context Learning"], "model pre-training demonstration selection": ["A Survey on In-context Learning"], "demonstration selection knowledge updating": ["A Survey on In-context Learning"], "knowledge updating data engineering": ["A Survey on In-context Learning"], "data engineering model augmentation": ["A Survey on In-context Learning"], "natural language processing few-shot learning meta-learning": ["A Survey on In-context Learning"], "few-shot learning meta-learning prompt engineering": ["A Survey on In-context Learning"], "meta-learning prompt engineering model pre-training": ["A Survey on In-context Learning"], "prompt engineering model pre-training demonstration selection": ["A Survey on In-context Learning"], "model pre-training demonstration selection knowledge updating": ["A Survey on In-context Learning"], "demonstration selection knowledge updating data engineering": ["A Survey on In-context Learning"], "knowledge updating data engineering model augmentation": ["A Survey on In-context Learning"], "natural language processing few-shot learning meta-learning prompt engineering": ["A Survey on In-context Learning"], "few-shot learning meta-learning prompt engineering model pre-training": ["A Survey on In-context Learning"], "meta-learning prompt engineering model pre-training demonstration selection": ["A Survey on In-context Learning"], "prompt engineering model pre-training demonstration selection knowledge updating": ["A Survey on In-context Learning"], "model pre-training demonstration selection knowledge updating data engineering": ["A Survey on In-context Learning"], "demonstration selection knowledge updating data engineering model augmentation": ["A Survey on In-context Learning"], "natural language processing few-shot learning meta-learning prompt engineering model pre-training": ["A Survey on In-context Learning"], "few-shot learning meta-learning prompt engineering model pre-training demonstration selection": ["A Survey on In-context Learning"], "meta-learning prompt engineering model pre-training demonstration selection knowledge updating": ["A Survey on In-context Learning"], "prompt engineering model pre-training demonstration selection knowledge updating data engineering": ["A Survey on In-context Learning"], "model pre-training demonstration selection knowledge updating data engineering model augmentation": ["A Survey on In-context Learning"], "document hierarchy parsing": ["DocHieNet: A Large and Diverse Dataset for Document Hierarchy Parsing"], "code generation": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation", "Automatic Instruction Evolving for Large Language Models", "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses", "Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding", "How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with Really Good Data", "Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector", "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?", "Re-ReST: Reflection-Reinforced Self-Training for Language Agents", "Free your mouse! Command Large Language Models to Generate Code to Format Word Documents", "CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing", "RAR: Retrieval-augmented retrieval for code generation in low-resource languages", "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "Improving Minimum Bayes Risk Decoding with Multi-Prompt", "MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems", "Large Language Model-based Human-Agent Collaboration for Complex Task Solving", "Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation", "EvOR: Evolving Retrieval for Code Generation", "CodeFort: Robust Training for Code Generation Models", "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection", "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision", "CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code", "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft", "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity", "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models", "On Leakage of Code Generation Evaluation Datasets", "SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement", "One-to-many testing for code generation from (just) natural language", "Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation", "PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs"], "knowledge distillation": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation", "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale", "MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval", "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server", "FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation", "Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach", "Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation", "Dual-Space Knowledge Distillation for Large Language Models", "PAIRDISTILL: Pairwise Relevance Distillation for Dense Retrieval", "xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics", "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation", "Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning", "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning", "Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "response refinement": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "modular programming": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "adaptive response evolution": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "code generation knowledge distillation": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "knowledge distillation response refinement": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "response refinement modular programming": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "modular programming adaptive response evolution": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "code generation knowledge distillation response refinement": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "knowledge distillation response refinement modular programming": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "response refinement modular programming adaptive response evolution": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "code generation knowledge distillation response refinement modular programming": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "knowledge distillation response refinement modular programming adaptive response evolution": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "code generation knowledge distillation response refinement modular programming adaptive response evolution": ["AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"], "multimodal hallucination mitigation": ["EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models"], "LLM pruning": ["Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization", "Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning", "Pruning Foundation Models for High Accuracy without Retraining"], "reconstruction error minimization": ["Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"], "generalization performance": ["Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"], "LLM pruning reconstruction error minimization": ["Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"], "reconstruction error minimization generalization performance": ["Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"], "LLM pruning reconstruction error minimization generalization performance": ["Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"], "simultaneous machine translation": ["LLMs Are Zero-Shot Context-Aware Simultaneous Translators", "PsFuture: A Pseudo-Future-based Zero-Shot Adaptive Policy for Simultaneous Machine Translation", "TRANSLLAMA: LLM-based Simultaneous Translation System"], "peer review simulation": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "bias analysis": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents", "Humans or LLMs as the Judge? A Study on Judgement Bias", "Statistical Uncertainty in Word Embeddings: GloVe-V", "Hate Personified: Investigating the role of LLMs in content moderation", "From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment", "Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models", "Modeling Gender and Dialect Bias in Automatic Speech Recognition"], "review quality assessment": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "impact of reviewer characteristics": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "meta-review analysis": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "peer review simulation bias analysis": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "bias analysis review quality assessment": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "review quality assessment impact of reviewer characteristics": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "impact of reviewer characteristics meta-review analysis": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "peer review simulation bias analysis review quality assessment": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "bias analysis review quality assessment impact of reviewer characteristics": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "review quality assessment impact of reviewer characteristics meta-review analysis": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "peer review simulation bias analysis review quality assessment impact of reviewer characteristics": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "bias analysis review quality assessment impact of reviewer characteristics meta-review analysis": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "peer review simulation bias analysis review quality assessment impact of reviewer characteristics meta-review analysis": ["AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents"], "conversational search": ["ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval", "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "dense retrieval": ["ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval", "Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment", "PAIRDISTILL: Pairwise Relevance Distillation for Dense Retrieval"], "language model adaptation": ["ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval", "Unsupervised Human Preference Learning", "SLANG: New Concept Comprehension of Large Language Models", "Gradient Localization Improves Lifelong Pretraining of Language Models"], "conversational search dense retrieval": ["ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval"], "dense retrieval language model adaptation": ["ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval"], "conversational search dense retrieval language model adaptation": ["ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval"], "LLM evaluation": ["Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments", "A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models", "Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts", "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context", "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "PARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data", "Split and Merge: Aligning Position Biases in LLM-based Evaluators", "A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations", "Towards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey", "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists", "Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs", "Assessing and Verifying Task Utility in LLM-Powered Applications", "An Open-Source Data Contamination Report for Large Language Models", "Can AI Relate: Testing Large Language Model Response for Mental Health Support", "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios", "Adversarial Math Word Problem Generation", "Self-Evaluation of Large Language Model based on Glass-box Features", "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs", "Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation", "Knowledge-based Consistency Testing of Large Language Models", "SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs", "Cognitive Bias in Decision-Making with LLMs", "Compare without Despair: Reliable Preference Evaluation with Generation SEPARABILITY", "TOWER: Tree Organized Weighting for Evaluating Complex Instructions", "Are Large Language Models Consistent over Value-laden Questions?", "SedarEval: Automated Evaluation using Self-Adaptive Rubrics"], "pairwise preference evaluation": ["Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"], "LLM evaluation prompt optimization": ["Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"], "prompt optimization pairwise preference evaluation": ["Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"], "LLM evaluation prompt optimization pairwise preference evaluation": ["Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"], "legal case retrieval": ["Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation", "Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs"], "natural language inference": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models", "FuseGen: PLM Fusion for Data-generation based Zero-shot Learning", "In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search", "QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios", "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving", "How Hard is this Test Set?\nNLI Characterization by Exploiting Training Dynamics", "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws", "Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks", "How Do Humans Write Code? Large Models Do It the Same Way Too", "Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars", "Revealing the Parallel Multilingual Learning within Large Language Models", "Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners", "Attribute or Abstain: Large Language Models as Long Document Assistants", "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic", "Atomic Inference for NLI with Generated Facts as Atoms", "More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation", "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models", "Latent Concept-based Explanation of NLP Models", "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives", "Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning", "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion", "VerifyMatch: A Semi-Supervised Learning Paradigm for Natural Language Inference with Confidence-Aware MixUp", "A Morphology-Based Investigation of Positional Encodings", "GottBERT: a pure German Language Model", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage", "FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding", "RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference", "Inference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs", "Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets", "Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text", "ALVIN: Active Learning Via INterpolation", "Measuring the Robustness of NLP Models to Domain Shifts", "Translation of Multifaceted Data without Re-Training of Machine Translation Systems", "Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals", "Self-Contradictory Reasoning Evaluation and Detection", "A Survey on Natural Language Counterfactual Generation", "DADEE: Unsupervised Domain Adaptation in Early Exit PLMS", "An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention", "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation", "How Entangled is Factuality and Deception in German?", "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection", "Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?", "\u201cSeeing the Big through the Small\u201d: Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?", "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study", "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization", "CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models", "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models", "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation", "Inference and Verbalization Functions During In-Context Learning"], "classification": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information", "Attribute or Abstain: Large Language Models as Long Document Assistants", "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?", "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity", "HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy", "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion", "Computational Meme Understanding: A Survey", "Adversarial Text Generation using Large Language Models for Dementia Detection", "Reformatted Alignment", "Categorial Grammar Supertagging via Large Language Models", "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios", "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent", "Rethinking Code Refinement: Learning to Judge Code Efficiency", "Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability", "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models", "Downstream Trade-offs of a Family of Text Watermarks", "Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models", "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains", "Unified Active Retrieval for Retrieval Augmented Generation"], "multi-choice question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "abstractive summarization": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "Safely Learning with Private Data: A Federated Learning Framework for Large Language Model", "An Audit on the Perspectives and Challenges of Hallucinations in NLP", "Revealing the Parallel Multilingual Learning within Large Language Models", "Model-based Preference Optimization in Abstractive Summarization without Human Feedback", "Measuring the Robustness of NLP Models to Domain Shifts"], "open domain question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "natural language inference classification": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "classification multi-choice question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "multi-choice question answering abstractive summarization": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "abstractive summarization open domain question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "natural language inference classification multi-choice question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "classification multi-choice question answering abstractive summarization": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "multi-choice question answering abstractive summarization open domain question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "natural language inference classification multi-choice question answering abstractive summarization": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "classification multi-choice question answering abstractive summarization open domain question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "natural language inference classification multi-choice question answering abstractive summarization open domain question answering": ["Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process"], "qud parsing": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "anchor selection": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "question generation": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing", "Paraphrase Types Elicit Prompt Engineering Capabilities", "Measuring the Robustness of NLP Models to Domain Shifts", "Translation of Multifaceted Data without Re-Training of Machine Translation Systems", "Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain", "Evaluation of Question Answer Generation for Portuguese: Insights and Datasets", "Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA", "Enable Fast Sampling for Seq2Seq Text Diffusion", "Reference-based Metrics Disprove Themselves in Question Generation"], "discourse structure": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "qud parsing anchor selection": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "anchor selection question generation": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "question generation discourse structure": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "qud parsing anchor selection question generation": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "anchor selection question generation discourse structure": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "qud parsing anchor selection question generation discourse structure": ["QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"], "social intelligence question answering": ["Mitigating Language Bias of LMMs in Social Intelligence Understanding with Virtual Counterfactual Calibration"], "scientific ML": ["Model Balancing Helps Low-data Training and Fine-tuning"], "glue": ["Model Balancing Helps Low-data Training and Fine-tuning", "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models", "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers", "IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules", "Leveraging Grammar Induction for Language Understanding and Generation", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models"], "superglue": ["Model Balancing Helps Low-data Training and Fine-tuning", "Safely Learning with Private Data: A Federated Learning Framework for Large Language Model", "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models", "Turn Waste into Worth: Rectifying Top-k Router of MoE", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes", "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models", "LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "scienceqa": ["Model Balancing Helps Low-data Training and Fine-tuning", "ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback", "On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models", "Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "biomedical text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "computer science text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "news text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "pde solving": ["Model Balancing Helps Low-data Training and Fine-tuning"], "natural language processing scientific ML": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scientific ML glue": ["Model Balancing Helps Low-data Training and Fine-tuning"], "glue superglue": ["Model Balancing Helps Low-data Training and Fine-tuning", "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models"], "superglue squad": ["Model Balancing Helps Low-data Training and Fine-tuning", "LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "squad scienceqa": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scienceqa biomedical text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "biomedical text classification computer science text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "computer science text classification news text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "news text classification pde solving": ["Model Balancing Helps Low-data Training and Fine-tuning"], "natural language processing scientific ML glue": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scientific ML glue superglue": ["Model Balancing Helps Low-data Training and Fine-tuning"], "glue superglue squad": ["Model Balancing Helps Low-data Training and Fine-tuning"], "superglue squad scienceqa": ["Model Balancing Helps Low-data Training and Fine-tuning"], "squad scienceqa biomedical text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scienceqa biomedical text classification computer science text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "biomedical text classification computer science text classification news text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "computer science text classification news text classification pde solving": ["Model Balancing Helps Low-data Training and Fine-tuning"], "natural language processing scientific ML glue superglue": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scientific ML glue superglue squad": ["Model Balancing Helps Low-data Training and Fine-tuning"], "glue superglue squad scienceqa": ["Model Balancing Helps Low-data Training and Fine-tuning"], "superglue squad scienceqa biomedical text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "squad scienceqa biomedical text classification computer science text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scienceqa biomedical text classification computer science text classification news text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "biomedical text classification computer science text classification news text classification pde solving": ["Model Balancing Helps Low-data Training and Fine-tuning"], "natural language processing scientific ML glue superglue squad": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scientific ML glue superglue squad scienceqa": ["Model Balancing Helps Low-data Training and Fine-tuning"], "glue superglue squad scienceqa biomedical text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "superglue squad scienceqa biomedical text classification computer science text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "squad scienceqa biomedical text classification computer science text classification news text classification": ["Model Balancing Helps Low-data Training and Fine-tuning"], "scienceqa biomedical text classification computer science text classification news text classification pde solving": ["Model Balancing Helps Low-data Training and Fine-tuning"], "dialog generation": ["Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"], "cross-lingual alignment": ["Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"], "summarization dialog generation": ["Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"], "dialog generation cross-lingual alignment": ["Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"], "summarization dialog generation cross-lingual alignment": ["Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"], "in-domain accuracy": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "data efficiency": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "zero-shot generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "lengthy retrieval generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "instruction-based retrieval": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "multi-task learning": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment", "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic", "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention", "Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing", "Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "dense retrieval in-domain accuracy": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "in-domain accuracy data efficiency": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "data efficiency zero-shot generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "zero-shot generalization lengthy retrieval generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "lengthy retrieval generalization instruction-based retrieval": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "instruction-based retrieval multi-task learning": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "dense retrieval in-domain accuracy data efficiency": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "in-domain accuracy data efficiency zero-shot generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "data efficiency zero-shot generalization lengthy retrieval generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "zero-shot generalization lengthy retrieval generalization instruction-based retrieval": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "lengthy retrieval generalization instruction-based retrieval multi-task learning": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "dense retrieval in-domain accuracy data efficiency zero-shot generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "in-domain accuracy data efficiency zero-shot generalization lengthy retrieval generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "data efficiency zero-shot generalization lengthy retrieval generalization instruction-based retrieval": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "zero-shot generalization lengthy retrieval generalization instruction-based retrieval multi-task learning": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "dense retrieval in-domain accuracy data efficiency zero-shot generalization lengthy retrieval generalization": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "in-domain accuracy data efficiency zero-shot generalization lengthy retrieval generalization instruction-based retrieval": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "data efficiency zero-shot generalization lengthy retrieval generalization instruction-based retrieval multi-task learning": ["Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"], "knowledge graph reasoning": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning", "CNEQ: Incorporating numbers into Knowledge Graph Reasoning", "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "entity prediction": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning", "Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text", "CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "knowledge alignment": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning", "Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging"], "entity reranking": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"], "knowledge graph reasoning entity prediction": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"], "entity prediction knowledge alignment": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"], "knowledge alignment entity reranking": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"], "knowledge graph reasoning entity prediction knowledge alignment": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"], "entity prediction knowledge alignment entity reranking": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"], "knowledge graph reasoning entity prediction knowledge alignment entity reranking": ["A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"], "helpfulness": ["Towards Tool Use Alignment of Large Language Models", "PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "harMLessness": ["Towards Tool Use Alignment of Large Language Models", "BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment", "PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "autonomy": ["Towards Tool Use Alignment of Large Language Models"], "helpfulness harMLessness": ["Towards Tool Use Alignment of Large Language Models"], "harMLessness autonomy": ["Towards Tool Use Alignment of Large Language Models"], "helpfulness harMLessness autonomy": ["Towards Tool Use Alignment of Large Language Models"], "corpus rating": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "text tagging": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "text editing": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "language model pre-training data enhancement": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "data engineering corpus rating": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "corpus rating text tagging": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "text tagging text editing": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "text editing language model pre-training data enhancement": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "data engineering corpus rating text tagging": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "corpus rating text tagging text editing": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "text tagging text editing language model pre-training data enhancement": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "data engineering corpus rating text tagging text editing": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "corpus rating text tagging text editing language model pre-training data enhancement": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "data engineering corpus rating text tagging text editing language model pre-training data enhancement": ["DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"], "summarization question answering": ["Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "ai alignment": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment", "On the Relationship between Truth and Political Bias in Language Models"], "multi-objective optimization": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment", "On Diversified Preferences of Large Language Model Alignment"], "human preference modeling": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "controllable generation": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "ai alignment multi-objective optimization": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "multi-objective optimization human preference modeling": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "human preference modeling controllable generation": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "ai alignment multi-objective optimization human preference modeling": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "multi-objective optimization human preference modeling controllable generation": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "ai alignment multi-objective optimization human preference modeling controllable generation": ["Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"], "conversational recommendation": ["Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation", "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "recommendation": ["Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation", "Decoding Matters: Addressing Amplification Bias and Homogeneity Issue for LLM-based Recommendation", "Make Large Language Model a Better Ranker"], "conversation": ["Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation", "BLSP-Emo: Towards Empathetic Large Speech-Language Models", "Reformatted Alignment"], "conversational recommendation recommendation": ["Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"], "recommendation conversation": ["Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"], "conversational recommendation recommendation conversation": ["Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"], "visual question answering": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors", "MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering", "Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering", "Tag-grounded Visual Instruction Tuning with Retrieval Augmentation", "DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models", "World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering", "From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis", "Concept-skill Transferability-based Data Selection for Large Vision-Language Models", "How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?", "Benchmarking Vision Language Models for Cultural Understanding", "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models", "MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model", "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning", "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification", "Attribute Diversity Determines the Systematicity Gap in VQA", "Large Language Models Know What is Key Visual Entity: An LLM-assisted Multimodal Retrieval for VQA", "Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?", "CommVQA: Situating Visual Question Answering in Communicative Contexts", "Re-ReST: Reflection-Reinforced Self-Training for Language Agents", "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension", "ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments", "The Instinctive Bias: Spurious Images lead to Illusion in MLLMs", "Reasoning Paths with Reference Objects Elicit Quantitative Spatial Reasoning in Large Vision-Language Models", "In-Context Compositional Generalization for Large Vision-Language Models", "Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory", "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems", "Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant", "Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities", "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models", "De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP", "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "Nearest Neighbor Normalization Improves Multimodal Retrieval", "SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM", "Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models", "Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP", "EchoSight: Advancing Visual-Language Models with Wiki Knowledge", "A Robust Dual-debiasing VQA Model based on Counterfactual Causal Effect", "M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks", "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models", "Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts", "Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs", "PropTest: Automatic Property Testing for Improved Visual Programming", "Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA", "AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for Vision-Language Models", "Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models", "VDebugger: Harnessing Execution Feedback for Debugging Visual Programs", "Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models", "Zero-shot Commonsense Reasoning over Machine Imagination", "\u201cWhat is the value of {templates}?\u201d Rethinking Document Information Extraction Datasets for LLMs", "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization", "Why do LLaVA Vision-Language Models Reply to Images in English?", "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM", "Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective", "TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling", "Towards One-to-Many Visual Question Answering"], "multiple-choice visual question answering": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "image understanding": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors", "TroL: Traversal of Layers for Large Language and Vision Models", "MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "cross-modality reasoning": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "visual question answering multiple-choice visual question answering": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "multiple-choice visual question answering image understanding": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "image understanding cross-modality reasoning": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "cross-modality reasoning data augmentation": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "visual question answering multiple-choice visual question answering image understanding": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "multiple-choice visual question answering image understanding cross-modality reasoning": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "image understanding cross-modality reasoning data augmentation": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "visual question answering multiple-choice visual question answering image understanding cross-modality reasoning": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "multiple-choice visual question answering image understanding cross-modality reasoning data augmentation": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "visual question answering multiple-choice visual question answering image understanding cross-modality reasoning data augmentation": ["Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"], "cross-modal retrieval": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation", "Nearest Neighbor Normalization Improves Multimodal Retrieval", "MATE: Meet At The Embedding - Connecting Images with Long Texts", "Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design"], "composed image retrieval": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "fashion image generation": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "cross-modal retrieval image captioning": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "image captioning composed image retrieval": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "composed image retrieval fashion image generation": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "cross-modal retrieval image captioning composed image retrieval": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "image captioning composed image retrieval fashion image generation": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "cross-modal retrieval image captioning composed image retrieval fashion image generation": ["UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"], "information diffusion": ["Tracking the perspectives of interacting language models"], "communication networks": ["Tracking the perspectives of interacting language models"], "perspective analysis": ["Tracking the perspectives of interacting language models"], "information diffusion language models": ["Tracking the perspectives of interacting language models"], "language models communication networks": ["Tracking the perspectives of interacting language models"], "communication networks perspective analysis": ["Tracking the perspectives of interacting language models"], "information diffusion language models communication networks": ["Tracking the perspectives of interacting language models"], "language models communication networks perspective analysis": ["Tracking the perspectives of interacting language models"], "information diffusion language models communication networks perspective analysis": ["Tracking the perspectives of interacting language models"], "visual-based entity question answering": ["MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering"], "visual question answering visual-based entity question answering": ["MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering"], "consistency evaluation": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?", "RepEval: Effective Text Evaluation with LLM Representation", "From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items", "AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "hard-to-easy inconsistency detection": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "metric design": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "benchmark creation": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?", "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention", "MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language", "CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules", "SedarEval: Automated Evaluation using Self-Adaptive Rubrics"], "fine-tuning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?", "Fast Forwarding Low-Rank Training", "Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models", "Large Language Models Can Be Contextual Privacy Protection Learners", "MIXTURE-OF-SKILLS: Learning to Optimize Data Usage for Fine-Tuning Large Language Models", "GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients", "On the Empirical Complexity of Reasoning and Planning in LLMs", "Private prediction for large-scale synthetic text generation", "Step-level Value Preference Optimization for Mathematical Reasoning", "Leveraging Web-Crawled Data for High-Quality Fine-Tuning", "TuringQ: Benchmarking AI Comprehension in Theory of Computation", "QEFT: Quantization for Efficient Fine-Tuning of LLMs"], "in-context learning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?", "Take Off the Training Wheels! Progressive In-Context Learning for Effective Alignment", "How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning", "Interpretability-based Tailored Knowledge Editing in Transformers", "EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning", "Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems", "Focused Large Language Models are Stable Many-Shot Learners", "Learning to Retrieve Iteratively for In-Context Learning", "Position Engineering: Boosting Large Language Models through Positional Information Manipulation", "Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning", "Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning", "Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning", "SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation", "On the In-context Generation of Language Models", "Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models", "Self-AMPLIFY : Improving Small Language Models with Self Post Hoc Explanations", "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach", "A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences", "Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning", "Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!", "Semformer: Transformer Language Models with Semantic Planning", "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models", "Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL", "On the Empirical Complexity of Reasoning and Planning in LLMs", "LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning", "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning", "Private prediction for large-scale synthetic text generation", "How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment", "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning", "Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression", "Large Language Models are In-context Teachers for Knowledge Reasoning"], "consistency evaluation hard-to-easy inconsistency detection": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "hard-to-easy inconsistency detection metric design": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "metric design benchmark creation": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "benchmark creation fine-tuning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "fine-tuning in-context learning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "consistency evaluation hard-to-easy inconsistency detection metric design": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "hard-to-easy inconsistency detection metric design benchmark creation": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "metric design benchmark creation fine-tuning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "benchmark creation fine-tuning in-context learning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "consistency evaluation hard-to-easy inconsistency detection metric design benchmark creation": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "hard-to-easy inconsistency detection metric design benchmark creation fine-tuning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "metric design benchmark creation fine-tuning in-context learning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "consistency evaluation hard-to-easy inconsistency detection metric design benchmark creation fine-tuning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "hard-to-easy inconsistency detection metric design benchmark creation fine-tuning in-context learning": ["Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"], "LLM agent": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "interactive tasks": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "online shopping": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "embodied housework": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "sql querying": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "LLM agent interactive tasks": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "interactive tasks online shopping": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "online shopping embodied housework": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "embodied housework sql querying": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "LLM agent interactive tasks online shopping": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "interactive tasks online shopping embodied housework": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "online shopping embodied housework sql querying": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "LLM agent interactive tasks online shopping embodied housework": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "interactive tasks online shopping embodied housework sql querying": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "LLM agent interactive tasks online shopping embodied housework sql querying": ["Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"], "standard-aligned content generation": ["STANDARDIZE: Aligning Language Models with Expert-Defined Standards for Content Generation"], "cross-domain named entity recognition": ["Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective"], "harmful output": ["Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models"], "enforced information": ["Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models"], "harmful output enforced information": ["Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models"], "scene graph generation": ["Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement", "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "predicate classification": ["Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement"], "scene graph classification": ["Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement"], "scene graph generation predicate classification": ["Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement"], "predicate classification scene graph classification": ["Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement"], "scene graph generation predicate classification scene graph classification": ["Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement"], "LLM text generation": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "copyright compliance": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "evaluation benchmark": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation", "AKEW: Assessing Knowledge Editing in the Wild", "LONGGENBENCH: Long-context Generation Benchmark", "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers"], "safeguard bypassing attacks": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "effective defenses": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "LLM text generation copyright compliance": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "copyright compliance evaluation benchmark": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "evaluation benchmark safeguard bypassing attacks": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "safeguard bypassing attacks effective defenses": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "LLM text generation copyright compliance evaluation benchmark": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "copyright compliance evaluation benchmark safeguard bypassing attacks": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "evaluation benchmark safeguard bypassing attacks effective defenses": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "LLM text generation copyright compliance evaluation benchmark safeguard bypassing attacks": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "copyright compliance evaluation benchmark safeguard bypassing attacks effective defenses": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "LLM text generation copyright compliance evaluation benchmark safeguard bypassing attacks effective defenses": ["SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation"], "soccer game commentary generation": ["MatchTime: Towards Automatic Soccer Game Commentary Generation"], "zero-shot evaluation": ["Rethinking Token Reduction for State Space Models", "Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "text processing": ["Rethinking Token Reduction for State Space Models"], "language modeling zero-shot evaluation": ["Rethinking Token Reduction for State Space Models"], "zero-shot evaluation text processing": ["Rethinking Token Reduction for State Space Models"], "language modeling zero-shot evaluation text processing": ["Rethinking Token Reduction for State Space Models"], "knowledge base question answering": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering", "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases", "Augmenting Reasoning Capabilities of LLMs with Graph Structures in Knowledge Base Question Answering", "SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions"], "question parsing": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "uri linking": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "query construction": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "answer generation": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering", "Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues", "MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "knowledge base question answering question parsing": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "question parsing uri linking": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "uri linking query construction": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "query construction answer generation": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "knowledge base question answering question parsing uri linking": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "question parsing uri linking query construction": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "uri linking query construction answer generation": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "knowledge base question answering question parsing uri linking query construction": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "question parsing uri linking query construction answer generation": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "knowledge base question answering question parsing uri linking query construction answer generation": ["Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"], "task arithmetic": ["MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"], "model merging": ["MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic", "DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging", "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch", "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "multi-task learning task arithmetic": ["MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"], "task arithmetic model merging": ["MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"], "multi-task learning task arithmetic model merging": ["MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"], "secondary structure prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "contact prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "remote homology prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "stability prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "subcellular localization": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "protein-protein interaction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "protein folding": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "secondary structure prediction contact prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "contact prediction remote homology prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "remote homology prediction stability prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "stability prediction subcellular localization": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "subcellular localization protein-protein interaction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "protein-protein interaction protein folding": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "secondary structure prediction contact prediction remote homology prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "contact prediction remote homology prediction stability prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "remote homology prediction stability prediction subcellular localization": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "stability prediction subcellular localization protein-protein interaction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "subcellular localization protein-protein interaction protein folding": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "secondary structure prediction contact prediction remote homology prediction stability prediction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "contact prediction remote homology prediction stability prediction subcellular localization": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "remote homology prediction stability prediction subcellular localization protein-protein interaction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "stability prediction subcellular localization protein-protein interaction protein folding": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "secondary structure prediction contact prediction remote homology prediction stability prediction subcellular localization": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "contact prediction remote homology prediction stability prediction subcellular localization protein-protein interaction": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "remote homology prediction stability prediction subcellular localization protein-protein interaction protein folding": ["Retrieved Sequence Augmentation for Protein Representation Learning"], "vision-language understanding": ["HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding", "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "hallucination mitigation": ["HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding", "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models", "Word Alignment as Preference for Machine Translation", "Analysis of Plan-based Retrieval for Grounded Text Generation", "Mitigating Open-Vocabulary Caption Hallucinations", "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully", "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations", "What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models", "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations", "Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "vision-language understanding hallucination mitigation": ["HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding"], "hallucination mitigation image captioning": ["HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding"], "vision-language understanding hallucination mitigation image captioning": ["HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding"], "top-view recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view localization": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "static spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "object recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners", "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models", "ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "scene recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "relative spatial relations": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "action counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic relative spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic spatial localization": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view recognition top-view localization": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view localization static spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "static spatial reasoning dynamic spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic spatial reasoning object recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "object recognition scene recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene recognition scene counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene counting relative spatial relations": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "relative spatial relations action counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "action counting dynamic relative spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic relative spatial reasoning dynamic spatial localization": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view recognition top-view localization static spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view localization static spatial reasoning dynamic spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "static spatial reasoning dynamic spatial reasoning object recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic spatial reasoning object recognition scene recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "object recognition scene recognition scene counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene recognition scene counting relative spatial relations": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene counting relative spatial relations action counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "relative spatial relations action counting dynamic relative spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "action counting dynamic relative spatial reasoning dynamic spatial localization": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view recognition top-view localization static spatial reasoning dynamic spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view localization static spatial reasoning dynamic spatial reasoning object recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "static spatial reasoning dynamic spatial reasoning object recognition scene recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic spatial reasoning object recognition scene recognition scene counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "object recognition scene recognition scene counting relative spatial relations": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene recognition scene counting relative spatial relations action counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene counting relative spatial relations action counting dynamic relative spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "relative spatial relations action counting dynamic relative spatial reasoning dynamic spatial localization": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view recognition top-view localization static spatial reasoning dynamic spatial reasoning object recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "top-view localization static spatial reasoning dynamic spatial reasoning object recognition scene recognition": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "static spatial reasoning dynamic spatial reasoning object recognition scene recognition scene counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "dynamic spatial reasoning object recognition scene recognition scene counting relative spatial relations": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "object recognition scene recognition scene counting relative spatial relations action counting": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene recognition scene counting relative spatial relations action counting dynamic relative spatial reasoning": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "scene counting relative spatial relations action counting dynamic relative spatial reasoning dynamic spatial localization": ["TOPVIEWRS: Vision-Language Models as Top-View Spatial Reasoners"], "grammar correctness": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models"], "textual entailment": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models", "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic", "Paraphrase Types Elicit Prompt Engineering Capabilities", "RepMatch: Quantifying Cross-Instance Similarities in Representation Space", "Open-world Multi-label Text Classification with Extremely Weak Supervision", "Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging", "MedINST: Meta Dataset of Biomedical Instructions", "Variational Language Concepts for Interpreting Foundation Language Models", "Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity"], "textual similarity": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models", "RoQLlama: A Lightweight Romanian Adapted Language Model"], "sentiment analysis grammar correctness": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models"], "grammar correctness textual entailment": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models"], "textual entailment textual similarity": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models"], "sentiment analysis grammar correctness textual entailment": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models"], "grammar correctness textual entailment textual similarity": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models"], "sentiment analysis grammar correctness textual entailment textual similarity": ["DA\u00b3: A Distribution-Aware Adversarial Attack against Language Models"], "psychological safety evaluation": ["Evaluating Psychological Safety of Large Language Models"], "sentiment classification data augmentation": ["An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification"], "knowledge selection": ["Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering"], "visual question answering knowledge selection": ["Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering"], "chart question answering": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging", "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?", "Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into Consistency and Robustness"], "chart-to-text": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-table": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging", "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "opencqa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-redrawing": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-qa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-description": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-summary": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart question answering chart-to-text": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-text chart-to-table": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-table opencqa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "opencqa chartx-redrawing": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-redrawing chartx-qa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-qa chartx-description": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-description chartx-summary": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart question answering chart-to-text chart-to-table": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-text chart-to-table opencqa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-table opencqa chartx-redrawing": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "opencqa chartx-redrawing chartx-qa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-redrawing chartx-qa chartx-description": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-qa chartx-description chartx-summary": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart question answering chart-to-text chart-to-table opencqa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-text chart-to-table opencqa chartx-redrawing": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-table opencqa chartx-redrawing chartx-qa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "opencqa chartx-redrawing chartx-qa chartx-description": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chartx-redrawing chartx-qa chartx-description chartx-summary": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart question answering chart-to-text chart-to-table opencqa chartx-redrawing": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-text chart-to-table opencqa chartx-redrawing chartx-qa": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "chart-to-table opencqa chartx-redrawing chartx-qa chartx-description": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "opencqa chartx-redrawing chartx-qa chartx-description chartx-summary": ["TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"], "fact-checking": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese", "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents", "Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data", "M\u00b3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection", "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models", "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers"], "adversarial dataset construction": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "chinese language processing": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "fact-checking natural language processing": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "natural language processing bias detection": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "bias detection adversarial dataset construction": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "adversarial dataset construction chinese language processing": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "fact-checking natural language processing bias detection": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "natural language processing bias detection adversarial dataset construction": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "bias detection adversarial dataset construction chinese language processing": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "fact-checking natural language processing bias detection adversarial dataset construction": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "natural language processing bias detection adversarial dataset construction chinese language processing": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "fact-checking natural language processing bias detection adversarial dataset construction chinese language processing": ["Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"], "visual commonsense reasoning": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "winoground": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "weird image explanation": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "humor understanding": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "multi-modal in-context learning": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "chain-of-comparison": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "visual commonsense reasoning winoground": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "winoground weird image explanation": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "weird image explanation humor understanding": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "humor understanding multi-modal in-context learning": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "multi-modal in-context learning chain-of-comparison": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "visual commonsense reasoning winoground weird image explanation": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "winoground weird image explanation humor understanding": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "weird image explanation humor understanding multi-modal in-context learning": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "humor understanding multi-modal in-context learning chain-of-comparison": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "visual commonsense reasoning winoground weird image explanation humor understanding": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "winoground weird image explanation humor understanding multi-modal in-context learning": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "weird image explanation humor understanding multi-modal in-context learning chain-of-comparison": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "visual commonsense reasoning winoground weird image explanation humor understanding multi-modal in-context learning": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "winoground weird image explanation humor understanding multi-modal in-context learning chain-of-comparison": ["Enhancing Advanced Visual Reasoning Ability of Large Language Models"], "text detoxification": ["CMD: a framework for Context-aware Model self-Detoxification", "XDetox: Text Detoxification with Token-Level Toxicity Explanations", "DetoxLLM: A Framework for Detoxification with Explanations", "LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification"], "language generation": ["CMD: a framework for Context-aware Model self-Detoxification", "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis", "Make Large Language Model a Better Ranker", "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling", "MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition", "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "safety": ["CMD: a framework for Context-aware Model self-Detoxification", "Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "text detoxification language generation": ["CMD: a framework for Context-aware Model self-Detoxification"], "language generation safety": ["CMD: a framework for Context-aware Model self-Detoxification"], "text detoxification language generation safety": ["CMD: a framework for Context-aware Model self-Detoxification"], "hallucination detection": ["Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection", "When Context Leads but Parametric Memory Follows in Large Language Models", "Knowledge-Centric Hallucination Detection", "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification", "CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios", "Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors", "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector", "Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators", "On the Universal Truthfulness Hyperplane Inside LLMS", "Enhanced Hallucination Detection in Neural Machine Translation through Simple Detector Aggregation", "Factuality of Large Language Models: A Survey", "Reference-free Hallucination Detection for Large Vision-Language Models", "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models", "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models", "InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States", "CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text", "Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning", "BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "singing voice synthesis": ["TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control"], "emotional support conversation": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "multi-turn dialogue generation": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "cognitive relevance optimization": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "dialogue policy optimization": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "emotional support conversation multi-turn dialogue generation": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "multi-turn dialogue generation cognitive relevance optimization": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "cognitive relevance optimization dialogue policy optimization": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "emotional support conversation multi-turn dialogue generation cognitive relevance optimization": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "multi-turn dialogue generation cognitive relevance optimization dialogue policy optimization": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "emotional support conversation multi-turn dialogue generation cognitive relevance optimization dialogue policy optimization": ["Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support"], "ambiguity resolution": ["Aligning Language Models to Explicitly Handle Ambiguity", "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "question answering ambiguity resolution": ["Aligning Language Models to Explicitly Handle Ambiguity"], "multimodal understanding": ["Tag-grounded Visual Instruction Tuning with Retrieval Augmentation", "VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "visual question answering image captioning": ["Tag-grounded Visual Instruction Tuning with Retrieval Augmentation", "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models", "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "image captioning multimodal understanding": ["Tag-grounded Visual Instruction Tuning with Retrieval Augmentation"], "visual question answering image captioning multimodal understanding": ["Tag-grounded Visual Instruction Tuning with Retrieval Augmentation"], "big-bench date": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "multiarith": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "aqua big-bench date": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "big-bench date gsm8k": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "gsm8k multiarith": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "multiarith svamp": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "svamp strategyqa": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "strategyqa math": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "math arithmetic reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "arithmetic reasoning commonsense reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models", "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Large Language Models Can Self-Correct with Key Condition Verification", "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "Re-Reading Improves Reasoning in Large Language Models", "ApiQ: Finetuning of 2-Bit Quantized Large Language Model", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "addsub aqua big-bench date": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "aqua big-bench date gsm8k": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "big-bench date gsm8k multiarith": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "gsm8k multiarith svamp": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "multiarith svamp strategyqa": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "svamp strategyqa math": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "strategyqa math arithmetic reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "math arithmetic reasoning commonsense reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "addsub aqua big-bench date gsm8k": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "aqua big-bench date gsm8k multiarith": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "big-bench date gsm8k multiarith svamp": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "gsm8k multiarith svamp strategyqa": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "multiarith svamp strategyqa math": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "svamp strategyqa math arithmetic reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "strategyqa math arithmetic reasoning commonsense reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "addsub aqua big-bench date gsm8k multiarith": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "aqua big-bench date gsm8k multiarith svamp": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "big-bench date gsm8k multiarith svamp strategyqa": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "gsm8k multiarith svamp strategyqa math": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "multiarith svamp strategyqa math arithmetic reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "svamp strategyqa math arithmetic reasoning commonsense reasoning": ["GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"], "memory disentangling": ["Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information"], "fmri decoding": ["Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information"], "semantic information extraction": ["Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information"], "memory disentangling fmri decoding": ["Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information"], "fmri decoding semantic information extraction": ["Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information"], "memory disentangling fmri decoding semantic information extraction": ["Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information"], "code retrieval": ["Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models", "Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "dataset annotation": ["Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models"], "query generation": ["Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models", "Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "code retrieval dataset annotation": ["Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models"], "dataset annotation query generation": ["Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models"], "code retrieval dataset annotation query generation": ["Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models"], "image classification": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models", "If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions", "Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification", "Retrieval-enriched zero-shot image classification in low-resource domains", "Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories", "Text2Model: Text-based Model Induction for Zero-shot Image Classification", "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "zero-shot learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models", "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment", "Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights", "Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks", "Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval", "Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models", "IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning", "Retrieval-enriched zero-shot image classification in low-resource domains", "Diversity, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA", "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning", "Disentangling Questions from Query Generation for Task-Adaptive Retrieval", "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization", "VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs", "Navigating Hallucinations for Reasoning of Unintentional Activities", "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs", "Zero-shot Commonsense Reasoning over Machine Imagination", "Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking", "Generate then Refine: Data Augmentation for Zero-shot Intent Detection", "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"], "efficient transfer learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models"], "image classification zero-shot learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models", "Retrieval-enriched zero-shot image classification in low-resource domains"], "zero-shot learning few-shot learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models", "Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "few-shot learning efficient transfer learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models"], "image classification zero-shot learning few-shot learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models"], "zero-shot learning few-shot learning efficient transfer learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models"], "image classification zero-shot learning few-shot learning efficient transfer learning": ["Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models"], "best-of-n decoding": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "verifier training": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "preference learning": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment", "What are the Generator Preferences for End-to-end Task-Oriented Dialog System?", "Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation", "Step-level Value Preference Optimization for Mathematical Reasoning", "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models", "Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "reasoning tree construction": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "commonsense reasoning gsm8k": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "gsm8k math": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks", "Skills-in-Context: Unlocking Compositionality in Large Language Models"], "math csqa": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "strategyqa best-of-n decoding": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "best-of-n decoding verifier training": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "verifier training preference learning": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "preference learning reasoning tree construction": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "arithmetic reasoning commonsense reasoning gsm8k": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "commonsense reasoning gsm8k math": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "gsm8k math csqa": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "math csqa strategyqa": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "csqa strategyqa best-of-n decoding": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "strategyqa best-of-n decoding verifier training": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "best-of-n decoding verifier training preference learning": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "verifier training preference learning reasoning tree construction": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "arithmetic reasoning commonsense reasoning gsm8k math": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "commonsense reasoning gsm8k math csqa": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "gsm8k math csqa strategyqa": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "math csqa strategyqa best-of-n decoding": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "csqa strategyqa best-of-n decoding verifier training": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "strategyqa best-of-n decoding verifier training preference learning": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "best-of-n decoding verifier training preference learning reasoning tree construction": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "arithmetic reasoning commonsense reasoning gsm8k math csqa": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "commonsense reasoning gsm8k math csqa strategyqa": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "gsm8k math csqa strategyqa best-of-n decoding": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "math csqa strategyqa best-of-n decoding verifier training": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "csqa strategyqa best-of-n decoding verifier training preference learning": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "strategyqa best-of-n decoding verifier training preference learning reasoning tree construction": ["Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"], "inference service security": ["An Inversion Attack Against Obfuscated Embedding Matrix in Language Model Inference"], "video quality assessment": ["VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation"], "metric learning": ["VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation"], "reinforcement learning": ["VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation", "Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use", "Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback", "Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems", "COFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code", "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "video quality assessment metric learning": ["VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation"], "metric learning reinforcement learning": ["VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation"], "video quality assessment metric learning reinforcement learning": ["VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation"], "evaluation": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models", "What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations", "AKEW: Assessing Knowledge Editing in the Wild", "Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis", "Creative and Context-Aware Translation of East Asian Idioms with GPT-4", "A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation", "Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition", "TuringQ: Benchmarking AI Comprehension in Theory of Computation", "BLADE: Benchmarking Language Model Agents for Data-Driven Science", "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers", "Knowledge-Centric Templatic Views of Documents"], "improvement": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"], "logical reasoning evaluation": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"], "evaluation improvement": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"], "improvement natural language inference": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"], "logical reasoning evaluation improvement": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"], "evaluation improvement natural language inference": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"], "logical reasoning evaluation improvement natural language inference": ["LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"], "ner": ["Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training", "PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study", "Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition", "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models"], "relation extraction": ["Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training", "ADELIE: Aligning Large Language Models on Information Extraction", "Bio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints", "SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents", "Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction", "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "Topic-Oriented Open Relation Extraction with A Priori Seed Generation", "SRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework", "FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding", "A Survey on Natural Language Counterfactual Generation", "A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction", "Entity or Relation Embeddings? An Analysis of Encoding Strategies for Relation Extraction", "MedINST: Meta Dataset of Biomedical Instructions", "C-ICL: Contrastive In-context Learning for Information Extraction", "Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases", "ITER: Iterative Transformer-based Entity Recognition and Relation Extraction", "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting", "AliGATr: Graph-based layout generation for form understanding", "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "event extraction": ["Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training", "ADELIE: Aligning Large Language Models on Information Extraction", "Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments", "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness", "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction", "DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction", "Employing Glyphic Information for Chinese Event Extraction with Vision-Language Model", "AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models", "Event-Keyed Summarization", "MedINST: Meta Dataset of Biomedical Instructions", "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction"], "ner relation extraction": ["Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training"], "relation extraction event extraction": ["Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training"], "ner relation extraction event extraction": ["Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training"], "understanding": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "generation": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning", "Safely Learning with Private Data: A Federated Learning Framework for Large Language Model", "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "COGEN: Learning from Feedback with Coupled Comprehension and Generation", "HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy", "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion", "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "Reformatted Alignment", "BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain", "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues", "Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "movie review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "restaurant review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "news category classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "question-information entailment classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "sentence-pair relation classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "question answering task": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "self-defined news articles classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "natural language inference understanding": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "understanding generation": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "generation movie review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "movie review semantic analysis restaurant review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "restaurant review semantic analysis news category classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "news category classification question-information entailment classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "question-information entailment classification sentence-pair relation classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "sentence-pair relation classification question answering task": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "question answering task self-defined news articles classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "natural language inference understanding generation": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "understanding generation movie review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "generation movie review semantic analysis restaurant review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "movie review semantic analysis restaurant review semantic analysis news category classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "restaurant review semantic analysis news category classification question-information entailment classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "news category classification question-information entailment classification sentence-pair relation classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "question-information entailment classification sentence-pair relation classification question answering task": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "sentence-pair relation classification question answering task self-defined news articles classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "natural language inference understanding generation movie review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "understanding generation movie review semantic analysis restaurant review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "generation movie review semantic analysis restaurant review semantic analysis news category classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "movie review semantic analysis restaurant review semantic analysis news category classification question-information entailment classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "restaurant review semantic analysis news category classification question-information entailment classification sentence-pair relation classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "news category classification question-information entailment classification sentence-pair relation classification question answering task": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "question-information entailment classification sentence-pair relation classification question answering task self-defined news articles classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "natural language inference understanding generation movie review semantic analysis restaurant review semantic analysis": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "understanding generation movie review semantic analysis restaurant review semantic analysis news category classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "generation movie review semantic analysis restaurant review semantic analysis news category classification question-information entailment classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "movie review semantic analysis restaurant review semantic analysis news category classification question-information entailment classification sentence-pair relation classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "restaurant review semantic analysis news category classification question-information entailment classification sentence-pair relation classification question answering task": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "news category classification question-information entailment classification sentence-pair relation classification question answering task self-defined news articles classification": ["FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"], "text-to-sql generation": ["I Need Help! Evaluating LLM\u2019s Ability to Ask for Users\u2019 Support: A Case Study on Text-to-SQL Generation"], "user support seeking": ["I Need Help! Evaluating LLM\u2019s Ability to Ask for Users\u2019 Support: A Case Study on Text-to-SQL Generation"], "text-to-sql generation user support seeking": ["I Need Help! Evaluating LLM\u2019s Ability to Ask for Users\u2019 Support: A Case Study on Text-to-SQL Generation"], "detecting abusive sentences where identity groups are depicted as deviating from the norm.": ["Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm"], "sensory tasks": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "human activity recognition": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "arrhythmia detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "hand gesture recognition": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "stress detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "sensory tasks human activity recognition": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "human activity recognition arrhythmia detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "arrhythmia detection hand gesture recognition": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "hand gesture recognition stress detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "sensory tasks human activity recognition arrhythmia detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "human activity recognition arrhythmia detection hand gesture recognition": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "arrhythmia detection hand gesture recognition stress detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "sensory tasks human activity recognition arrhythmia detection hand gesture recognition": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "human activity recognition arrhythmia detection hand gesture recognition stress detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "sensory tasks human activity recognition arrhythmia detection hand gesture recognition stress detection": ["By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"], "LLM quantization": ["Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization"], "activation outlier mitigation": ["Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization"], "per-tensor quantization": ["Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization"], "LLM quantization activation outlier mitigation": ["Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization"], "activation outlier mitigation per-tensor quantization": ["Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization"], "LLM quantization activation outlier mitigation per-tensor quantization": ["Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization"], "history enhancement": ["CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "conversational search query rewriting": ["CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "query rewriting ambiguity resolution": ["CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "ambiguity resolution history enhancement": ["CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "conversational search query rewriting ambiguity resolution": ["CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "query rewriting ambiguity resolution history enhancement": ["CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "conversational search query rewriting ambiguity resolution history enhancement": ["CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"], "harmful meme detection": ["Towards Low-Resource Harmful Meme Detection with LMM Agents"], "vision-grounded decision-making": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "human value inference": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "action selection": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "reason generation": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "vision-grounded decision-making human value inference": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "human value inference action selection": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "action selection reason generation": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "vision-grounded decision-making human value inference action selection": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "human value inference action selection reason generation": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "vision-grounded decision-making human value inference action selection reason generation": ["VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values"], "language agents": ["Direct Multi-Turn Preference Optimization for Language Agents", "METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "action planning": ["Direct Multi-Turn Preference Optimization for Language Agents"], "tool utilization": ["Direct Multi-Turn Preference Optimization for Language Agents", "FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "language agents instruction following": ["Direct Multi-Turn Preference Optimization for Language Agents"], "instruction following action planning": ["Direct Multi-Turn Preference Optimization for Language Agents"], "action planning tool utilization": ["Direct Multi-Turn Preference Optimization for Language Agents"], "language agents instruction following action planning": ["Direct Multi-Turn Preference Optimization for Language Agents"], "instruction following action planning tool utilization": ["Direct Multi-Turn Preference Optimization for Language Agents"], "language agents instruction following action planning tool utilization": ["Direct Multi-Turn Preference Optimization for Language Agents"], "math reasoning": ["Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors", "Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning", "SCIAGENT: Tool-augmented Language Models for Scientific Reasoning", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage", "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks", "MUSCLE: A Model Update Strategy for Compatible LLM Evolution", "Unlocking the Potential of Model Merging for Low-Resource Languages", "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models", "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "commonsense reasoning math reasoning": ["Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "MUSCLE: A Model Update Strategy for Compatible LLM Evolution", "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "math reasoning question answering": ["Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"], "question answering multi-task learning": ["Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"], "commonsense reasoning math reasoning question answering": ["Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"], "math reasoning question answering multi-task learning": ["Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"], "commonsense reasoning math reasoning question answering multi-task learning": ["Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"], "web scraper generation": ["AUTOSCRAPER: A Progressive Understanding Web Agent for Web Scraper Generation"], "web information extraction": ["AUTOSCRAPER: A Progressive Understanding Web Agent for Web Scraper Generation"], "web scraper generation web information extraction": ["AUTOSCRAPER: A Progressive Understanding Web Agent for Web Scraper Generation"], "interpretability": ["Backward Lens: Projecting Language Model Gradients into the Vocabulary Space", "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning", "Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings", "Variational Language Concepts for Interpreting Foundation Language Models", "Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes"], "language model editing": ["Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"], "knowledge acquisition": ["Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"], "interpretability language model editing": ["Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"], "language model editing knowledge acquisition": ["Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"], "interpretability language model editing knowledge acquisition": ["Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"], "premise localization": ["Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding"], "premise identification": ["Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding"], "conclusion deduction": ["Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding"], "premise localization premise identification": ["Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding"], "premise identification conclusion deduction": ["Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding"], "premise localization premise identification conclusion deduction": ["Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding"], "pun grounding": ["Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"], "disambiguation": ["Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!", "DICTDIS: Dictionary Constrained Disambiguation for Improved NMT", "Dual-Phase Accelerated Prompt Optimization", "CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "reconstruction": ["Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"], "pun grounding disambiguation": ["Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"], "disambiguation reconstruction": ["Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"], "pun grounding disambiguation reconstruction": ["Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"], "text style transfer": ["Reusing Transferable Weight Increments for Low-resource Style Generation", "Style-Specific Neurons for Steering LLMs in Text Style Transfer", "Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout", "MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization", "TINYSTYLER: Efficient Few-Shot Text Style Transfer with Authorship Embeddings"], "low-resource style generation": ["Reusing Transferable Weight Increments for Low-resource Style Generation"], "sequence-to-sequence generation": ["Reusing Transferable Weight Increments for Low-resource Style Generation", "Generative Models for Automatic Medical Decision Rule Extraction from Text"], "text style transfer low-resource style generation": ["Reusing Transferable Weight Increments for Low-resource Style Generation"], "low-resource style generation sequence-to-sequence generation": ["Reusing Transferable Weight Increments for Low-resource Style Generation"], "text style transfer low-resource style generation sequence-to-sequence generation": ["Reusing Transferable Weight Increments for Low-resource Style Generation"], "assignment evaluation": ["Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course"], "automatic evaluation": ["Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course", "Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "assignment evaluation automatic evaluation": ["Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course"], "multi-hop reasoning": ["Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?", "First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning", "Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations", "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies", "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models", "DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?", "TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation", "Cross-Lingual Multi-Hop Knowledge Editing", "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models", "Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective"], "multi-hop reasoning reading comprehension": ["Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?", "Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "reading comprehension question answering": ["Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?", "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks"], "multi-hop reasoning reading comprehension question answering": ["Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?"], "multitask learning": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners", "Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models", "MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "generalization": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners", "ControlMath: Controllable Data Generation Promotes Math Generalist Models", "MAIR: A Massive Benchmark for Evaluating Instructed Retrieval", "Data Contamination Can Cross Language Barriers", "Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks", "Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks", "PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection", "Knowledge Graph Enhanced Large Language Model Editing", "Can LLM Graph Reasoning Generalize beyond Pattern Memorization?", "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models", "From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models", "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "language modeling multitask learning": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners"], "multitask learning instruction following": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners"], "instruction following generalization": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners", "MAIR: A Massive Benchmark for Evaluating Instructed Retrieval"], "language modeling multitask learning instruction following": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners"], "multitask learning instruction following generalization": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners"], "language modeling multitask learning instruction following generalization": ["Instruction Pre-Training: Language Models are Supervised Multitask Learners"], "lifelong model editing": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models", "Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "knowledge updates": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "model correction": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "lifelong model editing knowledge updates": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "knowledge updates model correction": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "model correction knowledge injection": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "lifelong model editing knowledge updates model correction": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "knowledge updates model correction knowledge injection": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "lifelong model editing knowledge updates model correction knowledge injection": ["LEMOE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models"], "performance prediction": ["Collaborative Performance Prediction for Large Language Models"], "historical-psychological text analysis": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "cross-lingual questionnaire conversion": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "semantic textual similarity": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese", "Advancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss", "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity", "Scaling Sentence Embeddings with Large Language Models", "Variational Language Concepts for Interpreting Foundation Language Models", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention", "Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity", "MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation", "Regression-aware Inference with LLMs", "Representational Isomorphism and Alignment of Multilingual Large Language Models"], "questionnaire item classification": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "psychological measure": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "historical-psychological text analysis cross-lingual questionnaire conversion": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "cross-lingual questionnaire conversion semantic textual similarity": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "semantic textual similarity questionnaire item classification": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "questionnaire item classification psychological measure": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "historical-psychological text analysis cross-lingual questionnaire conversion semantic textual similarity": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "cross-lingual questionnaire conversion semantic textual similarity questionnaire item classification": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "semantic textual similarity questionnaire item classification psychological measure": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "historical-psychological text analysis cross-lingual questionnaire conversion semantic textual similarity questionnaire item classification": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "cross-lingual questionnaire conversion semantic textual similarity questionnaire item classification psychological measure": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "historical-psychological text analysis cross-lingual questionnaire conversion semantic textual similarity questionnaire item classification psychological measure": ["Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese"], "instruction-tuning": ["Knowledge Verification to Nip Hallucination in the Bud"], "truthful question answering": ["Knowledge Verification to Nip Hallucination in the Bud"], "clinical report generation": ["Knowledge Verification to Nip Hallucination in the Bud"], "instruction-tuning truthful question answering": ["Knowledge Verification to Nip Hallucination in the Bud"], "truthful question answering RAG": ["Knowledge Verification to Nip Hallucination in the Bud"], "RAG clinical report generation": ["Knowledge Verification to Nip Hallucination in the Bud"], "instruction-tuning truthful question answering RAG": ["Knowledge Verification to Nip Hallucination in the Bud"], "truthful question answering RAG clinical report generation": ["Knowledge Verification to Nip Hallucination in the Bud"], "instruction-tuning truthful question answering RAG clinical report generation": ["Knowledge Verification to Nip Hallucination in the Bud"], "bayesian reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "semantic parsing": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios", "Learning to Retrieve Iteratively for In-Context Learning", "Language-to-Code Translation with a Single Labeled Example", "Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations", "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing", "Scope-enhanced Compositional Semantic Parsing for DRT", "Predicting generalization performance with correctness discriminators"], "probabilistic reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "question answering natural language inference": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios", "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "natural language inference bayesian reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "bayesian reasoning semantic parsing": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "semantic parsing probabilistic reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "question answering natural language inference bayesian reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "natural language inference bayesian reasoning semantic parsing": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "bayesian reasoning semantic parsing probabilistic reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "question answering natural language inference bayesian reasoning semantic parsing": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "natural language inference bayesian reasoning semantic parsing probabilistic reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "question answering natural language inference bayesian reasoning semantic parsing probabilistic reasoning": ["QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios"], "fine-grained object classification": ["African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification"], "false premise detection": ["Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"], "knowledge assessment": ["Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"], "hallucination mitigation false premise detection": ["Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"], "false premise detection knowledge assessment": ["Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"], "hallucination mitigation false premise detection knowledge assessment": ["Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"], "concept induction": ["To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"], "word sense induction": ["To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models", "Automatically Generated Definitions and their utility for Modeling Word Meaning", "More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages"], "word-in-context": ["To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models", "Automatically Generated Definitions and their utility for Modeling Word Meaning"], "concept induction word sense induction": ["To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"], "word sense induction word-in-context": ["To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"], "concept induction word sense induction word-in-context": ["To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"], "jailbreak attack on LLMs": ["ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"], "collective decision-making": ["An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making"], "multi-agent collaboration": ["An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making", "ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models", "FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "question-answering": ["An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making", "DVD: Dynamic Contrastive Decoding for Knowledge Amplification in Multi-Document Question Answering", "SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers", "Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "collective decision-making multi-agent collaboration": ["An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making"], "multi-agent collaboration question-answering": ["An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making"], "collective decision-making multi-agent collaboration question-answering": ["An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making"], "hallucination evaluation": ["Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?", "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities", "FAITHSCORE: Fine-grained Evaluations of Hallucinations in Large Vision-Language Models"], "image captioning hallucination evaluation": ["Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?"], "LLM alignment": ["Take Off the Training Wheels! Progressive In-Context Learning for Effective Alignment", "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion", "Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization", "Reward Difference Optimization For Sample Reweighting In Offline RLHF", "Self-Evolution Fine-Tuning for Policy Optimization", "PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness", "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models", "On Diversified Preferences of Large Language Model Alignment", "ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline", "Enhancing Alignment using Curriculum Learning & Ranked Preferences", "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch", "Aligners: Decoupling LLMs and Alignment", "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks", "On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization"], "LLM alignment in-context learning": ["Take Off the Training Wheels! Progressive In-Context Learning for Effective Alignment"], "arithmetic": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning", "Abstraction-of-Thought Makes Language Models Better Reasoners", "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "humaneval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning", "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mbpp": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning", "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "medical": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medqa": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mMLu": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning", "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Turn Waste into Worth: Rectifying Top-k Router of MoE", "The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance", "RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization", "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement", "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "c-eval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "fingpt-headline": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "title-optimization": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "keyword-recommendation": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "gsm8k arithmetic": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "arithmetic mathqa": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mathqa humaneval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "humaneval mbpp": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mbpp medical": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medical medqa": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medqa mMLu": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mMLu c-eval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "c-eval fingpt-headline": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "fingpt-headline title-optimization": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "title-optimization keyword-recommendation": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "gsm8k arithmetic mathqa": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "arithmetic mathqa humaneval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mathqa humaneval mbpp": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "humaneval mbpp medical": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mbpp medical medqa": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medical medqa mMLu": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medqa mMLu c-eval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mMLu c-eval fingpt-headline": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "c-eval fingpt-headline title-optimization": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "fingpt-headline title-optimization keyword-recommendation": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "gsm8k arithmetic mathqa humaneval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "arithmetic mathqa humaneval mbpp": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mathqa humaneval mbpp medical": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "humaneval mbpp medical medqa": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mbpp medical medqa mMLu": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medical medqa mMLu c-eval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medqa mMLu c-eval fingpt-headline": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mMLu c-eval fingpt-headline title-optimization": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "c-eval fingpt-headline title-optimization keyword-recommendation": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "gsm8k arithmetic mathqa humaneval mbpp": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "arithmetic mathqa humaneval mbpp medical": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mathqa humaneval mbpp medical medqa": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "humaneval mbpp medical medqa mMLu": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mbpp medical medqa mMLu c-eval": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medical medqa mMLu c-eval fingpt-headline": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "medqa mMLu c-eval fingpt-headline title-optimization": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "mMLu c-eval fingpt-headline title-optimization keyword-recommendation": ["MODULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"], "restoration": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "attribution": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study", "AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings", "Improving LLM Attributions with Randomized Path-Integration", "LLM Explainability via Attributive Masking Learning"], "linguistic analysis": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study", "Evaluating Large Language Models via Linguistic Profiling", "I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "topic modeling": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study", "Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature", "AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments", "LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement", "LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement", "Unsupervised Hierarchical Topic Modeling via Anchor Word Clustering and Path Guidance", "NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization", "Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias", "Topic Modeling: Contextual Token Embeddings Are All You Need", "Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs"], "reasoning": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study", "To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models", "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs", "Learning to Correct for QA Reasoning with Black-box LLMs", "Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction", "Self-AMPLIFY : Improving Small Language Models with Self Post Hoc Explanations", "Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently", "DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models", "Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation", "Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators", "Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models", "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions", "AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories", "Head-wise Shareable Attention for Large Language Models", "On the Empirical Complexity of Reasoning and Planning in LLMs", "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models", "MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate", "Improving Multi-Agent Debate with Sparse Communication Topology", "In-Context Learning with Iterative Demonstration Selection", "Weak-to-Strong Reasoning", "Navigating Hallucinations for Reasoning of Unintentional Activities", "StraGo: Harnessing Strategic Guidance for Prompt Optimization", "What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models", "Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure", "ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering", "Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework", "Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "restoration attribution": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "attribution linguistic analysis": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "linguistic analysis question answering": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "question answering topic modeling": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "topic modeling ner": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "ner reasoning": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "restoration attribution linguistic analysis": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "attribution linguistic analysis question answering": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "linguistic analysis question answering topic modeling": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "question answering topic modeling ner": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "topic modeling ner reasoning": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "restoration attribution linguistic analysis question answering": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "attribution linguistic analysis question answering topic modeling": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "linguistic analysis question answering topic modeling ner": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "question answering topic modeling ner reasoning": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "restoration attribution linguistic analysis question answering topic modeling": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "attribution linguistic analysis question answering topic modeling ner": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "linguistic analysis question answering topic modeling ner reasoning": ["PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study"], "jailbreak defense": ["Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions", "From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking", "Defending Jailbreak Prompts via In-Context Adversarial Game", "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"], "aspect sentiment triplet extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction", "Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction", "Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "opinion extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction", "Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect opinion pair extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction", "Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment triplet extraction aspect extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction"], "aspect extraction opinion extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction"], "opinion extraction aspect opinion pair extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction"], "aspect sentiment triplet extraction aspect extraction opinion extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction"], "aspect extraction opinion extraction aspect opinion pair extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction"], "aspect sentiment triplet extraction aspect extraction opinion extraction aspect opinion pair extraction": ["MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction"], "sentence generation": ["Evaluating Large Language Models via Linguistic Profiling"], "morpho-syntactic analysis": ["Evaluating Large Language Models via Linguistic Profiling"], "evaluation of LLMs": ["Evaluating Large Language Models via Linguistic Profiling"], "sentence generation linguistic analysis": ["Evaluating Large Language Models via Linguistic Profiling"], "linguistic analysis morpho-syntactic analysis": ["Evaluating Large Language Models via Linguistic Profiling"], "morpho-syntactic analysis evaluation of LLMs": ["Evaluating Large Language Models via Linguistic Profiling"], "sentence generation linguistic analysis morpho-syntactic analysis": ["Evaluating Large Language Models via Linguistic Profiling"], "linguistic analysis morpho-syntactic analysis evaluation of LLMs": ["Evaluating Large Language Models via Linguistic Profiling"], "sentence generation linguistic analysis morpho-syntactic analysis evaluation of LLMs": ["Evaluating Large Language Models via Linguistic Profiling"], "shape symbolism": ["With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"], "magnitude symbolism": ["With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"], "iconicity rating": ["With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"], "shape symbolism magnitude symbolism": ["With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"], "magnitude symbolism iconicity rating": ["With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"], "shape symbolism magnitude symbolism iconicity rating": ["With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"], "program induction": ["KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases"], "program induction knowledge base question answering": ["KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases"], "semantic analysis": ["Understanding Higher-Order Correlations Among Semantic Components in Embeddings"], "embedding interpretation": ["Understanding Higher-Order Correlations Among Semantic Components in Embeddings"], "visualization": ["Understanding Higher-Order Correlations Among Semantic Components in Embeddings"], "semantic analysis embedding interpretation": ["Understanding Higher-Order Correlations Among Semantic Components in Embeddings"], "embedding interpretation visualization": ["Understanding Higher-Order Correlations Among Semantic Components in Embeddings"], "semantic analysis embedding interpretation visualization": ["Understanding Higher-Order Correlations Among Semantic Components in Embeddings"], "multi-modal sarcasm detection": ["DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection"], "passage retrieval": ["Evaluating D-MERIT of Partial-annotation on Information Retrieval", "Improve Dense Passage Retrieval with Entailment Tuning", "Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers", "Dense X Retrieval: What Retrieval Granularity Should We Use?"], "explanatory reasoning": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "autoformalisation": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "error correction": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving", "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check", "Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models", "E2CL: Exploration-based Error Correction Learning for Embodied Agents", "Resilience of Large Language Models for Noisy Instructions"], "natural language inference explanation generation": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "explanation generation explanatory reasoning": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "explanatory reasoning autoformalisation": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "autoformalisation error correction": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "natural language inference explanation generation explanatory reasoning": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "explanation generation explanatory reasoning autoformalisation": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "explanatory reasoning autoformalisation error correction": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "natural language inference explanation generation explanatory reasoning autoformalisation": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "explanation generation explanatory reasoning autoformalisation error correction": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "natural language inference explanation generation explanatory reasoning autoformalisation error correction": ["Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"], "multiple-choice question answering": ["Calibrating the Confidence of Large Language Models by Eliciting Fidelity", "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws", "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning", "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models", "BiMediX: Bilingual Medical Mixture of Experts LLM"], "relevance": ["The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models"], "factuality": ["The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models", "Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models", "Improving Multi-Agent Debate with Sparse Communication Topology"], "completeness": ["The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models"], "relevance factuality": ["The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models"], "factuality completeness": ["The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models"], "relevance factuality completeness": ["The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models"], "grammatical error detection": ["Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection"], "sequence labeling": ["Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection", "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures", "Automatic sentence segmentation of clinical record narratives in real-world data", "Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment"], "grammatical error detection sequence labeling": ["Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection"], "spelling": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "inverse spelling": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains char": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains word": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "orthographic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "semantic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "spelling inverse spelling": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "inverse spelling contains char": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains char contains word": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains word orthographic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "orthographic similarity semantic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "semantic similarity char insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char insertion word insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word insertion char deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char deletion word deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word deletion char substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char substitution word substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word substitution char swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char swapping word swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "spelling inverse spelling contains char": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "inverse spelling contains char contains word": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains char contains word orthographic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains word orthographic similarity semantic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "orthographic similarity semantic similarity char insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "semantic similarity char insertion word insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char insertion word insertion char deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word insertion char deletion word deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char deletion word deletion char substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word deletion char substitution word substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char substitution word substitution char swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word substitution char swapping word swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "spelling inverse spelling contains char contains word": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "inverse spelling contains char contains word orthographic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains char contains word orthographic similarity semantic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains word orthographic similarity semantic similarity char insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "orthographic similarity semantic similarity char insertion word insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "semantic similarity char insertion word insertion char deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char insertion word insertion char deletion word deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word insertion char deletion word deletion char substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char deletion word deletion char substitution word substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word deletion char substitution word substitution char swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char substitution word substitution char swapping word swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "spelling inverse spelling contains char contains word orthographic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "inverse spelling contains char contains word orthographic similarity semantic similarity": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains char contains word orthographic similarity semantic similarity char insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "contains word orthographic similarity semantic similarity char insertion word insertion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "orthographic similarity semantic similarity char insertion word insertion char deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "semantic similarity char insertion word insertion char deletion word deletion": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char insertion word insertion char deletion word deletion char substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word insertion char deletion word deletion char substitution word substitution": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "char deletion word deletion char substitution word substitution char swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "word deletion char substitution word substitution char swapping word swapping": ["CUTE: Measuring LLMs' Understanding of Their Tokens"], "reading time prediction": ["On the Role of Context in Reading Time Prediction", "Reverse-Engineering the Reader", "Towards a Similarity-adjusted Surprisal Theory", "On the Proper Treatment of Tokenization in Psycholinguistics"], "interactive theorem proving": ["BC-Prover: Backward Chaining Prover for Formal Theorem Proving"], "automated theorem proving": ["BC-Prover: Backward Chaining Prover for Formal Theorem Proving"], "proofstep generation": ["BC-Prover: Backward Chaining Prover for Formal Theorem Proving"], "interactive theorem proving automated theorem proving": ["BC-Prover: Backward Chaining Prover for Formal Theorem Proving"], "automated theorem proving proofstep generation": ["BC-Prover: Backward Chaining Prover for Formal Theorem Proving"], "interactive theorem proving automated theorem proving proofstep generation": ["BC-Prover: Backward Chaining Prover for Formal Theorem Proving"], "interpretability analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "citation analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "survey analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "mixed-methods analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "interpretability analysis citation analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "citation analysis survey analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "survey analysis mixed-methods analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "interpretability analysis citation analysis survey analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "citation analysis survey analysis mixed-methods analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "interpretability analysis citation analysis survey analysis mixed-methods analysis": ["From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP"], "cross-lingual language understanding": ["Autoregressive Pre-Training on Pixels and Texts"], "language understanding cross-lingual language understanding": ["Autoregressive Pre-Training on Pixels and Texts"], "webnlg": ["On Training Data Influence of GPT Models"], "wmt-16 de/en": ["On Training Data Influence of GPT Models"], "natural language understanding natural language generation": ["On Training Data Influence of GPT Models", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "natural language generation rte": ["On Training Data Influence of GPT Models"], "sst-2 boolq": ["On Training Data Influence of GPT Models"], "boolq webnlg": ["On Training Data Influence of GPT Models"], "webnlg wmt-16 de/en": ["On Training Data Influence of GPT Models"], "natural language understanding natural language generation rte": ["On Training Data Influence of GPT Models"], "natural language generation rte sst-2": ["On Training Data Influence of GPT Models"], "rte sst-2 boolq": ["On Training Data Influence of GPT Models"], "sst-2 boolq webnlg": ["On Training Data Influence of GPT Models"], "boolq webnlg wmt-16 de/en": ["On Training Data Influence of GPT Models"], "natural language understanding natural language generation rte sst-2": ["On Training Data Influence of GPT Models"], "natural language generation rte sst-2 boolq": ["On Training Data Influence of GPT Models"], "rte sst-2 boolq webnlg": ["On Training Data Influence of GPT Models"], "sst-2 boolq webnlg wmt-16 de/en": ["On Training Data Influence of GPT Models"], "natural language understanding natural language generation rte sst-2 boolq": ["On Training Data Influence of GPT Models"], "natural language generation rte sst-2 boolq webnlg": ["On Training Data Influence of GPT Models"], "rte sst-2 boolq webnlg wmt-16 de/en": ["On Training Data Influence of GPT Models"], "conceptual analysis": ["Understanding \u201cDemocratization\u201d in NLP and ML Research"], "entity extraction": ["DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models"], "document classification": ["DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models", "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization", "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP", "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "visual question answering entity extraction": ["DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models"], "entity extraction document classification": ["DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models"], "visual question answering entity extraction document classification": ["DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models"], "cross-lingual question generation": ["Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages"], "sentence completion": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws", "Temporally Consistent Factuality Probing for Large Language Models", "FAME: Towards Factual Multi-Task Model Editing"], "coreference resolution": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws", "Paraphrase Types Elicit Prompt Engineering Capabilities", "Major Entity Identification: A Generalizable Alternative to Coreference Resolution", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "Are LLMs Good Annotators for Discourse-level Event Relation Extraction?", "MedINST: Meta Dataset of Biomedical Instructions", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention", "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "sentence completion coreference resolution": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"], "coreference resolution natural language inference": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "natural language inference multiple-choice question answering": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"], "sentence completion coreference resolution natural language inference": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"], "coreference resolution natural language inference multiple-choice question answering": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"], "sentence completion coreference resolution natural language inference multiple-choice question answering": ["ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"], "omission mitigation": ["Word Alignment as Preference for Machine Translation"], "machine translation hallucination mitigation": ["Word Alignment as Preference for Machine Translation"], "hallucination mitigation omission mitigation": ["Word Alignment as Preference for Machine Translation"], "machine translation hallucination mitigation omission mitigation": ["Word Alignment as Preference for Machine Translation"], "multi-party dialogue generation": ["Improving Multi-party Dialogue Generation via Topic and Rhetorical Coherence"], "continual learning": ["SEEKR: Selective Attention-Guided Knowledge Retention for Continual Learning of Large Language Models", "Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting", "Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models", "Revisiting Catastrophic Forgetting in Large Language Model Tuning", "Unlocking Continual Learning Abilities in Language Models", "ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation", "Gradient Localization Improves Lifelong Pretraining of Language Models", "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "catastrophic forgetting mitigation": ["SEEKR: Selective Attention-Guided Knowledge Retention for Continual Learning of Large Language Models", "Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs", "Self-training Large Language Models through Knowledge Detection"], "continual learning catastrophic forgetting mitigation": ["SEEKR: Selective Attention-Guided Knowledge Retention for Continual Learning of Large Language Models"], "neuron-level knowledge attribution": ["Neuron-Level Knowledge Attribution in Large Language Models"], "knowledge localization": ["Neuron-Level Knowledge Attribution in Large Language Models", "Discovering Knowledge-Critical Subnetworks in Pretrained Language Models", "Local Contrastive Editing of Gender Stereotypes"], "identifying value neurons": ["Neuron-Level Knowledge Attribution in Large Language Models"], "identifying query neurons": ["Neuron-Level Knowledge Attribution in Large Language Models"], "analyzing knowledge types": ["Neuron-Level Knowledge Attribution in Large Language Models"], "neuron-level knowledge attribution knowledge localization": ["Neuron-Level Knowledge Attribution in Large Language Models"], "knowledge localization identifying value neurons": ["Neuron-Level Knowledge Attribution in Large Language Models"], "identifying value neurons identifying query neurons": ["Neuron-Level Knowledge Attribution in Large Language Models"], "identifying query neurons analyzing knowledge types": ["Neuron-Level Knowledge Attribution in Large Language Models"], "neuron-level knowledge attribution knowledge localization identifying value neurons": ["Neuron-Level Knowledge Attribution in Large Language Models"], "knowledge localization identifying value neurons identifying query neurons": ["Neuron-Level Knowledge Attribution in Large Language Models"], "identifying value neurons identifying query neurons analyzing knowledge types": ["Neuron-Level Knowledge Attribution in Large Language Models"], "neuron-level knowledge attribution knowledge localization identifying value neurons identifying query neurons": ["Neuron-Level Knowledge Attribution in Large Language Models"], "knowledge localization identifying value neurons identifying query neurons analyzing knowledge types": ["Neuron-Level Knowledge Attribution in Large Language Models"], "neuron-level knowledge attribution knowledge localization identifying value neurons identifying query neurons analyzing knowledge types": ["Neuron-Level Knowledge Attribution in Large Language Models"], "sentence classification": ["How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning", "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "sentence classification in-context learning": ["How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning"], "arithmetic ability analysis in LLMs": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "comparative neuron analysis": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "model pruning for arithmetic tasks": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "model editing for reducing gender bias": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "arithmetic ability analysis in LLMs comparative neuron analysis": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "comparative neuron analysis model pruning for arithmetic tasks": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "model pruning for arithmetic tasks model editing for reducing gender bias": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "arithmetic ability analysis in LLMs comparative neuron analysis model pruning for arithmetic tasks": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "comparative neuron analysis model pruning for arithmetic tasks model editing for reducing gender bias": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "arithmetic ability analysis in LLMs comparative neuron analysis model pruning for arithmetic tasks model editing for reducing gender bias": ["Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis"], "linguistic probing": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "visual probing": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "pos-tagging": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "dependency parsing": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models", "CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free-Word-Ordered and Morphologically-Rich Low-Resource Languages", "Contribution of Linguistic Typology to Universal Dependency Parsing: An Empirical Investigation", "A Morphology-Based Investigation of Positional Encodings", "Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing"], "linguistic probing visual probing": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "visual probing pos-tagging": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "pos-tagging dependency parsing": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "dependency parsing glue": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "linguistic probing visual probing pos-tagging": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "visual probing pos-tagging dependency parsing": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "pos-tagging dependency parsing glue": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "linguistic probing visual probing pos-tagging dependency parsing": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "visual probing pos-tagging dependency parsing glue": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "linguistic probing visual probing pos-tagging dependency parsing glue": ["Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"], "privacy violation detection": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "legal judgment": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "hipaa applicability": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "compliance": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "privacy violation detection legal judgment": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "legal judgment hipaa applicability": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "hipaa applicability compliance": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "privacy violation detection legal judgment hipaa applicability": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "legal judgment hipaa applicability compliance": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "privacy violation detection legal judgment hipaa applicability compliance": ["GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"], "noise detection": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise categorization": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "literary analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "soundscape analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise detection noise categorization": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise categorization topic modeling": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "topic modeling literary analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "literary analysis soundscape analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise detection noise categorization topic modeling": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise categorization topic modeling literary analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "topic modeling literary analysis soundscape analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise detection noise categorization topic modeling literary analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise categorization topic modeling literary analysis soundscape analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "noise detection noise categorization topic modeling literary analysis soundscape analysis": ["Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature"], "quantization": ["QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models", "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models", "xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics", "MobileQuant: Mobile-friendly Quantization for On-device Language Models", "Promoting Data and Model Privacy in Federated Learning through Quantized LoRA", "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs", "Exploring Quantization for Efficient Pre-Training of Transformer Language Models", "QEFT: Quantization for Efficient Fine-Tuning of LLMs", "How Does Quantization Affect Multilingual LLMs?", "ATQ: Activation Transformation for Weight-Activation Quantization of Large Language Models"], "inference": ["QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models", "HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy", "QEFT: Quantization for Efficient Fine-Tuning of LLMs"], "LLMs quantization": ["QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models"], "quantization inference": ["QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models", "QEFT: Quantization for Efficient Fine-Tuning of LLMs"], "LLMs quantization inference": ["QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models"], "reading comprehension prediction": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "eye movement analysis": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "multi-modal modeling": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "ordinary reading": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "information seeking": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements", "ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?", "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations", "Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain"], "reading comprehension prediction eye movement analysis": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "eye movement analysis multi-modal modeling": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "multi-modal modeling ordinary reading": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "ordinary reading information seeking": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "reading comprehension prediction eye movement analysis multi-modal modeling": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "eye movement analysis multi-modal modeling ordinary reading": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "multi-modal modeling ordinary reading information seeking": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "reading comprehension prediction eye movement analysis multi-modal modeling ordinary reading": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "eye movement analysis multi-modal modeling ordinary reading information seeking": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "reading comprehension prediction eye movement analysis multi-modal modeling ordinary reading information seeking": ["Fine-Grained Prediction of Reading Comprehension from Eye Movements"], "multi-hop question answering": ["EfficientRAG: Efficient Retriever for Multi-Hop Question Answering", "From RAG to RICHES: Retrieval Interlaced with Sequence Generation", "Re-ReST: Reflection-Reinforced Self-Training for Language Agents", "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning", "Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities", "LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments"], "multi-hop question answering RAG": ["EfficientRAG: Efficient Retriever for Multi-Hop Question Answering"], "human preference learning": ["Unsupervised Human Preference Learning"], "personalization": ["Unsupervised Human Preference Learning", "MisinfoEval: Generative AI in the Era of \u201cAlternative Facts\"", "Jump Starting Bandits with LLM-Generated Prior Knowledge", "Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "human preference learning personalization": ["Unsupervised Human Preference Learning"], "personalization language model adaptation": ["Unsupervised Human Preference Learning"], "human preference learning personalization language model adaptation": ["Unsupervised Human Preference Learning"], "hate speech countering": ["Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering", "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "hate speech countering natural language generation": ["Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering"], "cognitive modeling": ["Leading Whitespaces of Language Models' Subword Vocabulary Pose a Confound for Calculating Word Probabilities", "Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "cognitive modeling language modeling": ["Leading Whitespaces of Language Models' Subword Vocabulary Pose a Confound for Calculating Word Probabilities"], "decompilation": ["LLM4Decompile: Decompiling Binary Code with Large Language Models", "Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly", "Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement"], "mathematical reasoning svamp": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "svamp aqua": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "aqua addsub": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "addsub multiarith": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "multiarith singleeq": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "singleeq gsm8k": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "mathematical reasoning svamp aqua": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "svamp aqua addsub": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "aqua addsub multiarith": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "addsub multiarith singleeq": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning", "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "multiarith singleeq gsm8k": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "mathematical reasoning svamp aqua addsub": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "svamp aqua addsub multiarith": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "aqua addsub multiarith singleeq": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "addsub multiarith singleeq gsm8k": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "mathematical reasoning svamp aqua addsub multiarith": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "svamp aqua addsub multiarith singleeq": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "aqua addsub multiarith singleeq gsm8k": ["From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"], "knowledge graph question answering": ["CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering", "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering", "Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering", "Retrieval and Reasoning on KGs: Integrate Knowledge Graphs into Large Language Models for Complex Question Answering", "Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering", "A Framework of Knowledge Graph-Enhanced Large Language Model Based on Question Decomposition and Atomic Retrieval", "Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA"], "multilingual tasks": ["MTLS: Making Texts into Linguistic Symbols"], "syntactic processing": ["MTLS: Making Texts into Linguistic Symbols"], "semantic processing": ["MTLS: Making Texts into Linguistic Symbols"], "part-of-speech tagging": ["MTLS: Making Texts into Linguistic Symbols", "Lexically Grounded Subword Segmentation", "A Morphology-Based Investigation of Positional Encodings", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "Predicting generalization performance with correctness discriminators", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks", "Targeted Multilingual Adaptation for Low-resource Language Families"], "named entity recognition": ["MTLS: Making Texts into Linguistic Symbols", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "ADELIE: Aligning Large Language Models on Information Extraction", "Bio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints", "Paraphrase Types Elicit Prompt Engineering Capabilities", "NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data", "SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents", "Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages", "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives", "Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data", "Embedded Named Entity Recognition using Probing Classifiers", "NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition", "Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?", "NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries", "TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR", "A Morphology-Based Investigation of Positional Encodings", "Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4", "GottBERT: a pure German Language Model", "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction", "Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting", "MedINST: Meta Dataset of Biomedical Instructions", "C-ICL: Contrastive In-context Learning for Information Extraction", "Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases", "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science", "ITER: Iterative Transformer-based Entity Recognition and Relation Extraction", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks", "Efficient Active Learning with Adapters", "Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models"], "multilingual tasks syntactic processing": ["MTLS: Making Texts into Linguistic Symbols"], "syntactic processing semantic processing": ["MTLS: Making Texts into Linguistic Symbols"], "semantic processing part-of-speech tagging": ["MTLS: Making Texts into Linguistic Symbols"], "part-of-speech tagging named entity recognition": ["MTLS: Making Texts into Linguistic Symbols", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "multilingual tasks syntactic processing semantic processing": ["MTLS: Making Texts into Linguistic Symbols"], "syntactic processing semantic processing part-of-speech tagging": ["MTLS: Making Texts into Linguistic Symbols"], "semantic processing part-of-speech tagging named entity recognition": ["MTLS: Making Texts into Linguistic Symbols"], "multilingual tasks syntactic processing semantic processing part-of-speech tagging": ["MTLS: Making Texts into Linguistic Symbols"], "syntactic processing semantic processing part-of-speech tagging named entity recognition": ["MTLS: Making Texts into Linguistic Symbols"], "multilingual tasks syntactic processing semantic processing part-of-speech tagging named entity recognition": ["MTLS: Making Texts into Linguistic Symbols"], "multimodal sentiment detection": ["D2R: Dual-Branch Dynamic Routing Network for Multimodal Sentiment Detection"], "fine-grained category discovery": ["A Generic Method for Fine-grained Category Discovery in Natural Language Texts"], "fine-grained category discovery natural language processing": ["A Generic Method for Fine-grained Category Discovery in Natural Language Texts"], "rule-based moderation": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "toxicity detection": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method", "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric", "Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas", "BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers", "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models", "Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification", "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression", "CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack"], "LLM performance evaluation": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "moderation assistant needs analysis": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "rule-based moderation toxicity detection": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "toxicity detection LLM performance evaluation": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "LLM performance evaluation moderation assistant needs analysis": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "rule-based moderation toxicity detection LLM performance evaluation": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "toxicity detection LLM performance evaluation moderation assistant needs analysis": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "rule-based moderation toxicity detection LLM performance evaluation moderation assistant needs analysis": ["Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method"], "user intent understanding": ["A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models"], "multi-intent assessment": ["A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models"], "LLM evaluation user intent understanding": ["A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models"], "user intent understanding multi-intent assessment": ["A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models"], "LLM evaluation user intent understanding multi-intent assessment": ["A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models"], "vision-language models": ["Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison", "MACAROON: Training Vision-Language Models To Be Your Engaged Partners", "Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "reliability measurement": ["Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison"], "task decomposition": ["Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison", "DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents", "On the Empirical Complexity of Reasoning and Planning in LLMs"], "vision-language models reliability measurement": ["Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison"], "reliability measurement task decomposition": ["Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison"], "vision-language models reliability measurement task decomposition": ["Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison"], "visual understanding": ["VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation", "What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models"], "visual generation": ["VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation"], "visual understanding visual generation": ["VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation"], "visual generation question answering": ["VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation"], "visual understanding visual generation question answering": ["VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation"], "machine translation evaluation": ["What do Large Language Models Need for Machine Translation Evaluation?", "Beyond Reference: Evaluating High Quality Translations Better than Human References", "MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language", "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation", "Can Automatic Metrics Assess High-Quality Translations?", "BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "active learning": ["Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale", "Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models", "Annotator-Centric Active Learning for Subjective NLP Tasks", "On the Fragility of Active Learners for Text Classification", "Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization"], "text classification knowledge distillation": ["Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"], "knowledge distillation active learning": ["Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"], "text classification knowledge distillation active learning": ["Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"], "argument mining": ["External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models", "LawBench: Benchmarking Legal Knowledge of Large Language Models", "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "argument relation classification": ["External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models", "Argument Relation Classification through Discourse Markers and Adversarial Training"], "argument mining argument relation classification": ["External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models"], "privacy policy analysis": ["C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits"], "regulatory compliance audits": ["C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits"], "privacy policy analysis regulatory compliance audits": ["C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits"], "multimodal tasks": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "text-vqa": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "vsr": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "snli-ve": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "cifar-10": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "cifar-100": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "mnist": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "pope": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "multimodal tasks text-vqa": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "text-vqa vsr": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "vsr snli-ve": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "snli-ve cifar-10": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "cifar-10 cifar-100": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "cifar-100 mnist": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "mnist pope": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "multimodal tasks text-vqa vsr": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "text-vqa vsr snli-ve": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "vsr snli-ve cifar-10": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "snli-ve cifar-10 cifar-100": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "cifar-10 cifar-100 mnist": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "cifar-100 mnist pope": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "multimodal tasks text-vqa vsr snli-ve": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "text-vqa vsr snli-ve cifar-10": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "vsr snli-ve cifar-10 cifar-100": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "snli-ve cifar-10 cifar-100 mnist": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "cifar-10 cifar-100 mnist pope": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "multimodal tasks text-vqa vsr snli-ve cifar-10": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "text-vqa vsr snli-ve cifar-10 cifar-100": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "vsr snli-ve cifar-10 cifar-100 mnist": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "snli-ve cifar-10 cifar-100 mnist pope": ["M\u00b2PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning"], "zero-shot text classification": ["Incubating Text Classifiers Following User Instruction with Nothing but LLM"], "model incubation": ["Incubating Text Classifiers Following User Instruction with Nothing but LLM"], "text classification zero-shot text classification": ["Incubating Text Classifiers Following User Instruction with Nothing but LLM"], "zero-shot text classification model incubation": ["Incubating Text Classifiers Following User Instruction with Nothing but LLM"], "text classification zero-shot text classification model incubation": ["Incubating Text Classifiers Following User Instruction with Nothing but LLM"], "text-to-sql": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL", "Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments", "Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities", "Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL", "SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA", "Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL", "DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models", "TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "query group partitioning": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "targeted drilling": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "text-to-sql LLMs": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "LLMs query group partitioning": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "query group partitioning targeted drilling": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "text-to-sql LLMs query group partitioning": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "LLMs query group partitioning targeted drilling": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "text-to-sql LLMs query group partitioning targeted drilling": ["PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"], "logical inference": ["Conditional and Modal Reasoning in Large Language Models", "Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text", "Dual-Phase Accelerated Prompt Optimization"], "conditional reasoning": ["Conditional and Modal Reasoning in Large Language Models", "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMS"], "modal reasoning": ["Conditional and Modal Reasoning in Large Language Models"], "inference patterns": ["Conditional and Modal Reasoning in Large Language Models"], "logical inference conditional reasoning": ["Conditional and Modal Reasoning in Large Language Models"], "conditional reasoning modal reasoning": ["Conditional and Modal Reasoning in Large Language Models"], "modal reasoning inference patterns": ["Conditional and Modal Reasoning in Large Language Models"], "logical inference conditional reasoning modal reasoning": ["Conditional and Modal Reasoning in Large Language Models"], "conditional reasoning modal reasoning inference patterns": ["Conditional and Modal Reasoning in Large Language Models"], "logical inference conditional reasoning modal reasoning inference patterns": ["Conditional and Modal Reasoning in Large Language Models"], "attributed text generation": ["Advancing Large Language Model Attribution through Self-Improving"], "open-domain question-answering": ["Advancing Large Language Model Attribution through Self-Improving"], "long-form qa": ["Advancing Large Language Model Attribution through Self-Improving", "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "multi-step reasoning": ["Advancing Large Language Model Attribution through Self-Improving", "From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis", "Teaching Small Language Models Reasoning through Counterfactual Distillation", "Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "attributed text generation open-domain question-answering": ["Advancing Large Language Model Attribution through Self-Improving"], "open-domain question-answering long-form qa": ["Advancing Large Language Model Attribution through Self-Improving"], "long-form qa multi-step reasoning": ["Advancing Large Language Model Attribution through Self-Improving"], "attributed text generation open-domain question-answering long-form qa": ["Advancing Large Language Model Attribution through Self-Improving"], "open-domain question-answering long-form qa multi-step reasoning": ["Advancing Large Language Model Attribution through Self-Improving"], "attributed text generation open-domain question-answering long-form qa multi-step reasoning": ["Advancing Large Language Model Attribution through Self-Improving"], "speech emotion captioning": ["AlignCap: Aligning Speech Emotion Captioning to Human Preferences"], "parameter modification": ["Interpretability-based Tailored Knowledge Editing in Transformers"], "knowledge editing in-context learning": ["Interpretability-based Tailored Knowledge Editing in Transformers"], "in-context learning parameter modification": ["Interpretability-based Tailored Knowledge Editing in Transformers"], "knowledge editing in-context learning parameter modification": ["Interpretability-based Tailored Knowledge Editing in Transformers"], "multi-step task prompt optimization": ["PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"], "video question answering": ["Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting", "Video-LLaVA: Learning United Visual Representation by Alignment Before Projection", "Encoding and Controlling Global Semantics for Long-form Video Question Answering", "TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering", "Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge", "TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning", "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "Enhancing Temporal Modeling of Video LLMs via Time Gating", "Exploring Question Guidance and Answer Calibration for Visually Grounded Video Question Answering", "ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video question answering continual learning": ["Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting"], "unlearning": ["Dissecting Fine-Tuning Unlearning in Large Language Models", "Demystifying Verbatim Memorization in Large Language Models"], "faithfulness": ["Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"], "instruction following faithfulness": ["Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"], "faithfulness qa": ["Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"], "instruction following faithfulness qa": ["Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"], "faithfulness qa summarization": ["Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"], "instruction following faithfulness qa summarization": ["Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"], "private word embedding": ["Private Language Models via Truncated Laplacian Mechanism"], "downstream task": ["Private Language Models via Truncated Laplacian Mechanism"], "private word embedding downstream task": ["Private Language Models via Truncated Laplacian Mechanism"], "entity knowledge estimation": ["Estimating Knowledge in Large Language Models Without Generating a Single Token"], "open-ended generation": ["Estimating Knowledge in Large Language Models Without Generating a Single Token", "RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework", "RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs", "Factuality of Large Language Models: A Survey", "Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation"], "entity knowledge estimation question answering": ["Estimating Knowledge in Large Language Models Without Generating a Single Token"], "question answering open-ended generation": ["Estimating Knowledge in Large Language Models Without Generating a Single Token"], "entity knowledge estimation question answering open-ended generation": ["Estimating Knowledge in Large Language Models Without Generating a Single Token"], "autoformalization": ["Consistent Autoformalization for Constructing Mathematical Libraries"], "knowledge evaluation": ["When Context Leads but Parametric Memory Follows in Large Language Models"], "question answering knowledge evaluation": ["When Context Leads but Parametric Memory Follows in Large Language Models"], "knowledge evaluation hallucination detection": ["When Context Leads but Parametric Memory Follows in Large Language Models"], "question answering knowledge evaluation hallucination detection": ["When Context Leads but Parametric Memory Follows in Large Language Models"], "yes/no question formation": ["Semantic Training Signals Promote Hierarchical Syntactic Generalization in Transformers"], "form-to-meaning translation": ["Semantic Training Signals Promote Hierarchical Syntactic Generalization in Transformers"], "yes/no question formation form-to-meaning translation": ["Semantic Training Signals Promote Hierarchical Syntactic Generalization in Transformers"], "cross-lingual transfer learning": ["When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages", "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale", "T-FREE: Subword Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings"], "language modeling cross-lingual transfer learning": ["When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages", "T-FREE: Subword Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings"], "homegrid": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "alfworld": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use", "Retrospex: Language Agent Meets Offline Reinforcement Learning Critic", "QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning", "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking"], "messenger": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "metaworld": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "offline reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use", "LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble"], "homegrid alfworld": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "alfworld messenger": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "messenger metaworld": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "metaworld reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "reinforcement learning offline reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "homegrid alfworld messenger": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "alfworld messenger metaworld": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "messenger metaworld reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "metaworld reinforcement learning offline reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "homegrid alfworld messenger metaworld": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "alfworld messenger metaworld reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "messenger metaworld reinforcement learning offline reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "homegrid alfworld messenger metaworld reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "alfworld messenger metaworld reinforcement learning offline reinforcement learning": ["Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"], "gender mistranslation detection": ["MiTTenS: A Dataset for Evaluating Gender Mistranslation"], "evaluation of translation systems": ["MiTTenS: A Dataset for Evaluating Gender Mistranslation"], "evaluation of foundation models": ["MiTTenS: A Dataset for Evaluating Gender Mistranslation"], "gender mistranslation detection evaluation of translation systems": ["MiTTenS: A Dataset for Evaluating Gender Mistranslation"], "evaluation of translation systems evaluation of foundation models": ["MiTTenS: A Dataset for Evaluating Gender Mistranslation"], "gender mistranslation detection evaluation of translation systems evaluation of foundation models": ["MiTTenS: A Dataset for Evaluating Gender Mistranslation"], "abstainqa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "open-book qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "closed-book qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "commonsense qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback", "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM", "Explicit Memory Learning with Expectation Maximization"], "abstainqa open-book qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "open-book qa closed-book qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "closed-book qa commonsense qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "abstainqa open-book qa closed-book qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "open-book qa closed-book qa commonsense qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "abstainqa open-book qa closed-book qa commonsense qa": ["Teaching LLMs to Abstain across Languages via Multilingual Feedback"], "value kaleidoscope  dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "opinionqa dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "moralchoice dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "globalopinionqa dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "overton pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "steerable pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "distributional pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "nli evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "human evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration", "Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts", "I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "gpt-4 evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "value kaleidoscope  dataset opinionqa dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "opinionqa dataset moralchoice dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "moralchoice dataset globalopinionqa dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "globalopinionqa dataset overton pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "overton pluralism steerable pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "steerable pluralism distributional pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "distributional pluralism nli evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "nli evaluation human evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "human evaluation gpt-4 evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "value kaleidoscope  dataset opinionqa dataset moralchoice dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "opinionqa dataset moralchoice dataset globalopinionqa dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "moralchoice dataset globalopinionqa dataset overton pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "globalopinionqa dataset overton pluralism steerable pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "overton pluralism steerable pluralism distributional pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "steerable pluralism distributional pluralism nli evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "distributional pluralism nli evaluation human evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "nli evaluation human evaluation gpt-4 evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "value kaleidoscope  dataset opinionqa dataset moralchoice dataset globalopinionqa dataset": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "opinionqa dataset moralchoice dataset globalopinionqa dataset overton pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "moralchoice dataset globalopinionqa dataset overton pluralism steerable pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "globalopinionqa dataset overton pluralism steerable pluralism distributional pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "overton pluralism steerable pluralism distributional pluralism nli evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "steerable pluralism distributional pluralism nli evaluation human evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "distributional pluralism nli evaluation human evaluation gpt-4 evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "value kaleidoscope  dataset opinionqa dataset moralchoice dataset globalopinionqa dataset overton pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "opinionqa dataset moralchoice dataset globalopinionqa dataset overton pluralism steerable pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "moralchoice dataset globalopinionqa dataset overton pluralism steerable pluralism distributional pluralism": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "globalopinionqa dataset overton pluralism steerable pluralism distributional pluralism nli evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "overton pluralism steerable pluralism distributional pluralism nli evaluation human evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "steerable pluralism distributional pluralism nli evaluation human evaluation gpt-4 evaluation": ["Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"], "authorship obfuscation": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements", "Authorship Obfuscation in Multilingual Machine-Generated Text Detection"], "text rewriting": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements", "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "style transfer": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements", "A Survey of AMR Applications"], "authorship obfuscation text rewriting": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements"], "text rewriting style transfer": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements"], "style transfer natural language generation": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements"], "authorship obfuscation text rewriting style transfer": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements"], "text rewriting style transfer natural language generation": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements"], "authorship obfuscation text rewriting style transfer natural language generation": ["StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements"], "unanswerable question detection": ["I Could've Asked That: Reformulating Unanswerable Questions"], "question reformulation": ["I Could've Asked That: Reformulating Unanswerable Questions"], "document-grounded qa": ["I Could've Asked That: Reformulating Unanswerable Questions"], "question answering unanswerable question detection": ["I Could've Asked That: Reformulating Unanswerable Questions"], "unanswerable question detection question reformulation": ["I Could've Asked That: Reformulating Unanswerable Questions"], "question reformulation document-grounded qa": ["I Could've Asked That: Reformulating Unanswerable Questions"], "question answering unanswerable question detection question reformulation": ["I Could've Asked That: Reformulating Unanswerable Questions"], "unanswerable question detection question reformulation document-grounded qa": ["I Could've Asked That: Reformulating Unanswerable Questions"], "question answering unanswerable question detection question reformulation document-grounded qa": ["I Could've Asked That: Reformulating Unanswerable Questions"], "sensitivity testing": ["STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"], "bias detection sensitivity testing": ["STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"], "LLM political leaning detection": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "voter behavior simulation": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "human-LLM interaction analysis": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "political influence analysis": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "LLM political leaning detection voter behavior simulation": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "voter behavior simulation human-LLM interaction analysis": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "human-LLM interaction analysis political influence analysis": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "LLM political leaning detection voter behavior simulation human-LLM interaction analysis": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "voter behavior simulation human-LLM interaction analysis political influence analysis": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "LLM political leaning detection voter behavior simulation human-LLM interaction analysis political influence analysis": ["Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters"], "LLM unlearning": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning", "Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "fictitious unlearning": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "copyrighted information removal": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "model detoxification": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "LLM unlearning fictitious unlearning": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "fictitious unlearning copyrighted information removal": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "copyrighted information removal model detoxification": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "LLM unlearning fictitious unlearning copyrighted information removal": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "fictitious unlearning copyrighted information removal model detoxification": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "LLM unlearning fictitious unlearning copyrighted information removal model detoxification": ["SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning"], "analytical reasoning": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "information aggregation": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "longitudinal data analysis": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "score tracking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "entity linking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives", "OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting", "Unsupervised Named Entity Disambiguation for Low Resource Domains", "Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant", "BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers", "Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval", "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs"], "analytical reasoning information aggregation": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "information aggregation longitudinal data analysis": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "longitudinal data analysis score tracking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "score tracking entity linking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "analytical reasoning information aggregation longitudinal data analysis": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "information aggregation longitudinal data analysis score tracking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "longitudinal data analysis score tracking entity linking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "analytical reasoning information aggregation longitudinal data analysis score tracking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "information aggregation longitudinal data analysis score tracking entity linking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "analytical reasoning information aggregation longitudinal data analysis score tracking entity linking": ["When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives"], "factuality estimation of long-form texts in multilingual settings": ["An Analysis of Multilingual FActScore"], "language model evaluation": ["PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models", "First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning", "A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles", "Efficiently Computing Susceptibility to Context in Language Models", "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "direct assessment": ["PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models", "SpeechQE: Estimating the Quality of Direct Speech Translation"], "pairwise ranking": ["PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models", "Few-shot Prompting for Pairwise Ranking: An Effective Non-Parametric Retrieval Model"], "language model evaluation direct assessment": ["PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models"], "direct assessment pairwise ranking": ["PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models"], "language model evaluation direct assessment pairwise ranking": ["PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models"], "rag-qa": ["RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval-Augmented Question Answering"], "long-form answer generation": ["RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval-Augmented Question Answering"], "cross-domain generalization evaluation": ["RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval-Augmented Question Answering"], "rag-qa long-form answer generation": ["RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval-Augmented Question Answering"], "long-form answer generation cross-domain generalization evaluation": ["RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval-Augmented Question Answering"], "rag-qa long-form answer generation cross-domain generalization evaluation": ["RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval-Augmented Question Answering"], "zero-shot document retrieval": ["PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval", "GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation"], "zero-shot document retrieval text generation": ["PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval"], "automatic speech recognition": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects", "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "On Mitigating Performance Disparities in Multilingual Speech Recognition", "Optimized Speculative Sampling for GPU Hardware Accelerators", "Advancing Test-Time Adaptation in Wild Acoustic Test Settings", "Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models", "Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition", "Unveiling the Role of Pretraining in Direct Speech Translation", "Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding", "Are Modern Neural ASR Architectures Robust for Polysynthetic Languages?", "WavLLM: Towards Robust and Adaptive Speech Large Language Model", "Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models", "Modeling Gender and Dialect Bias in Automatic Speech Recognition", "Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper"], "speech-to-text translation": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects", "Curriculum Consistency Learning for Conditional Sentence Generation", "WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "machine translation automatic speech recognition": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects"], "automatic speech recognition speech-to-text translation": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects", "WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech-to-text translation speech-to-speech translation": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects"], "machine translation automatic speech recognition speech-to-text translation": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects"], "automatic speech recognition speech-to-text translation speech-to-speech translation": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects"], "machine translation automatic speech recognition speech-to-text translation speech-to-speech translation": ["Voices Unheard: NLP Resources and Models for Yor\u00f9b\u00e1 Regional Dialects"], "multi-modal reasoning": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback", "M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "chain-of-thought": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback", "How Do Humans Write Code? Large Models Do It the Same Way Too"], "a-okvqa": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"], "multi-modal reasoning chain-of-thought": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"], "chain-of-thought scienceqa": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"], "scienceqa a-okvqa": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"], "multi-modal reasoning chain-of-thought scienceqa": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"], "chain-of-thought scienceqa a-okvqa": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"], "multi-modal reasoning chain-of-thought scienceqa a-okvqa": ["ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"], "membership inference attacks": ["Order of Magnitude Speedups for LLM Membership Inference"], "text-to-video generation": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "subject-driven video generation": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "video prediction": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "multimodal instruction tuning": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "text-to-video generation subject-driven video generation": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "subject-driven video generation video prediction": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "video prediction multimodal instruction tuning": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "text-to-video generation subject-driven video generation video prediction": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "subject-driven video generation video prediction multimodal instruction tuning": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "text-to-video generation subject-driven video generation video prediction multimodal instruction tuning": ["VIMI: Grounding Video Generation through Multi-modal Instruction"], "counterspeech generation": ["F2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation", "Outcome-Constrained Large Language Models for Countering Hate Speech"], "rumor detection": ["Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"], "latent intent mining": ["Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"], "rumor detection latent intent mining": ["Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"], "visual prompting": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "spatial localization": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "face detection": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "emotion recognition visual prompting": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "visual prompting spatial localization": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "spatial localization face detection": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "emotion recognition visual prompting spatial localization": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "visual prompting spatial localization face detection": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "emotion recognition visual prompting spatial localization face detection": ["Visual Prompting in LLMs for Enhancing Emotion Recognition"], "audio watermarking": ["IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding"], "offensive language detection": ["Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset", "ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations", "Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research", "Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases", "BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "unintended offense detection": ["Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"], "dataset construction": ["Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"], "offensive language detection unintended offense detection": ["Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"], "unintended offense detection dataset construction": ["Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"], "offensive language detection unintended offense detection dataset construction": ["Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"], "hate speech mitigation": ["Outcome-Constrained Large Language Models for Countering Hate Speech", "A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation"], "conversation outcome modeling": ["Outcome-Constrained Large Language Models for Countering Hate Speech"], "counterspeech generation hate speech mitigation": ["Outcome-Constrained Large Language Models for Countering Hate Speech"], "hate speech mitigation conversation outcome modeling": ["Outcome-Constrained Large Language Models for Countering Hate Speech"], "counterspeech generation hate speech mitigation conversation outcome modeling": ["Outcome-Constrained Large Language Models for Countering Hate Speech"], "interlinear glossing": ["Multiple Sources are Better Than One: Incorporating External Knowledge in Low-Resource Glossing"], "adversarial attack": ["Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks", "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment", "Reasoning Robustness of LLMs to Adversarial Typographical Errors", "RAFT: Realistic Attacks to Fool Text Detectors", "RAt: Injecting Implicit Bias for Text-To-Image Prompt Refinement Models", "Robust Text Classification: Analyzing Prototype-Based Networks", "Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions"], "adversarial attack text classification": ["Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks"], "text classification natural language inference": ["Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks", "GottBERT: a pure German Language Model", "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "natural language inference sentiment analysis": ["Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks", "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models", "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion", "Inference and Verbalization Functions During In-Context Learning"], "adversarial attack text classification natural language inference": ["Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks"], "text classification natural language inference sentiment analysis": ["Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks"], "adversarial attack text classification natural language inference sentiment analysis": ["Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks"], "task-oriented dialogue": ["Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping", "Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel", "What are the Generator Preferences for End-to-end Task-Oriented Dialog System?", "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities", "Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues", "Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "suicide detection": ["PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling"], "risk assessment": ["PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling", "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "suicide detection risk assessment": ["PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling"], "visual grounding": ["World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering", "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models", "Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling", "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "PropTest: Automatic Property Testing for Improved Visual Programming", "VDebugger: Harnessing Execution Feedback for Debugging Visual Programs"], "visual question answering visual grounding": ["World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering", "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "VDebugger: Harnessing Execution Feedback for Debugging Visual Programs"], "program-of-thought": ["How Do Humans Write Code? Large Models Do It the Same Way Too"], "mathematical reasoning program-of-thought": ["How Do Humans Write Code? Large Models Do It the Same Way Too"], "program-of-thought chain-of-thought": ["How Do Humans Write Code? Large Models Do It the Same Way Too"], "chain-of-thought natural language inference": ["How Do Humans Write Code? Large Models Do It the Same Way Too"], "mathematical reasoning program-of-thought chain-of-thought": ["How Do Humans Write Code? Large Models Do It the Same Way Too"], "program-of-thought chain-of-thought natural language inference": ["How Do Humans Write Code? Large Models Do It the Same Way Too"], "mathematical reasoning program-of-thought chain-of-thought natural language inference": ["How Do Humans Write Code? Large Models Do It the Same Way Too"], "scienceworld": ["Retrospex: Language Agent Meets Offline Reinforcement Learning Critic"], "webshop": ["Retrospex: Language Agent Meets Offline Reinforcement Learning Critic", "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking"], "scienceworld alfworld": ["Retrospex: Language Agent Meets Offline Reinforcement Learning Critic"], "alfworld webshop": ["Retrospex: Language Agent Meets Offline Reinforcement Learning Critic", "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking"], "scienceworld alfworld webshop": ["Retrospex: Language Agent Meets Offline Reinforcement Learning Critic"], "long-context modeling": ["Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-context Models"], "memorization evaluation": ["Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-context Models"], "long-context modeling memorization evaluation": ["Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-context Models"], "knowledge-intensive generation": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "long-form generation": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation", "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation", "Analysis of Plan-based Retrieval for Grounded Text Generation", "Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models", "Calibrating Long-form Generations from Large Language Models", "Downstream Trade-offs of a Family of Text Watermarks"], "multi-hop qa": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation", "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection", "Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together", "FAME: Towards Factual Multi-Task Model Editing", "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs", "Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities", "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "short-form qa": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "knowledge-intensive generation long-form generation": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "long-form generation multi-hop qa": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "multi-hop qa short-form qa": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "short-form qa planning": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "knowledge-intensive generation long-form generation multi-hop qa": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "long-form generation multi-hop qa short-form qa": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "multi-hop qa short-form qa planning": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "knowledge-intensive generation long-form generation multi-hop qa short-form qa": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "long-form generation multi-hop qa short-form qa planning": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "knowledge-intensive generation long-form generation multi-hop qa short-form qa planning": ["Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"], "instruction finetuning": ["COEVOL: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation", "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models"], "instruction finetuning LLMs": ["COEVOL: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation"], "logical reasoning assessment": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "hypothesis testing": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "token bias identification": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "synthetic data generation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners", "LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives", "Synthetic Multimodal Question Generation", "Better Alignment with Instruction Back-and-Forth Translation", "Aligners: Decoupling LLMs and Alignment", "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "controlled experimentation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "logical reasoning assessment hypothesis testing": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "hypothesis testing token bias identification": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "token bias identification synthetic data generation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "synthetic data generation controlled experimentation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "logical reasoning assessment hypothesis testing token bias identification": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "hypothesis testing token bias identification synthetic data generation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "token bias identification synthetic data generation controlled experimentation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "logical reasoning assessment hypothesis testing token bias identification synthetic data generation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "hypothesis testing token bias identification synthetic data generation controlled experimentation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "logical reasoning assessment hypothesis testing token bias identification synthetic data generation controlled experimentation": ["A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"], "story generation": ["Bayesian Calibration of Win Rate Estimation with LLM Evaluators", "Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability", "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges", "Measuring Psychological Depth in Language Models", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models", "SWAG: Storytelling With Action Guidance", "Extrinsic Evaluation of Cultural Competence in Large Language Models"], "story generation summarization": ["Bayesian Calibration of Win Rate Estimation with LLM Evaluators"], "summarization instruction following": ["Bayesian Calibration of Win Rate Estimation with LLM Evaluators", "Inference-Time Language Model Alignment via Integrated Value Guidance", "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "story generation summarization instruction following": ["Bayesian Calibration of Win Rate Estimation with LLM Evaluators"], "tool use": ["MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "SCIAGENT: Tool-augmented Language Models for Scientific Reasoning", "Uncertainty Calibration for Tool-Using Language Agents"], "mathematical reasoning data augmentation": ["MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "ControlMath: Controllable Data Generation Promotes Math Generalist Models"], "data augmentation tool use": ["MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning"], "mathematical reasoning data augmentation tool use": ["MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning"], "gradient inversion attack": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "data leakage": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "federated learning": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients", "Enhancing Byzantine-Resistant Aggregations with Client Embedding", "Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "privacy": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "gradient inversion attack data leakage": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "data leakage federated learning": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "federated learning privacy": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "gradient inversion attack data leakage federated learning": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "data leakage federated learning privacy": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "gradient inversion attack data leakage federated learning privacy": ["Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients"], "linear probing": ["RWKV-CLIP: A Robust Vision-Language Representation Learner"], "zero-shot image-text retrieval": ["RWKV-CLIP: A Robust Vision-Language Representation Learner"], "zero-shot classification": ["RWKV-CLIP: A Robust Vision-Language Representation Learner", "Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP", "MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition", "EU DisinfoTest: a Benchmark for Evaluating Language Models' Ability to Detect Disinformation Narratives"], "linear probing zero-shot image-text retrieval": ["RWKV-CLIP: A Robust Vision-Language Representation Learner"], "zero-shot image-text retrieval zero-shot classification": ["RWKV-CLIP: A Robust Vision-Language Representation Learner"], "linear probing zero-shot image-text retrieval zero-shot classification": ["RWKV-CLIP: A Robust Vision-Language Representation Learner"], "child-specific language modeling": ["KidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions"], "language modeling text generation": ["KidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions", "Evaluating n-Gram Novelty of Language Models Using RUSTY-DAWG", "A Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors"], "text generation child-specific language modeling": ["KidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions"], "language modeling text generation child-specific language modeling": ["KidLM: Advancing Language Models for Children \u2013 Early Insights and Future Directions"], "lexical selection": ["Using Language Models to Disambiguate Lexical Choices in Translation"], "experimental study": ["How Does the Disclosure of AI Assistance Affect the Perceptions of Writing?"], "automated medical coding": ["An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"], "explainability": ["An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records", "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States", "Improving LLM Attributions with Randomized Path-Integration"], "automated medical coding explainability": ["An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"], "personalized agents": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "editable memory graphs": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "autofill forms": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "user services": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "personalized agents RAG": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "RAG editable memory graphs": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "editable memory graphs question answering": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "question answering autofill forms": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "autofill forms user services": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "personalized agents RAG editable memory graphs": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "RAG editable memory graphs question answering": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "editable memory graphs question answering autofill forms": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "question answering autofill forms user services": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "personalized agents RAG editable memory graphs question answering": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "RAG editable memory graphs question answering autofill forms": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "editable memory graphs question answering autofill forms user services": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "personalized agents RAG editable memory graphs question answering autofill forms": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "RAG editable memory graphs question answering autofill forms user services": ["Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"], "event-based knowledge editing": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"], "text completion": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation", "Paraphrase Types Elicit Prompt Engineering Capabilities", "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully"], "knowledge editing event-based knowledge editing": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"], "event-based knowledge editing text completion": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"], "text completion question answering": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"], "knowledge editing event-based knowledge editing text completion": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"], "event-based knowledge editing text completion question answering": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"], "knowledge editing event-based knowledge editing text completion question answering": ["EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"], "sentence processing": ["Modeling Nonnative Sentence Processing with L2 Language Models"], "language acquisition modeling": ["Modeling Nonnative Sentence Processing with L2 Language Models"], "sentence processing language acquisition modeling": ["Modeling Nonnative Sentence Processing with L2 Language Models"], "visual question answering multi-step reasoning": ["From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis"], "data quality assessment": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "intrinsic evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "in-context evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "extrinsic evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "tool-using LLMs": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "data quality assessment intrinsic evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "intrinsic evaluation in-context evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "in-context evaluation extrinsic evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "extrinsic evaluation tool-using LLMs": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "data quality assessment intrinsic evaluation in-context evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "intrinsic evaluation in-context evaluation extrinsic evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "in-context evaluation extrinsic evaluation tool-using LLMs": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "data quality assessment intrinsic evaluation in-context evaluation extrinsic evaluation": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "intrinsic evaluation in-context evaluation extrinsic evaluation tool-using LLMs": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "data quality assessment intrinsic evaluation in-context evaluation extrinsic evaluation tool-using LLMs": ["Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs"], "audio deepfake detection": ["Cross-Domain Audio Deepfake Detection: Dataset and Analysis"], "referring expression comprehension": ["MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension", "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension", "Grounding Language in Multi-Perspective Referential Communication", "RECANTFormer: Referring Expression Comprehension with Varying Numbers of Targets"], "knowledge reasoning": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization", "Large Language Models are In-context Teachers for Knowledge Reasoning"], "discrepancy analysis": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "hierarchical deconstruction": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "question answering knowledge reasoning": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "knowledge reasoning discrepancy analysis": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "discrepancy analysis hierarchical deconstruction": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "question answering knowledge reasoning discrepancy analysis": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "knowledge reasoning discrepancy analysis hierarchical deconstruction": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "question answering knowledge reasoning discrepancy analysis hierarchical deconstruction": ["Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"], "understanding alignment": ["Aligning Translation-Specific Understanding to General Understanding in Large Language Models"], "machine translation understanding alignment": ["Aligning Translation-Specific Understanding to General Understanding in Large Language Models"], "knowledge-grounded qa": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "optical character recognition": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models", "LOCR: Location-Guided Transformer for Optical Character Recognition"], "hallucination": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "multiple-choice": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "free-form generation": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "visual question answering knowledge-grounded qa": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "knowledge-grounded qa optical character recognition": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "optical character recognition hallucination": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "hallucination multiple-choice": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "multiple-choice free-form generation": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "visual question answering knowledge-grounded qa optical character recognition": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "knowledge-grounded qa optical character recognition hallucination": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "optical character recognition hallucination multiple-choice": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "hallucination multiple-choice free-form generation": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "visual question answering knowledge-grounded qa optical character recognition hallucination": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "knowledge-grounded qa optical character recognition hallucination multiple-choice": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "optical character recognition hallucination multiple-choice free-form generation": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "visual question answering knowledge-grounded qa optical character recognition hallucination multiple-choice": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "knowledge-grounded qa optical character recognition hallucination multiple-choice free-form generation": ["Concept-skill Transferability-based Data Selection for Large Vision-Language Models"], "LLM-generated paper reviews": ["LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing"], "review deficiency labeling": ["LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing"], "LLM-generated paper reviews review deficiency labeling": ["LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing"], "n/a": ["Academics Can Contribute to Domain-Specialized Language Models"], "sst2": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "cola": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mrpc": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "qqp": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "stem": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "humanities": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "social sciences": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "other": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "glue mMLu": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mMLu sst2": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "sst2 cola": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "cola mnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mnli qnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "qnli rte": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "rte mrpc": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "mrpc qqp": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "qqp stem": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "stem humanities": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "humanities social sciences": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "social sciences other": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "glue mMLu sst2": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mMLu sst2 cola": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "sst2 cola mnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "cola mnli qnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mnli qnli rte": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "qnli rte mrpc": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "rte mrpc qqp": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "mrpc qqp stem": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "qqp stem humanities": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "stem humanities social sciences": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "humanities social sciences other": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "glue mMLu sst2 cola": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mMLu sst2 cola mnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "sst2 cola mnli qnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "cola mnli qnli rte": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mnli qnli rte mrpc": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "qnli rte mrpc qqp": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "rte mrpc qqp stem": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mrpc qqp stem humanities": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "qqp stem humanities social sciences": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "stem humanities social sciences other": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "glue mMLu sst2 cola mnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mMLu sst2 cola mnli qnli": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "sst2 cola mnli qnli rte": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "cola mnli qnli rte mrpc": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mnli qnli rte mrpc qqp": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "qnli rte mrpc qqp stem": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "rte mrpc qqp stem humanities": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "mrpc qqp stem humanities social sciences": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "qqp stem humanities social sciences other": ["Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"], "topic classification": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning", "Revisiting Supervised Contrastive Learning for Microblog Classification", "CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs", "SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation", "Multilingual Topic Classification in X: Dataset and Analysis", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage", "Transfer Learning for Text Classification via Model Risk Analysis", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "In-Context Learning with Iterative Demonstration Selection", "Dual-Phase Accelerated Prompt Optimization", "Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models", "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons", "Inference and Verbalization Functions During In-Context Learning"], "natural language generation automatic speech recognition": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "automatic speech recognition image captioning": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "image captioning machine translation": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "machine translation summarization": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "question answering sentiment analysis": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentiment analysis topic classification": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages", "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning", "CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs", "Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models", "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons", "Inference and Verbalization Functions During In-Context Learning"], "topic classification named entity recognition": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "natural language understanding natural language generation automatic speech recognition": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "natural language generation automatic speech recognition image captioning": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "automatic speech recognition image captioning machine translation": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "image captioning machine translation summarization": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "machine translation summarization question answering": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "summarization question answering sentiment analysis": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "question answering sentiment analysis topic classification": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "sentiment analysis topic classification named entity recognition": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "natural language understanding natural language generation automatic speech recognition image captioning": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "natural language generation automatic speech recognition image captioning machine translation": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "automatic speech recognition image captioning machine translation summarization": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "image captioning machine translation summarization question answering": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "machine translation summarization question answering sentiment analysis": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "summarization question answering sentiment analysis topic classification": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "question answering sentiment analysis topic classification named entity recognition": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "natural language understanding natural language generation automatic speech recognition image captioning machine translation": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "natural language generation automatic speech recognition image captioning machine translation summarization": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "automatic speech recognition image captioning machine translation summarization question answering": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "image captioning machine translation summarization question answering sentiment analysis": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "machine translation summarization question answering sentiment analysis topic classification": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "summarization question answering sentiment analysis topic classification named entity recognition": ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"], "instruction induction": ["INDUCT-LEARN: Short Phrase Prompting with Instruction Induction", "StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models"], "prompting": ["INDUCT-LEARN: Short Phrase Prompting with Instruction Induction", "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting", "When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "instruction induction prompting": ["INDUCT-LEARN: Short Phrase Prompting with Instruction Induction"], "prompting few-shot learning": ["INDUCT-LEARN: Short Phrase Prompting with Instruction Induction"], "instruction induction prompting few-shot learning": ["INDUCT-LEARN: Short Phrase Prompting with Instruction Induction"], "temporal knowledge graph reasoning": ["Multi-Granularity History and Entity Similarity Learning for Temporal Knowledge Graph Reasoning", "SALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning", "Natural Evolution-based Dual-Level Aggregation for Temporal Knowledge Graph Reasoning"], "extrapolation": ["Multi-Granularity History and Entity Similarity Learning for Temporal Knowledge Graph Reasoning"], "temporal knowledge graph reasoning extrapolation": ["Multi-Granularity History and Entity Similarity Learning for Temporal Knowledge Graph Reasoning"], "long-text uncertainty quantification": ["LUQ: Long-text Uncertainty Quantification for LLMs"], "pretraining data detection": ["Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"], "membership inference attack": ["Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method", "RECALL: Membership Inference via Relative Conditional Log-Likelihoods", "Privacy Evaluation Benchmarks for NLP Models"], "pretraining data detection membership inference attack": ["Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"], "natural language inference logical reasoning": ["Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars"], "spoken language modeling": ["Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach"], "phoneme classification": ["Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach"], "spoken language modeling phoneme classification": ["Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach"], "phoneme classification speech resynthesis": ["Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach"], "spoken language modeling phoneme classification speech resynthesis": ["Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach"], "generation superglue": ["Safely Learning with Private Data: A Federated Learning Framework for Large Language Model"], "superglue abstractive summarization": ["Safely Learning with Private Data: A Federated Learning Framework for Large Language Model"], "generation superglue abstractive summarization": ["Safely Learning with Private Data: A Federated Learning Framework for Large Language Model"], "learning preferences of LLMs": ["Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge"], "data with conflicting knowledge": ["Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge"], "learning preferences of LLMs data with conflicting knowledge": ["Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge"], "rank classification": ["How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?"], "image captioning visual question answering": ["How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?", "The Instinctive Bias: Spurious Images lead to Illusion in MLLMs", "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "Nearest Neighbor Normalization Improves Multimodal Retrieval", "Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models"], "visual question answering rank classification": ["How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?"], "image captioning visual question answering rank classification": ["How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?"], "social norms": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "argumentation": ["How Far Can We Extract Diverse Perspectives from Large Language Models?", "An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "hate speech labeling": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "story continuation": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "social norms argumentation": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "argumentation hate speech labeling": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "hate speech labeling story continuation": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "social norms argumentation hate speech labeling": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "argumentation hate speech labeling story continuation": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "social norms argumentation hate speech labeling story continuation": ["How Far Can We Extract Diverse Perspectives from Large Language Models?"], "complex reasoning": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning", "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities", "LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning", "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "exemplar selection": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning"], "complex reasoning question answering": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning"], "question answering in-context learning": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning", "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models"], "in-context learning exemplar selection": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning"], "complex reasoning question answering in-context learning": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning"], "question answering in-context learning exemplar selection": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning"], "complex reasoning question answering in-context learning exemplar selection": ["EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning"], "dialogue constructiveness assessment": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "open-mindedness fostering": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "dialogue constructiveness assessment argumentation": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "argumentation persuasion": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "persuasion open-mindedness fostering": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "dialogue constructiveness assessment argumentation persuasion": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "argumentation persuasion open-mindedness fostering": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "dialogue constructiveness assessment argumentation persuasion open-mindedness fostering": ["An LLM Feature-based Framework for Dialogue Constructiveness Assessment"], "task-oriented dialogue system": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "end-to-end learning": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "knowledge retrieval": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System", "CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling", "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature", "The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance"], "response generation": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System", "What are the Generator Preferences for End-to-end Task-Oriented Dialog System?", "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation", "Thoughts to Target: Enhance Planning for Target-driven Conversation", "Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue", "SARCAT: Generative Span-Act Guided Response Generation Using Copy-Enhanced Target Augmentation"], "task-oriented dialogue system end-to-end learning": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "end-to-end learning knowledge retrieval": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "knowledge retrieval response generation": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "task-oriented dialogue system end-to-end learning knowledge retrieval": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "end-to-end learning knowledge retrieval response generation": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "task-oriented dialogue system end-to-end learning knowledge retrieval response generation": ["Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"], "dialog flow extraction": ["Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction"], "perceptual variability measurement": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "prompt reusability analysis": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "linguistic feature analysis": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "text-to-image generation perceptual variability measurement": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "perceptual variability measurement prompt reusability analysis": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "prompt reusability analysis linguistic feature analysis": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "text-to-image generation perceptual variability measurement prompt reusability analysis": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "perceptual variability measurement prompt reusability analysis linguistic feature analysis": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "text-to-image generation perceptual variability measurement prompt reusability analysis linguistic feature analysis": ["Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation"], "voting advice application": ["Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"], "contextual augmentation": ["Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"], "voting advice application contextual augmentation": ["Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"], "symbolic reasoning": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "Re-Reading Improves Reasoning in Large Language Models", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Learning to Plan by Updating Natural Language"], "last letters": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "coin flip": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "Tree of Problems: Improving structured problem solving with compositionality", "Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "arithmetic reasoning symbolic reasoning": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "symbolic reasoning commonsense reasoning": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "commonsense reasoning aqua": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "gsm8k svamp": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "svamp addsub": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "singleeq last letters": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "last letters coin flip": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "coin flip csqa": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "arithmetic reasoning symbolic reasoning commonsense reasoning": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "symbolic reasoning commonsense reasoning aqua": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "commonsense reasoning aqua gsm8k": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "aqua gsm8k svamp": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "gsm8k svamp addsub": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "svamp addsub multiarith": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "multiarith singleeq last letters": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "singleeq last letters coin flip": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "last letters coin flip csqa": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "coin flip csqa strategyqa": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "arithmetic reasoning symbolic reasoning commonsense reasoning aqua": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "symbolic reasoning commonsense reasoning aqua gsm8k": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "commonsense reasoning aqua gsm8k svamp": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "aqua gsm8k svamp addsub": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "gsm8k svamp addsub multiarith": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "svamp addsub multiarith singleeq": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "addsub multiarith singleeq last letters": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "multiarith singleeq last letters coin flip": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "singleeq last letters coin flip csqa": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "last letters coin flip csqa strategyqa": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "arithmetic reasoning symbolic reasoning commonsense reasoning aqua gsm8k": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "symbolic reasoning commonsense reasoning aqua gsm8k svamp": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "commonsense reasoning aqua gsm8k svamp addsub": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "aqua gsm8k svamp addsub multiarith": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "gsm8k svamp addsub multiarith singleeq": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "svamp addsub multiarith singleeq last letters": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "addsub multiarith singleeq last letters coin flip": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "multiarith singleeq last letters coin flip csqa": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "singleeq last letters coin flip csqa strategyqa": ["Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"], "document-level relation extraction": ["LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations", "SRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework", "Consistent Document-Level Relation Extraction via Counterfactuals"], "concept space alignment evaluation": ["Concept Space Alignment in Multilingual LLMs"], "generation detoxification": ["Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model"], "preference alignment": ["Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model", "Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective", "ORPO: Monolithic Preference Optimization without Reference Model", "FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization", "Self-Renewal Prompt Optimizing with Implicit Reasoning", "Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness"], "inference acceleration": ["Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model", "Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models"], "generation detoxification preference alignment": ["Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model"], "preference alignment inference acceleration": ["Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model"], "generation detoxification preference alignment inference acceleration": ["Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model"], "human annotation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "open-domain conversation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "news summarization": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian", "Improving Factual Consistency of News Summarization by Contrastive Preference Optimization"], "natural language generation translation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "translation human annotation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "human annotation instruction following": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "instruction following open-domain conversation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "open-domain conversation news summarization": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "news summarization natural language understanding": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "natural language understanding toxicity detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "toxicity detection bias detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "bias detection multi-task learning": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "natural language generation translation human annotation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "translation human annotation instruction following": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "human annotation instruction following open-domain conversation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "instruction following open-domain conversation news summarization": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "open-domain conversation news summarization natural language understanding": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "news summarization natural language understanding toxicity detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "natural language understanding toxicity detection bias detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "toxicity detection bias detection multi-task learning": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "natural language generation translation human annotation instruction following": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "translation human annotation instruction following open-domain conversation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "human annotation instruction following open-domain conversation news summarization": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "instruction following open-domain conversation news summarization natural language understanding": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "open-domain conversation news summarization natural language understanding toxicity detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "news summarization natural language understanding toxicity detection bias detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "natural language understanding toxicity detection bias detection multi-task learning": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "natural language generation translation human annotation instruction following open-domain conversation": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "translation human annotation instruction following open-domain conversation news summarization": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "human annotation instruction following open-domain conversation news summarization natural language understanding": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "instruction following open-domain conversation news summarization natural language understanding toxicity detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "open-domain conversation news summarization natural language understanding toxicity detection bias detection": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "news summarization natural language understanding toxicity detection bias detection multi-task learning": ["NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"], "controllable text generation": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "toxicity reduction": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework", "Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding", "Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis", "Towards Aligning Language Models with Textual Feedback", "Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models", "Promoting Constructive Deliberation: Reframing for Receptiveness"], "readability-controlled summarization": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "input-output tasks": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "controllable text generation toxicity reduction": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "toxicity reduction bias mitigation": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "bias mitigation readability-controlled summarization": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "readability-controlled summarization open-ended generation": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "open-ended generation input-output tasks": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "controllable text generation toxicity reduction bias mitigation": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "toxicity reduction bias mitigation readability-controlled summarization": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "bias mitigation readability-controlled summarization open-ended generation": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "readability-controlled summarization open-ended generation input-output tasks": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "controllable text generation toxicity reduction bias mitigation readability-controlled summarization": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "toxicity reduction bias mitigation readability-controlled summarization open-ended generation": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "bias mitigation readability-controlled summarization open-ended generation input-output tasks": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "controllable text generation toxicity reduction bias mitigation readability-controlled summarization open-ended generation": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "toxicity reduction bias mitigation readability-controlled summarization open-ended generation input-output tasks": ["RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework"], "scaling laws analysis": ["Scaling Laws Across Model Architectures: A Comparative Analysis of Dense and MoE Models in Large Language Models", "Scaling Laws for Fact Memorization of Large Language Models"], "task-oriented dialog": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems", "Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems", "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "end-to-end tod systems": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"], "dialogue generation": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems", "Ontologically Faithful Generation of Non-Player Character Dialogues", "Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning", "Paraphrase Types Elicit Prompt Engineering Capabilities", "Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models", "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities", "How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective", "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges", "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets", "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support", "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models", "Mixed-Session Conversation with Egocentric Memory", "Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers", "CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory", "TRIP NEGOTIATOR: A Travel Persona-aware Reinforced Dialogue Generation Model for Personalized Integrative Negotiation in Tourism"], "task-oriented dialog end-to-end tod systems": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"], "end-to-end tod systems in-context learning": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"], "in-context learning dialogue generation": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"], "task-oriented dialog end-to-end tod systems in-context learning": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"], "end-to-end tod systems in-context learning dialogue generation": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"], "task-oriented dialog end-to-end tod systems in-context learning dialogue generation": ["Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"], "spotlight locating": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "comparison": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "clustering": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA", "Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "chain of reasoning": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "sequential enumeration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "extremum acquisition": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "range awareness": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "report integration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "citation&reference": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "case classification": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "temporal analysis": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "spotlight locating comparison": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "comparison clustering": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "clustering chain of reasoning": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "chain of reasoning sequential enumeration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "sequential enumeration extremum acquisition": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "extremum acquisition range awareness": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "range awareness report integration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "report integration citation&reference": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "citation&reference case classification": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "case classification temporal analysis": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "spotlight locating comparison clustering": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "comparison clustering chain of reasoning": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "clustering chain of reasoning sequential enumeration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "chain of reasoning sequential enumeration extremum acquisition": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "sequential enumeration extremum acquisition range awareness": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "extremum acquisition range awareness report integration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "range awareness report integration citation&reference": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "report integration citation&reference case classification": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "citation&reference case classification temporal analysis": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "spotlight locating comparison clustering chain of reasoning": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "comparison clustering chain of reasoning sequential enumeration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "clustering chain of reasoning sequential enumeration extremum acquisition": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "chain of reasoning sequential enumeration extremum acquisition range awareness": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "sequential enumeration extremum acquisition range awareness report integration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "extremum acquisition range awareness report integration citation&reference": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "range awareness report integration citation&reference case classification": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "report integration citation&reference case classification temporal analysis": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "spotlight locating comparison clustering chain of reasoning sequential enumeration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "comparison clustering chain of reasoning sequential enumeration extremum acquisition": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "clustering chain of reasoning sequential enumeration extremum acquisition range awareness": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "chain of reasoning sequential enumeration extremum acquisition range awareness report integration": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "sequential enumeration extremum acquisition range awareness report integration citation&reference": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "extremum acquisition range awareness report integration citation&reference case classification": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "range awareness report integration citation&reference case classification temporal analysis": ["Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"], "text privatization": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "differential privacy": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting", "Private prediction for large-scale synthetic text generation"], "utility preservation": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "privacy protection": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting", "Granular Privacy Control for Geolocation with Vision Language Models", "Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "text privatization text rewriting": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "text rewriting differential privacy": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "differential privacy utility preservation": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "utility preservation privacy protection": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "text privatization text rewriting differential privacy": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "text rewriting differential privacy utility preservation": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "differential privacy utility preservation privacy protection": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "text privatization text rewriting differential privacy utility preservation": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "text rewriting differential privacy utility preservation privacy protection": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "text privatization text rewriting differential privacy utility preservation privacy protection": ["Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"], "coarse-grained perception": ["To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models"], "fine-grained perception": ["To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models", "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "coarse-grained perception fine-grained perception": ["To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models"], "fine-grained perception reasoning": ["To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models"], "coarse-grained perception fine-grained perception reasoning": ["To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models"], "meta-analysis of typological diversity claims in nlp research": ["What is \u201cTypological Diversity\u201d in NLP?"], "analysis of language samples": ["What is \u201cTypological Diversity\u201d in NLP?"], "recommendation of metrics for typological diversity": ["What is \u201cTypological Diversity\u201d in NLP?"], "meta-analysis of typological diversity claims in nlp research analysis of language samples": ["What is \u201cTypological Diversity\u201d in NLP?"], "analysis of language samples recommendation of metrics for typological diversity": ["What is \u201cTypological Diversity\u201d in NLP?"], "meta-analysis of typological diversity claims in nlp research analysis of language samples recommendation of metrics for typological diversity": ["What is \u201cTypological Diversity\u201d in NLP?"], "intellectual humility detection": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "intellectual arrogance detection": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "codebook development": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "LLM benchmarking": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse", "SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "intellectual humility detection intellectual arrogance detection": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "intellectual arrogance detection text classification": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "text classification codebook development": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "codebook development LLM benchmarking": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "intellectual humility detection intellectual arrogance detection text classification": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "intellectual arrogance detection text classification codebook development": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "text classification codebook development LLM benchmarking": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "intellectual humility detection intellectual arrogance detection text classification codebook development": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "intellectual arrogance detection text classification codebook development LLM benchmarking": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "intellectual humility detection intellectual arrogance detection text classification codebook development LLM benchmarking": ["The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse"], "language modelling": ["Consistent Bidirectional Language Modelling: Expressive Power and Representational Conciseness", "A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression"], "bidirectional language models": ["Consistent Bidirectional Language Modelling: Expressive Power and Representational Conciseness"], "language modelling bidirectional language models": ["Consistent Bidirectional Language Modelling: Expressive Power and Representational Conciseness"], "matrix language identity  determination": ["Methods for Automatic Matrix Language Determination of Code-Switched Speech"], "overall emotion tone prediction": ["Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts"], "character emotion prediction": ["Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts"], "contextually appropriate emotion expression selection": ["Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts"], "overall emotion tone prediction character emotion prediction": ["Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts"], "character emotion prediction contextually appropriate emotion expression selection": ["Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts"], "overall emotion tone prediction character emotion prediction contextually appropriate emotion expression selection": ["Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts"], "inference acceleration language modeling": ["Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models"], "question answering commonsense reasoning": ["Teaching Small Language Models Reasoning through Counterfactual Distillation"], "commonsense reasoning multi-step reasoning": ["Teaching Small Language Models Reasoning through Counterfactual Distillation"], "question answering commonsense reasoning multi-step reasoning": ["Teaching Small Language Models Reasoning through Counterfactual Distillation"], "nlg": ["Pretraining Language Models Using Translationese", "AmbigNLG: Addressing Task Ambiguity in Instruction for NLG"], "image-text retrieval": ["Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval", "Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP", "From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models", "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension", "Preserving Multi-Modal Capabilities of Pre-trained VLMS for Improving Vision-Linguistic Compositionality", "Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models", "TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "text-image retrieval": ["Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval"], "image-text retrieval text-image retrieval": ["Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval"], "dense passage retrieval": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval", "Dense Passage Retrieval: Is it Retrieving?"], "multi-teacher learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "iterative learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "assistant-based learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "dense passage retrieval knowledge distillation": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "knowledge distillation multi-teacher learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "multi-teacher learning iterative learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "iterative learning assistant-based learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "dense passage retrieval knowledge distillation multi-teacher learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "knowledge distillation multi-teacher learning iterative learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "multi-teacher learning iterative learning assistant-based learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "dense passage retrieval knowledge distillation multi-teacher learning iterative learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "knowledge distillation multi-teacher learning iterative learning assistant-based learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "dense passage retrieval knowledge distillation multi-teacher learning iterative learning assistant-based learning": ["MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"], "solidarity detection": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates"], "anti-solidarity detection": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates"], "solidarity detection anti-solidarity detection": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates"], "anti-solidarity detection text classification": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates"], "text classification sentiment analysis": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates", "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning", "Rethinking the Evaluation of In-Context Learning for LLMs", "Quantum Recurrent Architectures for Text Classification", "Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities", "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models", "Transfer Learning for Text Classification via Model Risk Analysis"], "solidarity detection anti-solidarity detection text classification": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates"], "anti-solidarity detection text classification sentiment analysis": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates"], "solidarity detection anti-solidarity detection text classification sentiment analysis": ["Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates"], "long document reading comprehension": ["CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling"], "long document reading comprehension knowledge retrieval": ["CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling"], "knowledge retrieval language modeling": ["CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling"], "long document reading comprehension knowledge retrieval language modeling": ["CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling"], "narrative retrieval": ["Story Embeddings \u2013 Narrative-Focused Representations of Fictional Stories"], "story cloze task": ["Story Embeddings \u2013 Narrative-Focused Representations of Fictional Stories"], "narrative understanding": ["Story Embeddings \u2013 Narrative-Focused Representations of Fictional Stories"], "narrative retrieval story cloze task": ["Story Embeddings \u2013 Narrative-Focused Representations of Fictional Stories"], "story cloze task narrative understanding": ["Story Embeddings \u2013 Narrative-Focused Representations of Fictional Stories"], "narrative retrieval story cloze task narrative understanding": ["Story Embeddings \u2013 Narrative-Focused Representations of Fictional Stories"], "chinese spell checking": ["C-LLM: Learn to Check Chinese Spelling Errors Character by Character"], "long-sequence language modeling": ["PSC: Extending Context Window of Large Language Models via Phase Shift Calibration"], "long-sequence language modeling passkey retrieval": ["PSC: Extending Context Window of Large Language Models via Phase Shift Calibration"], "image question answering": ["Video-LLaVA: Learning United Visual Representation by Alignment Before Projection"], "object hallucination evaluation": ["Video-LLaVA: Learning United Visual Representation by Alignment Before Projection"], "video question answering image question answering": ["Video-LLaVA: Learning United Visual Representation by Alignment Before Projection"], "image question answering object hallucination evaluation": ["Video-LLaVA: Learning United Visual Representation by Alignment Before Projection"], "video question answering image question answering object hallucination evaluation": ["Video-LLaVA: Learning United Visual Representation by Alignment Before Projection"], "confidence estimation": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "self-reflection": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "rationale generation": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales", "Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring", "SOCIALGAZE: Improving the Integration of Human Social Norms in Large Language Models"], "knowledge-intensive question answering": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "confidence estimation self-reflection": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "self-reflection rationale generation": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "rationale generation knowledge-intensive question answering": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "confidence estimation self-reflection rationale generation": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "self-reflection rationale generation knowledge-intensive question answering": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "confidence estimation self-reflection rationale generation knowledge-intensive question answering": ["SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"], "grammatical capability evaluation": ["Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing"], "language modeling grammatical capability evaluation": ["Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing"], "grammatical capability evaluation downstream task performance": ["Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing"], "language modeling grammatical capability evaluation downstream task performance": ["Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing"], "scientific concept understanding": ["Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?"], "analogy generation": ["Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?"], "scientific question answering": ["Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?", "Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "scientific concept understanding analogy generation": ["Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?"], "analogy generation scientific question answering": ["Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?"], "scientific concept understanding analogy generation scientific question answering": ["Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?"], "answer attribution": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"], "faithfulness evaluation": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation", "STORYSUMM: Evaluating Faithfulness in Story Summarization", "Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries"], "question answering answer attribution": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"], "answer attribution RAG": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"], "RAG faithfulness evaluation": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"], "question answering answer attribution RAG": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"], "answer attribution RAG faithfulness evaluation": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"], "question answering answer attribution RAG faithfulness evaluation": ["Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"], "knowledge awareness": ["Do Large Language Models Know How Much They Know?"], "information retrieval": ["Do Large Language Models Know How Much They Know?", "GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation", "FIRST: Faster Improved Listwise Reranking with Single Token Decoding", "OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer", "Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions", "Exploring the Practicality of Generative Retrieval on Dynamic Corpora", "MAIR: A Massive Benchmark for Evaluating Instructed Retrieval", "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity", "Bridging Local Details and Global Context in Text-Attributed Graphs", "LitSearch: A Retrieval Benchmark for Scientific Literature Search", "Scaling Laws for Linear Complexity Language Models", "One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models", "ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures", "LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement", "Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval", "Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation", "You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions", "Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark", "BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers", "MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning", "Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia", "Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model", "Exploring the Best Practices of Query Expansion with Large Language Models", "Revisiting Query Variation Robustness of Transformer Models", "Disentangling Questions from Query Generation for Task-Adaptive Retrieval", "MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation", "Numbers Matter! Bringing Quantity-awareness to Retrieval Systems", "Few-shot Prompting for Pairwise Ranking: An Effective Non-Parametric Retrieval Model", "Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations", "HyQE: Ranking Contexts with Hypothetical Query Embeddings"], "knowledge awareness information retrieval": ["Do Large Language Models Know How Much They Know?"], "model distillation": ["Investigating Mysteries of CoT-Augmented Distillation", "LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives"], "commonsense reasoning model distillation": ["Investigating Mysteries of CoT-Augmented Distillation"], "model distillation question answering": ["Investigating Mysteries of CoT-Augmented Distillation"], "commonsense reasoning model distillation question answering": ["Investigating Mysteries of CoT-Augmented Distillation"], "scientific text classification": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "fine-grained categorization": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "low-resource learning": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics", "Retrieval-enriched zero-shot image classification in low-resource domains", "LLM as a metric critic for low resource relation identification"], "prompt-based fine-tuning": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "verbalizer augmentation": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "scientific text classification fine-grained categorization": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "fine-grained categorization low-resource learning": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "low-resource learning prompt-based fine-tuning": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "prompt-based fine-tuning verbalizer augmentation": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "scientific text classification fine-grained categorization low-resource learning": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "fine-grained categorization low-resource learning prompt-based fine-tuning": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "low-resource learning prompt-based fine-tuning verbalizer augmentation": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "scientific text classification fine-grained categorization low-resource learning prompt-based fine-tuning": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "fine-grained categorization low-resource learning prompt-based fine-tuning verbalizer augmentation": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "scientific text classification fine-grained categorization low-resource learning prompt-based fine-tuning verbalizer augmentation": ["SCIPROMPT: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"], "visio-linguistic reasoning": ["Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP"], "visio-linguistic reasoning zero-shot classification": ["Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP"], "zero-shot classification image-text retrieval": ["Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP"], "visio-linguistic reasoning zero-shot classification image-text retrieval": ["Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP"], "entity matching": ["Learning from Natural Language Explanations for Generalizable Entity Matching", "Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "record linkage": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "data deduplication": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "conditional generation": ["Learning from Natural Language Explanations for Generalizable Entity Matching", "Aligning Large Language Models with Diverse Political Viewpoints"], "entity matching record linkage": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "record linkage data deduplication": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "data deduplication conditional generation": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "entity matching record linkage data deduplication": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "record linkage data deduplication conditional generation": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "entity matching record linkage data deduplication conditional generation": ["Learning from Natural Language Explanations for Generalizable Entity Matching"], "rag": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation", "QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning", "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs"], "query relevance evaluation": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "out-of-knowledge detection": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "query distribution shift detection": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "rag query relevance evaluation": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "query relevance evaluation out-of-knowledge detection": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "out-of-knowledge detection query distribution shift detection": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "rag query relevance evaluation out-of-knowledge detection": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "query relevance evaluation out-of-knowledge detection query distribution shift detection": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "rag query relevance evaluation out-of-knowledge detection query distribution shift detection": ["Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"], "LLM personality assessment": ["On the Reliability of Psychological Scales on Large Language Models"], "psychological scale reliability": ["On the Reliability of Psychological Scales on Large Language Models"], "simulating human populations": ["On the Reliability of Psychological Scales on Large Language Models"], "LLM personality assessment psychological scale reliability": ["On the Reliability of Psychological Scales on Large Language Models"], "psychological scale reliability simulating human populations": ["On the Reliability of Psychological Scales on Large Language Models"], "LLM personality assessment psychological scale reliability simulating human populations": ["On the Reliability of Psychological Scales on Large Language Models"], "entity coreference": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "entity disambiguation": ["Contrastive Entity Coreference and Disambiguation for Historical Texts", "ROCEL: Advancing Table Entity Linking through Distinctive Row and Column Contexts", "Efficient Overshadowed Entity Disambiguation by Mitigating Shortcut Learning"], "historical text processing": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "open-domain retrieval": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "entity coreference entity disambiguation": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "entity disambiguation historical text processing": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "historical text processing open-domain retrieval": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "entity coreference entity disambiguation historical text processing": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "entity disambiguation historical text processing open-domain retrieval": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "entity coreference entity disambiguation historical text processing open-domain retrieval": ["Contrastive Entity Coreference and Disambiguation for Historical Texts"], "fine-grained visual categorization": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models"], "visual reasoning": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models", "OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer", "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension", "Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model", "Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities", "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems", "CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models", "Plot Twist: Multimodal Models Don't Comprehend Simple Chart Details", "Large Language Models Are Challenged by Habitat-Centered Reasoning", "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables", "Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "attribute generation": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models"], "fine-grained visual categorization image captioning": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models"], "image captioning visual reasoning": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models", "Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "visual reasoning attribute generation": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models"], "fine-grained visual categorization image captioning visual reasoning": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models"], "image captioning visual reasoning attribute generation": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models"], "fine-grained visual categorization image captioning visual reasoning attribute generation": ["Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models"], "targeted concept simplification": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "text simplification": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts", "Revealing the Parallel Multilingual Learning within Large Language Models", "DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing", "Improving Minimum Bayes Risk Decoding with Multi-Prompt", "Enable Fast Sampling for Seq2Seq Text Diffusion", "ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models", "README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "domain-specific knowledge": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts", "StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "targeted concept simplification human evaluation": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "human evaluation LLM evaluation": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "LLM evaluation text simplification": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "text simplification domain-specific knowledge": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "targeted concept simplification human evaluation LLM evaluation": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "human evaluation LLM evaluation text simplification": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "LLM evaluation text simplification domain-specific knowledge": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "targeted concept simplification human evaluation LLM evaluation text simplification": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "human evaluation LLM evaluation text simplification domain-specific knowledge": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "targeted concept simplification human evaluation LLM evaluation text simplification domain-specific knowledge": ["Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"], "vision-language models  alignment": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "hallucination reduction": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment", "MDPO: Conditional Preference Optimization for Multimodal Large Language Models", "SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization", "SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM", "Self-training Large Language Models through Knowledge Detection"], "red-teaming": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment", "GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation"], "vision-language models  alignment preference learning": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "preference learning multimodal understanding": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "multimodal understanding hallucination reduction": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "hallucination reduction red-teaming": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "vision-language models  alignment preference learning multimodal understanding": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "preference learning multimodal understanding hallucination reduction": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "multimodal understanding hallucination reduction red-teaming": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "vision-language models  alignment preference learning multimodal understanding hallucination reduction": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "preference learning multimodal understanding hallucination reduction red-teaming": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "vision-language models  alignment preference learning multimodal understanding hallucination reduction red-teaming": ["VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment"], "task adaptation": ["Focused Large Language Models are Stable Many-Shot Learners", "Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "physical commonsense answering": ["Focused Large Language Models are Stable Many-Shot Learners"], "counting": ["Focused Large Language Models are Stable Many-Shot Learners", "Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "extensive knowledge and reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "multi-step mathematical reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "in-context learning task adaptation": ["Focused Large Language Models are Stable Many-Shot Learners"], "task adaptation commonsense reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "commonsense reasoning physical commonsense answering": ["Focused Large Language Models are Stable Many-Shot Learners"], "physical commonsense answering counting": ["Focused Large Language Models are Stable Many-Shot Learners"], "counting extensive knowledge and reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "extensive knowledge and reasoning multi-step mathematical reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "in-context learning task adaptation commonsense reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "task adaptation commonsense reasoning physical commonsense answering": ["Focused Large Language Models are Stable Many-Shot Learners"], "commonsense reasoning physical commonsense answering counting": ["Focused Large Language Models are Stable Many-Shot Learners"], "physical commonsense answering counting extensive knowledge and reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "counting extensive knowledge and reasoning multi-step mathematical reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "in-context learning task adaptation commonsense reasoning physical commonsense answering": ["Focused Large Language Models are Stable Many-Shot Learners"], "task adaptation commonsense reasoning physical commonsense answering counting": ["Focused Large Language Models are Stable Many-Shot Learners"], "commonsense reasoning physical commonsense answering counting extensive knowledge and reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "physical commonsense answering counting extensive knowledge and reasoning multi-step mathematical reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "in-context learning task adaptation commonsense reasoning physical commonsense answering counting": ["Focused Large Language Models are Stable Many-Shot Learners"], "task adaptation commonsense reasoning physical commonsense answering counting extensive knowledge and reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "commonsense reasoning physical commonsense answering counting extensive knowledge and reasoning multi-step mathematical reasoning": ["Focused Large Language Models are Stable Many-Shot Learners"], "asl to english translation": ["Reconsidering Sentence-Level Sign Language Translation"], "human baseline creation": ["Reconsidering Sentence-Level Sign Language Translation"], "asl to english translation human baseline creation": ["Reconsidering Sentence-Level Sign Language Translation"], "audio understanding": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "audio captioning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "event detection": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities", "ADELIE: Aligning Large Language Models on Information Extraction", "LawBench: Benchmarking Legal Knowledge of Large Language Models", "Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments", "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction", "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models", "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction"], "deductive reasoning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities", "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution", "Puzzle Solving using Reasoning of Large Language Models: A Survey", "A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "audio understanding complex reasoning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "complex reasoning instruction following": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "instruction following question answering": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "question answering audio captioning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "audio captioning event detection": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "event detection deductive reasoning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "deductive reasoning hallucination evaluation": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "audio understanding complex reasoning instruction following": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "complex reasoning instruction following question answering": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "instruction following question answering audio captioning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "question answering audio captioning event detection": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "audio captioning event detection deductive reasoning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "event detection deductive reasoning hallucination evaluation": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "audio understanding complex reasoning instruction following question answering": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "complex reasoning instruction following question answering audio captioning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "instruction following question answering audio captioning event detection": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "question answering audio captioning event detection deductive reasoning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "audio captioning event detection deductive reasoning hallucination evaluation": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "audio understanding complex reasoning instruction following question answering audio captioning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "complex reasoning instruction following question answering audio captioning event detection": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "instruction following question answering audio captioning event detection deductive reasoning": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "question answering audio captioning event detection deductive reasoning hallucination evaluation": ["GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"], "protoword reconstruction": ["Verba volant, scripta volant? Don't worry! There are computational solutions for protoword reconstruction"], "guardrail analysis": ["ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"], "bias detection guardrail analysis": ["ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"], "guardrail analysis natural language processing": ["ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"], "natural language processing LLM evaluation": ["ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"], "bias detection guardrail analysis natural language processing": ["ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"], "guardrail analysis natural language processing LLM evaluation": ["ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"], "bias detection guardrail analysis natural language processing LLM evaluation": ["ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"], "truthfulness": ["Personas as a Way to Model Truthfulness in Language Models", "Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective", "Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models", "Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "persona modeling": ["Personas as a Way to Model Truthfulness in Language Models"], "truthfulness language models": ["Personas as a Way to Model Truthfulness in Language Models"], "language models persona modeling": ["Personas as a Way to Model Truthfulness in Language Models"], "truthfulness language models persona modeling": ["Personas as a Way to Model Truthfulness in Language Models"], "phoneme recognition": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "keyword spotting": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning", "Towards Robust Speech Representation Learning for Thousands of Languages"], "intent classification": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning", "Towards Robust Speech Representation Learning for Thousands of Languages", "Self-Powered LLM Modality Expansion for Large Speech-Text Models", "LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement", "Multi-dimensional Evaluation of Empathetic Dialogue Responses", "LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization", "Class Name Guided Out-of-Scope Intent Classification"], "slot filling": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning", "Towards Robust Speech Representation Learning for Thousands of Languages", "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities", "DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding", "Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling", "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science", "Designing Logic Pattern Templates for Counter-Argument Logical Structure Analysis"], "speech recognition phoneme recognition": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "phoneme recognition keyword spotting": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "keyword spotting intent classification": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "intent classification slot filling": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning", "Towards Robust Speech Representation Learning for Thousands of Languages"], "speech recognition phoneme recognition keyword spotting": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "phoneme recognition keyword spotting intent classification": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "keyword spotting intent classification slot filling": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "speech recognition phoneme recognition keyword spotting intent classification": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "phoneme recognition keyword spotting intent classification slot filling": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "speech recognition phoneme recognition keyword spotting intent classification slot filling": ["EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning"], "long-horizon decision-making": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "subgoal prediction": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "low-level action generation": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "preference optimization": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization", "Aligning Large Language Models with Diverse Political Viewpoints", "RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs", "Model-based Preference Optimization in Abstractive Summarization without Human Feedback", "BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization", "Enhancing Alignment using Curriculum Learning & Ranked Preferences", "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "long-horizon decision-making subgoal prediction": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "subgoal prediction low-level action generation": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "low-level action generation preference optimization": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "long-horizon decision-making subgoal prediction low-level action generation": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "subgoal prediction low-level action generation preference optimization": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "long-horizon decision-making subgoal prediction low-level action generation preference optimization": ["EPO: Hierarchical LLM Agents with Environment Preference Optimization"], "text generation analysis": ["Detection and Measurement of Syntactic Templates in Generated Text"], "syntactic template detection": ["Detection and Measurement of Syntactic Templates in Generated Text"], "data memorization detection": ["Detection and Measurement of Syntactic Templates in Generated Text"], "text generation analysis syntactic template detection": ["Detection and Measurement of Syntactic Templates in Generated Text"], "syntactic template detection data memorization detection": ["Detection and Measurement of Syntactic Templates in Generated Text"], "text generation analysis syntactic template detection data memorization detection": ["Detection and Measurement of Syntactic Templates in Generated Text"], "image captioning visual grounding": ["UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"], "visual grounding object recognition": ["UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"], "visual question answering image captioning visual grounding": ["UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"], "image captioning visual grounding object recognition": ["UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"], "visual question answering image captioning visual grounding object recognition": ["UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"], "automatic speech recognition summarization": ["Optimized Speculative Sampling for GPU Hardware Accelerators"], "personalized LLMs": ["PERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts"], "personalized LLMs text classification": ["PERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts"], "text classification text generation": ["PERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts", "BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "personalized LLMs text classification text generation": ["PERSONALIZED PIECES: Efficient Personalized Large Language Models through Collaborative Efforts"], "personalized citation identification": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news categorization": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized movie tagging": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized product rating": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news headline generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized scholarly title generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized tweet paraphrasing": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized citation identification personalized news categorization": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news categorization personalized movie tagging": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized movie tagging personalized product rating": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized product rating personalized news headline generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news headline generation personalized scholarly title generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized scholarly title generation personalized tweet paraphrasing": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized citation identification personalized news categorization personalized movie tagging": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news categorization personalized movie tagging personalized product rating": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized movie tagging personalized product rating personalized news headline generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized product rating personalized news headline generation personalized scholarly title generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news headline generation personalized scholarly title generation personalized tweet paraphrasing": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized citation identification personalized news categorization personalized movie tagging personalized product rating": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news categorization personalized movie tagging personalized product rating personalized news headline generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized movie tagging personalized product rating personalized news headline generation personalized scholarly title generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized product rating personalized news headline generation personalized scholarly title generation personalized tweet paraphrasing": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized citation identification personalized news categorization personalized movie tagging personalized product rating personalized news headline generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized news categorization personalized movie tagging personalized product rating personalized news headline generation personalized scholarly title generation": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "personalized movie tagging personalized product rating personalized news headline generation personalized scholarly title generation personalized tweet paraphrasing": ["Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning"], "web page retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "slide retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "text-intensive document retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "mixed-modality task": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "document retrieval web page retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "web page retrieval slide retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "slide retrieval text-intensive document retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "text-intensive document retrieval mixed-modality task": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "document retrieval web page retrieval slide retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "web page retrieval slide retrieval text-intensive document retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "slide retrieval text-intensive document retrieval mixed-modality task": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "document retrieval web page retrieval slide retrieval text-intensive document retrieval": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "web page retrieval slide retrieval text-intensive document retrieval mixed-modality task": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "document retrieval web page retrieval slide retrieval text-intensive document retrieval mixed-modality task": ["Unifying Multimodal Retrieval via Document Screenshot Embedding"], "multilingual machine translation": ["Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation", "Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "conversational ai": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP", "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"], "data-to-text generation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP", "DATATALES: A Benchmark for Real-World Intelligent Data Narration", "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "image-video captioning": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "conversational ai abstractive summarization": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "abstractive summarization data-to-text generation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "data-to-text generation machine translation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "machine translation image-video captioning": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "image-video captioning data augmentation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "conversational ai abstractive summarization data-to-text generation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "abstractive summarization data-to-text generation machine translation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "data-to-text generation machine translation image-video captioning": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "machine translation image-video captioning data augmentation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "conversational ai abstractive summarization data-to-text generation machine translation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "abstractive summarization data-to-text generation machine translation image-video captioning": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "data-to-text generation machine translation image-video captioning data augmentation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "conversational ai abstractive summarization data-to-text generation machine translation image-video captioning": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "abstractive summarization data-to-text generation machine translation image-video captioning data augmentation": ["An Audit on the Perspectives and Challenges of Hallucinations in NLP"], "subnetwork identification": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "model pruning": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models", "Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "LaCo: Large Language Model Pruning via Layer Collapse"], "relational knowledge expression": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "knowledge localization subnetwork identification": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "subnetwork identification model pruning": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "model pruning relational knowledge expression": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "knowledge localization subnetwork identification model pruning": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "subnetwork identification model pruning relational knowledge expression": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "knowledge localization subnetwork identification model pruning relational knowledge expression": ["Discovering Knowledge-Critical Subnetworks in Pretrained Language Models"], "privacy leakage in conversation with gpt models": ["Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models"], "claim verification": ["Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering", "FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents", "One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models", "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation"], "preference matching": ["Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"], "knowledge graph question answering claim verification": ["Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"], "claim verification preference matching": ["Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"], "knowledge graph question answering claim verification preference matching": ["Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"], "preference reasoning": ["Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"], "causal commonsense reasoning": ["Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"], "preference reasoning deductive reasoning": ["Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"], "deductive reasoning causal commonsense reasoning": ["Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"], "preference reasoning deductive reasoning causal commonsense reasoning": ["Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"], "monolingual generation": ["Understanding and Mitigating Language Confusion in LLMs"], "cross-lingual generation": ["Understanding and Mitigating Language Confusion in LLMs"], "monolingual generation cross-lingual generation": ["Understanding and Mitigating Language Confusion in LLMs"], "abstract reasoning": ["Can Large Language Models Learn Independent Causal Mechanisms?", "ANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies", "Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game", "Inference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs", "CELLO: Causal Evaluation of Large Vision-Language Models"], "causal reasoning": ["Can Large Language Models Learn Independent Causal Mechanisms?", "CAT-BENCH: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans", "Learning to Plan by Updating Natural Language", "Exploring Design Choices for Building Language-Specific LLMs"], "out-of-distribution generalization": ["Can Large Language Models Learn Independent Causal Mechanisms?"], "abstract reasoning causal reasoning": ["Can Large Language Models Learn Independent Causal Mechanisms?"], "causal reasoning out-of-distribution generalization": ["Can Large Language Models Learn Independent Causal Mechanisms?"], "out-of-distribution generalization language modeling": ["Can Large Language Models Learn Independent Causal Mechanisms?"], "abstract reasoning causal reasoning out-of-distribution generalization": ["Can Large Language Models Learn Independent Causal Mechanisms?"], "causal reasoning out-of-distribution generalization language modeling": ["Can Large Language Models Learn Independent Causal Mechanisms?"], "abstract reasoning causal reasoning out-of-distribution generalization language modeling": ["Can Large Language Models Learn Independent Causal Mechanisms?"], "narrative generation": ["MIRRORSTORIES: Reflecting Diversity through Personalized Narrative Generation with Large Language Models"], "intention selection": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention following": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention summarization": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention guessing": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention selection intention following": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention following intention summarization": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention summarization intention guessing": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention selection intention following intention summarization": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention following intention summarization intention guessing": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "intention selection intention following intention summarization intention guessing": ["INTERINTENT: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context"], "cross-lingual comparison": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "information gap detection": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "narrative inconsistency detection": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "fact alignment": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "cross-lingual comparison information gap detection": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "information gap detection narrative inconsistency detection": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "narrative inconsistency detection fact alignment": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "cross-lingual comparison information gap detection narrative inconsistency detection": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "information gap detection narrative inconsistency detection fact alignment": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "cross-lingual comparison information gap detection narrative inconsistency detection fact alignment": ["Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"], "cultural visual grounding": ["From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models"], "image-text retrieval cultural visual grounding": ["From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models"], "multi-style controllable generation": ["Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation"], "neuron analysis": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "domain-specific neurons identification": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "multimodal LLMs interpretability": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "neuron analysis domain-specific neurons identification": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "domain-specific neurons identification multimodal LLMs interpretability": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "multimodal LLMs interpretability visual question answering": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "neuron analysis domain-specific neurons identification multimodal LLMs interpretability": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "domain-specific neurons identification multimodal LLMs interpretability visual question answering": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "neuron analysis domain-specific neurons identification multimodal LLMs interpretability visual question answering": ["MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"], "structured entity extraction": ["Learning to Extract Structured Entities Using Language Models"], "nlg evaluation": ["Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons", "Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"], "comparative assessment": ["Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons"], "nlg evaluation comparative assessment": ["Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons"], "information extraction": ["A Survey of AMR Applications", "Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights", "Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction", "Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding", "Paraphrase Types Elicit Prompt Engineering Capabilities", "FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents", "TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs", "De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP", "When and Where Did It Happen? An Encoder-Decoder Model to Identify Scenario Context", "Schema-Driven Information Extraction from Heterogeneous Tables", "SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "explainable semantic similarity": ["A Survey of AMR Applications"], "dialogue evaluation": ["A Survey of AMR Applications", "SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "paraphrase generation": ["A Survey of AMR Applications"], "grammatical error correction": ["A Survey of AMR Applications", "Multi-pass Decoding for Grammatical Error Correction", "LLM-based Code-Switched Text Generation for Grammatical Error Correction", "To Err Is Human, but Llamas Can Learn It Too", "To Ask LLMs about English Grammaticality, Prompt Them in a Different Language", "Gazelle: An Instruction Dataset for Arabic Writing Assistance", "Efficient and Interpretable Grammatical Error Correction with Mixture of Experts"], "information extraction question answering": ["A Survey of AMR Applications", "Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding"], "question answering summarization": ["A Survey of AMR Applications", "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation", "LongAlign: A Recipe for Long Context Alignment of Large Language Models", "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "Calibrating Long-form Generations from Large Language Models"], "summarization explainable semantic similarity": ["A Survey of AMR Applications"], "explainable semantic similarity dialogue evaluation": ["A Survey of AMR Applications"], "dialogue evaluation style transfer": ["A Survey of AMR Applications"], "style transfer paraphrase generation": ["A Survey of AMR Applications"], "paraphrase generation grammatical error correction": ["A Survey of AMR Applications"], "grammatical error correction machine translation": ["A Survey of AMR Applications"], "machine translation image captioning": ["A Survey of AMR Applications"], "information extraction question answering summarization": ["A Survey of AMR Applications"], "question answering summarization explainable semantic similarity": ["A Survey of AMR Applications"], "summarization explainable semantic similarity dialogue evaluation": ["A Survey of AMR Applications"], "explainable semantic similarity dialogue evaluation style transfer": ["A Survey of AMR Applications"], "dialogue evaluation style transfer paraphrase generation": ["A Survey of AMR Applications"], "style transfer paraphrase generation grammatical error correction": ["A Survey of AMR Applications"], "paraphrase generation grammatical error correction machine translation": ["A Survey of AMR Applications"], "grammatical error correction machine translation image captioning": ["A Survey of AMR Applications"], "information extraction question answering summarization explainable semantic similarity": ["A Survey of AMR Applications"], "question answering summarization explainable semantic similarity dialogue evaluation": ["A Survey of AMR Applications"], "summarization explainable semantic similarity dialogue evaluation style transfer": ["A Survey of AMR Applications"], "explainable semantic similarity dialogue evaluation style transfer paraphrase generation": ["A Survey of AMR Applications"], "dialogue evaluation style transfer paraphrase generation grammatical error correction": ["A Survey of AMR Applications"], "style transfer paraphrase generation grammatical error correction machine translation": ["A Survey of AMR Applications"], "paraphrase generation grammatical error correction machine translation image captioning": ["A Survey of AMR Applications"], "information extraction question answering summarization explainable semantic similarity dialogue evaluation": ["A Survey of AMR Applications"], "question answering summarization explainable semantic similarity dialogue evaluation style transfer": ["A Survey of AMR Applications"], "summarization explainable semantic similarity dialogue evaluation style transfer paraphrase generation": ["A Survey of AMR Applications"], "explainable semantic similarity dialogue evaluation style transfer paraphrase generation grammatical error correction": ["A Survey of AMR Applications"], "dialogue evaluation style transfer paraphrase generation grammatical error correction machine translation": ["A Survey of AMR Applications"], "style transfer paraphrase generation grammatical error correction machine translation image captioning": ["A Survey of AMR Applications"], "image reasoning": ["Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"], "visual question answering image reasoning": ["Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"], "caregiver strategy classification": ["CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation"], "paraphrasing": ["CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "Dual-Phase Accelerated Prompt Optimization"], "caregiver strategy classification data augmentation": ["CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation"], "data augmentation paraphrasing": ["CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation"], "caregiver strategy classification data augmentation paraphrasing": ["CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation"], "LLM security": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion", "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"], "ownership protection": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "abuse prevention": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "weight protection": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "LLM security ownership protection": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "ownership protection abuse prevention": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "abuse prevention weight protection": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "LLM security ownership protection abuse prevention": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "ownership protection abuse prevention weight protection": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "LLM security ownership protection abuse prevention weight protection": ["Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion"], "temporal knowledge graph question answering": ["TimeR4: Time-aware Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering"], "hallucination detection natural language processing": ["Knowledge-Centric Hallucination Detection"], "machine translation natural language inference": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "natural language inference reading comprehension": ["Revealing the Parallel Multilingual Learning within Large Language Models", "More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation", "Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals"], "reading comprehension text simplification": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "text simplification abstractive summarization": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "abstractive summarization mathematical reasoning": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "machine translation natural language inference reading comprehension": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "natural language inference reading comprehension text simplification": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "reading comprehension text simplification abstractive summarization": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "text simplification abstractive summarization mathematical reasoning": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "machine translation natural language inference reading comprehension text simplification": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "natural language inference reading comprehension text simplification abstractive summarization": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "reading comprehension text simplification abstractive summarization mathematical reasoning": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "machine translation natural language inference reading comprehension text simplification abstractive summarization": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "natural language inference reading comprehension text simplification abstractive summarization mathematical reasoning": ["Revealing the Parallel Multilingual Learning within Large Language Models"], "instruction following mathematical reasoning": ["Automatic Instruction Evolving for Large Language Models"], "mathematical reasoning code generation": ["Automatic Instruction Evolving for Large Language Models"], "instruction following mathematical reasoning code generation": ["Automatic Instruction Evolving for Large Language Models"], "text evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "harmful response detection": ["RepEval: Effective Text Evaluation with LLM Representation", "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"], "high-quality data identification": ["RepEval: Effective Text Evaluation with LLM Representation"], "preference data construction": ["RepEval: Effective Text Evaluation with LLM Representation"], "absolute evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "pair-wise evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "fluency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "coherence evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "text evaluation harmful response detection": ["RepEval: Effective Text Evaluation with LLM Representation"], "harmful response detection high-quality data identification": ["RepEval: Effective Text Evaluation with LLM Representation"], "high-quality data identification preference data construction": ["RepEval: Effective Text Evaluation with LLM Representation"], "preference data construction absolute evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "absolute evaluation pair-wise evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "pair-wise evaluation fluency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "fluency evaluation consistency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "consistency evaluation coherence evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "text evaluation harmful response detection high-quality data identification": ["RepEval: Effective Text Evaluation with LLM Representation"], "harmful response detection high-quality data identification preference data construction": ["RepEval: Effective Text Evaluation with LLM Representation"], "high-quality data identification preference data construction absolute evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "preference data construction absolute evaluation pair-wise evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "absolute evaluation pair-wise evaluation fluency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "pair-wise evaluation fluency evaluation consistency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "fluency evaluation consistency evaluation coherence evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "text evaluation harmful response detection high-quality data identification preference data construction": ["RepEval: Effective Text Evaluation with LLM Representation"], "harmful response detection high-quality data identification preference data construction absolute evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "high-quality data identification preference data construction absolute evaluation pair-wise evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "preference data construction absolute evaluation pair-wise evaluation fluency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "absolute evaluation pair-wise evaluation fluency evaluation consistency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "pair-wise evaluation fluency evaluation consistency evaluation coherence evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "text evaluation harmful response detection high-quality data identification preference data construction absolute evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "harmful response detection high-quality data identification preference data construction absolute evaluation pair-wise evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "high-quality data identification preference data construction absolute evaluation pair-wise evaluation fluency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "preference data construction absolute evaluation pair-wise evaluation fluency evaluation consistency evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "absolute evaluation pair-wise evaluation fluency evaluation consistency evaluation coherence evaluation": ["RepEval: Effective Text Evaluation with LLM Representation"], "medical decision rule extraction": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "autoregressive generation": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "medical decision rule extraction sequence-to-sequence generation": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "sequence-to-sequence generation autoregressive generation": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "autoregressive generation natural language generation": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "medical decision rule extraction sequence-to-sequence generation autoregressive generation": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "sequence-to-sequence generation autoregressive generation natural language generation": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "medical decision rule extraction sequence-to-sequence generation autoregressive generation natural language generation": ["Generative Models for Automatic Medical Decision Rule Extraction from Text"], "jailbreak attack analysis": ["Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis"], "text categorization": ["Does Large Language Model Contain Task-Specific Neurons?", "Paraphrase Types Elicit Prompt Engineering Capabilities"], "question understanding": ["Does Large Language Model Contain Task-Specific Neurons?", "Paraphrase Types Elicit Prompt Engineering Capabilities"], "law text categorization": ["Does Large Language Model Contain Task-Specific Neurons?"], "cause effect classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "text matching": ["Does Large Language Model Contain Task-Specific Neurons?", "Paraphrase Types Elicit Prompt Engineering Capabilities"], "text categorization sentiment analysis": ["Does Large Language Model Contain Task-Specific Neurons?"], "sentiment analysis question answering": ["Does Large Language Model Contain Task-Specific Neurons?", "Rethinking the Evaluation of In-Context Learning for LLMs", "The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "question answering question understanding": ["Does Large Language Model Contain Task-Specific Neurons?"], "question understanding law text categorization": ["Does Large Language Model Contain Task-Specific Neurons?"], "law text categorization cause effect classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "cause effect classification emotion classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "emotion classification text matching": ["Does Large Language Model Contain Task-Specific Neurons?"], "text categorization sentiment analysis question answering": ["Does Large Language Model Contain Task-Specific Neurons?"], "sentiment analysis question answering question understanding": ["Does Large Language Model Contain Task-Specific Neurons?"], "question answering question understanding law text categorization": ["Does Large Language Model Contain Task-Specific Neurons?"], "question understanding law text categorization cause effect classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "law text categorization cause effect classification emotion classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "cause effect classification emotion classification text matching": ["Does Large Language Model Contain Task-Specific Neurons?"], "text categorization sentiment analysis question answering question understanding": ["Does Large Language Model Contain Task-Specific Neurons?"], "sentiment analysis question answering question understanding law text categorization": ["Does Large Language Model Contain Task-Specific Neurons?"], "question answering question understanding law text categorization cause effect classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "question understanding law text categorization cause effect classification emotion classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "law text categorization cause effect classification emotion classification text matching": ["Does Large Language Model Contain Task-Specific Neurons?"], "text categorization sentiment analysis question answering question understanding law text categorization": ["Does Large Language Model Contain Task-Specific Neurons?"], "sentiment analysis question answering question understanding law text categorization cause effect classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "question answering question understanding law text categorization cause effect classification emotion classification": ["Does Large Language Model Contain Task-Specific Neurons?"], "question understanding law text categorization cause effect classification emotion classification text matching": ["Does Large Language Model Contain Task-Specific Neurons?"], "suppositional reasoning": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "logical deduction": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "truthfulness assessment": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "hypothetical scenarios": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "suppositional reasoning logical deduction": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "logical deduction truthfulness assessment": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "truthfulness assessment hypothetical scenarios": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "suppositional reasoning logical deduction truthfulness assessment": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "logical deduction truthfulness assessment hypothetical scenarios": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "suppositional reasoning logical deduction truthfulness assessment hypothetical scenarios": ["Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models"], "test-time adaptation": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings", "Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech"], "domain adaptation": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings", "Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition", "Domain adapted machine translation: What does catastrophic forgetting forget and why?", "Generation with Dynamic Vocabulary", "Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?", "Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts", "A Survey on Natural Language Counterfactual Generation", "Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "noise robustness": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings", "Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models", "Resilience of Large Language Models for Noisy Instructions"], "automatic speech recognition test-time adaptation": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings"], "test-time adaptation domain adaptation": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings"], "domain adaptation noise robustness": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings"], "automatic speech recognition test-time adaptation domain adaptation": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings"], "test-time adaptation domain adaptation noise robustness": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings"], "automatic speech recognition test-time adaptation domain adaptation noise robustness": ["Advancing Test-Time Adaptation in Wild Acoustic Test Settings"], "semantic parsing in-context learning": ["Learning to Retrieve Iteratively for In-Context Learning"], "in-context learning few-shot learning": ["Learning to Retrieve Iteratively for In-Context Learning"], "semantic parsing in-context learning few-shot learning": ["Learning to Retrieve Iteratively for In-Context Learning"], "academic paper search": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "literature discovery": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "scientific advancement": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "semantic indexing": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "concept matching": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "academic paper search literature discovery": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "literature discovery scientific advancement": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "scientific advancement semantic indexing": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "semantic indexing concept matching": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "academic paper search literature discovery scientific advancement": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "literature discovery scientific advancement semantic indexing": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "scientific advancement semantic indexing concept matching": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "academic paper search literature discovery scientific advancement semantic indexing": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "literature discovery scientific advancement semantic indexing concept matching": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "academic paper search literature discovery scientific advancement semantic indexing concept matching": ["Taxonomy-guided Semantic Indexing for Academic Paper Search"], "math application": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "date": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "tabular": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "spatial": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "math application date": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "date tabular": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "tabular spatial": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "spatial math": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "math application date tabular": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "date tabular spatial": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "tabular spatial math": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "math application date tabular spatial": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "date tabular spatial math": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "math application date tabular spatial math": ["Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"], "transfer learning": ["Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models", "NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data", "Data Contamination Can Cross Language Barriers", "Scaling Sentence Embeddings with Large Language Models", "Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation", "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "jailbreaking LLMs": ["Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models", "GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation", "DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLMs Jailbreakers"], "adversarial attacks transfer learning": ["Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models"], "transfer learning jailbreaking LLMs": ["Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models"], "adversarial attacks transfer learning jailbreaking LLMs": ["Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models"], "incomplete utterance rewriting": ["Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"], "fuzzy reasoning": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "quantifier reasoning": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "fuzzy reasoning mathematical reasoning": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "mathematical reasoning quantifier reasoning": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "quantifier reasoning natural language understanding": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "fuzzy reasoning mathematical reasoning quantifier reasoning": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "mathematical reasoning quantifier reasoning natural language understanding": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "fuzzy reasoning mathematical reasoning quantifier reasoning natural language understanding": ["FROG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models"], "political bias mitigation": ["Aligning Large Language Models with Diverse Political Viewpoints"], "text summarization": ["Aligning Large Language Models with Diverse Political Viewpoints", "Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic", "Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors", "Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding", "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges", "Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?", "FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping", "Semformer: Transformer Language Models with Semantic Planning", "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "Exploring the Relationship between In-Context Learning and Instruction Tuning", "Divide and Conquer: Legal Concept-guided Criminal Court View Generation", "RoQLlama: A Lightweight Romanian Adapted Language Model", "ALIGNSUM: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference", "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation", "HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues", "A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers", "FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models", "Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions", "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "conditional generation preference optimization": ["Aligning Large Language Models with Diverse Political Viewpoints"], "preference optimization political bias mitigation": ["Aligning Large Language Models with Diverse Political Viewpoints"], "political bias mitigation text summarization": ["Aligning Large Language Models with Diverse Political Viewpoints"], "conditional generation preference optimization political bias mitigation": ["Aligning Large Language Models with Diverse Political Viewpoints"], "preference optimization political bias mitigation text summarization": ["Aligning Large Language Models with Diverse Political Viewpoints"], "conditional generation preference optimization political bias mitigation text summarization": ["Aligning Large Language Models with Diverse Political Viewpoints"], "hiring recommendation": ["\"You Gotta be a Doctor, Lin\": An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations"], "salary recommendation": ["\"You Gotta be a Doctor, Lin\": An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations"], "hiring recommendation salary recommendation": ["\"You Gotta be a Doctor, Lin\": An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations"], "long-text modeling": ["Extending Context Window of Large Language Models from a Distributional Perspective"], "context window extension": ["Extending Context Window of Large Language Models from a Distributional Perspective"], "long-text modeling context window extension": ["Extending Context Window of Large Language Models from a Distributional Perspective"], "context window extension language modeling": ["Extending Context Window of Large Language Models from a Distributional Perspective"], "long-text modeling context window extension language modeling": ["Extending Context Window of Large Language Models from a Distributional Perspective"], "argument structure construction identification": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "supervised learning": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions", "README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "prompt-guided annotation": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "argument structure construction identification supervised learning": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "supervised learning prompt-guided annotation": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "prompt-guided annotation data generation": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "argument structure construction identification supervised learning prompt-guided annotation": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "supervised learning prompt-guided annotation data generation": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "argument structure construction identification supervised learning prompt-guided annotation data generation": ["Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions"], "multi-agent systems": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "social deduction games": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "game theory scenarios": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "multi-agent systems LLM evaluation": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "LLM evaluation social deduction games": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "social deduction games game theory scenarios": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "game theory scenarios reasoning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "reasoning planning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "On the Empirical Complexity of Reasoning and Planning in LLMs"], "planning collaboration": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "multi-agent systems LLM evaluation social deduction games": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "LLM evaluation social deduction games game theory scenarios": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "social deduction games game theory scenarios reasoning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "game theory scenarios reasoning planning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "reasoning planning collaboration": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "multi-agent systems LLM evaluation social deduction games game theory scenarios": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "LLM evaluation social deduction games game theory scenarios reasoning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "social deduction games game theory scenarios reasoning planning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "game theory scenarios reasoning planning collaboration": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "multi-agent systems LLM evaluation social deduction games game theory scenarios reasoning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "LLM evaluation social deduction games game theory scenarios reasoning planning": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "social deduction games game theory scenarios reasoning planning collaboration": ["MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"], "RAG in-context learning": ["Position Engineering: Boosting Large Language Models through Positional Information Manipulation", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "medical image analysis": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"], "data denoising": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data reformatting": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical multimodal capabilities": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical understanding": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical reasoning": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios", "MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "image captioning multimodal learning": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "multimodal learning medical image analysis": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical image analysis data denoising": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data denoising data reformatting": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data reformatting knowledge injection": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "knowledge injection medical multimodal capabilities": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical multimodal capabilities medical understanding": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical understanding medical reasoning": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "visual question answering image captioning multimodal learning": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "image captioning multimodal learning medical image analysis": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "multimodal learning medical image analysis data denoising": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical image analysis data denoising data reformatting": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data denoising data reformatting knowledge injection": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data reformatting knowledge injection medical multimodal capabilities": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "knowledge injection medical multimodal capabilities medical understanding": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical multimodal capabilities medical understanding medical reasoning": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "visual question answering image captioning multimodal learning medical image analysis": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "image captioning multimodal learning medical image analysis data denoising": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "multimodal learning medical image analysis data denoising data reformatting": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical image analysis data denoising data reformatting knowledge injection": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data denoising data reformatting knowledge injection medical multimodal capabilities": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data reformatting knowledge injection medical multimodal capabilities medical understanding": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "knowledge injection medical multimodal capabilities medical understanding medical reasoning": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "visual question answering image captioning multimodal learning medical image analysis data denoising": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "image captioning multimodal learning medical image analysis data denoising data reformatting": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "multimodal learning medical image analysis data denoising data reformatting knowledge injection": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "medical image analysis data denoising data reformatting knowledge injection medical multimodal capabilities": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data denoising data reformatting knowledge injection medical multimodal capabilities medical understanding": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "data reformatting knowledge injection medical multimodal capabilities medical understanding medical reasoning": ["Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"], "closed ie": ["ADELIE: Aligning Large Language Models on Information Extraction"], "open ie": ["ADELIE: Aligning Large Language Models on Information Extraction"], "on-demand ie": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation classification": ["ADELIE: Aligning Large Language Models on Information Extraction", "GDTB: Genre Diverse Data for English Shallow Discourse Parsing across Modalities, Text Types, and Domains", "InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration", "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "event argument extraction": ["ADELIE: Aligning Large Language Models on Information Extraction", "Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments", "DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction", "OEE-CFC: A Dataset for Open Event Extraction from Chinese Financial Commentary", "MMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling", "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science", "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction"], "event relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction", "Are LLMs Good Annotators for Discourse-level Event Relation Extraction?", "Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "closed ie open ie": ["ADELIE: Aligning Large Language Models on Information Extraction"], "open ie on-demand ie": ["ADELIE: Aligning Large Language Models on Information Extraction"], "on-demand ie named entity recognition": ["ADELIE: Aligning Large Language Models on Information Extraction"], "named entity recognition relation classification": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation classification relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation extraction event detection": ["ADELIE: Aligning Large Language Models on Information Extraction"], "event detection event argument extraction": ["ADELIE: Aligning Large Language Models on Information Extraction", "Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments", "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction"], "event argument extraction event extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "event extraction event relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "closed ie open ie on-demand ie": ["ADELIE: Aligning Large Language Models on Information Extraction"], "open ie on-demand ie named entity recognition": ["ADELIE: Aligning Large Language Models on Information Extraction"], "on-demand ie named entity recognition relation classification": ["ADELIE: Aligning Large Language Models on Information Extraction"], "named entity recognition relation classification relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation classification relation extraction event detection": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation extraction event detection event argument extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "event detection event argument extraction event extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "event argument extraction event extraction event relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "closed ie open ie on-demand ie named entity recognition": ["ADELIE: Aligning Large Language Models on Information Extraction"], "open ie on-demand ie named entity recognition relation classification": ["ADELIE: Aligning Large Language Models on Information Extraction"], "on-demand ie named entity recognition relation classification relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "named entity recognition relation classification relation extraction event detection": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation classification relation extraction event detection event argument extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation extraction event detection event argument extraction event extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "event detection event argument extraction event extraction event relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "closed ie open ie on-demand ie named entity recognition relation classification": ["ADELIE: Aligning Large Language Models on Information Extraction"], "open ie on-demand ie named entity recognition relation classification relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "on-demand ie named entity recognition relation classification relation extraction event detection": ["ADELIE: Aligning Large Language Models on Information Extraction"], "named entity recognition relation classification relation extraction event detection event argument extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation classification relation extraction event detection event argument extraction event extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "relation extraction event detection event argument extraction event extraction event relation extraction": ["ADELIE: Aligning Large Language Models on Information Extraction"], "factual reasoning": ["Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons"], "tokenization": ["Lexically Grounded Subword Segmentation", "Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs", "BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training"], "subword segmentation": ["Lexically Grounded Subword Segmentation"], "morphological analysis": ["Lexically Grounded Subword Segmentation"], "tokenization subword segmentation": ["Lexically Grounded Subword Segmentation"], "subword segmentation morphological analysis": ["Lexically Grounded Subword Segmentation"], "morphological analysis part-of-speech tagging": ["Lexically Grounded Subword Segmentation"], "part-of-speech tagging machine translation": ["Lexically Grounded Subword Segmentation"], "tokenization subword segmentation morphological analysis": ["Lexically Grounded Subword Segmentation"], "subword segmentation morphological analysis part-of-speech tagging": ["Lexically Grounded Subword Segmentation"], "morphological analysis part-of-speech tagging machine translation": ["Lexically Grounded Subword Segmentation"], "tokenization subword segmentation morphological analysis part-of-speech tagging": ["Lexically Grounded Subword Segmentation"], "subword segmentation morphological analysis part-of-speech tagging machine translation": ["Lexically Grounded Subword Segmentation"], "tokenization subword segmentation morphological analysis part-of-speech tagging machine translation": ["Lexically Grounded Subword Segmentation"], "multi-turn conversation": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping"], "multi-turn conversation code generation": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "code generation mathematical reasoning": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "mathematical reasoning instruction following": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees", "Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment"], "instruction following summarization": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "multi-turn conversation code generation mathematical reasoning": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "code generation mathematical reasoning instruction following": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "mathematical reasoning instruction following summarization": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "instruction following summarization question answering": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "multi-turn conversation code generation mathematical reasoning instruction following": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "code generation mathematical reasoning instruction following summarization": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "mathematical reasoning instruction following summarization question answering": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "multi-turn conversation code generation mathematical reasoning instruction following summarization": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "code generation mathematical reasoning instruction following summarization question answering": ["EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"], "text-to-vis": ["Do Text-to-Vis Benchmarks Test Real Use of Visualisations?"], "benchmark analysis": ["Do Text-to-Vis Benchmarks Test Real Use of Visualisations?"], "code analysis": ["Do Text-to-Vis Benchmarks Test Real Use of Visualisations?", "Applying Contrastive Learning to Code Vulnerability Type Classification"], "text-to-vis benchmark analysis": ["Do Text-to-Vis Benchmarks Test Real Use of Visualisations?"], "benchmark analysis code analysis": ["Do Text-to-Vis Benchmarks Test Real Use of Visualisations?"], "text-to-vis benchmark analysis code analysis": ["Do Text-to-Vis Benchmarks Test Real Use of Visualisations?"], "vocabulary expansion": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "domain-specific LLMs": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "math calculation": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "safety assessment": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "vocabulary expansion domain-specific LLMs": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "domain-specific LLMs catastrophic forgetting mitigation": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "catastrophic forgetting mitigation instruction following": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "instruction following math calculation": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "math calculation safety assessment": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "vocabulary expansion domain-specific LLMs catastrophic forgetting mitigation": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "domain-specific LLMs catastrophic forgetting mitigation instruction following": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "catastrophic forgetting mitigation instruction following math calculation": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "instruction following math calculation safety assessment": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "vocabulary expansion domain-specific LLMs catastrophic forgetting mitigation instruction following": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "domain-specific LLMs catastrophic forgetting mitigation instruction following math calculation": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "catastrophic forgetting mitigation instruction following math calculation safety assessment": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "vocabulary expansion domain-specific LLMs catastrophic forgetting mitigation instruction following math calculation": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "domain-specific LLMs catastrophic forgetting mitigation instruction following math calculation safety assessment": ["Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs"], "fairness in LLM": ["Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning"], "tabular data classification": ["Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning", "Precise Model Benchmarking with Only a Few Observations"], "fairness in LLM in-context learning": ["Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning"], "in-context learning tabular data classification": ["Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning"], "fairness in LLM in-context learning tabular data classification": ["Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning"], "dialect identification": ["Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges", "Casablanca: Data and Models for Multidialectal Arabic Speech Recognition"], "dialect identification speech recognition": ["Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges"], "LLM assessment": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"], "robustness analysis": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment", "Assessing and Verifying Task Utility in LLM-Powered Applications", "Robust Text Classification: Analyzing Prototype-Based Networks"], "LLM assessment adversarial attack": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"], "adversarial attack robustness analysis": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"], "robustness analysis zero-shot learning": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"], "LLM assessment adversarial attack robustness analysis": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"], "adversarial attack robustness analysis zero-shot learning": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"], "LLM assessment adversarial attack robustness analysis zero-shot learning": ["Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"], "knowledge clarity": ["Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal"], "entity correlation modeling": ["Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal"], "pairwise relationship reasoning capability": ["Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal"], "knowledge clarity entity correlation modeling": ["Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal"], "entity correlation modeling pairwise relationship reasoning capability": ["Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal"], "knowledge clarity entity correlation modeling pairwise relationship reasoning capability": ["Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal"], "law article qa": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "calculation": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "safe dialogues": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "legal ie": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "mrc": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "legal event summary": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "law article qa reasoning": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "reasoning calculation": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "calculation safe dialogues": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "safe dialogues legal ie": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "legal ie mrc": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "mrc legal event summary": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "law article qa reasoning calculation": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "reasoning calculation safe dialogues": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "calculation safe dialogues legal ie": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "safe dialogues legal ie mrc": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "legal ie mrc legal event summary": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "law article qa reasoning calculation safe dialogues": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "reasoning calculation safe dialogues legal ie": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "calculation safe dialogues legal ie mrc": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "safe dialogues legal ie mrc legal event summary": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "law article qa reasoning calculation safe dialogues legal ie": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "reasoning calculation safe dialogues legal ie mrc": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "calculation safe dialogues legal ie mrc legal event summary": ["More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"], "speech translation": ["Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models", "Towards Robust Speech Representation Learning for Thousands of Languages", "Self-Powered LLM Modality Expansion for Large Speech-Text Models", "Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "automatic speech recognition speech translation": ["Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models"], "rank aggregation": ["GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation"], "zero-shot document retrieval information retrieval": ["GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation"], "information retrieval rank aggregation": ["GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation"], "zero-shot document retrieval information retrieval rank aggregation": ["GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation"], "LLM interpretability": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"], "knowledge graph integration": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs", "LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments"], "LLM interpretability explanation generation": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"], "explanation generation knowledge graph integration": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"], "knowledge graph integration qa": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"], "LLM interpretability explanation generation knowledge graph integration": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"], "explanation generation knowledge graph integration qa": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"], "LLM interpretability explanation generation knowledge graph integration qa": ["XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"], "radiology report generation": ["Divide and Conquer Radiology Report Generation via Observation Level Fine-grained Pretraining and Prompt Tuning", "RaTEScore: A Metric for Radiology Report Generation", "ICON: Improving Inter-Report Consistency in Radiology Report Generation via Lesion-aware Mixup Augmentation"], "vqa": ["SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information", "CommVQA: Situating Visual Question Answering in Communicative Contexts", "VGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning", "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent", "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding", "Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design"], "captioning": ["SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information", "Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling"], "vqa captioning": ["SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information"], "captioning classification": ["SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information"], "vqa captioning classification": ["SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information"], "sequential decision-making": ["UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models"], "uno game playing": ["UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models"], "sequential decision-making LLMs": ["UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models"], "LLMs uno game playing": ["UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models"], "sequential decision-making LLMs uno game playing": ["UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models"], "kbqa": ["Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments"], "kbqa text-to-sql": ["Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments"], "personalized dialogue generation": ["Morpheus: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space", "\u201cIn Dialogues We Learn\u201d: Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning"], "privacy-preserving synthetic text generation": ["KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"], "client-server framework": ["KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"], "privacy-preserving synthetic text generation knowledge distillation": ["KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"], "knowledge distillation client-server framework": ["KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"], "privacy-preserving synthetic text generation knowledge distillation client-server framework": ["KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"], "object hallucination reduction": ["DAMRO: Dive into the Attention Mechanism of LVLM to Reduce Object Hallucination"], "planning interpretability analysis": ["Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"], "multi-layer perception": ["Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"], "multi-head self-attention": ["Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"], "planning interpretability analysis multi-layer perception": ["Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"], "multi-layer perception multi-head self-attention": ["Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"], "planning interpretability analysis multi-layer perception multi-head self-attention": ["Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"], "continual pre-training": ["Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale", "A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models", "CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models", "Improving Referring Ability for Biomedical Language Models", "Unlocking Continual Learning Abilities in Language Models"], "language model scaling": ["Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale"], "cross-lingual transfer learning continual pre-training": ["Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale"], "continual pre-training language model scaling": ["Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale"], "cross-lingual transfer learning continual pre-training language model scaling": ["Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale"], "multilingual question answering": ["An Empirical Study of Multilingual Reasoning Distillation for Question Answering"], "reasoning distillation": ["An Empirical Study of Multilingual Reasoning Distillation for Question Answering"], "multilingual question answering reasoning distillation": ["An Empirical Study of Multilingual Reasoning Distillation for Question Answering"], "knowledge-intensive qa": ["Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?"], "question answering knowledge-intensive qa": ["Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?"], "closed-book question answering": ["Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?", "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "cross-modality learning": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "vision-language hate speech": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "text-based hate speech classification": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "hate speech detection cross-modality learning": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "cross-modality learning few-shot learning": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "few-shot learning in-context learning": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "in-context learning vision-language hate speech": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "vision-language hate speech text-based hate speech classification": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "hate speech detection cross-modality learning few-shot learning": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "cross-modality learning few-shot learning in-context learning": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "few-shot learning in-context learning vision-language hate speech": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "in-context learning vision-language hate speech text-based hate speech classification": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "hate speech detection cross-modality learning few-shot learning in-context learning": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "cross-modality learning few-shot learning in-context learning vision-language hate speech": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "few-shot learning in-context learning vision-language hate speech text-based hate speech classification": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "hate speech detection cross-modality learning few-shot learning in-context learning vision-language hate speech": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "cross-modality learning few-shot learning in-context learning vision-language hate speech text-based hate speech classification": ["Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"], "e-commerce intention distillation": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "purchase understanding": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention comprehension": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention utilization": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention generation": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "quality filtering": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "e-commerce intention distillation purchase understanding": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "purchase understanding intention comprehension": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention comprehension intention utilization": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention utilization intention generation": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention generation quality filtering": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "e-commerce intention distillation purchase understanding intention comprehension": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "purchase understanding intention comprehension intention utilization": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention comprehension intention utilization intention generation": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention utilization intention generation quality filtering": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "e-commerce intention distillation purchase understanding intention comprehension intention utilization": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "purchase understanding intention comprehension intention utilization intention generation": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "intention comprehension intention utilization intention generation quality filtering": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "e-commerce intention distillation purchase understanding intention comprehension intention utilization intention generation": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "purchase understanding intention comprehension intention utilization intention generation quality filtering": ["MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding"], "evidence conflict detection": ["ECON: On the Detection and Resolution of Evidence Conflicts"], "evidence conflict resolution": ["ECON: On the Detection and Resolution of Evidence Conflicts"], "evidence conflict detection evidence conflict resolution": ["ECON: On the Detection and Resolution of Evidence Conflicts"], "image contextualization": ["\u201cImage, Tell me your story!\" Predicting the original meta-context of visual misinformation"], "visual misinformation detection": ["\u201cImage, Tell me your story!\" Predicting the original meta-context of visual misinformation"], "image contextualization visual misinformation detection": ["\u201cImage, Tell me your story!\" Predicting the original meta-context of visual misinformation"], "visual misinformation detection question answering": ["\u201cImage, Tell me your story!\" Predicting the original meta-context of visual misinformation"], "image contextualization visual misinformation detection question answering": ["\u201cImage, Tell me your story!\" Predicting the original meta-context of visual misinformation"], "text-to-sql semantic parsing": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "few-shot example selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "schema pruning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "database value selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "text-to-sql semantic parsing RAG": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "RAG few-shot example selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "few-shot example selection schema pruning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "schema pruning database value selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "database value selection in-context learning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "text-to-sql semantic parsing RAG few-shot example selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "RAG few-shot example selection schema pruning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "few-shot example selection schema pruning database value selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "schema pruning database value selection in-context learning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "text-to-sql semantic parsing RAG few-shot example selection schema pruning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "RAG few-shot example selection schema pruning database value selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "few-shot example selection schema pruning database value selection in-context learning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "text-to-sql semantic parsing RAG few-shot example selection schema pruning database value selection": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "RAG few-shot example selection schema pruning database value selection in-context learning": ["Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning"], "visual instruction tuning": ["Mixture-of-Subspaces in Low-Rank Adaptation", "TroL: Traversal of Layers for Large Language and Vision Models", "RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization"], "subject-driven generation": ["Mixture-of-Subspaces in Low-Rank Adaptation"], "commonsense reasoning visual instruction tuning": ["Mixture-of-Subspaces in Low-Rank Adaptation"], "visual instruction tuning subject-driven generation": ["Mixture-of-Subspaces in Low-Rank Adaptation"], "commonsense reasoning visual instruction tuning subject-driven generation": ["Mixture-of-Subspaces in Low-Rank Adaptation"], "multilingual evaluation": ["PARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data", "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?", "SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading", "GuardBench: A Large-Scale Benchmark for Guardrail Models"], "multi-cultural evaluation": ["PARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"], "LLM evaluation multilingual evaluation": ["PARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"], "multilingual evaluation multi-cultural evaluation": ["PARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"], "LLM evaluation multilingual evaluation multi-cultural evaluation": ["PARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"], "article recitation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "knowledge question answering": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "document proofreading": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "dispute focus identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "marital disputes identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "issue topic identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "named-entity recognition": ["LawBench: Benchmarking Legal Knowledge of Large Language Models", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu", "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "opinion summarization": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "trigger word extraction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "fact-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "scene-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "charge prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w.o. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "case analysis": ["LawBench: Benchmarking Legal Knowledge of Large Language Models", "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "criminal damages calculation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "consultation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "article recitation knowledge question answering": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "knowledge question answering document proofreading": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "document proofreading dispute focus identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "dispute focus identification marital disputes identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "marital disputes identification issue topic identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "issue topic identification reading comprehension": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "reading comprehension named-entity recognition": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "named-entity recognition opinion summarization": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "opinion summarization argument mining": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "argument mining event detection": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "event detection trigger word extraction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "trigger word extraction fact-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "fact-based article prediction scene-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "scene-based article prediction charge prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "charge prediction prison term prediction w.o. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w.o. article prison term prediction w. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w. article case analysis": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "case analysis criminal damages calculation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "criminal damages calculation consultation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "article recitation knowledge question answering document proofreading": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "knowledge question answering document proofreading dispute focus identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "document proofreading dispute focus identification marital disputes identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "dispute focus identification marital disputes identification issue topic identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "marital disputes identification issue topic identification reading comprehension": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "issue topic identification reading comprehension named-entity recognition": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "reading comprehension named-entity recognition opinion summarization": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "named-entity recognition opinion summarization argument mining": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "opinion summarization argument mining event detection": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "argument mining event detection trigger word extraction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "event detection trigger word extraction fact-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "trigger word extraction fact-based article prediction scene-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "fact-based article prediction scene-based article prediction charge prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "scene-based article prediction charge prediction prison term prediction w.o. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "charge prediction prison term prediction w.o. article prison term prediction w. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w.o. article prison term prediction w. article case analysis": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w. article case analysis criminal damages calculation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "case analysis criminal damages calculation consultation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "article recitation knowledge question answering document proofreading dispute focus identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "knowledge question answering document proofreading dispute focus identification marital disputes identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "document proofreading dispute focus identification marital disputes identification issue topic identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "dispute focus identification marital disputes identification issue topic identification reading comprehension": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "marital disputes identification issue topic identification reading comprehension named-entity recognition": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "issue topic identification reading comprehension named-entity recognition opinion summarization": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "reading comprehension named-entity recognition opinion summarization argument mining": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "named-entity recognition opinion summarization argument mining event detection": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "opinion summarization argument mining event detection trigger word extraction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "argument mining event detection trigger word extraction fact-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "event detection trigger word extraction fact-based article prediction scene-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "trigger word extraction fact-based article prediction scene-based article prediction charge prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "fact-based article prediction scene-based article prediction charge prediction prison term prediction w.o. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "scene-based article prediction charge prediction prison term prediction w.o. article prison term prediction w. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "charge prediction prison term prediction w.o. article prison term prediction w. article case analysis": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w.o. article prison term prediction w. article case analysis criminal damages calculation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w. article case analysis criminal damages calculation consultation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "article recitation knowledge question answering document proofreading dispute focus identification marital disputes identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "knowledge question answering document proofreading dispute focus identification marital disputes identification issue topic identification": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "document proofreading dispute focus identification marital disputes identification issue topic identification reading comprehension": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "dispute focus identification marital disputes identification issue topic identification reading comprehension named-entity recognition": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "marital disputes identification issue topic identification reading comprehension named-entity recognition opinion summarization": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "issue topic identification reading comprehension named-entity recognition opinion summarization argument mining": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "reading comprehension named-entity recognition opinion summarization argument mining event detection": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "named-entity recognition opinion summarization argument mining event detection trigger word extraction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "opinion summarization argument mining event detection trigger word extraction fact-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "argument mining event detection trigger word extraction fact-based article prediction scene-based article prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "event detection trigger word extraction fact-based article prediction scene-based article prediction charge prediction": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "trigger word extraction fact-based article prediction scene-based article prediction charge prediction prison term prediction w.o. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "fact-based article prediction scene-based article prediction charge prediction prison term prediction w.o. article prison term prediction w. article": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "scene-based article prediction charge prediction prison term prediction w.o. article prison term prediction w. article case analysis": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "charge prediction prison term prediction w.o. article prison term prediction w. article case analysis criminal damages calculation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "prison term prediction w.o. article prison term prediction w. article case analysis criminal damages calculation consultation": ["LawBench: Benchmarking Legal Knowledge of Large Language Models"], "leaderboard construction": ["Efficient Performance Tracking: Leveraging Large Language Models for Automated Construction of Scientific Leaderboards"], "image retrieval": ["Efficient Vision-Language pre-training via domain-specific learning for human activities", "Altogether: Image Captioning via Re-aligning Alt-text", "Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP"], "video retrieval": ["Efficient Vision-Language pre-training via domain-specific learning for human activities"], "action recognition": ["Efficient Vision-Language pre-training via domain-specific learning for human activities", "MOSEL: Inference Serving Using Dynamic Modality Selection", "Text2Model: Text-based Model Induction for Zero-shot Image Classification"], "image retrieval video retrieval": ["Efficient Vision-Language pre-training via domain-specific learning for human activities"], "video retrieval action recognition": ["Efficient Vision-Language pre-training via domain-specific learning for human activities"], "image retrieval video retrieval action recognition": ["Efficient Vision-Language pre-training via domain-specific learning for human activities"], "visual text generation": ["Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"], "chinese text generation": ["Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"], "visual text generation text-to-image generation": ["Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"], "text-to-image generation chinese text generation": ["Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"], "visual text generation text-to-image generation chinese text generation": ["Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"], "character profiling": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "motivation recognition": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "factual consistency examination": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "character profiling summarization": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "summarization motivation recognition": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "motivation recognition factual consistency examination": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "character profiling summarization motivation recognition": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "summarization motivation recognition factual consistency examination": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "character profiling summarization motivation recognition factual consistency examination": ["Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works"], "paraphrase identification": ["Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners", "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models", "FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding", "Variational Language Concepts for Interpreting Foundation Language Models", "Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity", "Functionality learning through specification instructions", "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "sentiment analysis natural language inference": ["Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage", "ALVIN: Active Learning Via INterpolation", "Measuring the Robustness of NLP Models to Domain Shifts", "A Survey on Natural Language Counterfactual Generation", "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation", "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection", "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study"], "natural language inference paraphrase identification": ["Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners", "FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding"], "sentiment analysis natural language inference paraphrase identification": ["Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners"], "g_hard": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "asdiv": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Task Oriented In-Domain Data Augmentation"], "complex qa reasoning": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "musique": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "hotpotqa": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "mathematical reasoning gsm8k": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "gsm8k g_hard": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "g_hard svamp": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "svamp asdiv": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning", "Task Oriented In-Domain Data Augmentation"], "asdiv multiarith": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "multiarith complex qa reasoning": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "complex qa reasoning musique": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "musique hotpotqa": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "mathematical reasoning gsm8k g_hard": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "gsm8k g_hard svamp": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "g_hard svamp asdiv": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "svamp asdiv multiarith": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "asdiv multiarith complex qa reasoning": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "multiarith complex qa reasoning musique": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "complex qa reasoning musique hotpotqa": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "mathematical reasoning gsm8k g_hard svamp": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "gsm8k g_hard svamp asdiv": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "g_hard svamp asdiv multiarith": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "svamp asdiv multiarith complex qa reasoning": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "asdiv multiarith complex qa reasoning musique": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "multiarith complex qa reasoning musique hotpotqa": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "mathematical reasoning gsm8k g_hard svamp asdiv": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "gsm8k g_hard svamp asdiv multiarith": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "g_hard svamp asdiv multiarith complex qa reasoning": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "svamp asdiv multiarith complex qa reasoning musique": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "asdiv multiarith complex qa reasoning musique hotpotqa": ["ADASWITCH: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"], "code completion": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models", "Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly", "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches", "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning", "Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "code-related task": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "xtreme-up": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "multi-domain qa": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "code completion code-related task": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "code-related task xtreme-up": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "xtreme-up multi-domain qa": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "code completion code-related task xtreme-up": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "code-related task xtreme-up multi-domain qa": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "code completion code-related task xtreme-up multi-domain qa": ["CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models"], "multimodal LLM alignment": ["MDPO: Conditional Preference Optimization for Multimodal Large Language Models"], "multimodal LLM alignment hallucination reduction": ["MDPO: Conditional Preference Optimization for Multimodal Large Language Models"], "safety alignment": ["DATA ADVISOR: Dynamic Data Curation for Safety Alignment of Large Language Models", "Can Textual Unlearning Solve Cross-Modality Safety Alignment?", "CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues", "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "language-to-code translation": ["Language-to-Code Translation with a Single Labeled Example"], "language-to-code translation semantic parsing": ["Language-to-Code Translation with a Single Labeled Example"], "semantic parsing question answering": ["Language-to-Code Translation with a Single Labeled Example"], "language-to-code translation semantic parsing question answering": ["Language-to-Code Translation with a Single Labeled Example"], "fact checking": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "question answering classification": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "classification fact checking": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "fact checking natural language inference": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "natural language inference summarization": ["Attribute or Abstain: Large Language Models as Long Document Assistants", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "question answering classification fact checking": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "classification fact checking natural language inference": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "fact checking natural language inference summarization": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "question answering classification fact checking natural language inference": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "classification fact checking natural language inference summarization": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "question answering classification fact checking natural language inference summarization": ["Attribute or Abstain: Large Language Models as Long Document Assistants"], "covid-19 detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "lung opacity detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ecg abnormal detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "mortality prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models", "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?"], "enlarged cardiomediastinum detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "pleural effusion detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "atelectasis detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ectopic beats detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "sepsis prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "medvqa-rad": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "medvqa-slake": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "signal noise clarification": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "covid-19 detection lung opacity detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "lung opacity detection ecg abnormal detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ecg abnormal detection mortality prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "mortality prediction enlarged cardiomediastinum detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "enlarged cardiomediastinum detection pleural effusion detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "pleural effusion detection atelectasis detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "atelectasis detection ectopic beats detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ectopic beats detection sepsis prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "sepsis prediction medvqa-rad": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "medvqa-rad medvqa-slake": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "medvqa-slake signal noise clarification": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "covid-19 detection lung opacity detection ecg abnormal detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "lung opacity detection ecg abnormal detection mortality prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ecg abnormal detection mortality prediction enlarged cardiomediastinum detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "mortality prediction enlarged cardiomediastinum detection pleural effusion detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "enlarged cardiomediastinum detection pleural effusion detection atelectasis detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "pleural effusion detection atelectasis detection ectopic beats detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "atelectasis detection ectopic beats detection sepsis prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ectopic beats detection sepsis prediction medvqa-rad": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "sepsis prediction medvqa-rad medvqa-slake": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "medvqa-rad medvqa-slake signal noise clarification": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "covid-19 detection lung opacity detection ecg abnormal detection mortality prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "lung opacity detection ecg abnormal detection mortality prediction enlarged cardiomediastinum detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ecg abnormal detection mortality prediction enlarged cardiomediastinum detection pleural effusion detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "mortality prediction enlarged cardiomediastinum detection pleural effusion detection atelectasis detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "enlarged cardiomediastinum detection pleural effusion detection atelectasis detection ectopic beats detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "pleural effusion detection atelectasis detection ectopic beats detection sepsis prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "atelectasis detection ectopic beats detection sepsis prediction medvqa-rad": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ectopic beats detection sepsis prediction medvqa-rad medvqa-slake": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "sepsis prediction medvqa-rad medvqa-slake signal noise clarification": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "covid-19 detection lung opacity detection ecg abnormal detection mortality prediction enlarged cardiomediastinum detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "lung opacity detection ecg abnormal detection mortality prediction enlarged cardiomediastinum detection pleural effusion detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ecg abnormal detection mortality prediction enlarged cardiomediastinum detection pleural effusion detection atelectasis detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "mortality prediction enlarged cardiomediastinum detection pleural effusion detection atelectasis detection ectopic beats detection": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "enlarged cardiomediastinum detection pleural effusion detection atelectasis detection ectopic beats detection sepsis prediction": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "pleural effusion detection atelectasis detection ectopic beats detection sepsis prediction medvqa-rad": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "atelectasis detection ectopic beats detection sepsis prediction medvqa-rad medvqa-slake": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "ectopic beats detection sepsis prediction medvqa-rad medvqa-slake signal noise clarification": ["FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models"], "mathematical reasoning commonsense reasoning": ["Retrieved In-Context Principles from Previous Mistakes", "AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations", "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "commonsense reasoning logical reasoning": ["Retrieved In-Context Principles from Previous Mistakes"], "mathematical reasoning commonsense reasoning logical reasoning": ["Retrieved In-Context Principles from Previous Mistakes"], "emotion control": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "voice cloning": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "text-to-speech": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "emotion control speech synthesis": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "speech synthesis voice cloning": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "voice cloning text-to-speech": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "emotion control speech synthesis voice cloning": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "speech synthesis voice cloning text-to-speech": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "emotion control speech synthesis voice cloning text-to-speech": ["Emoknob: Enhance Voice Cloning with Fine-Grained Emotion Control"], "quantization language modeling": ["VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models", "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs"], "automata extraction": ["An L* Algorithm for Deterministic Weighted Regular Languages"], "verifiable text generation": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "open-domain qa": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection", "AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings", "Improve Dense Passage Retrieval with Entailment Tuning", "Dense X Retrieval: What Retrieval Granularity Should We Use?", "Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation", "Learning to Paraphrase for Alignment with LLM Preference"], "verifiable text generation multi-hop qa": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "multi-hop qa long-form qa": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "long-form qa open-domain qa": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "verifiable text generation multi-hop qa long-form qa": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "multi-hop qa long-form qa open-domain qa": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "verifiable text generation multi-hop qa long-form qa open-domain qa": ["Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"], "visual claim verification": ["Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"], "hallucination detection visual claim verification": ["Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"], "visual claim verification visual question answering": ["Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"], "hallucination detection visual claim verification visual question answering": ["Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"], "multi-label image classification": ["Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes"], "multi-label image classification image captioning": ["Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes"], "vulnerability detection": ["RealVul: Can We Detect Vulnerabilities in Web Applications with LLM?"], "dialogue state tracking": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel", "Zero-shot Cross-domain Dialogue State Tracking via Context-aware Auto-prompting and Instruction-following Contrastive Decoding", "Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue", "Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking"], "dialogue act tagging": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"], "end-to-end dialogue generation": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"], "task-oriented dialogue dialogue state tracking": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel", "Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "dialogue state tracking dialogue act tagging": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"], "dialogue act tagging end-to-end dialogue generation": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"], "task-oriented dialogue dialogue state tracking dialogue act tagging": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"], "dialogue state tracking dialogue act tagging end-to-end dialogue generation": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"], "task-oriented dialogue dialogue state tracking dialogue act tagging end-to-end dialogue generation": ["Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"], "instruction following reinforcement learning from human feedback": ["WPO: Enhancing RLHF with Weighted Preference Optimization"], "detoxification": ["Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias", "Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "debiasing": ["Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias", "Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "detoxification debiasing": ["Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias"], "biomedical semantic similarity": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "open world question answering": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "vulnerability threat detection": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "language agents logical reasoning": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "logical reasoning biomedical semantic similarity": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "biomedical semantic similarity open world question answering": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "open world question answering vulnerability threat detection": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "language agents logical reasoning biomedical semantic similarity": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "logical reasoning biomedical semantic similarity open world question answering": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "biomedical semantic similarity open world question answering vulnerability threat detection": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "language agents logical reasoning biomedical semantic similarity open world question answering": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "logical reasoning biomedical semantic similarity open world question answering vulnerability threat detection": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "language agents logical reasoning biomedical semantic similarity open world question answering vulnerability threat detection": ["METAREFLECTION: Learning Instructions for Language Agents using Past Reflections"], "feedback generation": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors", "More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation", "Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions", "E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "dialogue tutoring": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"], "math reasoning error detection": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"], "error detection feedback generation": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"], "feedback generation dialogue tutoring": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"], "math reasoning error detection feedback generation": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"], "error detection feedback generation dialogue tutoring": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"], "math reasoning error detection feedback generation dialogue tutoring": ["Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"], "unsupervised parsing": ["On Eliciting Syntax from Language Models via Hashing"], "grammar induction": ["On Eliciting Syntax from Language Models via Hashing"], "unsupervised parsing grammar induction": ["On Eliciting Syntax from Language Models via Hashing"], "medical LLM evaluation": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "clinical question answering": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios", "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs."], "factual consistency": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios", "Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues", "Improving Factual Consistency of News Summarization by Contrastive Preference Optimization"], "toxicity assessment": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "medical LLM evaluation clinical question answering": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "clinical question answering medical reasoning": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "medical reasoning factual consistency": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "factual consistency hallucination detection": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "hallucination detection toxicity assessment": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "medical LLM evaluation clinical question answering medical reasoning": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "clinical question answering medical reasoning factual consistency": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "medical reasoning factual consistency hallucination detection": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "factual consistency hallucination detection toxicity assessment": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "medical LLM evaluation clinical question answering medical reasoning factual consistency": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "clinical question answering medical reasoning factual consistency hallucination detection": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "medical reasoning factual consistency hallucination detection toxicity assessment": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "medical LLM evaluation clinical question answering medical reasoning factual consistency hallucination detection": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "clinical question answering medical reasoning factual consistency hallucination detection toxicity assessment": ["CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios"], "adversarial defense": ["The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples"], "text classification adversarial defense": ["The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples"], "human-ai interaction": ["Perceptions of Linguistic Uncertainty by Language Models and Humans", "MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "theory of mind": ["Perceptions of Linguistic Uncertainty by Language Models and Humans", "FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition", "Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models", "A Notion of Complexity for Theory of Mind via Discrete World Models"], "uncertainty quantification natural language understanding": ["Perceptions of Linguistic Uncertainty by Language Models and Humans"], "natural language understanding human-ai interaction": ["Perceptions of Linguistic Uncertainty by Language Models and Humans"], "human-ai interaction theory of mind": ["Perceptions of Linguistic Uncertainty by Language Models and Humans"], "uncertainty quantification natural language understanding human-ai interaction": ["Perceptions of Linguistic Uncertainty by Language Models and Humans"], "natural language understanding human-ai interaction theory of mind": ["Perceptions of Linguistic Uncertainty by Language Models and Humans"], "uncertainty quantification natural language understanding human-ai interaction theory of mind": ["Perceptions of Linguistic Uncertainty by Language Models and Humans"], "open-ended text generation": ["Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM", "A Thorough Examination of Decoding Methods in the Era of LLMs"], "open-ended text generation commonsense qa": ["Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"], "zero-shot cross-domain dialogue state tracking": ["Zero-shot Cross-domain Dialogue State Tracking via Context-aware Auto-prompting and Instruction-following Contrastive Decoding"], "dialogue state tracking zero-shot cross-domain dialogue state tracking": ["Zero-shot Cross-domain Dialogue State Tracking via Context-aware Auto-prompting and Instruction-following Contrastive Decoding"], "knowledge conflict analysis": ["Knowledge Conflicts for LLMs: A Survey", "DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models"], "misinformation detection": ["MisinfoEval: Generative AI in the Era of \u201cAlternative Facts\"", "Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research", "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness", "Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach", "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models", "Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "intervention effectiveness": ["MisinfoEval: Generative AI in the Era of \u201cAlternative Facts\""], "misinformation detection intervention effectiveness": ["MisinfoEval: Generative AI in the Era of \u201cAlternative Facts\""], "intervention effectiveness personalization": ["MisinfoEval: Generative AI in the Era of \u201cAlternative Facts\""], "misinformation detection intervention effectiveness personalization": ["MisinfoEval: Generative AI in the Era of \u201cAlternative Facts\""], "stock market prediction": ["MEANT: Multimodal Encoder for Antecedent Information"], "temporal dependency modeling": ["MEANT: Multimodal Encoder for Antecedent Information"], "stock market prediction multimodal learning": ["MEANT: Multimodal Encoder for Antecedent Information"], "multimodal learning temporal dependency modeling": ["MEANT: Multimodal Encoder for Antecedent Information"], "stock market prediction multimodal learning temporal dependency modeling": ["MEANT: Multimodal Encoder for Antecedent Information"], "coding": ["A Thorough Examination of Decoding Methods in the Era of LLMs", "How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective", "LongAlign: A Recipe for Long Context Alignment of Large Language Models", "AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models", "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement", "Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "math problem solving": ["A Thorough Examination of Decoding Methods in the Era of LLMs", "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses", "Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "An Analysis and Mitigation of the Reversal Curse", "Tools Fail: Detecting Silent Errors in Faulty Tools", "Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector", "LLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks", "Assessing and Verifying Task Utility in LLM-Powered Applications", "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision", "ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline", "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?"], "factual knowledge": ["A Thorough Examination of Decoding Methods in the Era of LLMs", "FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition", "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations", "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "coding math problem solving": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "math problem solving summarization": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "summarization translation": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "translation commonsense reasoning": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "commonsense reasoning factual knowledge": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "factual knowledge instruction following": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "instruction following open-ended text generation": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "coding math problem solving summarization": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "math problem solving summarization translation": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "summarization translation commonsense reasoning": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "translation commonsense reasoning factual knowledge": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "commonsense reasoning factual knowledge instruction following": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "factual knowledge instruction following open-ended text generation": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "coding math problem solving summarization translation": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "math problem solving summarization translation commonsense reasoning": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "summarization translation commonsense reasoning factual knowledge": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "translation commonsense reasoning factual knowledge instruction following": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "commonsense reasoning factual knowledge instruction following open-ended text generation": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "coding math problem solving summarization translation commonsense reasoning": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "math problem solving summarization translation commonsense reasoning factual knowledge": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "summarization translation commonsense reasoning factual knowledge instruction following": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "translation commonsense reasoning factual knowledge instruction following open-ended text generation": ["A Thorough Examination of Decoding Methods in the Era of LLMs"], "atomic fact retrieval": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "ranking open-domain qa": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "open-domain qa attribution": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "attribution RAG": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "RAG atomic fact retrieval": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "ranking open-domain qa attribution": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "open-domain qa attribution RAG": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "attribution RAG atomic fact retrieval": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "ranking open-domain qa attribution RAG": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "open-domain qa attribution RAG atomic fact retrieval": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "ranking open-domain qa attribution RAG atomic fact retrieval": ["AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings"], "reranking": ["FIRST: Faster Improved Listwise Reranking with Single Token Decoding", "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "reranking information retrieval": ["FIRST: Faster Improved Listwise Reranking with Single Token Decoding"], "nested ner": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "nested ner information extraction": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "information extraction instruction tuning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "instruction tuning few-shot learning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "few-shot learning zero-shot learning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "nested ner information extraction instruction tuning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "information extraction instruction tuning few-shot learning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "instruction tuning few-shot learning zero-shot learning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "nested ner information extraction instruction tuning few-shot learning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "information extraction instruction tuning few-shot learning zero-shot learning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "nested ner information extraction instruction tuning few-shot learning zero-shot learning": ["Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"], "bias amplification measurement": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "demographic bias evaluation": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-subject cloze completion": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-property cloze completion": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "open-ended subject description": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "fact verification": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models", "NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization", "Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification", "PROTRIX: Building Models for Planning and Reasoning over Tables with Sentence Context", "Evidence Retrieval for Fact Verification using Multi-stage Reranking", "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs", "How Entangled is Factuality and Deception in German?", "ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs", "Zero-Shot Fact Verification via Natural Logic and Large Language Models"], "bias amplification measurement demographic bias evaluation": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "demographic bias evaluation cross-subject cloze completion": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-subject cloze completion cross-property cloze completion": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-property cloze completion open-ended subject description": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "open-ended subject description fact verification": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "fact verification text generation": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "bias amplification measurement demographic bias evaluation cross-subject cloze completion": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "demographic bias evaluation cross-subject cloze completion cross-property cloze completion": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-subject cloze completion cross-property cloze completion open-ended subject description": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-property cloze completion open-ended subject description fact verification": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "open-ended subject description fact verification text generation": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "bias amplification measurement demographic bias evaluation cross-subject cloze completion cross-property cloze completion": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "demographic bias evaluation cross-subject cloze completion cross-property cloze completion open-ended subject description": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-subject cloze completion cross-property cloze completion open-ended subject description fact verification": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-property cloze completion open-ended subject description fact verification text generation": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "bias amplification measurement demographic bias evaluation cross-subject cloze completion cross-property cloze completion open-ended subject description": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "demographic bias evaluation cross-subject cloze completion cross-property cloze completion open-ended subject description fact verification": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "cross-subject cloze completion cross-property cloze completion open-ended subject description fact verification text generation": ["\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"], "LLM targeted unlearning": ["Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"], "causal intervention": ["Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"], "LLM targeted unlearning causal intervention": ["Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"], "language model alignment": ["LIONS: An Empirically Optimized Approach to Align Language Models", "Reverse-Engineering the Reader", "Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities", "Rethinking the Role of Proxy Rewards in Language Model Alignment", "Enhancing Language Model Alignment: A Confidence-Based Approach to Label Smoothing", "Filtered Direct Preference Optimization", "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search", "Knowledge Editing in Language Models via Adapted Direct Preference Optimization", "Evolutionary Contrastive Distillation for Language Model Alignment", "FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "supervised fine-tuning": ["LIONS: An Empirically Optimized Approach to Align Language Models", "KNN-INSTRUCT: Automatic Instruction Construction with K Nearest Neighbor Deduction", "A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "offline preference learning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "online preference learning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "language model alignment supervised fine-tuning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "supervised fine-tuning offline preference learning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "offline preference learning online preference learning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "language model alignment supervised fine-tuning offline preference learning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "supervised fine-tuning offline preference learning online preference learning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "language model alignment supervised fine-tuning offline preference learning online preference learning": ["LIONS: An Empirically Optimized Approach to Align Language Models"], "data imputation": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "schema matching": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "column type annotation": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "attribute value extraction": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "error detection data imputation": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "data imputation schema matching": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "schema matching entity matching": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "entity matching column type annotation": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "column type annotation attribute value extraction": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "error detection data imputation schema matching": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "data imputation schema matching entity matching": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "schema matching entity matching column type annotation": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "entity matching column type annotation attribute value extraction": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "error detection data imputation schema matching entity matching": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "data imputation schema matching entity matching column type annotation": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "schema matching entity matching column type annotation attribute value extraction": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "error detection data imputation schema matching entity matching column type annotation": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "data imputation schema matching entity matching column type annotation attribute value extraction": ["Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"], "scientific LLMs": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "cross-field analysis": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "cross-modal connections": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "pre-training techniques": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "scientific discovery": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery", "BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "scientific LLMs cross-field analysis": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "cross-field analysis cross-modal connections": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "cross-modal connections pre-training techniques": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "pre-training techniques scientific discovery": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "scientific LLMs cross-field analysis cross-modal connections": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "cross-field analysis cross-modal connections pre-training techniques": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "cross-modal connections pre-training techniques scientific discovery": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "scientific LLMs cross-field analysis cross-modal connections pre-training techniques": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "cross-field analysis cross-modal connections pre-training techniques scientific discovery": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "scientific LLMs cross-field analysis cross-modal connections pre-training techniques scientific discovery": ["A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery"], "grounded generation": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "document-grounded dialogue": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents", "Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "fact-checking grounded generation": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "grounded generation summarization": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "summarization document-grounded dialogue": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "document-grounded dialogue RAG": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "fact-checking grounded generation summarization": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "grounded generation summarization document-grounded dialogue": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "summarization document-grounded dialogue RAG": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "fact-checking grounded generation summarization document-grounded dialogue": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "grounded generation summarization document-grounded dialogue RAG": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "fact-checking grounded generation summarization document-grounded dialogue RAG": ["MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"], "medical coding": ["Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning"], "medical coding interpretability": ["Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning"], "multi-label classification": ["MOSEL: Inference Serving Using Dynamic Modality Selection", "A Closer Look at Multidimensional Online Political Incivility", "Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis", "Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification", "Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems", "CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "sentiment analysis speech recognition": ["MOSEL: Inference Serving Using Dynamic Modality Selection"], "speech recognition action recognition": ["MOSEL: Inference Serving Using Dynamic Modality Selection"], "action recognition multi-label classification": ["MOSEL: Inference Serving Using Dynamic Modality Selection"], "sentiment analysis speech recognition action recognition": ["MOSEL: Inference Serving Using Dynamic Modality Selection"], "speech recognition action recognition multi-label classification": ["MOSEL: Inference Serving Using Dynamic Modality Selection"], "sentiment analysis speech recognition action recognition multi-label classification": ["MOSEL: Inference Serving Using Dynamic Modality Selection"], "attributed question answering": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "sequence generation": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "retrieval": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation", "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity", "BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain", "ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "open domain question answering multi-hop question answering": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "multi-hop question answering attributed question answering": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "attributed question answering sequence generation": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "sequence generation retrieval": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "open domain question answering multi-hop question answering attributed question answering": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "multi-hop question answering attributed question answering sequence generation": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "attributed question answering sequence generation retrieval": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "open domain question answering multi-hop question answering attributed question answering sequence generation": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "multi-hop question answering attributed question answering sequence generation retrieval": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "open domain question answering multi-hop question answering attributed question answering sequence generation retrieval": ["From RAG to RICHES: Retrieval Interlaced with Sequence Generation"], "synthetic-to-real adaptation": ["Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition"], "automatic speech recognition domain adaptation": ["Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition"], "domain adaptation synthetic-to-real adaptation": ["Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition"], "automatic speech recognition domain adaptation synthetic-to-real adaptation": ["Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition"], "question answering reasoning": ["Learning to Correct for QA Reasoning with Black-box LLMs"], "realistic web tasks": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "time-consuming tasks": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web navigation": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?", "DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents", "AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories", "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "web browsing": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "open-web interaction": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "planning and reasoning": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "multi-hop questions": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "fact hallucination": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "error analysis": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?", "NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition", "DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers", "Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation", "Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?", "What's under the hood: Investigating Automatic Metrics on Meeting Summarization", "Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "realistic web tasks time-consuming tasks": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "time-consuming tasks information seeking": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "information seeking web navigation": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web navigation web browsing": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web browsing open-web interaction": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "open-web interaction planning and reasoning": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "planning and reasoning multi-hop questions": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "multi-hop questions fact hallucination": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "fact hallucination error analysis": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "realistic web tasks time-consuming tasks information seeking": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "time-consuming tasks information seeking web navigation": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "information seeking web navigation web browsing": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web navigation web browsing open-web interaction": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web browsing open-web interaction planning and reasoning": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "open-web interaction planning and reasoning multi-hop questions": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "planning and reasoning multi-hop questions fact hallucination": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "multi-hop questions fact hallucination error analysis": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "realistic web tasks time-consuming tasks information seeking web navigation": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "time-consuming tasks information seeking web navigation web browsing": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "information seeking web navigation web browsing open-web interaction": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web navigation web browsing open-web interaction planning and reasoning": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web browsing open-web interaction planning and reasoning multi-hop questions": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "open-web interaction planning and reasoning multi-hop questions fact hallucination": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "planning and reasoning multi-hop questions fact hallucination error analysis": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "realistic web tasks time-consuming tasks information seeking web navigation web browsing": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "time-consuming tasks information seeking web navigation web browsing open-web interaction": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "information seeking web navigation web browsing open-web interaction planning and reasoning": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web navigation web browsing open-web interaction planning and reasoning multi-hop questions": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "web browsing open-web interaction planning and reasoning multi-hop questions fact hallucination": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "open-web interaction planning and reasoning multi-hop questions fact hallucination error analysis": ["ASSISTANTBENCH: Can Web Agents Solve Realistic and Time-Consuming Tasks?"], "watermarking": ["POSTMARK: A Robust Blackbox Watermark for Large Language Models", "Where Am I From? Identifying Origin of LLM-generated Content", "Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models", "GuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack", "CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "text detection": ["POSTMARK: A Robust Blackbox Watermark for Large Language Models"], "watermarking text detection": ["POSTMARK: A Robust Blackbox Watermark for Large Language Models"], "question answering RAG": ["Assessing \"Implicit\" Retrieval Robustness of Large Language Models", "ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR", "Searching for Best Practices in Retrieval-Augmented Generation", "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation", "R2AG: Incorporating Retrieval Information into Retrieval Augmented Generation", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "RAG robustness evaluation": ["Assessing \"Implicit\" Retrieval Robustness of Large Language Models"], "question answering RAG robustness evaluation": ["Assessing \"Implicit\" Retrieval Robustness of Large Language Models"], "LLM truthfulness": ["On the Relationship between Truth and Political Bias in Language Models"], "political bias": ["On the Relationship between Truth and Political Bias in Language Models"], "ai alignment LLM truthfulness": ["On the Relationship between Truth and Political Bias in Language Models"], "LLM truthfulness political bias": ["On the Relationship between Truth and Political Bias in Language Models"], "ai alignment LLM truthfulness political bias": ["On the Relationship between Truth and Political Bias in Language Models"], "atis intent classification": ["Can Active Label Correction Improve LLM-based Modular AI Systems?"], "conll 2003 named entity recognition": ["Can Active Label Correction Improve LLM-based Modular AI Systems?"], "qnli natural language inference": ["Can Active Label Correction Improve LLM-based Modular AI Systems?"], "atis intent classification conll 2003 named entity recognition": ["Can Active Label Correction Improve LLM-based Modular AI Systems?"], "conll 2003 named entity recognition qnli natural language inference": ["Can Active Label Correction Improve LLM-based Modular AI Systems?"], "atis intent classification conll 2003 named entity recognition qnli natural language inference": ["Can Active Label Correction Improve LLM-based Modular AI Systems?"], "word embeddings": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "similarity comparison": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "model selection": ["Statistical Uncertainty in Word Embeddings: GloVe-V", "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking", "Characterizing Text Datasets with Psycholinguistic Features"], "word embeddings similarity comparison": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "similarity comparison model selection": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "model selection bias analysis": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "word embeddings similarity comparison model selection": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "similarity comparison model selection bias analysis": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "word embeddings similarity comparison model selection bias analysis": ["Statistical Uncertainty in Word Embeddings: GloVe-V"], "annotation alignment": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "conversational safety": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "human-LLM comparison": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "demographic disparities": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "safety prediction": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "annotation alignment conversational safety": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "conversational safety human-LLM comparison": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "human-LLM comparison demographic disparities": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "demographic disparities safety prediction": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "annotation alignment conversational safety human-LLM comparison": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "conversational safety human-LLM comparison demographic disparities": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "human-LLM comparison demographic disparities safety prediction": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "annotation alignment conversational safety human-LLM comparison demographic disparities": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "conversational safety human-LLM comparison demographic disparities safety prediction": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "annotation alignment conversational safety human-LLM comparison demographic disparities safety prediction": ["Annotation alignment: Comparing LLM and human annotations of conversational safety"], "distractor generation": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions", "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation", "DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking"], "error generation": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "multiple-choice question generation": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions", "From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions", "DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking"], "error representation learning": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "distractor generation error generation": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "error generation multiple-choice question generation": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "multiple-choice question generation error representation learning": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "distractor generation error generation multiple-choice question generation": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "error generation multiple-choice question generation error representation learning": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "distractor generation error generation multiple-choice question generation error representation learning": ["DIVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"], "diversity intervention evaluation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "demographic factuality assessment": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "historical accuracy": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "text-to-image generation diversity intervention evaluation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "diversity intervention evaluation demographic factuality assessment": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "demographic factuality assessment bias mitigation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "bias mitigation historical accuracy": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "historical accuracy benchmark creation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "text-to-image generation diversity intervention evaluation demographic factuality assessment": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "diversity intervention evaluation demographic factuality assessment bias mitigation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "demographic factuality assessment bias mitigation historical accuracy": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "bias mitigation historical accuracy benchmark creation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "text-to-image generation diversity intervention evaluation demographic factuality assessment bias mitigation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "diversity intervention evaluation demographic factuality assessment bias mitigation historical accuracy": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "demographic factuality assessment bias mitigation historical accuracy benchmark creation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "text-to-image generation diversity intervention evaluation demographic factuality assessment bias mitigation historical accuracy": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "diversity intervention evaluation demographic factuality assessment bias mitigation historical accuracy benchmark creation": ["The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"], "mitigating backdoor attacks": ["CLEANGEN: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models"], "sentiment control": ["Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic"], "lm detoxification": ["Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic"], "sentiment control lm detoxification": ["Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic"], "lm detoxification text summarization": ["Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic"], "sentiment control lm detoxification text summarization": ["Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic"], "stigma detection": ["Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models", "Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "de-stigmatization": ["Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models"], "stigma detection de-stigmatization": ["Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models"], "contextual bandits": ["Efficient Sequential Decision Making with Large Language Models"], "recommendation systems": ["Efficient Sequential Decision Making with Large Language Models", "PepRec: Progressive Enhancement of Prompting for Recommendation", "Jump Starting Bandits with LLM-Generated Prior Knowledge", "I-AM-G: Interest Augmented Multimodal Generator for Item Personalization", "QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware", "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "healthcare": ["Efficient Sequential Decision Making with Large Language Models", "HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "dialogue systems": ["Efficient Sequential Decision Making with Large Language Models", "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation", "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity", "From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues", "CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "item tag prediction": ["Efficient Sequential Decision Making with Large Language Models"], "contextual bandits recommendation systems": ["Efficient Sequential Decision Making with Large Language Models"], "recommendation systems healthcare": ["Efficient Sequential Decision Making with Large Language Models"], "healthcare dialogue systems": ["Efficient Sequential Decision Making with Large Language Models"], "dialogue systems item tag prediction": ["Efficient Sequential Decision Making with Large Language Models"], "contextual bandits recommendation systems healthcare": ["Efficient Sequential Decision Making with Large Language Models"], "recommendation systems healthcare dialogue systems": ["Efficient Sequential Decision Making with Large Language Models"], "healthcare dialogue systems item tag prediction": ["Efficient Sequential Decision Making with Large Language Models"], "contextual bandits recommendation systems healthcare dialogue systems": ["Efficient Sequential Decision Making with Large Language Models"], "recommendation systems healthcare dialogue systems item tag prediction": ["Efficient Sequential Decision Making with Large Language Models"], "contextual bandits recommendation systems healthcare dialogue systems item tag prediction": ["Efficient Sequential Decision Making with Large Language Models"], "sign language processing": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "text-to-video retrieval": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "video-to-text retrieval": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "sign language processing text-to-video retrieval": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "text-to-video retrieval video-to-text retrieval": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "video-to-text retrieval isolated sign language recognition": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "sign language processing text-to-video retrieval video-to-text retrieval": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "text-to-video retrieval video-to-text retrieval isolated sign language recognition": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "sign language processing text-to-video retrieval video-to-text retrieval isolated sign language recognition": ["SignCLIP: Connecting Text and Sign Language by Contrastive Learning"], "plain language summarization evaluation": ["APPLS: Evaluating Evaluation Metrics for Plain Language Summarization"], "knowledge-constrained generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "user-npc dialogue generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "dialogue tree generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "dialogue generation natural language generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "natural language generation knowledge-constrained generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "knowledge-constrained generation user-npc dialogue generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "user-npc dialogue generation dialogue tree generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "dialogue generation natural language generation knowledge-constrained generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "natural language generation knowledge-constrained generation user-npc dialogue generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "knowledge-constrained generation user-npc dialogue generation dialogue tree generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "dialogue generation natural language generation knowledge-constrained generation user-npc dialogue generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "natural language generation knowledge-constrained generation user-npc dialogue generation dialogue tree generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "dialogue generation natural language generation knowledge-constrained generation user-npc dialogue generation dialogue tree generation": ["Ontologically Faithful Generation of Non-Player Character Dialogues"], "synthetic data generation model distillation": ["LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives"], "model distillation bias mitigation": ["LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives"], "bias mitigation text generation": ["LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives"], "synthetic data generation model distillation bias mitigation": ["LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives"], "model distillation bias mitigation text generation": ["LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives"], "synthetic data generation model distillation bias mitigation text generation": ["LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives"], "benchmark": ["RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs", "AKEW: Assessing Knowledge Editing in the Wild", "The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning", "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling", "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers", "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "linguistic minimal pairs": ["RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"], "benchmark linguistic minimal pairs": ["RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"], "text-to-table generation": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction", "TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs"], "information integration": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "structured summarization": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "text-to-table generation information extraction": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "information extraction reasoning": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "reasoning information integration": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "information integration structured summarization": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "text-to-table generation information extraction reasoning": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "information extraction reasoning information integration": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "reasoning information integration structured summarization": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "text-to-table generation information extraction reasoning information integration": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "information extraction reasoning information integration structured summarization": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "text-to-table generation information extraction reasoning information integration structured summarization": ["Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"], "compositionality evaluation": ["Toward Compositional Behavior in Neural Models: A Survey of Current Views"], "compositionality evaluation natural language processing": ["Toward Compositional Behavior in Neural Models: A Survey of Current Views"], "language model programs": ["Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs"], "multi-stage pipelines": ["Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs"], "prompt optimization language model programs": ["Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs"], "language model programs multi-stage pipelines": ["Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs"], "prompt optimization language model programs multi-stage pipelines": ["Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs"], "psychometric prediction": ["Reverse-Engineering the Reader"], "psychometric prediction language model alignment": ["Reverse-Engineering the Reader"], "language model alignment reading time prediction": ["Reverse-Engineering the Reader"], "psychometric prediction language model alignment reading time prediction": ["Reverse-Engineering the Reader"], "faithfulness detection": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "data-to-text": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "biography generation": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "faithfulness detection long-form generation": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "long-form generation question answering": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation", "Calibrating Long-form Generations from Large Language Models"], "summarization data-to-text": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "data-to-text biography generation": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "faithfulness detection long-form generation question answering": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "long-form generation question answering summarization": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation", "Calibrating Long-form Generations from Large Language Models"], "question answering summarization data-to-text": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "summarization data-to-text biography generation": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "faithfulness detection long-form generation question answering summarization": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "long-form generation question answering summarization data-to-text": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "question answering summarization data-to-text biography generation": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "faithfulness detection long-form generation question answering summarization data-to-text": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "long-form generation question answering summarization data-to-text biography generation": ["Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"], "relation prediction": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text", "Multi-Level Cross-Modal Alignment for Speech Relation Extraction", "Llamipa: An Incremental Discourse Parser"], "complex entity prediction": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "graph sorting": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "graph query": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "relation prediction entity prediction": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "entity prediction complex entity prediction": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "complex entity prediction graph sorting": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "graph sorting graph query": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "graph query logical inference": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "relation prediction entity prediction complex entity prediction": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "entity prediction complex entity prediction graph sorting": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "complex entity prediction graph sorting graph query": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "graph sorting graph query logical inference": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "relation prediction entity prediction complex entity prediction graph sorting": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "entity prediction complex entity prediction graph sorting graph query": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "complex entity prediction graph sorting graph query logical inference": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "relation prediction entity prediction complex entity prediction graph sorting graph query": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "entity prediction complex entity prediction graph sorting graph query logical inference": ["Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"], "intermediate task selection": ["Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning"], "nlp task transferability": ["Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning"], "task selection": ["Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning", "Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"], "intermediate task selection nlp task transferability": ["Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning"], "nlp task transferability task selection": ["Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning"], "intermediate task selection nlp task transferability task selection": ["Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning"], "npi licensing": ["The effects of distance on NPI illusive effects in BERT"], "natural language inference textual entailment": ["Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"], "textual entailment question answering": ["Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic", "RepMatch: Quantifying Cross-Instance Similarities in Representation Space"], "natural language inference textual entailment question answering": ["Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"], "commonsense reasoning cultural adaptation": ["Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S."], "screen point-and-read": ["Layout-aware GUI Screen Reading with Tree-of-Lens Grounding"], "gui understanding": ["Layout-aware GUI Screen Reading with Tree-of-Lens Grounding"], "mobile gui navigation": ["Layout-aware GUI Screen Reading with Tree-of-Lens Grounding"], "screen point-and-read gui understanding": ["Layout-aware GUI Screen Reading with Tree-of-Lens Grounding"], "gui understanding mobile gui navigation": ["Layout-aware GUI Screen Reading with Tree-of-Lens Grounding"], "screen point-and-read gui understanding mobile gui navigation": ["Layout-aware GUI Screen Reading with Tree-of-Lens Grounding"], "conversational search ranking": ["Ranking Manipulation for Conversational Search Engines"], "adversarial prompt injection": ["Ranking Manipulation for Conversational Search Engines"], "rag model manipulation": ["Ranking Manipulation for Conversational Search Engines"], "consumer product recommendation": ["Ranking Manipulation for Conversational Search Engines"], "conversational search ranking adversarial prompt injection": ["Ranking Manipulation for Conversational Search Engines"], "adversarial prompt injection rag model manipulation": ["Ranking Manipulation for Conversational Search Engines"], "rag model manipulation consumer product recommendation": ["Ranking Manipulation for Conversational Search Engines"], "conversational search ranking adversarial prompt injection rag model manipulation": ["Ranking Manipulation for Conversational Search Engines"], "adversarial prompt injection rag model manipulation consumer product recommendation": ["Ranking Manipulation for Conversational Search Engines"], "conversational search ranking adversarial prompt injection rag model manipulation consumer product recommendation": ["Ranking Manipulation for Conversational Search Engines"], "medical-domain tuning": ["Fast Forwarding Low-Rank Training"], "chat tuning": ["Fast Forwarding Low-Rank Training"], "fine-tuning medical-domain tuning": ["Fast Forwarding Low-Rank Training"], "medical-domain tuning instruction tuning": ["Fast Forwarding Low-Rank Training"], "instruction tuning chat tuning": ["Fast Forwarding Low-Rank Training"], "fine-tuning medical-domain tuning instruction tuning": ["Fast Forwarding Low-Rank Training"], "medical-domain tuning instruction tuning chat tuning": ["Fast Forwarding Low-Rank Training"], "fine-tuning medical-domain tuning instruction tuning chat tuning": ["Fast Forwarding Low-Rank Training"], "LLM accuracy estimation": ["Precise Model Benchmarking with Only a Few Observations"], "mc qa": ["Precise Model Benchmarking with Only a Few Observations"], "computer vision classification": ["Precise Model Benchmarking with Only a Few Observations"], "LLM accuracy estimation mc qa": ["Precise Model Benchmarking with Only a Few Observations"], "mc qa text generation": ["Precise Model Benchmarking with Only a Few Observations"], "text generation computer vision classification": ["Precise Model Benchmarking with Only a Few Observations"], "computer vision classification image captioning": ["Precise Model Benchmarking with Only a Few Observations"], "image captioning tabular data classification": ["Precise Model Benchmarking with Only a Few Observations"], "LLM accuracy estimation mc qa text generation": ["Precise Model Benchmarking with Only a Few Observations"], "mc qa text generation computer vision classification": ["Precise Model Benchmarking with Only a Few Observations"], "text generation computer vision classification image captioning": ["Precise Model Benchmarking with Only a Few Observations"], "computer vision classification image captioning tabular data classification": ["Precise Model Benchmarking with Only a Few Observations"], "LLM accuracy estimation mc qa text generation computer vision classification": ["Precise Model Benchmarking with Only a Few Observations"], "mc qa text generation computer vision classification image captioning": ["Precise Model Benchmarking with Only a Few Observations"], "text generation computer vision classification image captioning tabular data classification": ["Precise Model Benchmarking with Only a Few Observations"], "LLM accuracy estimation mc qa text generation computer vision classification image captioning": ["Precise Model Benchmarking with Only a Few Observations"], "mc qa text generation computer vision classification image captioning tabular data classification": ["Precise Model Benchmarking with Only a Few Observations"], "literature review table generation": ["ARXIVDIGESTABLES: Synthesizing Scientific Literature into Tables using Language Models"], "schema generation": ["ARXIVDIGESTABLES: Synthesizing Scientific Literature into Tables using Language Models"], "value generation": ["ARXIVDIGESTABLES: Synthesizing Scientific Literature into Tables using Language Models"], "literature review table generation schema generation": ["ARXIVDIGESTABLES: Synthesizing Scientific Literature into Tables using Language Models"], "schema generation value generation": ["ARXIVDIGESTABLES: Synthesizing Scientific Literature into Tables using Language Models"], "literature review table generation schema generation value generation": ["ARXIVDIGESTABLES: Synthesizing Scientific Literature into Tables using Language Models"], "numerical ability": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "linguistic abilities": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "conceptual understanding": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "fluid reasoning": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "numerical ability linguistic abilities": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "linguistic abilities conceptual understanding": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "conceptual understanding fluid reasoning": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "numerical ability linguistic abilities conceptual understanding": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "linguistic abilities conceptual understanding fluid reasoning": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "numerical ability linguistic abilities conceptual understanding fluid reasoning": ["Development of Cognitive Intelligence in Pre-trained Language Models"], "reading order prediction": ["Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding"], "document understanding": ["Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding", "TroL: Traversal of Layers for Large Language and Vision Models", "mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "reading order prediction document understanding": ["Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding"], "document understanding information extraction": ["Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding"], "reading order prediction document understanding information extraction": ["Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding"], "document understanding information extraction question answering": ["Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding"], "reading order prediction document understanding information extraction question answering": ["Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding"], "in-context retrieval": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives", "Can't Remember Details in Long Documents? You Need Some R&R"], "phone book lookup": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "long paragraph question answering": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "infilling": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "language modeling in-context retrieval": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "in-context retrieval phone book lookup": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "phone book lookup long paragraph question answering": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "long paragraph question answering infilling": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "language modeling in-context retrieval phone book lookup": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "in-context retrieval phone book lookup long paragraph question answering": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "phone book lookup long paragraph question answering infilling": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "language modeling in-context retrieval phone book lookup long paragraph question answering": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "in-context retrieval phone book lookup long paragraph question answering infilling": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "language modeling in-context retrieval phone book lookup long paragraph question answering infilling": ["Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives"], "instruction tuning multilingual evaluation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "multilingual evaluation question answering": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "question answering machine translation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "machine translation text generation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "text generation classification": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?", "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "instruction tuning multilingual evaluation question answering": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "multilingual evaluation question answering machine translation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "question answering machine translation text generation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "machine translation text generation classification": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "instruction tuning multilingual evaluation question answering machine translation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "multilingual evaluation question answering machine translation text generation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "question answering machine translation text generation classification": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "instruction tuning multilingual evaluation question answering machine translation text generation": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "multilingual evaluation question answering machine translation text generation classification": ["Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"], "vocabulary": ["Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs"], "language models tokenization": ["Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs"], "tokenization vocabulary": ["Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs"], "language models tokenization vocabulary": ["Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs"], "conversational grounding": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "listener": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "speaker": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "cancel": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding", "Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "anaphora": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "reference ambiguity": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "conversational grounding listener": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "listener speaker": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "speaker repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "repair cancel": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "cancel request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "request-repair request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "request-repair anaphora": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "anaphora reference ambiguity": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "conversational grounding listener speaker": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "listener speaker repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "speaker repair cancel": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "repair cancel request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "cancel request-repair request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "request-repair request-repair anaphora": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "request-repair anaphora reference ambiguity": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "conversational grounding listener speaker repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "listener speaker repair cancel": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "speaker repair cancel request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "repair cancel request-repair request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "cancel request-repair request-repair anaphora": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "request-repair request-repair anaphora reference ambiguity": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "conversational grounding listener speaker repair cancel": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "listener speaker repair cancel request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "speaker repair cancel request-repair request-repair": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "repair cancel request-repair request-repair anaphora": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "cancel request-repair request-repair anaphora reference ambiguity": ["Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"], "text generation code generation": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "code generation summarization": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"], "question answering translation": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "text generation code generation summarization": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "code generation summarization question answering": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "summarization question answering translation": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "text generation code generation summarization question answering": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "code generation summarization question answering translation": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "text generation code generation summarization question answering translation": ["Unlocking Memorization in Large Language Models with Dynamic Soft Prompting"], "vlm analysis": ["If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions"], "image classification vlm analysis": ["If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions"], "vlm analysis text generation": ["If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions"], "image classification vlm analysis text generation": ["If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions"], "knowledge graph construction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction", "Topic-Oriented Open Relation Extraction with A Priori Seed Generation", "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "open information extraction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction", "A Survey on Open Information Extraction from Rule-based Model to Large Language Model"], "schema definition": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "schema canonicalization": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "relational triplet extraction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "knowledge graph construction open information extraction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "open information extraction schema definition": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "schema definition schema canonicalization": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "schema canonicalization relational triplet extraction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "knowledge graph construction open information extraction schema definition": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "open information extraction schema definition schema canonicalization": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "schema definition schema canonicalization relational triplet extraction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "knowledge graph construction open information extraction schema definition schema canonicalization": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "open information extraction schema definition schema canonicalization relational triplet extraction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "knowledge graph construction open information extraction schema definition schema canonicalization relational triplet extraction": ["Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"], "knowledge graph embedding": ["MQuinE: a Cure for \"Z-paradox\" in Knowledge Graph Embedding", "Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding"], "link prediction": ["MQuinE: a Cure for \"Z-paradox\" in Knowledge Graph Embedding", "MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion", "ATAP: Automatic Template-Augmented Commonsense Knowledge Graph Completion via Pre-Trained Language Models", "Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction", "Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction", "Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs", "Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning", "OpenGraph: Towards Open Graph Foundation Models", "Llamipa: An Incremental Discourse Parser", "Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding"], "knowledge graph embedding link prediction": ["MQuinE: a Cure for \"Z-paradox\" in Knowledge Graph Embedding", "Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding"], "text classification question answering": ["StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models", "Memory-Efficient Fine-Tuning of Transformers via Token Selection", "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation", "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "question answering text generation": ["StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models", "Are LLMs Aware that Some Questions are not Open-ended?"], "text generation instruction induction": ["StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models"], "text classification question answering text generation": ["StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models"], "question answering text generation instruction induction": ["StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models"], "text classification question answering text generation instruction induction": ["StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models"], "long-context summarization": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "rag evaluation": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "coverage": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "citation": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "long-context summarization rag evaluation": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "rag evaluation coverage": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "coverage citation": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "long-context summarization rag evaluation coverage": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "rag evaluation coverage citation": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "long-context summarization rag evaluation coverage citation": ["Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"], "sequence-to-sequence learning": ["Multi-pass Decoding for Grammatical Error Correction"], "grammatical error correction sequence-to-sequence learning": ["Multi-pass Decoding for Grammatical Error Correction"], "knowledge discovery": ["Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations"], "collaborative discourse": ["Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations"], "information seeking knowledge discovery": ["Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations"], "knowledge discovery collaborative discourse": ["Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations"], "information seeking knowledge discovery collaborative discourse": ["Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations"], "machine translation in-context learning": ["SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation"], "temporal question grounding on video": ["Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge"], "video question answering temporal question grounding on video": ["Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge"], "story summarization": ["STORYSUMM: Evaluating Faithfulness in Story Summarization"], "faithfulness evaluation story summarization": ["STORYSUMM: Evaluating Faithfulness in Story Summarization"], "sarcasm detection": ["MMOE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts", "Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "humor detection": ["MMOE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts", "CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs", "SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "sarcasm detection humor detection": ["MMOE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts"], "video understanding": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer", "A Simple LLM Framework for Long-Range Video Question-Answering", "Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP", "Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "task planning": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer", "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "E2CL: Exploration-based Error Correction Learning for Embodied Agents", "TrustAgent: Towards Safe and Trustworthy LLM-based Agents", "Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "tool invocation": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer", "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent"], "long video processing": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "event localization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "information summarization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "external knowledge integration": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "video understanding question answering": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "question answering task planning": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "task planning tool invocation": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer", "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent"], "tool invocation long video processing": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "long video processing information retrieval": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "information retrieval event localization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "event localization information summarization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "information summarization external knowledge integration": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "external knowledge integration visual reasoning": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "video understanding question answering task planning": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "question answering task planning tool invocation": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "task planning tool invocation long video processing": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "tool invocation long video processing information retrieval": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "long video processing information retrieval event localization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "information retrieval event localization information summarization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "event localization information summarization external knowledge integration": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "information summarization external knowledge integration visual reasoning": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "video understanding question answering task planning tool invocation": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "question answering task planning tool invocation long video processing": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "task planning tool invocation long video processing information retrieval": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "tool invocation long video processing information retrieval event localization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "long video processing information retrieval event localization information summarization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "information retrieval event localization information summarization external knowledge integration": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "event localization information summarization external knowledge integration visual reasoning": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "video understanding question answering task planning tool invocation long video processing": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "question answering task planning tool invocation long video processing information retrieval": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "task planning tool invocation long video processing information retrieval event localization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "tool invocation long video processing information retrieval event localization information summarization": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "long video processing information retrieval event localization information summarization external knowledge integration": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "information retrieval event localization information summarization external knowledge integration visual reasoning": ["OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer"], "machine reading comprehension": ["Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension", "MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning", "Unlocking the Potential of Model Merging for Low-Resource Languages"], "extractive qa": ["Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension"], "machine reading comprehension extractive qa": ["Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension"], "instruction tuning LLMs": ["CommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions", "Better Alignment with Instruction Back-and-Forth Translation"], "speech coding": ["ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers"], "multilingual learning": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models", "Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions", "Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia", "Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding"], "language models multitask learning": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "multitask learning multilingual learning": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "multilingual learning fine-tuning": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "fine-tuning zero-shot evaluation": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "language models multitask learning multilingual learning": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "multitask learning multilingual learning fine-tuning": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "multilingual learning fine-tuning zero-shot evaluation": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "language models multitask learning multilingual learning fine-tuning": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "multitask learning multilingual learning fine-tuning zero-shot evaluation": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "language models multitask learning multilingual learning fine-tuning zero-shot evaluation": ["Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models"], "human-model text detection": ["Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood"], "ai-generated feedback": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "harMLessness mitigation": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "helpfulness enhancement": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning", "TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "reinforcement learning from human feedback ai-generated feedback": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "ai-generated feedback dialogue generation": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "dialogue generation question answering": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning", "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "question answering harMLessness mitigation": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "harMLessness mitigation helpfulness enhancement": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "reinforcement learning from human feedback ai-generated feedback dialogue generation": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "ai-generated feedback dialogue generation question answering": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "dialogue generation question answering harMLessness mitigation": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "question answering harMLessness mitigation helpfulness enhancement": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "reinforcement learning from human feedback ai-generated feedback dialogue generation question answering": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "ai-generated feedback dialogue generation question answering harMLessness mitigation": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "dialogue generation question answering harMLessness mitigation helpfulness enhancement": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "reinforcement learning from human feedback ai-generated feedback dialogue generation question answering harMLessness mitigation": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "ai-generated feedback dialogue generation question answering harMLessness mitigation helpfulness enhancement": ["Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"], "knowledge unlearning": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models", "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "toxicity removal": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "personally identifiable information removal": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "behavior alignment": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "knowledge unlearning toxicity removal": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "toxicity removal personally identifiable information removal": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "personally identifiable information removal behavior alignment": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "knowledge unlearning toxicity removal personally identifiable information removal": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "toxicity removal personally identifiable information removal behavior alignment": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "knowledge unlearning toxicity removal personally identifiable information removal behavior alignment": ["Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models"], "chinese spelling check": ["ARM: An Alignment-and-Replacement Module for Chinese Spelling Check Based on LLMs", "Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check"], "in-context generation": ["On the In-context Generation of Language Models"], "in-context generation in-context learning": ["On the In-context Generation of Language Models"], "asr": ["Towards Robust Speech Representation Learning for Thousands of Languages", "Self-Powered LLM Modality Expansion for Large Speech-Text Models", "Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech", "TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR", "STTATTS: Unified Speech-To-Text And Text-To-Speech Model"], "speaker identification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker verification": ["Towards Robust Speech Representation Learning for Thousands of Languages", "WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speaker diarization": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "query by example": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "asr speech translation": ["Towards Robust Speech Representation Learning for Thousands of Languages", "Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech translation speech resynthesis": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speech resynthesis emotion recognition": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "emotion recognition speaker identification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker identification speaker verification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker verification speaker diarization": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker diarization intent classification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "slot filling keyword spotting": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "keyword spotting query by example": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "asr speech translation speech resynthesis": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speech translation speech resynthesis emotion recognition": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speech resynthesis emotion recognition speaker identification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "emotion recognition speaker identification speaker verification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker identification speaker verification speaker diarization": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker verification speaker diarization intent classification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker diarization intent classification slot filling": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "intent classification slot filling keyword spotting": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "slot filling keyword spotting query by example": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "asr speech translation speech resynthesis emotion recognition": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speech translation speech resynthesis emotion recognition speaker identification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speech resynthesis emotion recognition speaker identification speaker verification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "emotion recognition speaker identification speaker verification speaker diarization": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker identification speaker verification speaker diarization intent classification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker verification speaker diarization intent classification slot filling": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker diarization intent classification slot filling keyword spotting": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "intent classification slot filling keyword spotting query by example": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "asr speech translation speech resynthesis emotion recognition speaker identification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speech translation speech resynthesis emotion recognition speaker identification speaker verification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speech resynthesis emotion recognition speaker identification speaker verification speaker diarization": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "emotion recognition speaker identification speaker verification speaker diarization intent classification": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker identification speaker verification speaker diarization intent classification slot filling": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker verification speaker diarization intent classification slot filling keyword spotting": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "speaker diarization intent classification slot filling keyword spotting query by example": ["Towards Robust Speech Representation Learning for Thousands of Languages"], "reasoning tasks": ["I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"], "reasoning tasks code generation": ["I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"], "code generation math problem solving": ["I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"], "math problem solving commonsense reasoning": ["I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"], "reasoning tasks code generation math problem solving": ["I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"], "code generation math problem solving commonsense reasoning": ["I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"], "reasoning tasks code generation math problem solving commonsense reasoning": ["I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"], "zero-shot cross-lingual transfer": ["PREALIGN: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"], "cross-lingual knowledge application": ["PREALIGN: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"], "language modeling zero-shot cross-lingual transfer": ["PREALIGN: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"], "zero-shot cross-lingual transfer cross-lingual knowledge application": ["PREALIGN: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"], "language modeling zero-shot cross-lingual transfer cross-lingual knowledge application": ["PREALIGN: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"], "image transcreation": ["An image speaks a thousand words, but can everyone listen? On image transcreation for cultural relevance"], "wic": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models", "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "agnews": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "arc-easy": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models", "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "sst2 boolq": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "boolq qqp": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "qqp wic": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "wic rte": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "rte mnli": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "mnli agnews": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "agnews arc-easy": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "sst2 boolq qqp": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "boolq qqp wic": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "qqp wic rte": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "wic rte mnli": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "rte mnli agnews": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "mnli agnews arc-easy": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "sst2 boolq qqp wic": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "boolq qqp wic rte": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "qqp wic rte mnli": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "wic rte mnli agnews": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "rte mnli agnews arc-easy": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "sst2 boolq qqp wic rte": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "boolq qqp wic rte mnli": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "qqp wic rte mnli agnews": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "wic rte mnli agnews arc-easy": ["When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models"], "clickbait detection": ["Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference"], "text embeddings": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "dimensionality reduction": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions", "Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "text embeddings dimensionality reduction": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "dimensionality reduction information retrieval": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "information retrieval multimodal learning": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "multimodal learning multilingual learning": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "text embeddings dimensionality reduction information retrieval": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "dimensionality reduction information retrieval multimodal learning": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "information retrieval multimodal learning multilingual learning": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "text embeddings dimensionality reduction information retrieval multimodal learning": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "dimensionality reduction information retrieval multimodal learning multilingual learning": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "text embeddings dimensionality reduction information retrieval multimodal learning multilingual learning": ["Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions"], "instruction construction": ["KNN-INSTRUCT: Automatic Instruction Construction with K Nearest Neighbor Deduction"], "supervised fine-tuning instruction construction": ["KNN-INSTRUCT: Automatic Instruction Construction with K Nearest Neighbor Deduction"], "natural language generation question answering": ["Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation"], "document retrieval question answering": ["MixGR: Enhancing Retriever Generalization for Scientific Domain through Complementary Granularity"], "heart failure prediction": ["CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"], "full diagnosis prediction": ["CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"], "heart failure prediction full diagnosis prediction": ["CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"], "mechanistic interpretability": ["Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective", "Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions", "Information Flow Routes: Automatically Interpreting Language Models at Scale", "Activation Scaling for Steering and Interpreting Language Models"], "language models mechanistic interpretability": ["Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective"], "mechanistic interpretability preference alignment": ["Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective"], "language models mechanistic interpretability preference alignment": ["Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective"], "calibration": ["Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding", "FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation", "CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models", "Calibrating Language Models with Adaptive Temperature Scaling", "Reconfidencing LLMs from the Grouping Loss Perspective", "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration", "Self-Consistency Boosts Calibration for Math Reasoning", "Distance-aware Calibration for Pre-trained Language Models", "Calibrating Long-form Generations from Large Language Models", "Uncertainty Calibration for Tool-Using Language Agents"], "factuality enhancement": ["Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding"], "question answering calibration": ["Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding"], "calibration factuality enhancement": ["Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding"], "question answering calibration factuality enhancement": ["Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding"], "reasoning robustness": ["Reasoning Robustness of LLMs to Adversarial Typographical Errors"], "typographical errors": ["Reasoning Robustness of LLMs to Adversarial Typographical Errors"], "reasoning robustness adversarial attack": ["Reasoning Robustness of LLMs to Adversarial Typographical Errors"], "adversarial attack typographical errors": ["Reasoning Robustness of LLMs to Adversarial Typographical Errors"], "reasoning robustness adversarial attack typographical errors": ["Reasoning Robustness of LLMs to Adversarial Typographical Errors"], "harMLessness alignment": ["InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance"], "cross-model guidance": ["InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance"], "inference-time alignment": ["InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance"], "harMLessness alignment cross-model guidance": ["InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance"], "cross-model guidance inference-time alignment": ["InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance"], "harMLessness alignment cross-model guidance inference-time alignment": ["InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance"], "belief revision": ["Belief Revision: The Adaptability of Large Language Models Reasoning"], "reasoning evaluation": ["Belief Revision: The Adaptability of Large Language Models Reasoning", "Self-Contradictory Reasoning Evaluation and Detection", "Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries"], "belief revision reasoning evaluation": ["Belief Revision: The Adaptability of Large Language Models Reasoning"], "mpqa": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "subj": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "trec": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models", "InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "qnli sst-2": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "sst-2 cola": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "cola mrpc": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "mrpc rte": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "rte boolq": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "boolq mpqa": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "mpqa subj": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "subj trec": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "trec mr": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "qnli sst-2 cola": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "sst-2 cola mrpc": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "cola mrpc rte": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "mrpc rte boolq": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "rte boolq mpqa": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "boolq mpqa subj": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "mpqa subj trec": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "subj trec mr": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "qnli sst-2 cola mrpc": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "sst-2 cola mrpc rte": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "cola mrpc rte boolq": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "mrpc rte boolq mpqa": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "rte boolq mpqa subj": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "boolq mpqa subj trec": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "mpqa subj trec mr": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "qnli sst-2 cola mrpc rte": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "sst-2 cola mrpc rte boolq": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "cola mrpc rte boolq mpqa": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "mrpc rte boolq mpqa subj": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "rte boolq mpqa subj trec": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "boolq mpqa subj trec mr": ["Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models"], "named entity recognition relation extraction": ["Bio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints", "SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents", "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction", "C-ICL: Contrastive In-context Learning for Information Extraction", "Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "LLM": ["Decoding Matters: Addressing Amplification Bias and Homogeneity Issue for LLM-based Recommendation", "When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "decoding": ["Decoding Matters: Addressing Amplification Bias and Homogeneity Issue for LLM-based Recommendation"], "recommendation LLM": ["Decoding Matters: Addressing Amplification Bias and Homogeneity Issue for LLM-based Recommendation"], "LLM decoding": ["Decoding Matters: Addressing Amplification Bias and Homogeneity Issue for LLM-based Recommendation", "Decoding with Limited Teacher Supervision Requires Understanding When to Trust the Teacher"], "recommendation LLM decoding": ["Decoding Matters: Addressing Amplification Bias and Homogeneity Issue for LLM-based Recommendation"], "causal inference": ["LLMs Are Prone to Fallacies in Causal Inference", "SLANG: New Concept Comprehension of Large Language Models", "AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "causal discovery": ["LLMs Are Prone to Fallacies in Causal Inference", "Do LLMs Think Fast and Slow? A Causal Study on Sentiment Analysis"], "causal inference causal discovery": ["LLMs Are Prone to Fallacies in Causal Inference"], "creating ai patients for novice therapists": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "improving LLM simulations": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "guiding LLM roleplay": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "aligning LLM with domain experts": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "constrained text generation": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "creating ai patients for novice therapists improving LLM simulations": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "improving LLM simulations guiding LLM roleplay": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "guiding LLM roleplay aligning LLM with domain experts": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "aligning LLM with domain experts constrained text generation": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "creating ai patients for novice therapists improving LLM simulations guiding LLM roleplay": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "improving LLM simulations guiding LLM roleplay aligning LLM with domain experts": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "guiding LLM roleplay aligning LLM with domain experts constrained text generation": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "creating ai patients for novice therapists improving LLM simulations guiding LLM roleplay aligning LLM with domain experts": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "improving LLM simulations guiding LLM roleplay aligning LLM with domain experts constrained text generation": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "creating ai patients for novice therapists improving LLM simulations guiding LLM roleplay aligning LLM with domain experts constrained text generation": ["Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"], "stance detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification", "Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets", "Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research", "I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining", "Stanceformer: Target-Aware Transformer for Stance Detection", "Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter", "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"], "toxicity classification": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification", "Latent Concept-based Explanation of NLP Models"], "fact claiming": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "engaging detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "stance detection toxicity classification": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "toxicity classification fact claiming": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "fact claiming sentiment analysis": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "sentiment analysis hate speech detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification", "Revisiting Supervised Contrastive Learning for Microblog Classification"], "hate speech detection engaging detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "stance detection toxicity classification fact claiming": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "toxicity classification fact claiming sentiment analysis": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "fact claiming sentiment analysis hate speech detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "sentiment analysis hate speech detection engaging detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "stance detection toxicity classification fact claiming sentiment analysis": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "toxicity classification fact claiming sentiment analysis hate speech detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "fact claiming sentiment analysis hate speech detection engaging detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "stance detection toxicity classification fact claiming sentiment analysis hate speech detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "toxicity classification fact claiming sentiment analysis hate speech detection engaging detection": ["The Lou Dataset: Exploring the Impact of Gender-Fair Language in German Text Classification"], "chinese word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "cross-domain chinese word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "korean word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "japanese word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "english named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese part-of-speech tagging": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese word segmentation cross-domain chinese word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "cross-domain chinese word segmentation korean word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "korean word segmentation japanese word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "japanese word segmentation chinese named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese named entity recognition english named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "english named entity recognition chinese part-of-speech tagging": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese word segmentation cross-domain chinese word segmentation korean word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "cross-domain chinese word segmentation korean word segmentation japanese word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "korean word segmentation japanese word segmentation chinese named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "japanese word segmentation chinese named entity recognition english named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese named entity recognition english named entity recognition chinese part-of-speech tagging": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese word segmentation cross-domain chinese word segmentation korean word segmentation japanese word segmentation": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "cross-domain chinese word segmentation korean word segmentation japanese word segmentation chinese named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "korean word segmentation japanese word segmentation chinese named entity recognition english named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "japanese word segmentation chinese named entity recognition english named entity recognition chinese part-of-speech tagging": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "chinese word segmentation cross-domain chinese word segmentation korean word segmentation japanese word segmentation chinese named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "cross-domain chinese word segmentation korean word segmentation japanese word segmentation chinese named entity recognition english named entity recognition": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "korean word segmentation japanese word segmentation chinese named entity recognition english named entity recognition chinese part-of-speech tagging": ["When Generative Adversarial Networks Meet Sequence Labeling Challenges"], "instruction-tuned language models": ["Speechworthy Instruction-tuned Language Models"], "pretraining dataset construction": ["Data, Data Everywhere: A Guide for Pretraining Dataset Construction"], "feature-based classification": ["Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together"], "multi-hop qa mathematical reasoning": ["Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together"], "mathematical reasoning feature-based classification": ["Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together"], "multi-hop qa mathematical reasoning feature-based classification": ["Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together"], "verbatim memorization": ["Demystifying Verbatim Memorization in Large Language Models"], "verbatim memorization language modeling": ["Demystifying Verbatim Memorization in Large Language Models"], "language modeling unlearning": ["Demystifying Verbatim Memorization in Large Language Models"], "verbatim memorization language modeling unlearning": ["Demystifying Verbatim Memorization in Large Language Models"], "task ambiguity mitigation": ["AmbigNLG: Addressing Task Ambiguity in Instruction for NLG"], "nlg instruction following": ["AmbigNLG: Addressing Task Ambiguity in Instruction for NLG"], "instruction following task ambiguity mitigation": ["AmbigNLG: Addressing Task Ambiguity in Instruction for NLG"], "nlg instruction following task ambiguity mitigation": ["AmbigNLG: Addressing Task Ambiguity in Instruction for NLG"], "data narration": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "table insight generation": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "financial nlp": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "news narration": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "data narration table insight generation": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "table insight generation data-to-text generation": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "data-to-text generation financial nlp": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "financial nlp news narration": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "data narration table insight generation data-to-text generation": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "table insight generation data-to-text generation financial nlp": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "data-to-text generation financial nlp news narration": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "data narration table insight generation data-to-text generation financial nlp": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "table insight generation data-to-text generation financial nlp news narration": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "data narration table insight generation data-to-text generation financial nlp news narration": ["DATATALES: A Benchmark for Real-World Intelligent Data Narration"], "multilingual translation": ["Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters"], "speculative decoding": ["Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters", "Draft on the Fly: Adaptive Self-Speculative Decoding using Cosine Similarity", "Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "language-specific draft models": ["Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters"], "multilingual translation speculative decoding": ["Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters"], "speculative decoding language-specific draft models": ["Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters"], "multilingual translation speculative decoding language-specific draft models": ["Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters"], "multi-lingual summarization": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "cross-lingual summarization": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization", "Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach"], "mcms": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "multi-lingual summarization cross-lingual summarization": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "cross-lingual summarization multi-document summarization": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "multi-document summarization mcms": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "multi-lingual summarization cross-lingual summarization multi-document summarization": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "cross-lingual summarization multi-document summarization mcms": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "multi-lingual summarization cross-lingual summarization multi-document summarization mcms": ["GLOBESUMM: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"], "cross-lingual transfer": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models", "README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment", ">Why Does New Knowledge Create Messy Ripple Effects in LLMs?", "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing", "Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models", "Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "adaptation to new languages": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"], "language modeling cross-lingual transfer": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"], "cross-lingual transfer adaptation to new languages": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"], "adaptation to new languages in-context learning": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"], "language modeling cross-lingual transfer adaptation to new languages": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"], "cross-lingual transfer adaptation to new languages in-context learning": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"], "language modeling cross-lingual transfer adaptation to new languages in-context learning": ["Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"], "feedback generation natural language inference": ["More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation"], "feedback generation natural language inference reading comprehension": ["More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation"], "pre-training stability": ["Stable Language Model Pre-training by Reducing Embedding Variability"], "language modeling pre-training stability": ["Stable Language Model Pre-training by Reducing Embedding Variability"], "multilingual asr": ["What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations"], "speech recognition evaluation": ["What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations"], "evaluation multilingual asr": ["What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations"], "speech recognition evaluation multilingual asr": ["What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations"], "topic-dependent argument mining": ["Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets"], "argument component extraction": ["Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets"], "topic-dependent argument mining argument component extraction": ["Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets"], "argument component extraction stance detection": ["Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets"], "topic-dependent argument mining argument component extraction stance detection": ["Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets"], "negotiation behavior analysis": ["Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas"], "visual persona assignment": ["Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas"], "aggressiveness perception": ["Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas"], "negotiation behavior analysis visual persona assignment": ["Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas"], "visual persona assignment aggressiveness perception": ["Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas"], "negotiation behavior analysis visual persona assignment aggressiveness perception": ["Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas"], "robustness": ["ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR"], "RAG robustness": ["ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR"], "question answering RAG robustness": ["ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented GENERATOR"], "aspect-based sentiment analysis": ["Dynamic Multi-granularity Attribution Network for Aspect-based Sentiment Analysis", "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction", "Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis", "Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "occupation prediction": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization"], "mention detection": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization", "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "document classification occupation prediction": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization"], "occupation prediction hate speech detection": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization"], "hate speech detection mention detection": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization"], "document classification occupation prediction hate speech detection": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization"], "occupation prediction hate speech detection mention detection": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization"], "document classification occupation prediction hate speech detection mention detection": ["Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization"], "risk detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "multimodal analysis": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights", "Emosical: An Emotion-Annotated Musical Theatre Dataset"], "threat detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "imitation detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "stereotype detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights", "Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models"], "risk detection speech analysis": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "speech analysis multimodal analysis": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "multimodal analysis bias detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "bias detection sarcasm detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "sarcasm detection threat detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "threat detection imitation detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "imitation detection stereotype detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "risk detection speech analysis multimodal analysis": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "speech analysis multimodal analysis bias detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "multimodal analysis bias detection sarcasm detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "bias detection sarcasm detection threat detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "sarcasm detection threat detection imitation detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "threat detection imitation detection stereotype detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "risk detection speech analysis multimodal analysis bias detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "speech analysis multimodal analysis bias detection sarcasm detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "multimodal analysis bias detection sarcasm detection threat detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "bias detection sarcasm detection threat detection imitation detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "sarcasm detection threat detection imitation detection stereotype detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "risk detection speech analysis multimodal analysis bias detection sarcasm detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "speech analysis multimodal analysis bias detection sarcasm detection threat detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "multimodal analysis bias detection sarcasm detection threat detection imitation detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "bias detection sarcasm detection threat detection imitation detection stereotype detection": ["Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"], "natural language rationales generation": ["Self-AMPLIFY : Improving Small Language Models with Self Post Hoc Explanations"], "in-context learning natural language rationales generation": ["Self-AMPLIFY : Improving Small Language Models with Self Post Hoc Explanations"], "natural language rationales generation reasoning": ["Self-AMPLIFY : Improving Small Language Models with Self Post Hoc Explanations"], "in-context learning natural language rationales generation reasoning": ["Self-AMPLIFY : Improving Small Language Models with Self Post Hoc Explanations"], "entity retrieval": ["What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"], "task-oriented dialogue entity retrieval": ["What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"], "entity retrieval response generation": ["What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"], "response generation preference learning": ["What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"], "task-oriented dialogue entity retrieval response generation": ["What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"], "entity retrieval response generation preference learning": ["What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"], "task-oriented dialogue entity retrieval response generation preference learning": ["What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"], "title generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities", "Task Oriented In-Domain Data Augmentation", "Measuring the Robustness of NLP Models to Domain Shifts"], "answerability classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question rewriting": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentence composition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text to code": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text quality evaluation": ["Paraphrase Types Elicit Prompt Engineering Capabilities", "Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "commonsense classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "program execution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "word semantics": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "fill in the blank": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "wrong candidate generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text completion title generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "title generation question generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question generation answerability classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "answerability classification question rewriting": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question rewriting sentence composition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentence composition summarization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "summarization information extraction": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "information extraction dialogue generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "dialogue generation coreference resolution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "coreference resolution named entity recognition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "named entity recognition text categorization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text categorization text matching": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text matching text to code": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text to code question answering": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentiment analysis text quality evaluation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text quality evaluation commonsense classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "commonsense classification program execution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "program execution textual entailment": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "textual entailment question understanding": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question understanding word semantics": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "word semantics fill in the blank": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "fill in the blank wrong candidate generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text completion title generation question generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "title generation question generation answerability classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question generation answerability classification question rewriting": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "answerability classification question rewriting sentence composition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question rewriting sentence composition summarization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentence composition summarization information extraction": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "summarization information extraction dialogue generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "information extraction dialogue generation coreference resolution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "dialogue generation coreference resolution named entity recognition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "coreference resolution named entity recognition text categorization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "named entity recognition text categorization text matching": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text categorization text matching text to code": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text matching text to code question answering": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text to code question answering sentiment analysis": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question answering sentiment analysis text quality evaluation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentiment analysis text quality evaluation commonsense classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text quality evaluation commonsense classification program execution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "commonsense classification program execution textual entailment": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "program execution textual entailment question understanding": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "textual entailment question understanding word semantics": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question understanding word semantics fill in the blank": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "word semantics fill in the blank wrong candidate generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text completion title generation question generation answerability classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "title generation question generation answerability classification question rewriting": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question generation answerability classification question rewriting sentence composition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "answerability classification question rewriting sentence composition summarization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question rewriting sentence composition summarization information extraction": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentence composition summarization information extraction dialogue generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "summarization information extraction dialogue generation coreference resolution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "information extraction dialogue generation coreference resolution named entity recognition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "dialogue generation coreference resolution named entity recognition text categorization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "coreference resolution named entity recognition text categorization text matching": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "named entity recognition text categorization text matching text to code": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text categorization text matching text to code question answering": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text matching text to code question answering sentiment analysis": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text to code question answering sentiment analysis text quality evaluation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question answering sentiment analysis text quality evaluation commonsense classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentiment analysis text quality evaluation commonsense classification program execution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text quality evaluation commonsense classification program execution textual entailment": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "commonsense classification program execution textual entailment question understanding": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "program execution textual entailment question understanding word semantics": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "textual entailment question understanding word semantics fill in the blank": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question understanding word semantics fill in the blank wrong candidate generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text completion title generation question generation answerability classification question rewriting": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "title generation question generation answerability classification question rewriting sentence composition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question generation answerability classification question rewriting sentence composition summarization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "answerability classification question rewriting sentence composition summarization information extraction": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question rewriting sentence composition summarization information extraction dialogue generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentence composition summarization information extraction dialogue generation coreference resolution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "summarization information extraction dialogue generation coreference resolution named entity recognition": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "information extraction dialogue generation coreference resolution named entity recognition text categorization": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "dialogue generation coreference resolution named entity recognition text categorization text matching": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "coreference resolution named entity recognition text categorization text matching text to code": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "named entity recognition text categorization text matching text to code question answering": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text categorization text matching text to code question answering sentiment analysis": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text matching text to code question answering sentiment analysis text quality evaluation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text to code question answering sentiment analysis text quality evaluation commonsense classification": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "question answering sentiment analysis text quality evaluation commonsense classification program execution": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "sentiment analysis text quality evaluation commonsense classification program execution textual entailment": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text quality evaluation commonsense classification program execution textual entailment question understanding": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "commonsense classification program execution textual entailment question understanding word semantics": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "program execution textual entailment question understanding word semantics fill in the blank": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "textual entailment question understanding word semantics fill in the blank wrong candidate generation": ["Paraphrase Types Elicit Prompt Engineering Capabilities"], "text-to-image generalizability evaluation": ["VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models"], "continuous sign language recognition": ["Towards Online Continuous Sign Language Recognition and Translation"], "sign language translation": ["Towards Online Continuous Sign Language Recognition and Translation", "Unsupervised Discrete Representations of American Sign Language", "Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "continuous sign language recognition isolated sign language recognition": ["Towards Online Continuous Sign Language Recognition and Translation"], "isolated sign language recognition sign language translation": ["Towards Online Continuous Sign Language Recognition and Translation"], "continuous sign language recognition isolated sign language recognition sign language translation": ["Towards Online Continuous Sign Language Recognition and Translation"], "psychometric dimension prediction": ["Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment"], "hate speech detection sentiment analysis": ["Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment"], "sentiment analysis psychometric dimension prediction": ["Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment"], "hate speech detection sentiment analysis psychometric dimension prediction": ["Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment"], "pairwise comparison": ["Split and Merge: Aligning Position Biases in LLM-based Evaluators"], "LLM evaluation bias mitigation": ["Split and Merge: Aligning Position Biases in LLM-based Evaluators"], "bias mitigation pairwise comparison": ["Split and Merge: Aligning Position Biases in LLM-based Evaluators"], "LLM evaluation bias mitigation pairwise comparison": ["Split and Merge: Aligning Position Biases in LLM-based Evaluators"], "misinformation countering": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument generation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "strategy adaptation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument graph construction": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "misinformation countering hate speech countering": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "hate speech countering argument generation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument generation dialogue systems": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "dialogue systems response generation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "response generation strategy adaptation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "strategy adaptation argument graph construction": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument graph construction persuasion": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "persuasion text classification": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "text classification natural language processing": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "misinformation countering hate speech countering argument generation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "hate speech countering argument generation dialogue systems": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument generation dialogue systems response generation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "dialogue systems response generation strategy adaptation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "response generation strategy adaptation argument graph construction": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "strategy adaptation argument graph construction persuasion": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument graph construction persuasion text classification": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "persuasion text classification natural language processing": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "misinformation countering hate speech countering argument generation dialogue systems": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "hate speech countering argument generation dialogue systems response generation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument generation dialogue systems response generation strategy adaptation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "dialogue systems response generation strategy adaptation argument graph construction": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "response generation strategy adaptation argument graph construction persuasion": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "strategy adaptation argument graph construction persuasion text classification": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument graph construction persuasion text classification natural language processing": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "misinformation countering hate speech countering argument generation dialogue systems response generation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "hate speech countering argument generation dialogue systems response generation strategy adaptation": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "argument generation dialogue systems response generation strategy adaptation argument graph construction": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "dialogue systems response generation strategy adaptation argument graph construction persuasion": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "response generation strategy adaptation argument graph construction persuasion text classification": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "strategy adaptation argument graph construction persuasion text classification natural language processing": ["Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"], "tl;dr": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "anthropic helpfulness": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "direct preference optimization": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment", "Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "tl;dr anthropic helpfulness": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "anthropic helpfulness harMLessness": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "harMLessness direct preference optimization": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "tl;dr anthropic helpfulness harMLessness": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "anthropic helpfulness harMLessness direct preference optimization": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "tl;dr anthropic helpfulness harMLessness direct preference optimization": ["BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment"], "keyphrase generation": ["ONE2SET + Large Language Model: Best Partners for Keyphrase Generation", "Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts", "METAKP: On-Demand Keyphrase Generation"], "multilingual cross-market product-based question answering": ["Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"], "review-based answer generation": ["Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"], "product-related question ranking": ["Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"], "multilingual cross-market product-based question answering review-based answer generation": ["Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"], "review-based answer generation product-related question ranking": ["Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"], "multilingual cross-market product-based question answering review-based answer generation product-related question ranking": ["Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"], "language model fine-tuning": ["ORPO: Monolithic Preference Optimization without Reference Model", "Model-based Preference Optimization in Abstractive Summarization without Human Feedback", "CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "preference alignment language model fine-tuning": ["ORPO: Monolithic Preference Optimization without Reference Model"], "memorization analysis": ["A Multi-Perspective Analysis of Memorization in Large Language Models"], "addressee recognition": ["Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations"], "response selection": ["Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations", "Unlocking the Potential of Model Merging for Low-Resource Languages"], "addressee recognition response selection": ["Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations"], "conditional reasoning question answering": ["Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMS"], "direct speech translation": ["Unveiling the Role of Pretraining in Direct Speech Translation"], "direct speech translation automatic speech recognition": ["Unveiling the Role of Pretraining in Direct Speech Translation"], "conclusion-driven conversational question generation": ["PCQPR: Proactive Conversational Question Planning with Reflection"], "code change and commit message consistency": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "vulnerability analysis": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "code style adherence": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "code revision": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "code change and commit message consistency vulnerability analysis": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "vulnerability analysis code style adherence": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "code style adherence code revision": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "code change and commit message consistency vulnerability analysis code style adherence": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "vulnerability analysis code style adherence code revision": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "code change and commit message consistency vulnerability analysis code style adherence code revision": ["CodeAgent: Autonomous Communicative Agents for Code Review"], "vision language understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "chart understanding": ["TroL: Traversal of Layers for Large Language and Vision Models", "Plot Twist: Multimodal Models Don't Comprehend Simple Chart Details"], "math problems": ["TroL: Traversal of Layers for Large Language and Vision Models", "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "spatial awareness": ["TroL: Traversal of Layers for Large Language and Vision Models"], "commonsense knowledge": ["TroL: Traversal of Layers for Large Language and Vision Models"], "vision language understanding visual instruction tuning": ["TroL: Traversal of Layers for Large Language and Vision Models"], "visual instruction tuning question answering": ["TroL: Traversal of Layers for Large Language and Vision Models"], "question answering image understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "image understanding document understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "document understanding chart understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "chart understanding math problems": ["TroL: Traversal of Layers for Large Language and Vision Models"], "math problems spatial awareness": ["TroL: Traversal of Layers for Large Language and Vision Models"], "spatial awareness commonsense knowledge": ["TroL: Traversal of Layers for Large Language and Vision Models"], "vision language understanding visual instruction tuning question answering": ["TroL: Traversal of Layers for Large Language and Vision Models"], "visual instruction tuning question answering image understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "question answering image understanding document understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "image understanding document understanding chart understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "document understanding chart understanding math problems": ["TroL: Traversal of Layers for Large Language and Vision Models"], "chart understanding math problems spatial awareness": ["TroL: Traversal of Layers for Large Language and Vision Models"], "math problems spatial awareness commonsense knowledge": ["TroL: Traversal of Layers for Large Language and Vision Models"], "vision language understanding visual instruction tuning question answering image understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "visual instruction tuning question answering image understanding document understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "question answering image understanding document understanding chart understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "image understanding document understanding chart understanding math problems": ["TroL: Traversal of Layers for Large Language and Vision Models"], "document understanding chart understanding math problems spatial awareness": ["TroL: Traversal of Layers for Large Language and Vision Models"], "chart understanding math problems spatial awareness commonsense knowledge": ["TroL: Traversal of Layers for Large Language and Vision Models"], "vision language understanding visual instruction tuning question answering image understanding document understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "visual instruction tuning question answering image understanding document understanding chart understanding": ["TroL: Traversal of Layers for Large Language and Vision Models"], "question answering image understanding document understanding chart understanding math problems": ["TroL: Traversal of Layers for Large Language and Vision Models"], "image understanding document understanding chart understanding math problems spatial awareness": ["TroL: Traversal of Layers for Large Language and Vision Models"], "document understanding chart understanding math problems spatial awareness commonsense knowledge": ["TroL: Traversal of Layers for Large Language and Vision Models"], "metaphorical language translation": ["MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language"], "machine translation evaluation metaphorical language translation": ["MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language"], "supertagging": ["Revisiting Supertagging for Faster HPSG Parsing"], "hpsg parsing": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing speed improvement": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing accuracy improvement": ["Revisiting Supertagging for Faster HPSG Parsing"], "grammar-based treebank training": ["Revisiting Supertagging for Faster HPSG Parsing"], "dependency structure parsing": ["Revisiting Supertagging for Faster HPSG Parsing"], "lexical type prediction": ["Revisiting Supertagging for Faster HPSG Parsing"], "supertagging hpsg parsing": ["Revisiting Supertagging for Faster HPSG Parsing"], "hpsg parsing parsing speed improvement": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing speed improvement parsing accuracy improvement": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing accuracy improvement grammar-based treebank training": ["Revisiting Supertagging for Faster HPSG Parsing"], "grammar-based treebank training dependency structure parsing": ["Revisiting Supertagging for Faster HPSG Parsing"], "dependency structure parsing lexical type prediction": ["Revisiting Supertagging for Faster HPSG Parsing"], "supertagging hpsg parsing parsing speed improvement": ["Revisiting Supertagging for Faster HPSG Parsing"], "hpsg parsing parsing speed improvement parsing accuracy improvement": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing speed improvement parsing accuracy improvement grammar-based treebank training": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing accuracy improvement grammar-based treebank training dependency structure parsing": ["Revisiting Supertagging for Faster HPSG Parsing"], "grammar-based treebank training dependency structure parsing lexical type prediction": ["Revisiting Supertagging for Faster HPSG Parsing"], "supertagging hpsg parsing parsing speed improvement parsing accuracy improvement": ["Revisiting Supertagging for Faster HPSG Parsing"], "hpsg parsing parsing speed improvement parsing accuracy improvement grammar-based treebank training": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing speed improvement parsing accuracy improvement grammar-based treebank training dependency structure parsing": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing accuracy improvement grammar-based treebank training dependency structure parsing lexical type prediction": ["Revisiting Supertagging for Faster HPSG Parsing"], "supertagging hpsg parsing parsing speed improvement parsing accuracy improvement grammar-based treebank training": ["Revisiting Supertagging for Faster HPSG Parsing"], "hpsg parsing parsing speed improvement parsing accuracy improvement grammar-based treebank training dependency structure parsing": ["Revisiting Supertagging for Faster HPSG Parsing"], "parsing speed improvement parsing accuracy improvement grammar-based treebank training dependency structure parsing lexical type prediction": ["Revisiting Supertagging for Faster HPSG Parsing"], "passage retrieval open-domain qa": ["Improve Dense Passage Retrieval with Entailment Tuning"], "open-domain qa RAG": ["Improve Dense Passage Retrieval with Entailment Tuning"], "passage retrieval open-domain qa RAG": ["Improve Dense Passage Retrieval with Entailment Tuning"], "hallucination diagnosis": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "solvability detection": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "solution planning": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "missing-tool analysis": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "hallucination diagnosis solvability detection": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "solvability detection solution planning": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "solution planning missing-tool analysis": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "hallucination diagnosis solvability detection solution planning": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "solvability detection solution planning missing-tool analysis": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "hallucination diagnosis solvability detection solution planning missing-tool analysis": ["ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models"], "pseudo-perplexity": ["TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"], "xtreme": ["TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"], "pseudo-perplexity xtreme": ["TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"], "xtreme superglue": ["TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"], "pseudo-perplexity xtreme superglue": ["TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"], "incoherence detection": ["DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting"], "incoherence reasoning": ["DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting"], "incoherence rewriting": ["DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting"], "incoherence detection incoherence reasoning": ["DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting"], "incoherence reasoning incoherence rewriting": ["DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting"], "incoherence detection incoherence reasoning incoherence rewriting": ["DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting"], "chart generation": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"], "data visualization": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback", "Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts"], "chart generation instruction tuning": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"], "instruction tuning data visualization": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"], "data visualization reinforcement learning": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"], "chart generation instruction tuning data visualization": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"], "instruction tuning data visualization reinforcement learning": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"], "chart generation instruction tuning data visualization reinforcement learning": ["Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"], "machine translation evaluation summarization evaluation": ["PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation"], "text classification sentiment analysis topic classification": ["Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning"], "source block prediction": ["Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models"], "target position prediction": ["Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models"], "source block prediction target position prediction": ["Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models"], "real-time interaction": ["Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models"], "dialogue generation real-time interaction": ["Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models"], "syntactic transformation": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "chunking": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "few-shot learning syntactic transformation": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "syntactic transformation chunking": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "chunking semantic parsing": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "few-shot learning syntactic transformation chunking": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "syntactic transformation chunking semantic parsing": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "few-shot learning syntactic transformation chunking semantic parsing": ["Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations"], "puzzle solving": ["Puzzle Solving using Reasoning of Large Language Models: A Survey", "Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?"], "spatial cognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "creative thinking": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "pattern recognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey", "Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "puzzle solving logical reasoning": ["Puzzle Solving using Reasoning of Large Language Models: A Survey", "Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?"], "logical reasoning spatial cognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "spatial cognition creative thinking": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "creative thinking deductive reasoning": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "deductive reasoning pattern recognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "puzzle solving logical reasoning spatial cognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "logical reasoning spatial cognition creative thinking": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "spatial cognition creative thinking deductive reasoning": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "creative thinking deductive reasoning pattern recognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "puzzle solving logical reasoning spatial cognition creative thinking": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "logical reasoning spatial cognition creative thinking deductive reasoning": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "spatial cognition creative thinking deductive reasoning pattern recognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "puzzle solving logical reasoning spatial cognition creative thinking deductive reasoning": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "logical reasoning spatial cognition creative thinking deductive reasoning pattern recognition": ["Puzzle Solving using Reasoning of Large Language Models: A Survey"], "scientific exam solving": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "freeform question answering": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "multimodal evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading", "MULTISKILL: Evaluating Large Multimodal Models for Fine-grained Alignment Skills"], "automatic grading": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "scientific exam solving LLM benchmarking": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "LLM benchmarking freeform question answering": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "freeform question answering multilingual evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "multilingual evaluation multimodal evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "multimodal evaluation automatic grading": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "scientific exam solving LLM benchmarking freeform question answering": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "LLM benchmarking freeform question answering multilingual evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "freeform question answering multilingual evaluation multimodal evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "multilingual evaluation multimodal evaluation automatic grading": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "scientific exam solving LLM benchmarking freeform question answering multilingual evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "LLM benchmarking freeform question answering multilingual evaluation multimodal evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "freeform question answering multilingual evaluation multimodal evaluation automatic grading": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "scientific exam solving LLM benchmarking freeform question answering multilingual evaluation multimodal evaluation": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "LLM benchmarking freeform question answering multilingual evaluation multimodal evaluation automatic grading": ["SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading"], "contradiction detection": ["Red Teaming Language Models for Processing Contradictory Dialogues"], "contradiction explanation": ["Red Teaming Language Models for Processing Contradictory Dialogues"], "dialogue modification": ["Red Teaming Language Models for Processing Contradictory Dialogues"], "contradiction detection contradiction explanation": ["Red Teaming Language Models for Processing Contradictory Dialogues"], "contradiction explanation dialogue modification": ["Red Teaming Language Models for Processing Contradictory Dialogues"], "contradiction detection contradiction explanation dialogue modification": ["Red Teaming Language Models for Processing Contradictory Dialogues"], "under-trained token detection": ["Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models"], "transitive reasoning": ["Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs"], "compositional reasoning": ["Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs", "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "transitive reasoning question answering": ["Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs"], "question answering compositional reasoning": ["Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs"], "transitive reasoning question answering compositional reasoning": ["Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs"], "symbol grounding problem": ["Pragmatic Norms Are All You Need \u2013 Why The Symbol Grounding Problem Does Not Apply to LLMs"], "natural language processing symbol grounding problem": ["Pragmatic Norms Are All You Need \u2013 Why The Symbol Grounding Problem Does Not Apply to LLMs"], "major entity identification": ["Major Entity Identification: A Generalizable Alternative to Coreference Resolution"], "major entity identification coreference resolution": ["Major Entity Identification: A Generalizable Alternative to Coreference Resolution"], "direct recommendation": ["Enhancing High-order Interaction Awareness in LLM-based Recommender Model"], "sequential recommendation": ["Enhancing High-order Interaction Awareness in LLM-based Recommender Model", "Enhancing Large Language Model Based Sequential Recommender Systems with Pseudo Labels Reconstruction", "AuriSRec: Adversarial User Intention Learning in Sequential Recommendation", "Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation"], "direct recommendation sequential recommendation": ["Enhancing High-order Interaction Awareness in LLM-based Recommender Model"], "sequential recommendation explanation generation": ["Enhancing High-order Interaction Awareness in LLM-based Recommender Model"], "direct recommendation sequential recommendation explanation generation": ["Enhancing High-order Interaction Awareness in LLM-based Recommender Model"], "percentile estimation": ["What Are the Odds? Language Models Are Capable of Probabilistic Reasoning"], "sampling": ["What Are the Odds? Language Models Are Capable of Probabilistic Reasoning"], "probability calculation": ["What Are the Odds? Language Models Are Capable of Probabilistic Reasoning"], "percentile estimation sampling": ["What Are the Odds? Language Models Are Capable of Probabilistic Reasoning"], "sampling probability calculation": ["What Are the Odds? Language Models Are Capable of Probabilistic Reasoning"], "percentile estimation sampling probability calculation": ["What Are the Odds? Language Models Are Capable of Probabilistic Reasoning"], "unsupervised rationale extraction": ["MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction"], "multi-aspect analysis": ["MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction"], "unsupervised rationale extraction multi-aspect analysis": ["MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction"], "multi-aspect analysis text classification": ["MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction"], "unsupervised rationale extraction multi-aspect analysis text classification": ["MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction"], "harmful content detection": ["LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models", "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "content moderation": ["LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models", "Hate Personified: Investigating the role of LLMs in content moderation", "CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "harmful content detection content moderation": ["LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models"], "pun recognition": ["\"A good pun is its own reword\": Can Large Language Models Understand Puns?"], "pun explanation": ["\"A good pun is its own reword\": Can Large Language Models Understand Puns?"], "pun generation": ["\"A good pun is its own reword\": Can Large Language Models Understand Puns?"], "pun recognition pun explanation": ["\"A good pun is its own reword\": Can Large Language Models Understand Puns?"], "pun explanation pun generation": ["\"A good pun is its own reword\": Can Large Language Models Understand Puns?"], "pun recognition pun explanation pun generation": ["\"A good pun is its own reword\": Can Large Language Models Understand Puns?"], "question generation evaluation": ["QGEval: Benchmarking Multi-dimensional Evaluation for Question Generation"], "dependency graph parsing": ["Dependency Graph Parsing as Sequence Labeling"], "semantic dependency parsing": ["Dependency Graph Parsing as Sequence Labeling"], "enhanced ud parsing": ["Dependency Graph Parsing as Sequence Labeling"], "dependency graph parsing semantic dependency parsing": ["Dependency Graph Parsing as Sequence Labeling"], "semantic dependency parsing enhanced ud parsing": ["Dependency Graph Parsing as Sequence Labeling"], "dependency graph parsing semantic dependency parsing enhanced ud parsing": ["Dependency Graph Parsing as Sequence Labeling"], "named entity recognition few-shot learning": ["NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data"], "few-shot learning transfer learning": ["NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data"], "named entity recognition few-shot learning transfer learning": ["NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data"], "proverb geolocation": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "text regression": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "attributing unregistered proverbs": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "proverb geolocation text classification": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "text classification text regression": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "text regression attributing unregistered proverbs": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "proverb geolocation text classification text regression": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "text classification text regression attributing unregistered proverbs": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "proverb geolocation text classification text regression attributing unregistered proverbs": ["Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs"], "multilingual activation analysis": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "sparse activation": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "knowledge representation": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications", "Enhancing Incremental Summarization with Structured Representations"], "multilingual activation analysis sparse activation": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "sparse activation model pruning": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "model pruning language understanding": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "language understanding knowledge representation": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "knowledge representation natural language processing": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "natural language processing question answering": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "question answering math problem solving": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "math problem solving common sense reasoning": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "common sense reasoning language modeling": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "multilingual activation analysis sparse activation model pruning": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "sparse activation model pruning language understanding": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "model pruning language understanding knowledge representation": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "language understanding knowledge representation natural language processing": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "knowledge representation natural language processing question answering": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "natural language processing question answering math problem solving": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "question answering math problem solving common sense reasoning": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "math problem solving common sense reasoning language modeling": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "multilingual activation analysis sparse activation model pruning language understanding": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "sparse activation model pruning language understanding knowledge representation": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "model pruning language understanding knowledge representation natural language processing": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "language understanding knowledge representation natural language processing question answering": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "knowledge representation natural language processing question answering math problem solving": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "natural language processing question answering math problem solving common sense reasoning": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "question answering math problem solving common sense reasoning language modeling": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "multilingual activation analysis sparse activation model pruning language understanding knowledge representation": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "sparse activation model pruning language understanding knowledge representation natural language processing": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "model pruning language understanding knowledge representation natural language processing question answering": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "language understanding knowledge representation natural language processing question answering math problem solving": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "knowledge representation natural language processing question answering math problem solving common sense reasoning": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "natural language processing question answering math problem solving common sense reasoning language modeling": ["Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications"], "sts": ["Advancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss"], "semantic textual similarity sts": ["Advancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss"], "sentence segmentation": ["Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation", "Automatic sentence segmentation of clinical record narratives in real-world data"], "vulnerability classification": ["Applying Contrastive Learning to Code Vulnerability Type Classification"], "software security": ["Applying Contrastive Learning to Code Vulnerability Type Classification"], "vulnerability classification code analysis": ["Applying Contrastive Learning to Code Vulnerability Type Classification"], "code analysis software security": ["Applying Contrastive Learning to Code Vulnerability Type Classification"], "vulnerability classification code analysis software security": ["Applying Contrastive Learning to Code Vulnerability Type Classification"], "theorem proving": ["TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts"], "speech relation extraction": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction"], "entity recognition": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction", "SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "relation triplet extraction": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction", "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "speech relation extraction entity recognition": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction"], "entity recognition relation prediction": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction"], "relation prediction relation triplet extraction": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction"], "speech relation extraction entity recognition relation prediction": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction"], "entity recognition relation prediction relation triplet extraction": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction"], "speech relation extraction entity recognition relation prediction relation triplet extraction": ["Multi-Level Cross-Modal Alignment for Speech Relation Extraction"], "self-training": ["Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models", "Self-training Language Models for Arithmetic Reasoning", "Self-training Large Language Models through Knowledge Detection"], "text classification active learning": ["Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models", "On the Fragility of Active Learners for Text Classification"], "active learning self-training": ["Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models"], "text classification active learning self-training": ["Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models"], "persona-grounded dialogue generation": ["PANDA: Persona Attributes Navigation for Detecting and Alleviating Overuse Problem in Large Language Models"], "harm mitigation": ["The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm"], "multilingual alignment": ["The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm"], "preference training": ["The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm"], "harm mitigation multilingual alignment": ["The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm"], "multilingual alignment preference training": ["The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm"], "harm mitigation multilingual alignment preference training": ["The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm"], "verb lemma prediction": ["Subword Segmentation in LLMs: Looking at Inflection and Consistency"], "generation of inflected forms": ["Subword Segmentation in LLMs: Looking at Inflection and Consistency"], "verb lemma prediction generation of inflected forms": ["Subword Segmentation in LLMs: Looking at Inflection and Consistency"], "event extraction event detection": ["Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments", "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction"], "event extraction event detection event argument extraction": ["Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments", "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction"], "natural language feedback": ["Let Me Teach You: Pedagogical Foundations of Feedback for Language Models"], "aligning LLMs": ["Let Me Teach You: Pedagogical Foundations of Feedback for Language Models"], "feedback taxonomy": ["Let Me Teach You: Pedagogical Foundations of Feedback for Language Models"], "natural language feedback aligning LLMs": ["Let Me Teach You: Pedagogical Foundations of Feedback for Language Models"], "aligning LLMs feedback taxonomy": ["Let Me Teach You: Pedagogical Foundations of Feedback for Language Models"], "natural language feedback aligning LLMs feedback taxonomy": ["Let Me Teach You: Pedagogical Foundations of Feedback for Language Models"], "claim generation": ["Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data"], "evidence selection": ["Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data", "Where am I? Large Language Models Wandering between Semantics and Structures in Long Contexts"], "fact-checking claim generation": ["Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data"], "claim generation evidence selection": ["Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data"], "fact-checking claim generation evidence selection": ["Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data"], "task incremental continual learning": ["TL-CL: Task And Language Incremental Continual Learning"], "language incremental continual learning": ["TL-CL: Task And Language Incremental Continual Learning"], "task incremental continual learning language incremental continual learning": ["TL-CL: Task And Language Incremental Continual Learning"], "medical question answering": ["Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?", "LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning", "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures", "AMPO: Automatic Multi-Branched Prompt Optimization", "Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering", "Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering", "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration", "MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate", "MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation", "Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks", "Large Language Models are In-context Teachers for Knowledge Reasoning", "MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures"], "textual question answering": ["Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?"], "medical question answering visual question answering": ["Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?"], "visual question answering textual question answering": ["Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?"], "medical question answering visual question answering textual question answering": ["Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?"], "multilingual reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models", "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping"], "cross-lingual reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models"], "mathematical reasoning multilingual reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models"], "multilingual reasoning arithmetic reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models"], "arithmetic reasoning cross-lingual reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models"], "mathematical reasoning multilingual reasoning arithmetic reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models"], "multilingual reasoning arithmetic reasoning cross-lingual reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models"], "mathematical reasoning multilingual reasoning arithmetic reasoning cross-lingual reasoning": ["Empowering Multi-step Reasoning across Languages via Program-Aided Language Models"], "sentiment analysis paraphrase identification": ["Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models", "Functionality learning through specification instructions"], "natural language inference sentiment analysis paraphrase identification": ["Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models"], "data augmentation generalization": ["ControlMath: Controllable Data Generation Promotes Math Generalist Models"], "mathematical reasoning data augmentation generalization": ["ControlMath: Controllable Data Generation Promotes Math Generalist Models"], "digital forensics": ["Where Am I From? Identifying Origin of LLM-generated Content"], "LLM tracing": ["Where Am I From? Identifying Origin of LLM-generated Content"], "digital forensics LLM tracing": ["Where Am I From? Identifying Origin of LLM-generated Content"], "LLM tracing watermarking": ["Where Am I From? Identifying Origin of LLM-generated Content"], "digital forensics LLM tracing watermarking": ["Where Am I From? Identifying Origin of LLM-generated Content"], "multilingual analysis": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "cross-domain evaluation": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "few-shot prompting": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "unsupervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment", "Cluster-Norm for Unsupervised Probing of Knowledge"], "readability assessment multilingual analysis": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "multilingual analysis cross-domain evaluation": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "cross-domain evaluation few-shot prompting": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "few-shot prompting supervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "supervised learning unsupervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "unsupervised learning cross-lingual transfer": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "readability assessment multilingual analysis cross-domain evaluation": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "multilingual analysis cross-domain evaluation few-shot prompting": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "cross-domain evaluation few-shot prompting supervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "few-shot prompting supervised learning unsupervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "supervised learning unsupervised learning cross-lingual transfer": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "readability assessment multilingual analysis cross-domain evaluation few-shot prompting": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "multilingual analysis cross-domain evaluation few-shot prompting supervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "cross-domain evaluation few-shot prompting supervised learning unsupervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "few-shot prompting supervised learning unsupervised learning cross-lingual transfer": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "readability assessment multilingual analysis cross-domain evaluation few-shot prompting supervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "multilingual analysis cross-domain evaluation few-shot prompting supervised learning unsupervised learning": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "cross-domain evaluation few-shot prompting supervised learning unsupervised learning cross-lingual transfer": ["README++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment"], "interlinear glossed text  generation": ["GlossLM: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text", "Can we teach language models to gloss endangered languages?"], "crosslingual transfer": ["GlossLM: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text"], "interlinear glossed text  generation crosslingual transfer": ["GlossLM: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text"], "discourse parsing": ["GDTB: Genre Diverse Data for English Shallow Discourse Parsing across Modalities, Text Types, and Domains", "Llamipa: An Incremental Discourse Parser"], "discourse parsing relation classification": ["GDTB: Genre Diverse Data for English Shallow Discourse Parsing across Modalities, Text Types, and Domains"], "knowledge-grounded dialogue": ["RA2FD: Distilling Faithfulness into Efficient Dialogue Systems", "Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts"], "retrieval-free generation": ["RA2FD: Distilling Faithfulness into Efficient Dialogue Systems"], "knowledge-grounded dialogue retrieval-free generation": ["RA2FD: Distilling Faithfulness into Efficient Dialogue Systems"], "retrieval-free generation RAG": ["RA2FD: Distilling Faithfulness into Efficient Dialogue Systems"], "knowledge-grounded dialogue retrieval-free generation RAG": ["RA2FD: Distilling Faithfulness into Efficient Dialogue Systems"], "subjective reasoning": ["Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation"], "objective reasoning": ["Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation"], "subjective reasoning objective reasoning": ["Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation"], "property inheritance": ["Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently"], "semantic property prediction": ["Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently"], "property inheritance semantic property prediction": ["Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently"], "semantic property prediction reasoning": ["Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently"], "property inheritance semantic property prediction reasoning": ["Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently"], "text ranking": ["Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"], "text ranking model selection": ["Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"], "question type classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "in-context learning classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "classification generation": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy", "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "generation sentiment analysis": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "sentiment analysis question type classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "question type classification emotion classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism", "TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "emotion classification hate speech detection": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "hate speech detection machine translation": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "in-context learning classification generation": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "classification generation sentiment analysis": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "generation sentiment analysis question type classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "sentiment analysis question type classification emotion classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "question type classification emotion classification hate speech detection": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "emotion classification hate speech detection machine translation": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "in-context learning classification generation sentiment analysis": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "classification generation sentiment analysis question type classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "generation sentiment analysis question type classification emotion classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "sentiment analysis question type classification emotion classification hate speech detection": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "question type classification emotion classification hate speech detection machine translation": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "in-context learning classification generation sentiment analysis question type classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "classification generation sentiment analysis question type classification emotion classification": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "generation sentiment analysis question type classification emotion classification hate speech detection": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "sentiment analysis question type classification emotion classification hate speech detection machine translation": ["Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism"], "speech language understanding": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "keyword extraction": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech translation speech language understanding": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech language understanding question answering": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "question answering emotion recognition": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "emotion recognition keyword extraction": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "keyword extraction intent classification": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "asr speech translation speech language understanding": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech translation speech language understanding question answering": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech language understanding question answering emotion recognition": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "question answering emotion recognition keyword extraction": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "emotion recognition keyword extraction intent classification": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "asr speech translation speech language understanding question answering": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech translation speech language understanding question answering emotion recognition": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech language understanding question answering emotion recognition keyword extraction": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "question answering emotion recognition keyword extraction intent classification": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "asr speech translation speech language understanding question answering emotion recognition": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech translation speech language understanding question answering emotion recognition keyword extraction": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "speech language understanding question answering emotion recognition keyword extraction intent classification": ["Self-Powered LLM Modality Expansion for Large Speech-Text Models"], "script evaluation": ["ABSEval: An Agent-based Framework for Script Evaluation"], "script planning": ["ABSEval: An Agent-based Framework for Script Evaluation"], "script evaluation script planning": ["ABSEval: An Agent-based Framework for Script Evaluation"], "parts-of-speech tagging": ["Latent Concept-based Explanation of NLP Models"], "sentiment analysis parts-of-speech tagging": ["Latent Concept-based Explanation of NLP Models"], "parts-of-speech tagging toxicity classification": ["Latent Concept-based Explanation of NLP Models"], "toxicity classification natural language inference": ["Latent Concept-based Explanation of NLP Models"], "sentiment analysis parts-of-speech tagging toxicity classification": ["Latent Concept-based Explanation of NLP Models"], "parts-of-speech tagging toxicity classification natural language inference": ["Latent Concept-based Explanation of NLP Models"], "sentiment analysis parts-of-speech tagging toxicity classification natural language inference": ["Latent Concept-based Explanation of NLP Models"], "speech act detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "offensive language detection misinformation detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "misinformation detection speech act detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "speech act detection sentiment analysis": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "sentiment analysis stance detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "offensive language detection misinformation detection speech act detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "misinformation detection speech act detection sentiment analysis": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "speech act detection sentiment analysis stance detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "offensive language detection misinformation detection speech act detection sentiment analysis": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "misinformation detection speech act detection sentiment analysis stance detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "offensive language detection misinformation detection speech act detection sentiment analysis stance detection": ["Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"], "path-star graph generation": ["The Mystery of the Pathological Path-star Task for Language Models"], "text clustering": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives", "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity", "LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "perspective identification": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "annotation disagreement analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "political bias analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives", "Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles"], "text clustering bias detection": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "bias detection perspective identification": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "perspective identification annotation disagreement analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "annotation disagreement analysis political bias analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "text clustering bias detection perspective identification": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "bias detection perspective identification annotation disagreement analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "perspective identification annotation disagreement analysis political bias analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "text clustering bias detection perspective identification annotation disagreement analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "bias detection perspective identification annotation disagreement analysis political bias analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "text clustering bias detection perspective identification annotation disagreement analysis political bias analysis": ["Voices in a Crowd: Searching for Clusters of Unique Perspectives"], "multi-character role-playing": ["Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent"], "concept comprehension": ["SLANG: New Concept Comprehension of Large Language Models"], "slang understanding": ["SLANG: New Concept Comprehension of Large Language Models"], "meme interpretation": ["SLANG: New Concept Comprehension of Large Language Models"], "language model adaptation concept comprehension": ["SLANG: New Concept Comprehension of Large Language Models"], "concept comprehension slang understanding": ["SLANG: New Concept Comprehension of Large Language Models"], "slang understanding meme interpretation": ["SLANG: New Concept Comprehension of Large Language Models"], "meme interpretation causal inference": ["SLANG: New Concept Comprehension of Large Language Models"], "language model adaptation concept comprehension slang understanding": ["SLANG: New Concept Comprehension of Large Language Models"], "concept comprehension slang understanding meme interpretation": ["SLANG: New Concept Comprehension of Large Language Models"], "slang understanding meme interpretation causal inference": ["SLANG: New Concept Comprehension of Large Language Models"], "language model adaptation concept comprehension slang understanding meme interpretation": ["SLANG: New Concept Comprehension of Large Language Models"], "concept comprehension slang understanding meme interpretation causal inference": ["SLANG: New Concept Comprehension of Large Language Models"], "language model adaptation concept comprehension slang understanding meme interpretation causal inference": ["SLANG: New Concept Comprehension of Large Language Models"], "sequence continuation": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "circuit interpretability analysis": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "model alignment": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models", "Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting", "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "adverse effect prevention": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "sequence continuation circuit interpretability analysis": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "circuit interpretability analysis model alignment": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "model alignment adverse effect prevention": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "adverse effect prevention arithmetic reasoning": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "arithmetic reasoning natural language processing": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "sequence continuation circuit interpretability analysis model alignment": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "circuit interpretability analysis model alignment adverse effect prevention": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "model alignment adverse effect prevention arithmetic reasoning": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "adverse effect prevention arithmetic reasoning natural language processing": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "sequence continuation circuit interpretability analysis model alignment adverse effect prevention": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "circuit interpretability analysis model alignment adverse effect prevention arithmetic reasoning": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "model alignment adverse effect prevention arithmetic reasoning natural language processing": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "sequence continuation circuit interpretability analysis model alignment adverse effect prevention arithmetic reasoning": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "circuit interpretability analysis model alignment adverse effect prevention arithmetic reasoning natural language processing": ["Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models"], "ripple effect evaluation": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "gradient similarity analysis": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "negation": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "over-ripple errors": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "knowledge editing ripple effect evaluation": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "ripple effect evaluation gradient similarity analysis": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "gradient similarity analysis negation": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "negation over-ripple errors": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "over-ripple errors cross-lingual transfer": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "knowledge editing ripple effect evaluation gradient similarity analysis": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "ripple effect evaluation gradient similarity analysis negation": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "gradient similarity analysis negation over-ripple errors": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "negation over-ripple errors cross-lingual transfer": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "knowledge editing ripple effect evaluation gradient similarity analysis negation": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "ripple effect evaluation gradient similarity analysis negation over-ripple errors": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "gradient similarity analysis negation over-ripple errors cross-lingual transfer": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "knowledge editing ripple effect evaluation gradient similarity analysis negation over-ripple errors": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "ripple effect evaluation gradient similarity analysis negation over-ripple errors cross-lingual transfer": [">Why Does New Knowledge Create Messy Ripple Effects in LLMs?"], "continual event detection": ["Lifelong Event Detection via Optimal Transport"], "evaluating LLMs": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "task setup": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "research repository": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "code execution": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "evaluating LLMs task setup": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "task setup task execution": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "task execution research repository": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "research repository code execution": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "evaluating LLMs task setup task execution": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "task setup task execution research repository": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "task execution research repository code execution": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "evaluating LLMs task setup task execution research repository": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "task setup task execution research repository code execution": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "evaluating LLMs task setup task execution research repository code execution": ["SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories"], "language models knowledge distillation": ["FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation"], "knowledge distillation calibration": ["FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation"], "language models knowledge distillation calibration": ["FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation"], "neural machine translation": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?", "Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation", "DICTDIS: Dictionary Constrained Disambiguation for Improved NMT", "Finding the Optimal Byte-Pair Encoding Merge Operations for Neural Machine Translation in a Low-Resource Setting", "Does Context Help Mitigate Gender Bias in Neural Machine Translation?"], "catastrophic forgetting analysis": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "vocabulary shift measurement": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "forgetting mitigation": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "neural machine translation domain adaptation": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "domain adaptation catastrophic forgetting analysis": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "catastrophic forgetting analysis vocabulary shift measurement": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "vocabulary shift measurement forgetting mitigation": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "neural machine translation domain adaptation catastrophic forgetting analysis": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "domain adaptation catastrophic forgetting analysis vocabulary shift measurement": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "catastrophic forgetting analysis vocabulary shift measurement forgetting mitigation": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "neural machine translation domain adaptation catastrophic forgetting analysis vocabulary shift measurement": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "domain adaptation catastrophic forgetting analysis vocabulary shift measurement forgetting mitigation": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "neural machine translation domain adaptation catastrophic forgetting analysis vocabulary shift measurement forgetting mitigation": ["Domain adapted machine translation: What does catastrophic forgetting forget and why?"], "ai-assisted writing": ["Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback"], "smart reply systems": ["Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback"], "implicit negative feedback": ["Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback"], "ai-assisted writing smart reply systems": ["Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback"], "smart reply systems implicit negative feedback": ["Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback"], "ai-assisted writing smart reply systems implicit negative feedback": ["Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback"], "long-form question answering": ["Atomic Self-Consistency for Better Long Form Generations", "LongForm: Effective Instruction Tuning with Reverse Instructions", "Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision"], "brand bias detection": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "attribute association": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "gift recommendation bias": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "country-of-origin effect": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "brand bias detection attribute association": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "attribute association gift recommendation bias": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "gift recommendation bias country-of-origin effect": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "brand bias detection attribute association gift recommendation bias": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "attribute association gift recommendation bias country-of-origin effect": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "brand bias detection attribute association gift recommendation bias country-of-origin effect": ["\"Global is Good, Local is Bad?\u201d: Understanding Brand Bias in LLMs"], "rare word translation": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "retrieval-based translation": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "speech translation rare word translation": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "rare word translation retrieval-based translation": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "retrieval-based translation in-context learning": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "speech translation rare word translation retrieval-based translation": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "rare word translation retrieval-based translation in-context learning": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "speech translation rare word translation retrieval-based translation in-context learning": ["Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"], "negotiation coaching": ["ACE: A LLM-based Negotiation Coaching System"], "ai tutoring system": ["ACE: A LLM-based Negotiation Coaching System"], "negotiation strategy annotation": ["ACE: A LLM-based Negotiation Coaching System"], "negotiation coaching ai tutoring system": ["ACE: A LLM-based Negotiation Coaching System"], "ai tutoring system negotiation strategy annotation": ["ACE: A LLM-based Negotiation Coaching System"], "negotiation coaching ai tutoring system negotiation strategy annotation": ["ACE: A LLM-based Negotiation Coaching System"], "information collection": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "task-oriented dialogue information collection": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "information collection slot filling": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "slot filling dialogue generation": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "task-oriented dialogue information collection slot filling": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "information collection slot filling dialogue generation": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "slot filling dialogue generation question answering": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "task-oriented dialogue information collection slot filling dialogue generation": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "information collection slot filling dialogue generation question answering": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "task-oriented dialogue information collection slot filling dialogue generation question answering": ["TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"], "patient simulation": ["PATIENT-\u03a8: Using Large Language Models to Simulate Patients for Training Mental Health Professionals"], "cognitive behavior therapy  training": ["PATIENT-\u03a8: Using Large Language Models to Simulate Patients for Training Mental Health Professionals"], "cognitive model formulation": ["PATIENT-\u03a8: Using Large Language Models to Simulate Patients for Training Mental Health Professionals"], "patient simulation cognitive behavior therapy  training": ["PATIENT-\u03a8: Using Large Language Models to Simulate Patients for Training Mental Health Professionals"], "cognitive behavior therapy  training cognitive model formulation": ["PATIENT-\u03a8: Using Large Language Models to Simulate Patients for Training Mental Health Professionals"], "patient simulation cognitive behavior therapy  training cognitive model formulation": ["PATIENT-\u03a8: Using Large Language Models to Simulate Patients for Training Mental Health Professionals"], "multi-label text classification": ["DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis Prediction", "Open-world Multi-label Text Classification with Extremely Weak Supervision", "Enhancing Multi-Label Text Classification under Label-Dependent Noise: A Label-Specific Denoising Framework", "From Text Segmentation to Enhanced Representation Learning: A Novel Approach to Multi-Label Classification for Long Texts"], "diagnosis prediction": ["DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis Prediction", "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?"], "multi-label text classification diagnosis prediction": ["DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis Prediction"], "stereotypical bias detection": ["ModSCAN: Measuring Stereotypical Bias in Large Vision-Language Models from Vision and Language Modalities"], "commonsense reasoning open-domain question answering": ["Large Language Models Can Self-Correct with Key Condition Verification"], "arithmetic reasoning commonsense reasoning open-domain question answering": ["Large Language Models Can Self-Correct with Key Condition Verification"], "essay analysis": ["Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays"], "l2 writing": ["Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays"], "information distribution": ["Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays"], "essay analysis l2 writing": ["Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays"], "l2 writing information distribution": ["Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays"], "essay analysis l2 writing information distribution": ["Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays"], "cse detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "malicious intent detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "message-level si detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "conversation-level se attempt detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "cse detection malicious intent detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "malicious intent detection message-level si detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "message-level si detection conversation-level se attempt detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "cse detection malicious intent detection message-level si detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "malicious intent detection message-level si detection conversation-level se attempt detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "cse detection malicious intent detection message-level si detection conversation-level se attempt detection": ["Defending Against Social Engineering Attacks in the Age of LLMs"], "federated fine-tuning": ["Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models"], "on-device foundation models": ["Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models"], "federated fine-tuning on-device foundation models": ["Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models"], "on-device foundation models natural language processing": ["Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models"], "federated fine-tuning on-device foundation models natural language processing": ["Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models"], "language model inference acceleration": ["Make Some Noise: Unlocking Language Model Parallel Inference Capability through Noisy Training"], "data sampling": ["Target-Aware Language Modeling via Granular Data Sampling"], "language modeling data sampling": ["Target-Aware Language Modeling via Granular Data Sampling"], "data sampling downstream task performance": ["Target-Aware Language Modeling via Granular Data Sampling"], "language modeling data sampling downstream task performance": ["Target-Aware Language Modeling via Granular Data Sampling"], "epidemic prediction": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "public attention monitoring": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "event extraction epidemic prediction": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "epidemic prediction misinformation detection": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "misinformation detection public attention monitoring": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "event extraction epidemic prediction misinformation detection": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "epidemic prediction misinformation detection public attention monitoring": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "event extraction epidemic prediction misinformation detection public attention monitoring": ["SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"], "comprehension": ["COGEN: Learning from Feedback with Coupled Comprehension and Generation", "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "reference game": ["COGEN: Learning from Feedback with Coupled Comprehension and Generation"], "comprehension generation": ["COGEN: Learning from Feedback with Coupled Comprehension and Generation"], "generation reference game": ["COGEN: Learning from Feedback with Coupled Comprehension and Generation"], "comprehension generation reference game": ["COGEN: Learning from Feedback with Coupled Comprehension and Generation"], "moment retrieval": ["UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks"], "video paragraph captioning": ["UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks"], "dense video captioning": ["UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks"], "moment retrieval video paragraph captioning": ["UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks"], "video paragraph captioning dense video captioning": ["UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks"], "moment retrieval video paragraph captioning dense video captioning": ["UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks"], "narrative schema labeling": ["Story Morals: Surfacing value-driven narrative schemas using large language models"], "story moral extraction": ["Story Morals: Surfacing value-driven narrative schemas using large language models"], "value-driven schema identification": ["Story Morals: Surfacing value-driven narrative schemas using large language models"], "narrative schema labeling story moral extraction": ["Story Morals: Surfacing value-driven narrative schemas using large language models"], "story moral extraction value-driven schema identification": ["Story Morals: Surfacing value-driven narrative schemas using large language models"], "narrative schema labeling story moral extraction value-driven schema identification": ["Story Morals: Surfacing value-driven narrative schemas using large language models"], "frame discovery": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "frame analysis": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "sentiment prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "toxicity prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants", "Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree"], "frame discovery data annotation": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "data annotation frame analysis": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "frame analysis sentiment prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "sentiment prediction toxicity prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "frame discovery data annotation frame analysis": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "data annotation frame analysis sentiment prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "frame analysis sentiment prediction toxicity prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "frame discovery data annotation frame analysis sentiment prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "data annotation frame analysis sentiment prediction toxicity prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "frame discovery data annotation frame analysis sentiment prediction toxicity prediction": ["OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"], "analogy identification": ["ANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies"], "long-context understanding": ["ANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies"], "analogy identification abstract reasoning": ["ANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies"], "abstract reasoning long-context understanding": ["ANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies"], "analogy identification abstract reasoning long-context understanding": ["ANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies"], "entity and relation extraction": ["SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents"], "relation extraction entity and relation extraction": ["SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents"], "named entity recognition relation extraction entity and relation extraction": ["SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents"], "text generation hallucination mitigation": ["Analysis of Plan-based Retrieval for Grounded Text Generation"], "hallucination mitigation RAG": ["Analysis of Plan-based Retrieval for Grounded Text Generation"], "RAG long-form generation": ["Analysis of Plan-based Retrieval for Grounded Text Generation"], "text generation hallucination mitigation RAG": ["Analysis of Plan-based Retrieval for Grounded Text Generation"], "hallucination mitigation RAG long-form generation": ["Analysis of Plan-based Retrieval for Grounded Text Generation"], "text generation hallucination mitigation RAG long-form generation": ["Analysis of Plan-based Retrieval for Grounded Text Generation"], "factual error detection": ["Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors"], "text summarization factual error detection": ["Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors"], "factual error detection hallucination detection": ["Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors"], "text summarization factual error detection hallucination detection": ["Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors"], "multilingual alignment of LLMs": ["RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"], "multilingual alignment of LLMs preference optimization": ["RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"], "preference optimization open-ended generation": ["RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"], "open-ended generation summarization": ["RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"], "multilingual alignment of LLMs preference optimization open-ended generation": ["RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"], "preference optimization open-ended generation summarization": ["RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"], "multilingual alignment of LLMs preference optimization open-ended generation summarization": ["RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"], "fallacy detection": ["Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tree", "Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "fallacy classification": ["Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tree", "Are LLMs Good Zero-Shot Fallacy Classifiers?", "Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "fallacy detection fallacy classification": ["Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tree"], "entity tracking": ["Chain and Causal Attention for Efficient Entity Tracking", "Representational Analysis of Binding in Language Models"], "entity tracking language modeling": ["Chain and Causal Attention for Efficient Entity Tracking"], "safety backdoor mitigation": ["BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models"], "authorship attribution": ["A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution", "Can Large Language Models Identify Authorship?", "Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "forensic linguistics": ["A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution"], "authorship attribution forensic linguistics": ["A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution"], "forensic linguistics text classification": ["A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution"], "authorship attribution forensic linguistics text classification": ["A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution"], "linguistic knowledge": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "formal knowledge": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "world modeling": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "social modeling": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "agreements": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "licensing": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "long-distance dependency": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "garden-path effects": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "lexical semantics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "deductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "inductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "analogical": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "numeric": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "logic": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "manipulation": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "commonsense": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "pragmatics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "linguistic knowledge formal knowledge": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "formal knowledge world modeling": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "world modeling social modeling": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "social modeling agreements": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "agreements licensing": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "licensing long-distance dependency": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "long-distance dependency garden-path effects": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "garden-path effects lexical semantics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "lexical semantics deductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "deductive inductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "inductive analogical": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "analogical numeric": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "numeric logic": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "logic manipulation": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "manipulation factual knowledge": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "factual knowledge reading comprehension": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "reading comprehension commonsense": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "commonsense pragmatics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "pragmatics theory of mind": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "linguistic knowledge formal knowledge world modeling": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "formal knowledge world modeling social modeling": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "world modeling social modeling agreements": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "social modeling agreements licensing": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "agreements licensing long-distance dependency": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "licensing long-distance dependency garden-path effects": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "long-distance dependency garden-path effects lexical semantics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "garden-path effects lexical semantics deductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "lexical semantics deductive inductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "deductive inductive analogical": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "inductive analogical numeric": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "analogical numeric logic": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "numeric logic manipulation": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "logic manipulation factual knowledge": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "manipulation factual knowledge reading comprehension": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "factual knowledge reading comprehension commonsense": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "reading comprehension commonsense pragmatics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "commonsense pragmatics theory of mind": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "linguistic knowledge formal knowledge world modeling social modeling": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "formal knowledge world modeling social modeling agreements": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "world modeling social modeling agreements licensing": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "social modeling agreements licensing long-distance dependency": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "agreements licensing long-distance dependency garden-path effects": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "licensing long-distance dependency garden-path effects lexical semantics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "long-distance dependency garden-path effects lexical semantics deductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "garden-path effects lexical semantics deductive inductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "lexical semantics deductive inductive analogical": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "deductive inductive analogical numeric": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "inductive analogical numeric logic": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "analogical numeric logic manipulation": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "numeric logic manipulation factual knowledge": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "logic manipulation factual knowledge reading comprehension": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "manipulation factual knowledge reading comprehension commonsense": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "factual knowledge reading comprehension commonsense pragmatics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "reading comprehension commonsense pragmatics theory of mind": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "linguistic knowledge formal knowledge world modeling social modeling agreements": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "formal knowledge world modeling social modeling agreements licensing": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "world modeling social modeling agreements licensing long-distance dependency": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "social modeling agreements licensing long-distance dependency garden-path effects": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "agreements licensing long-distance dependency garden-path effects lexical semantics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "licensing long-distance dependency garden-path effects lexical semantics deductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "long-distance dependency garden-path effects lexical semantics deductive inductive": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "garden-path effects lexical semantics deductive inductive analogical": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "lexical semantics deductive inductive analogical numeric": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "deductive inductive analogical numeric logic": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "inductive analogical numeric logic manipulation": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "analogical numeric logic manipulation factual knowledge": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "numeric logic manipulation factual knowledge reading comprehension": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "logic manipulation factual knowledge reading comprehension commonsense": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "manipulation factual knowledge reading comprehension commonsense pragmatics": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "factual knowledge reading comprehension commonsense pragmatics theory of mind": ["FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"], "audio source separation": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "textual inversion": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "audio source separation textual inversion": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "textual inversion few-shot learning": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "few-shot learning LLMs": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "audio source separation textual inversion few-shot learning": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "textual inversion few-shot learning LLMs": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "audio source separation textual inversion few-shot learning LLMs": ["OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation"], "multilingual retrieval": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "cross-lingual retrieval": ["Language Concept Erasure for Language-invariant Dense Retrieval", "Representational Isomorphism and Alignment of Multilingual Large Language Models"], "monolingual retrieval": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "language invariance": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "multilingual retrieval cross-lingual retrieval": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "cross-lingual retrieval monolingual retrieval": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "monolingual retrieval language invariance": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "multilingual retrieval cross-lingual retrieval monolingual retrieval": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "cross-lingual retrieval monolingual retrieval language invariance": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "multilingual retrieval cross-lingual retrieval monolingual retrieval language invariance": ["Language Concept Erasure for Language-invariant Dense Retrieval"], "personalized alignment": ["Learning Personalized Alignment in Evaluating Open-ended Text Generation"], "open-ended text generation evaluation": ["Learning Personalized Alignment in Evaluating Open-ended Text Generation"], "personalized alignment open-ended text generation evaluation": ["Learning Personalized Alignment in Evaluating Open-ended Text Generation"], "jailbreak attacks": ["Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks", "Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection"], "fallacious reasoning generation": ["Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks"], "jailbreak attacks fallacious reasoning generation": ["Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks"], "truthfulqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE", "Unleashing the Potential of Large Language Models through Spectral Modulation"], "logiqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "language modeling mMLu": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "mMLu superglue": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "superglue truthfulqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "truthfulqa logiqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "language modeling mMLu superglue": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "mMLu superglue truthfulqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "superglue truthfulqa logiqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "language modeling mMLu superglue truthfulqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "mMLu superglue truthfulqa logiqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "language modeling mMLu superglue truthfulqa logiqa": ["Turn Waste into Worth: Rectifying Top-k Router of MoE"], "commonsense reasoning reading comprehension": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination", "LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training", "InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "reading comprehension natural language inference": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "natural language inference closed-book question answering": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "closed-book question answering hallucination detection": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "arithmetic reasoning commonsense reasoning reading comprehension": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "commonsense reasoning reading comprehension natural language inference": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "reading comprehension natural language inference closed-book question answering": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "natural language inference closed-book question answering hallucination detection": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "arithmetic reasoning commonsense reasoning reading comprehension natural language inference": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "commonsense reasoning reading comprehension natural language inference closed-book question answering": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "reading comprehension natural language inference closed-book question answering hallucination detection": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "arithmetic reasoning commonsense reasoning reading comprehension natural language inference closed-book question answering": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "commonsense reasoning reading comprehension natural language inference closed-book question answering hallucination detection": ["Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination"], "visual question answering vqa": ["CommVQA: Situating Visual Question Answering in Communicative Contexts"], "code generation text summarization": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "text summarization machine translation": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "machine translation arithmetic reasoning": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "text generation code generation text summarization": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "code generation text summarization machine translation": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "text summarization machine translation arithmetic reasoning": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "text generation code generation text summarization machine translation": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "code generation text summarization machine translation arithmetic reasoning": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "text generation code generation text summarization machine translation arithmetic reasoning": ["Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding"], "multilingual knowledge aggregation": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "low-resource knowledge detection": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "target language selection": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "answer replacement": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "answer integration": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "multilingual knowledge aggregation low-resource knowledge detection": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "low-resource knowledge detection target language selection": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "target language selection answer replacement": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "answer replacement answer integration": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "multilingual knowledge aggregation low-resource knowledge detection target language selection": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "low-resource knowledge detection target language selection answer replacement": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "target language selection answer replacement answer integration": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "multilingual knowledge aggregation low-resource knowledge detection target language selection answer replacement": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "low-resource knowledge detection target language selection answer replacement answer integration": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "multilingual knowledge aggregation low-resource knowledge detection target language selection answer replacement answer integration": ["1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"], "instruction-following": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective", "Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging", "Evolutionary Contrastive Distillation for Language Model Alignment", "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning", "AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "math problem-solving": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "helpfulness and harMLessness": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "instruction-following commonsense reasoning": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "commonsense reasoning coding": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "coding summarization": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "summarization math problem-solving": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "math problem-solving dialogue generation": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "dialogue generation helpfulness and harMLessness": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "instruction-following commonsense reasoning coding": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "commonsense reasoning coding summarization": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "coding summarization math problem-solving": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "summarization math problem-solving dialogue generation": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "math problem-solving dialogue generation helpfulness and harMLessness": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "instruction-following commonsense reasoning coding summarization": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "commonsense reasoning coding summarization math problem-solving": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "coding summarization math problem-solving dialogue generation": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "summarization math problem-solving dialogue generation helpfulness and harMLessness": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "instruction-following commonsense reasoning coding summarization math problem-solving": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "commonsense reasoning coding summarization math problem-solving dialogue generation": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "coding summarization math problem-solving dialogue generation helpfulness and harMLessness": ["How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective"], "formality": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "toxicity": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer", "Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "politics": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "politeness": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "authorship": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "sentiment": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "text style transfer formality": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "formality toxicity": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "toxicity politics": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "politics politeness": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "politeness authorship": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "authorship sentiment": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "text style transfer formality toxicity": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "formality toxicity politics": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "toxicity politics politeness": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "politics politeness authorship": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "politeness authorship sentiment": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "text style transfer formality toxicity politics": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "formality toxicity politics politeness": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "toxicity politics politeness authorship": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "politics politeness authorship sentiment": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "text style transfer formality toxicity politics politeness": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "formality toxicity politics politeness authorship": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "toxicity politics politeness authorship sentiment": ["Style-Specific Neurons for Steering LLMs in Text Style Transfer"], "conversational question answering": ["Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers", "Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA", "Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision"], "query rewriting conversational question answering": ["Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers"], "conversational question answering passage retrieval": ["Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers"], "query rewriting conversational question answering passage retrieval": ["Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers"], "data wrangling": ["DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models"], "ML": ["DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models"], "exploratory data analysis": ["DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models"], "data wrangling ML": ["DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models"], "ML exploratory data analysis": ["DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models"], "data wrangling ML exploratory data analysis": ["DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models"], "commit message generation": ["Leveraging Context-Aware Prompting for Commit Message Generation"], "dialect bias analysis": ["Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination"], "linguistic feature retention": ["Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination"], "native speaker evaluation": ["Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination"], "dialect bias analysis linguistic feature retention": ["Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination"], "linguistic feature retention native speaker evaluation": ["Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination"], "dialect bias analysis linguistic feature retention native speaker evaluation": ["Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination"], "knowledge retention": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "generality": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "locality": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning", "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models"], "fast editing": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "lifelong model editing knowledge retention": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "knowledge retention generality": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "generality locality": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "locality fast editing": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "lifelong model editing knowledge retention generality": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "knowledge retention generality locality": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "generality locality fast editing": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "lifelong model editing knowledge retention generality locality": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "knowledge retention generality locality fast editing": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "lifelong model editing knowledge retention generality locality fast editing": ["Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"], "version update": ["A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models"], "continual pre-training LLMs": ["A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models"], "LLMs version update": ["A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models"], "continual pre-training LLMs version update": ["A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models"], "reversal curse mitigation": ["An Analysis and Mitigation of the Reversal Curse"], "name-to-description task": ["An Analysis and Mitigation of the Reversal Curse"], "reversal curse mitigation name-to-description task": ["An Analysis and Mitigation of the Reversal Curse"], "name-to-description task math problem solving": ["An Analysis and Mitigation of the Reversal Curse"], "math problem solving translation": ["An Analysis and Mitigation of the Reversal Curse"], "reversal curse mitigation name-to-description task math problem solving": ["An Analysis and Mitigation of the Reversal Curse"], "name-to-description task math problem solving translation": ["An Analysis and Mitigation of the Reversal Curse"], "reversal curse mitigation name-to-description task math problem solving translation": ["An Analysis and Mitigation of the Reversal Curse"], "generative retrieval": ["Exploring the Practicality of Generative Retrieval on Dynamic Corpora"], "dynamic corpora": ["Exploring the Practicality of Generative Retrieval on Dynamic Corpora"], "information retrieval generative retrieval": ["Exploring the Practicality of Generative Retrieval on Dynamic Corpora"], "generative retrieval dynamic corpora": ["Exploring the Practicality of Generative Retrieval on Dynamic Corpora"], "information retrieval generative retrieval dynamic corpora": ["Exploring the Practicality of Generative Retrieval on Dynamic Corpora"], "named entity disambiguation": ["OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting", "Unsupervised Named Entity Disambiguation for Low Resource Domains", "MedINST: Meta Dataset of Biomedical Instructions"], "entity linking named entity disambiguation": ["OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting"], "unknown question detection": ["Don't Just Say \"I don't know\"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations"], "unknown question classification": ["Don't Just Say \"I don't know\"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations"], "open-ended response generation": ["Don't Just Say \"I don't know\"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations"], "unknown question detection unknown question classification": ["Don't Just Say \"I don't know\"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations"], "unknown question classification open-ended response generation": ["Don't Just Say \"I don't know\"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations"], "unknown question detection unknown question classification open-ended response generation": ["Don't Just Say \"I don't know\"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations"], "context pruning": ["Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning"], "math reasoning few-shot learning": ["Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning"], "few-shot learning prompt optimization": ["Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning"], "prompt optimization context pruning": ["Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning"], "math reasoning few-shot learning prompt optimization": ["Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning"], "few-shot learning prompt optimization context pruning": ["Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning"], "math reasoning few-shot learning prompt optimization context pruning": ["Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning"], "pharmacology qa for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "drug interaction for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "question answering language generation": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language generation language understanding": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language understanding named entity recognition": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "relation extraction document classification": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "document classification pharmacology qa for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "pharmacology qa for emerging drugs drug interaction for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "question answering language generation language understanding": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language generation language understanding named entity recognition": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language understanding named entity recognition relation extraction": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "named entity recognition relation extraction document classification": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "relation extraction document classification pharmacology qa for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "document classification pharmacology qa for emerging drugs drug interaction for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "question answering language generation language understanding named entity recognition": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language generation language understanding named entity recognition relation extraction": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language understanding named entity recognition relation extraction document classification": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "named entity recognition relation extraction document classification pharmacology qa for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "relation extraction document classification pharmacology qa for emerging drugs drug interaction for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "question answering language generation language understanding named entity recognition relation extraction": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language generation language understanding named entity recognition relation extraction document classification": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "language understanding named entity recognition relation extraction document classification pharmacology qa for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "named entity recognition relation extraction document classification pharmacology qa for emerging drugs drug interaction for emerging drugs": ["Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"], "LLM safety": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction", "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States", "Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "adversarial probing": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "red teaming LLM safety": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "LLM safety adversarial probing": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "adversarial probing risk assessment": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "red teaming LLM safety adversarial probing": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "LLM safety adversarial probing risk assessment": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "red teaming LLM safety adversarial probing risk assessment": ["Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction"], "activation editing": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "bias": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "ethics": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "activation editing truthfulness": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "truthfulness bias": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "bias ethics": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "ethics toxicity": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "activation editing truthfulness bias": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "truthfulness bias ethics": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "bias ethics toxicity": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "activation editing truthfulness bias ethics": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "truthfulness bias ethics toxicity": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "activation editing truthfulness bias ethics toxicity": ["Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"], "dynamic entity mention resolution": ["DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG"], "entity-centric knowledge-intensive qa": ["DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG"], "dynamic entity mention resolution entity-centric knowledge-intensive qa": ["DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG"], "few-shot continual relation extraction": ["Preserving Generalization of Language Models in Few-shot Continual Relation Extraction"], "model editing": ["Consecutive Batch Model Editing with HooK Layers", "On the Robustness of Editing Large Language Models", "Local Contrastive Editing of Gender Stereotypes", "Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing", "Knowledge Graph Enhanced Large Language Model Editing", "The Fall of ROME: Understanding the Collapse of LLMs in Model Editing", "Better Call SAUL: Fluent and Consistent Language Model Editing with Generation Regularization", "A Unified Framework for Model Editing"], "open relation extraction": ["Topic-Oriented Open Relation Extraction with A Priori Seed Generation"], "open relation extraction relation extraction": ["Topic-Oriented Open Relation Extraction with A Priori Seed Generation"], "relation extraction knowledge graph construction": ["Topic-Oriented Open Relation Extraction with A Priori Seed Generation"], "open relation extraction relation extraction knowledge graph construction": ["Topic-Oriented Open Relation Extraction with A Priori Seed Generation"], "related work generation": ["Related Work and Citation Text Generation: A Survey"], "citation text generation": ["Related Work and Citation Text Generation: A Survey"], "literature review": ["Related Work and Citation Text Generation: A Survey"], "related work generation citation text generation": ["Related Work and Citation Text Generation: A Survey"], "citation text generation literature review": ["Related Work and Citation Text Generation: A Survey"], "related work generation citation text generation literature review": ["Related Work and Citation Text Generation: A Survey"], "textual machine translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "multimodal machine translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "instruction tuning textual machine translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "textual machine translation multimodal machine translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "multimodal machine translation speech-to-text translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "instruction tuning textual machine translation multimodal machine translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "textual machine translation multimodal machine translation speech-to-text translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "instruction tuning textual machine translation multimodal machine translation speech-to-text translation": ["Curriculum Consistency Learning for Conditional Sentence Generation"], "syllogistic reasoning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "chain-of-thought reasoning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences", "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning", "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping"], "syllogistic reasoning chain-of-thought reasoning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "chain-of-thought reasoning in-context learning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "in-context learning supervised fine-tuning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "supervised fine-tuning deductive reasoning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "syllogistic reasoning chain-of-thought reasoning in-context learning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "chain-of-thought reasoning in-context learning supervised fine-tuning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "in-context learning supervised fine-tuning deductive reasoning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "syllogistic reasoning chain-of-thought reasoning in-context learning supervised fine-tuning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "chain-of-thought reasoning in-context learning supervised fine-tuning deductive reasoning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "syllogistic reasoning chain-of-thought reasoning in-context learning supervised fine-tuning deductive reasoning": ["A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences"], "cross-lingual open domain question answering": ["Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision"], "cross-lingual passage retrieval": ["Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision"], "multilingual open-domain question answering": ["Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision"], "cross-lingual open domain question answering cross-lingual passage retrieval": ["Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision"], "cross-lingual passage retrieval multilingual open-domain question answering": ["Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision"], "cross-lingual open domain question answering cross-lingual passage retrieval multilingual open-domain question answering": ["Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision"], "open-source model training": ["950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages"], "eu language support": ["950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages"], "speech recognition open-source model training": ["950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages"], "open-source model training eu language support": ["950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages"], "speech recognition open-source model training eu language support": ["950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages"], "knowledge graph completion": ["Improving Knowledge Graph Completion with Structure-Aware Supervised Contrastive Learning", "MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion", "Joint Pre-Encoding Representation and Sturcture Embedding for Efficient and Low-Resource Knowledge Graph Completion", "Varying Sentence Representations via Condition-Specified Routers", "Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs", "Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs", "SALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning"], "text reuse in-context": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "topic variation ranking across corpus": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "text reuse in-context topic variation ranking across corpus": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "topic variation ranking across corpus binary classification": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "binary classification ranking": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "text reuse in-context topic variation ranking across corpus binary classification": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "topic variation ranking across corpus binary classification ranking": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "text reuse in-context topic variation ranking across corpus binary classification ranking": ["TROTR: A Framework for Evaluating the Recontextualization of Text"], "language models pruning": ["Structured Optimal Brain Pruning for Large Language Models"], "model compression": ["Structured Optimal Brain Pruning for Large Language Models", "Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging", "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning", "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy", "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs", "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models"], "structured pruning": ["Structured Optimal Brain Pruning for Large Language Models"], "language models pruning model compression": ["Structured Optimal Brain Pruning for Large Language Models"], "model compression structured pruning": ["Structured Optimal Brain Pruning for Large Language Models"], "language models pruning model compression structured pruning": ["Structured Optimal Brain Pruning for Large Language Models"], "definition generation": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "lexical semantic change": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "definition generation word-in-context": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "word-in-context word sense induction": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "word sense induction lexical semantic change": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "definition generation word-in-context word sense induction": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "word-in-context word sense induction lexical semantic change": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "definition generation word-in-context word sense induction lexical semantic change": ["Automatically Generated Definitions and their utility for Modeling Word Meaning"], "code instruction tuning": ["How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with Really Good Data"], "code generation code instruction tuning": ["How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with Really Good Data"], "information retrieval instruction following": ["MAIR: A Massive Benchmark for Evaluating Instructed Retrieval"], "information retrieval instruction following generalization": ["MAIR: A Massive Benchmark for Evaluating Instructed Retrieval"], "text classification sentiment analysis question answering": ["Rethinking the Evaluation of In-Context Learning for LLMs"], "knowledge probing": ["Cluster-Norm for Unsupervised Probing of Knowledge", "Exploring Design Choices for Building Language-Specific LLMs", "What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models", "Gradient Localization Improves Lifelong Pretraining of Language Models"], "feature extraction": ["Cluster-Norm for Unsupervised Probing of Knowledge"], "knowledge probing unsupervised learning": ["Cluster-Norm for Unsupervised Probing of Knowledge"], "unsupervised learning feature extraction": ["Cluster-Norm for Unsupervised Probing of Knowledge"], "knowledge probing unsupervised learning feature extraction": ["Cluster-Norm for Unsupervised Probing of Knowledge"], "latent reasoning analysis": ["Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries"], "question answering latent reasoning analysis": ["Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries"], "training data attribution": ["Enhancing Training Data Attribution for Large Language Models with Fitting Error Consideration"], "hallucination tracing": ["Enhancing Training Data Attribution for Large Language Models with Fitting Error Consideration"], "training data attribution hallucination tracing": ["Enhancing Training Data Attribution for Large Language Models with Fitting Error Consideration"], "open-domain question answering evidence selection": ["Where am I? Large Language Models Wandering between Semantics and Structures in Long Contexts"], "flashcard scheduling": ["KAR\u00b3L: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"], "student modeling": ["KAR\u00b3L: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"], "knowledge tracing": ["KAR\u00b3L: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"], "flashcard scheduling student modeling": ["KAR\u00b3L: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"], "student modeling knowledge tracing": ["KAR\u00b3L: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"], "flashcard scheduling student modeling knowledge tracing": ["KAR\u00b3L: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"], "contextual privacy protection": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "sensitive information safeguarding": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "contextual privacy protection fine-tuning": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "fine-tuning knowledge injection": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "knowledge injection sensitive information safeguarding": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "contextual privacy protection fine-tuning knowledge injection": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "fine-tuning knowledge injection sensitive information safeguarding": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "contextual privacy protection fine-tuning knowledge injection sensitive information safeguarding": ["Large Language Models Can Be Contextual Privacy Protection Learners"], "mnemonic generation": ["A SMART Mnemonic Sounds like \u201cGlue Tonic\": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick"], "vocabulary learning": ["A SMART Mnemonic Sounds like \u201cGlue Tonic\": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick"], "mnemonic generation vocabulary learning": ["A SMART Mnemonic Sounds like \u201cGlue Tonic\": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick"], "data usage optimization": ["MIXTURE-OF-SKILLS: Learning to Optimize Data Usage for Fine-Tuning Large Language Models"], "skill development": ["MIXTURE-OF-SKILLS: Learning to Optimize Data Usage for Fine-Tuning Large Language Models"], "fine-tuning data usage optimization": ["MIXTURE-OF-SKILLS: Learning to Optimize Data Usage for Fine-Tuning Large Language Models"], "data usage optimization skill development": ["MIXTURE-OF-SKILLS: Learning to Optimize Data Usage for Fine-Tuning Large Language Models"], "fine-tuning data usage optimization skill development": ["MIXTURE-OF-SKILLS: Learning to Optimize Data Usage for Fine-Tuning Large Language Models"], "molecular property prediction": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction", "MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension", "Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction", "Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "bbbp": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "tox21": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "toxcast": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "clintox": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "muv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "hiv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bace": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "sider": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "qm9": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "esol": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "freesolv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "lipophilicity": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "molecular property prediction bbbp": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bbbp tox21": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "tox21 toxcast": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "toxcast clintox": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "clintox muv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "muv hiv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "hiv bace": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bace sider": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "sider qm9": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "qm9 esol": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "esol freesolv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "freesolv lipophilicity": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "molecular property prediction bbbp tox21": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bbbp tox21 toxcast": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "tox21 toxcast clintox": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "toxcast clintox muv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "clintox muv hiv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "muv hiv bace": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "hiv bace sider": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bace sider qm9": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "sider qm9 esol": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "qm9 esol freesolv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "esol freesolv lipophilicity": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "molecular property prediction bbbp tox21 toxcast": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bbbp tox21 toxcast clintox": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "tox21 toxcast clintox muv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "toxcast clintox muv hiv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "clintox muv hiv bace": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "muv hiv bace sider": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "hiv bace sider qm9": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bace sider qm9 esol": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "sider qm9 esol freesolv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "qm9 esol freesolv lipophilicity": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "molecular property prediction bbbp tox21 toxcast clintox": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bbbp tox21 toxcast clintox muv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "tox21 toxcast clintox muv hiv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "toxcast clintox muv hiv bace": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "clintox muv hiv bace sider": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "muv hiv bace sider qm9": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "hiv bace sider qm9 esol": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "bace sider qm9 esol freesolv": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "sider qm9 esol freesolv lipophilicity": ["MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction"], "heuristics analysis": ["First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning"], "arithmetic reasoning multi-hop reasoning": ["First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning"], "multi-hop reasoning heuristics analysis": ["First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning"], "heuristics analysis language model evaluation": ["First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning"], "arithmetic reasoning multi-hop reasoning heuristics analysis": ["First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning"], "multi-hop reasoning heuristics analysis language model evaluation": ["First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning"], "arithmetic reasoning multi-hop reasoning heuristics analysis language model evaluation": ["First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning"], "tool error detection": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "embodied agent planning": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "object detection evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "action planner evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "tool error detection math problem solving": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "math problem solving embodied agent planning": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "embodied agent planning object detection evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "object detection evaluation action planner evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "tool error detection math problem solving embodied agent planning": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "math problem solving embodied agent planning object detection evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "embodied agent planning object detection evaluation action planner evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "tool error detection math problem solving embodied agent planning object detection evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "math problem solving embodied agent planning object detection evaluation action planner evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "tool error detection math problem solving embodied agent planning object detection evaluation action planner evaluation": ["Tools Fail: Detecting Silent Errors in Faulty Tools"], "sentence embeddings": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "pair classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "semantic textual similarity text clustering": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "text clustering information retrieval": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "information retrieval dialogue systems": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "dialogue systems sentence embeddings": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "sentence embeddings retrieval": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "retrieval reranking": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "reranking classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "classification pair classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "semantic textual similarity text clustering information retrieval": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "text clustering information retrieval dialogue systems": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "information retrieval dialogue systems sentence embeddings": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "dialogue systems sentence embeddings retrieval": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "sentence embeddings retrieval reranking": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "retrieval reranking classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "reranking classification pair classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "semantic textual similarity text clustering information retrieval dialogue systems": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "text clustering information retrieval dialogue systems sentence embeddings": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "information retrieval dialogue systems sentence embeddings retrieval": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "dialogue systems sentence embeddings retrieval reranking": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "sentence embeddings retrieval reranking classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "retrieval reranking classification pair classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "semantic textual similarity text clustering information retrieval dialogue systems sentence embeddings": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "text clustering information retrieval dialogue systems sentence embeddings retrieval": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "information retrieval dialogue systems sentence embeddings retrieval reranking": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "dialogue systems sentence embeddings retrieval reranking classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "sentence embeddings retrieval reranking classification pair classification": ["Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity"], "utterance synthesis": ["Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"], "semantic parsing cross-lingual transfer": ["Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"], "cross-lingual transfer data augmentation": ["Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"], "data augmentation utterance synthesis": ["Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"], "semantic parsing cross-lingual transfer data augmentation": ["Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"], "cross-lingual transfer data augmentation utterance synthesis": ["Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"], "semantic parsing cross-lingual transfer data augmentation utterance synthesis": ["Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"], "captioning question answering": ["Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling"], "question answering reading comprehension": ["Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling", "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation", "SCIDQA: A Deep Reading Comprehension Dataset over Scientific Papers"], "reading comprehension visual grounding": ["Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling"], "captioning question answering reading comprehension": ["Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling"], "question answering reading comprehension visual grounding": ["Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling"], "captioning question answering reading comprehension visual grounding": ["Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling"], "machine translation sentiment analysis": ["The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis"], "machine translation sentiment analysis question answering": ["The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis"], "lexical semantic change detection": ["More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages"], "word sense induction lexical semantic change detection": ["More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages"], "lexical semantic change detection word sense disambiguation": ["More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages"], "word sense induction lexical semantic change detection word sense disambiguation": ["More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages"], "video question generation": ["ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"], "entity-centric question generation": ["ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"], "information-seeking question generation": ["ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"], "video question generation entity-centric question generation": ["ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"], "entity-centric question generation information-seeking question generation": ["ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"], "video question generation entity-centric question generation information-seeking question generation": ["ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"], "fill-in-the-blank": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "multiple-choice questions": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation", "FAME: Towards Factual Multi-Task Model Editing", "QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism"], "multi-modal question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "distractor generation fill-in-the-blank": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "fill-in-the-blank multiple-choice questions": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "multiple-choice questions question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "reading comprehension multi-modal question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "distractor generation fill-in-the-blank multiple-choice questions": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "fill-in-the-blank multiple-choice questions question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "multiple-choice questions question answering reading comprehension": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "question answering reading comprehension multi-modal question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "distractor generation fill-in-the-blank multiple-choice questions question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "fill-in-the-blank multiple-choice questions question answering reading comprehension": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "multiple-choice questions question answering reading comprehension multi-modal question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "distractor generation fill-in-the-blank multiple-choice questions question answering reading comprehension": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "fill-in-the-blank multiple-choice questions question answering reading comprehension multi-modal question answering": ["Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"], "novelty detection": ["Evaluating n-Gram Novelty of Language Models Using RUSTY-DAWG"], "text generation novelty detection": ["Evaluating n-Gram Novelty of Language Models Using RUSTY-DAWG"], "language modeling text generation novelty detection": ["Evaluating n-Gram Novelty of Language Models Using RUSTY-DAWG"], "fingerspelling detection": ["ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"], "fingerspelling alignment": ["ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"], "automatic sign suggestion": ["ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"], "fingerspelling detection fingerspelling alignment": ["ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"], "fingerspelling alignment automatic sign suggestion": ["ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"], "fingerspelling detection fingerspelling alignment automatic sign suggestion": ["ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"], "machine translation preference learning": ["Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation"], "multi-intent spoken language understanding": ["DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"], "multiple intent detection": ["DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"], "multi-intent spoken language understanding multiple intent detection": ["DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"], "multiple intent detection slot filling": ["DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"], "multi-intent spoken language understanding multiple intent detection slot filling": ["DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"], "knowledge-intensive tasks": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models", "Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models", "Searching for Best Practices in Retrieval-Augmented Generation", "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "fine-grained knowledge extraction": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "coarse-grained knowledge comparison": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "question answering knowledge-intensive tasks": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "knowledge-intensive tasks fine-grained knowledge extraction": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "fine-grained knowledge extraction coarse-grained knowledge comparison": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "question answering knowledge-intensive tasks fine-grained knowledge extraction": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "knowledge-intensive tasks fine-grained knowledge extraction coarse-grained knowledge comparison": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "question answering knowledge-intensive tasks fine-grained knowledge extraction coarse-grained knowledge comparison": ["KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"], "secure code generation": ["SecCoder: Towards Generalizable and Robust Secure Code Generation"], "arabic reasoning": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "commonsense question answering": ["Nash CoT: Multi-Path Inference with Preference Equilibrium", "Towards Faithful Knowledge Graph Explanation Through Deep Alignment in Commonsense Question Answering", "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "symbolic inference": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "arabic reasoning commonsense question answering": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "commonsense question answering symbolic inference": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "symbolic inference math": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "arabic reasoning commonsense question answering symbolic inference": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "commonsense question answering symbolic inference math": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "arabic reasoning commonsense question answering symbolic inference math": ["Nash CoT: Multi-Path Inference with Preference Equilibrium"], "pre-training": ["Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention", "Exploring Quantization for Efficient Pre-Training of Transformer Language Models"], "downstream tasks": ["Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention"], "language modeling pre-training": ["Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention"], "pre-training downstream tasks": ["Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention"], "language modeling pre-training downstream tasks": ["Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention"], "knowledge-based qa": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "conditional text generation": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector", "Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning"], "semantic consistency": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "hallucination detection knowledge-based qa": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "knowledge-based qa conditional text generation": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "conditional text generation semantic consistency": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "semantic consistency math problem solving": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "math problem solving code generation": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector", "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision"], "hallucination detection knowledge-based qa conditional text generation": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "knowledge-based qa conditional text generation semantic consistency": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "conditional text generation semantic consistency math problem solving": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "semantic consistency math problem solving code generation": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "hallucination detection knowledge-based qa conditional text generation semantic consistency": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "knowledge-based qa conditional text generation semantic consistency math problem solving": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "conditional text generation semantic consistency math problem solving code generation": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "hallucination detection knowledge-based qa conditional text generation semantic consistency math problem solving": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "knowledge-based qa conditional text generation semantic consistency math problem solving code generation": ["Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector"], "visio-linguistic compositional understanding": ["Interpretable Composition Attribution Enhancement for Visio-linguistic Compositional Understanding"], "image-text matching": ["Interpretable Composition Attribution Enhancement for Visio-linguistic Compositional Understanding"], "visio-linguistic compositional understanding image-text matching": ["Interpretable Composition Attribution Enhancement for Visio-linguistic Compositional Understanding"], "math multiple choice question": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "social question answer": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "social multiple choice question": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "summarization math multiple choice question": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "math multiple choice question social question answer": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "social question answer sentiment classification": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "sentiment classification social multiple choice question": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "summarization math multiple choice question social question answer": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "math multiple choice question social question answer sentiment classification": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "social question answer sentiment classification social multiple choice question": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "summarization math multiple choice question social question answer sentiment classification": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "math multiple choice question social question answer sentiment classification social multiple choice question": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "summarization math multiple choice question social question answer sentiment classification social multiple choice question": ["LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History"], "fairness benchmarking": ["Social Bias Probing: Fairness Benchmarking for Language Models"], "retrieval-augmented language model": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "qa performance": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "unknown robustness": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "retrieval-augmented language model qa performance": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "qa performance noise robustness": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "noise robustness unknown robustness": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "retrieval-augmented language model qa performance noise robustness": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "qa performance noise robustness unknown robustness": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "retrieval-augmented language model qa performance noise robustness unknown robustness": ["Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"], "dynamic decision-making": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "task categorization": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "efficiency optimization": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "resource allocation": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models", "SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"], "reasoning dynamic decision-making": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "dynamic decision-making task categorization": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "task categorization efficiency optimization": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "efficiency optimization resource allocation": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "reasoning dynamic decision-making task categorization": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "dynamic decision-making task categorization efficiency optimization": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "task categorization efficiency optimization resource allocation": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "reasoning dynamic decision-making task categorization efficiency optimization": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "dynamic decision-making task categorization efficiency optimization resource allocation": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "reasoning dynamic decision-making task categorization efficiency optimization resource allocation": ["DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models"], "long-form table question answering": ["Revisiting Automated Evaluation for Long-form Table Question Answering"], "meta-evaluation": ["Revisiting Automated Evaluation for Long-form Table Question Answering", "OffsetBias: Leveraging Debiased Data for Tuning Evaluators", "A Critical Look at Meta-evaluating Summarisation Evaluation Metrics"], "long-form table question answering meta-evaluation": ["Revisiting Automated Evaluation for Long-form Table Question Answering"], "causal event extraction": ["Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems"], "human preference alignment": ["Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems", "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "ALIGNSUM: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference", "DEFT: Distribution-guided Efficient Fine-Tuning for Human Alignment"], "causal event extraction reinforcement learning": ["Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems"], "reinforcement learning human preference alignment": ["Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems"], "causal event extraction reinforcement learning human preference alignment": ["Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems"], "reflective reasoning": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "follow-up question answering": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "mathematical reasoning reflective reasoning": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "reflective reasoning question answering": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "question answering code generation": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "Large Language Model-based Human-Agent Collaboration for Complex Task Solving", "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"], "code generation error correction": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "error correction follow-up question answering": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "mathematical reasoning reflective reasoning question answering": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "reflective reasoning question answering code generation": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "question answering code generation error correction": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "code generation error correction follow-up question answering": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "mathematical reasoning reflective reasoning question answering code generation": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "reflective reasoning question answering code generation error correction": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "question answering code generation error correction follow-up question answering": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "mathematical reasoning reflective reasoning question answering code generation error correction": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "reflective reasoning question answering code generation error correction follow-up question answering": ["Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning"], "numerical reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents", "CNEQ: Incorporating numbers into Knowledge Graph Reasoning", "Fine-tuning Smaller Language Models for Question Answering over Financial Documents"], "knowledge-intensive reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "explainable reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "claim verification information extraction": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "information extraction numerical reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "numerical reasoning knowledge-intensive reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "knowledge-intensive reasoning explainable reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "claim verification information extraction numerical reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "information extraction numerical reasoning knowledge-intensive reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "numerical reasoning knowledge-intensive reasoning explainable reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "claim verification information extraction numerical reasoning knowledge-intensive reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "information extraction numerical reasoning knowledge-intensive reasoning explainable reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "claim verification information extraction numerical reasoning knowledge-intensive reasoning explainable reasoning": ["FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents"], "language model inversion": ["Extracting Prompts by Inverting LLM Outputs"], "prompt extraction": ["Extracting Prompts by Inverting LLM Outputs"], "language model inversion prompt extraction": ["Extracting Prompts by Inverting LLM Outputs"], "social bias detection": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "open-text generation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "bias evaluation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs", "Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP\\", "A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models", "Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts", "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "social bias detection open-text generation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "open-text generation bias evaluation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "bias evaluation bias mitigation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "social bias detection open-text generation bias evaluation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "open-text generation bias evaluation bias mitigation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "social bias detection open-text generation bias evaluation bias mitigation": ["BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs"], "text generation reinforcement learning from human feedback": ["A Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors"], "language modeling text generation reinforcement learning from human feedback": ["A Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors"], "node classification": ["Bridging Local Details and Global Context in Text-Attributed Graphs", "Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning", "OpenGraph: Towards Open Graph Foundation Models", "HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs"], "graph learning": ["Bridging Local Details and Global Context in Text-Attributed Graphs"], "node classification graph learning": ["Bridging Local Details and Global Context in Text-Attributed Graphs"], "graph learning information retrieval": ["Bridging Local Details and Global Context in Text-Attributed Graphs"], "node classification graph learning information retrieval": ["Bridging Local Details and Global Context in Text-Attributed Graphs"], "news classification": ["Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks", "Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks", "LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization"], "machine translation news classification": ["Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"], "sentiment analysis textual entailment": ["RepMatch: Quantifying Cross-Instance Similarities in Representation Space"], "sentiment analysis textual entailment question answering": ["RepMatch: Quantifying Cross-Instance Similarities in Representation Space"], "free-text editing": ["Commonsense Knowledge Editing Based on Free-Text in LLMs"], "commonsense reasoning free-text editing": ["Commonsense Knowledge Editing Based on Free-Text in LLMs"], "knowledge editing commonsense reasoning free-text editing": ["Commonsense Knowledge Editing Based on Free-Text in LLMs"], "political incivility detection": ["A Closer Look at Multidimensional Online Political Incivility"], "political incivility detection multi-label classification": ["A Closer Look at Multidimensional Online Political Incivility"], "short text clustering": ["Leveraging BERT and TFIDF Features for Short Text Clustering via Alignment-Promoting Co-Training"], "intrinsic debiasing": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "extrinsic bias evaluation": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "machine translation bias mitigation": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "bias mitigation intrinsic debiasing": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "intrinsic debiasing extrinsic bias evaluation": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "machine translation bias mitigation intrinsic debiasing": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "bias mitigation intrinsic debiasing extrinsic bias evaluation": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "machine translation bias mitigation intrinsic debiasing extrinsic bias evaluation": ["Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation"], "named entity disambiguation entity linking": ["Unsupervised Named Entity Disambiguation for Low Resource Domains"], "bert": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "roberta": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "llama-2": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "question-answering glue": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "glue bert": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "bert roberta": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "roberta llama-2": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "question-answering glue bert": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "glue bert roberta": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "bert roberta llama-2": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "question-answering glue bert roberta": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "glue bert roberta llama-2": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "question-answering glue bert roberta llama-2": ["SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"], "knowledge graph completion link prediction": ["MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion", "Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs"], "procedural planning": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "visual language understanding": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "household activities": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "counterfactual reasoning": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities", "CELLO: Causal Evaluation of Large Vision-Language Models"], "procedural planning visual language understanding": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "visual language understanding household activities": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "household activities counterfactual reasoning": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "procedural planning visual language understanding household activities": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "visual language understanding household activities counterfactual reasoning": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "procedural planning visual language understanding household activities counterfactual reasoning": ["ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities"], "backdoor attack": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning", "Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "prompt-based learning": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "toxic detection": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "text classification backdoor attack": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "backdoor attack prompt-based learning": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "prompt-based learning few-shot learning": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "few-shot learning sentiment analysis": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "sentiment analysis toxic detection": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "text classification backdoor attack prompt-based learning": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "backdoor attack prompt-based learning few-shot learning": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "prompt-based learning few-shot learning sentiment analysis": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "few-shot learning sentiment analysis toxic detection": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "text classification backdoor attack prompt-based learning few-shot learning": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "backdoor attack prompt-based learning few-shot learning sentiment analysis": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "prompt-based learning few-shot learning sentiment analysis toxic detection": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "text classification backdoor attack prompt-based learning few-shot learning sentiment analysis": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "backdoor attack prompt-based learning few-shot learning sentiment analysis toxic detection": ["Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"], "pretraining": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients", "Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "instruction-finetuning": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients"], "pretraining fine-tuning": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients"], "fine-tuning instruction-finetuning": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients"], "instruction-finetuning language modeling": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients"], "pretraining fine-tuning instruction-finetuning": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients"], "fine-tuning instruction-finetuning language modeling": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients"], "pretraining fine-tuning instruction-finetuning language modeling": ["GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients"], "evaluation metric": ["RaTEScore: A Metric for Radiology Report Generation", "PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition", "Reference-based Metrics Disprove Themselves in Question Generation"], "radiology report generation evaluation metric": ["RaTEScore: A Metric for Radiology Report Generation"], "hallucination detection in LLM responses": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "claim extraction": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "claim classification": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "error type identification": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning", "Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method"], "hallucination detection in LLM responses claim extraction": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "claim extraction claim classification": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "claim classification error type identification": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "hallucination detection in LLM responses claim extraction claim classification": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "claim extraction claim classification error type identification": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "hallucination detection in LLM responses claim extraction claim classification error type identification": ["HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning"], "query-focused summarization": ["Learning to Rank Salient Content for Query-focused Summarization"], "learning-to-rank": ["Learning to Rank Salient Content for Query-focused Summarization"], "query-focused summarization learning-to-rank": ["Learning to Rank Salient Content for Query-focused Summarization"], "edit intent classification": ["Are Large Language Models Good Classifiers? A Study on Edit Intent Classification in Scientific Document Revisions"], "edit intent classification text classification": ["Are Large Language Models Good Classifiers? A Study on Edit Intent Classification in Scientific Document Revisions"], "literature search": ["LitSearch: A Retrieval Benchmark for Scientific Literature Search"], "citation recommendation": ["LitSearch: A Retrieval Benchmark for Scientific Literature Search"], "literature search citation recommendation": ["LitSearch: A Retrieval Benchmark for Scientific Literature Search"], "citation recommendation information retrieval": ["LitSearch: A Retrieval Benchmark for Scientific Literature Search"], "literature search citation recommendation information retrieval": ["LitSearch: A Retrieval Benchmark for Scientific Literature Search"], "open-world learning": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "extremely weak supervision": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "label space discovery": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "multi-label text classification open-world learning": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "open-world learning extremely weak supervision": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "extremely weak supervision label space discovery": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "label space discovery textual entailment": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "multi-label text classification open-world learning extremely weak supervision": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "open-world learning extremely weak supervision label space discovery": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "extremely weak supervision label space discovery textual entailment": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "multi-label text classification open-world learning extremely weak supervision label space discovery": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "open-world learning extremely weak supervision label space discovery textual entailment": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "multi-label text classification open-world learning extremely weak supervision label space discovery textual entailment": ["Open-world Multi-label Text Classification with Extremely Weak Supervision"], "time series extrapolation": ["LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law"], "dynamical systems modeling": ["LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law"], "transition rules learning": ["LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law"], "time series extrapolation dynamical systems modeling": ["LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law"], "dynamical systems modeling transition rules learning": ["LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law"], "time series extrapolation dynamical systems modeling transition rules learning": ["LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law"], "knowledge editing evaluation": ["AKEW: Assessing Knowledge Editing in the Wild"], "knowledge editing evaluation benchmark": ["AKEW: Assessing Knowledge Editing in the Wild"], "literal copying": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "non-literal copying": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "fact recall": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation", "What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models"], "fluency": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation", "DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "literal copying non-literal copying": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "non-literal copying fact recall": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "fact recall fluency": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "literal copying non-literal copying fact recall": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "non-literal copying fact recall fluency": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "literal copying non-literal copying fact recall fluency": ["COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"], "open-domain qa passage retrieval": ["Dense X Retrieval: What Retrieval Granularity Should We Use?"], "susceptibility modeling": ["Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach"], "user behavior analysis": ["Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach"], "misinformation detection susceptibility modeling": ["Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach"], "susceptibility modeling user behavior analysis": ["Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach"], "misinformation detection susceptibility modeling user behavior analysis": ["Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach"], "struct-to-text": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "closed-book question answering commonsense reasoning": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "commonsense reasoning coreference resolution": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "natural language inference paraphrase detection": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "ALVIN: Active Learning Via INterpolation"], "paraphrase detection reading comprehension": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "reading comprehension sentiment analysis": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "sentiment analysis struct-to-text": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "struct-to-text translation": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "translation summarization": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "MedINST: Meta Dataset of Biomedical Instructions"], "closed-book question answering commonsense reasoning coreference resolution": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "commonsense reasoning coreference resolution natural language inference": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "coreference resolution natural language inference paraphrase detection": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "natural language inference paraphrase detection reading comprehension": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "paraphrase detection reading comprehension sentiment analysis": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "reading comprehension sentiment analysis struct-to-text": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "sentiment analysis struct-to-text translation": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "struct-to-text translation summarization": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "closed-book question answering commonsense reasoning coreference resolution natural language inference": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "commonsense reasoning coreference resolution natural language inference paraphrase detection": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "coreference resolution natural language inference paraphrase detection reading comprehension": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "natural language inference paraphrase detection reading comprehension sentiment analysis": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "paraphrase detection reading comprehension sentiment analysis struct-to-text": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "reading comprehension sentiment analysis struct-to-text translation": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "sentiment analysis struct-to-text translation summarization": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "closed-book question answering commonsense reasoning coreference resolution natural language inference paraphrase detection": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "commonsense reasoning coreference resolution natural language inference paraphrase detection reading comprehension": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "coreference resolution natural language inference paraphrase detection reading comprehension sentiment analysis": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "natural language inference paraphrase detection reading comprehension sentiment analysis struct-to-text": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "paraphrase detection reading comprehension sentiment analysis struct-to-text translation": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "reading comprehension sentiment analysis struct-to-text translation summarization": ["Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"], "chinese lexical simplification": ["Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach"], "retrieval-based interpretation augmentation": ["Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach"], "chinese lexical simplification knowledge distillation": ["Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach"], "knowledge distillation retrieval-based interpretation augmentation": ["Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach"], "chinese lexical simplification knowledge distillation retrieval-based interpretation augmentation": ["Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach"], "lexically constrained generation": ["Control Large Language Models via Divide and Conquer"], "recipe generation": ["Control Large Language Models via Divide and Conquer"], "table to text": ["Control Large Language Models via Divide and Conquer"], "profile writing": ["Control Large Language Models via Divide and Conquer"], "lexically constrained generation recipe generation": ["Control Large Language Models via Divide and Conquer"], "recipe generation table to text": ["Control Large Language Models via Divide and Conquer"], "table to text profile writing": ["Control Large Language Models via Divide and Conquer"], "lexically constrained generation recipe generation table to text": ["Control Large Language Models via Divide and Conquer"], "recipe generation table to text profile writing": ["Control Large Language Models via Divide and Conquer"], "lexically constrained generation recipe generation table to text profile writing": ["Control Large Language Models via Divide and Conquer"], "reward modeling": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging", "Reward Modeling Requires Automatic Adjustment Based on Data Quality", "Semi-Supervised Reward Modeling via Iterative Self-Training", "On Diversified Preferences of Large Language Model Alignment", "Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "contrastive learning": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "reward modeling reinforcement learning from human feedback": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "Reward Modeling Requires Automatic Adjustment Based on Data Quality", "Semi-Supervised Reward Modeling via Iterative Self-Training"], "reinforcement learning from human feedback language model alignment": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "Filtered Direct Preference Optimization"], "language model alignment contrastive learning": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning"], "reward modeling reinforcement learning from human feedback language model alignment": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning"], "reinforcement learning from human feedback language model alignment contrastive learning": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning"], "reward modeling reinforcement learning from human feedback language model alignment contrastive learning": ["Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning"], "table entity linking": ["ROCEL: Advancing Table Entity Linking through Distinctive Row and Column Contexts"], "table entity linking entity disambiguation": ["ROCEL: Advancing Table Entity Linking through Distinctive Row and Column Contexts"], "natural language reasoning": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models", "FOLIO: Natural Language Reasoning with First-Order Logic", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "proof construction": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "entailment": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "natural language reasoning multi-step reasoning": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "multi-step reasoning proof construction": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "proof construction entailment": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "entailment question answering": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "natural language reasoning multi-step reasoning proof construction": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "multi-step reasoning proof construction entailment": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "proof construction entailment question answering": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "natural language reasoning multi-step reasoning proof construction entailment": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "multi-step reasoning proof construction entailment question answering": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "natural language reasoning multi-step reasoning proof construction entailment question answering": ["Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models"], "api planning": ["AppBench: Planning of Multiple APIs from Various APPs for Complex User Instruction"], "tool usage": ["AppBench: Planning of Multiple APIs from Various APPs for Complex User Instruction", "TOOLVERIFIER: Generalization to New Tools via Self-Verification", "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "api planning tool usage": ["AppBench: Planning of Multiple APIs from Various APPs for Complex User Instruction"], "question answering mathematical reasoning": ["Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment"], "question answering mathematical reasoning instruction following": ["Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment"], "visual speech recognition": ["AudioVSR: Enhancing Video Speech Recognition with Audio Data", "Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing"], "audio-lip alignment": ["AudioVSR: Enhancing Video Speech Recognition with Audio Data"], "visual speech recognition audio-lip alignment": ["AudioVSR: Enhancing Video Speech Recognition with Audio Data"], "code optimization": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "program efficiency": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "functional correctness": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "code optimization code generation": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "code generation program efficiency": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "program efficiency functional correctness": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "code optimization code generation program efficiency": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "code generation program efficiency functional correctness": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "code optimization code generation program efficiency functional correctness": ["ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?"], "translation refinement": ["Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level"], "machine translation translation refinement": ["Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level"], "sequential decision making": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "multi-hop question answering sequential decision making": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "sequential decision making code generation": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "code generation visual question answering": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "visual question answering text-to-image generation": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "multi-hop question answering sequential decision making code generation": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "sequential decision making code generation visual question answering": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "code generation visual question answering text-to-image generation": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "multi-hop question answering sequential decision making code generation visual question answering": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "sequential decision making code generation visual question answering text-to-image generation": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "multi-hop question answering sequential decision making code generation visual question answering text-to-image generation": ["Re-ReST: Reflection-Reinforced Self-Training for Language Agents"], "ocr post-correction": ["Effective Synthetic Data and Test-Time Adaptation for OCR Correction", "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "document-level relation extraction relation extraction": ["SRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework"], "cross-modal interaction": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "referring expression comprehension visual question answering": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "visual question answering image-text retrieval": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "image-text retrieval compositional reasoning": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "compositional reasoning visual reasoning": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "visual reasoning cross-modal interaction": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "referring expression comprehension visual question answering image-text retrieval": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "visual question answering image-text retrieval compositional reasoning": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "image-text retrieval compositional reasoning visual reasoning": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "compositional reasoning visual reasoning cross-modal interaction": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "referring expression comprehension visual question answering image-text retrieval compositional reasoning": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "visual question answering image-text retrieval compositional reasoning visual reasoning": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "image-text retrieval compositional reasoning visual reasoning cross-modal interaction": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "referring expression comprehension visual question answering image-text retrieval compositional reasoning visual reasoning": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "visual question answering image-text retrieval compositional reasoning visual reasoning cross-modal interaction": ["FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"], "world model learning": ["Exploring the Learning Capabilities of Language Models using LEVERWORLDS"], "sample efficiency analysis": ["Exploring the Learning Capabilities of Language Models using LEVERWORLDS"], "bias-variance tradeoff": ["Exploring the Learning Capabilities of Language Models using LEVERWORLDS"], "world model learning sample efficiency analysis": ["Exploring the Learning Capabilities of Language Models using LEVERWORLDS"], "sample efficiency analysis bias-variance tradeoff": ["Exploring the Learning Capabilities of Language Models using LEVERWORLDS"], "world model learning sample efficiency analysis bias-variance tradeoff": ["Exploring the Learning Capabilities of Language Models using LEVERWORLDS"], "probabilistic consistency": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "span prediction": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models", "An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference"], "density estimation": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "language models probabilistic consistency": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "probabilistic consistency span prediction": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "span prediction calibration": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "calibration density estimation": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "language models probabilistic consistency span prediction": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "probabilistic consistency span prediction calibration": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "span prediction calibration density estimation": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "language models probabilistic consistency span prediction calibration": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "probabilistic consistency span prediction calibration density estimation": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "language models probabilistic consistency span prediction calibration density estimation": ["CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models"], "document editing": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "multimodal grounding": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "command generation": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "htML structure editing": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "document editing multimodal grounding": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "multimodal grounding command generation": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "command generation htML structure editing": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "document editing multimodal grounding command generation": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "multimodal grounding command generation htML structure editing": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "document editing multimodal grounding command generation htML structure editing": ["DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding"], "aligning language models": ["DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"], "reward modeling model merging": ["DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"], "model merging reinforcement learning from human feedback": ["DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"], "reinforcement learning from human feedback aligning language models": ["DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"], "reward modeling model merging reinforcement learning from human feedback": ["DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"], "model merging reinforcement learning from human feedback aligning language models": ["DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"], "reward modeling model merging reinforcement learning from human feedback aligning language models": ["DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"], "slang paraphrasing": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "cross-cultural understanding": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "bias reduction": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "slang paraphrasing emotion classification": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "emotion classification cross-cultural understanding": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "cross-cultural understanding bias reduction": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "slang paraphrasing emotion classification cross-cultural understanding": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "emotion classification cross-cultural understanding bias reduction": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "slang paraphrasing emotion classification cross-cultural understanding bias reduction": ["Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing"], "keyword-constrained generation": ["Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding"], "factual correctness in question-answering": ["Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding"], "keyword-constrained generation toxicity reduction": ["Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding"], "toxicity reduction factual correctness in question-answering": ["Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding"], "keyword-constrained generation toxicity reduction factual correctness in question-answering": ["Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding"], "commonsense reasoning symbolic reasoning": ["Re-Reading Improves Reasoning in Large Language Models"], "arithmetic reasoning commonsense reasoning symbolic reasoning": ["Re-Reading Improves Reasoning in Large Language Models"], "social stereotype analysis": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "in-domain framing capture": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "time-series stereotype tracking": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "domain-specific semantic axis analysis": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "social stereotype analysis in-domain framing capture": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "in-domain framing capture time-series stereotype tracking": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "time-series stereotype tracking domain-specific semantic axis analysis": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "social stereotype analysis in-domain framing capture time-series stereotype tracking": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "in-domain framing capture time-series stereotype tracking domain-specific semantic axis analysis": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "social stereotype analysis in-domain framing capture time-series stereotype tracking domain-specific semantic axis analysis": ["ADAPTIVE AXES: A Pipeline for In-domain Social Stereotype Analysis"], "healthcare knowledge assessment": ["ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments"], "visual question answering healthcare knowledge assessment": ["ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments"], "text answer aggregation": ["Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations"], "crowd annotations": ["Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations"], "quality control": ["Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations"], "text answer aggregation crowd annotations": ["Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations"], "crowd annotations quality control": ["Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations"], "text answer aggregation crowd annotations quality control": ["Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations"], "reasoning knowledge distillation": ["Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation"], "microblog classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "tweet classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification", "Multilingual Topic Classification in X: Dataset and Analysis"], "irony detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "microblog classification text classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "text classification tweet classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "tweet classification topic classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "topic classification sentiment analysis": ["Revisiting Supervised Contrastive Learning for Microblog Classification", "SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation", "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "hate speech detection irony detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "irony detection emotion recognition": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "microblog classification text classification tweet classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "text classification tweet classification topic classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "tweet classification topic classification sentiment analysis": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "topic classification sentiment analysis hate speech detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "sentiment analysis hate speech detection irony detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "hate speech detection irony detection emotion recognition": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "microblog classification text classification tweet classification topic classification": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "text classification tweet classification topic classification sentiment analysis": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "tweet classification topic classification sentiment analysis hate speech detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "topic classification sentiment analysis hate speech detection irony detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "sentiment analysis hate speech detection irony detection emotion recognition": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "microblog classification text classification tweet classification topic classification sentiment analysis": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "text classification tweet classification topic classification sentiment analysis hate speech detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "tweet classification topic classification sentiment analysis hate speech detection irony detection": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "topic classification sentiment analysis hate speech detection irony detection emotion recognition": ["Revisiting Supervised Contrastive Learning for Microblog Classification"], "jailbreak attack": ["BaitAttack: Alleviating Intention Shift in Jailbreak Attacks via Adaptive Bait Crafting", "Distract Large Language Models for Automatic Jailbreak Attack", "From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking"], "object detection": ["Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective", "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models", "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "scientific reasoning": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "stem problem solving": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "scientific reasoning tool use": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "tool use stem problem solving": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "stem problem solving math reasoning": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "scientific reasoning tool use stem problem solving": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "tool use stem problem solving math reasoning": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "scientific reasoning tool use stem problem solving math reasoning": ["SCIAGENT: Tool-augmented Language Models for Scientific Reasoning"], "dialogue agent alignment": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "reward model training": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents", "On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization"], "multimodal dialogue generation": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "dialogue agent alignment reward model training": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "reward model training reinforcement learning from human feedback": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "reinforcement learning from human feedback multimodal dialogue generation": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "dialogue agent alignment reward model training reinforcement learning from human feedback": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "reward model training reinforcement learning from human feedback multimodal dialogue generation": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "dialogue agent alignment reward model training reinforcement learning from human feedback multimodal dialogue generation": ["Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"], "cultural representation": ["Towards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey"], "cultural representation bias detection": ["Towards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey"], "bias detection LLM evaluation": ["Towards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey"], "cultural representation bias detection LLM evaluation": ["Towards Measuring and Modeling \u201cCulture\u201d in LLMs: A Survey"], "evaluating emotion support conversation  in LLMs": ["ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models"], "LLM probing": ["Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting"], "cultural bias analysis": ["Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting"], "LLM probing cultural bias analysis": ["Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting"], "cultural bias analysis model alignment": ["Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting"], "LLM probing cultural bias analysis model alignment": ["Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting"], "LLM-generated text detection": ["Text Fluoroscopy: Detecting LLM-Generated Text through Intrinsic Features", "Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness", "SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation", "How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection"], "hate speech detection content moderation": ["Hate Personified: Investigating the role of LLMs in content moderation"], "content moderation bias analysis": ["Hate Personified: Investigating the role of LLMs in content moderation"], "hate speech detection content moderation bias analysis": ["Hate Personified: Investigating the role of LLMs in content moderation"], "factuality probing": ["Temporally Consistent Factuality Probing for Large Language Models"], "temporal reasoning": ["Temporally Consistent Factuality Probing for Large Language Models", "CAT-BENCH: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans", "MIBench: Evaluating Multimodal Large Language Models over Multiple Images", "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs", "Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models", "NARRATIVE-OF-THOUGHT: Improving Temporal Reasoning of Large Language Models via Recounted Narratives"], "factuality probing temporal reasoning": ["Temporally Consistent Factuality Probing for Large Language Models"], "temporal reasoning sentence completion": ["Temporally Consistent Factuality Probing for Large Language Models"], "factuality probing temporal reasoning sentence completion": ["Temporally Consistent Factuality Probing for Large Language Models"], "pos tagging": ["A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives", "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models"], "sentiment analysis named entity recognition": ["A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives", "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data"], "named entity recognition pos tagging": ["A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives"], "pos tagging natural language inference": ["A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives"], "sentiment analysis named entity recognition pos tagging": ["A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives"], "named entity recognition pos tagging natural language inference": ["A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives"], "sentiment analysis named entity recognition pos tagging natural language inference": ["A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives"], "boolean question answering": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "verification": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators", "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision"], "abstention": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators", "Characterizing LLM Abstention Behavior in Science QA with Context Perturbations"], "scientific question answering boolean question answering": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "boolean question answering reasoning": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "reasoning verification": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "verification abstention": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "abstention hallucination detection": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "scientific question answering boolean question answering reasoning": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "boolean question answering reasoning verification": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "reasoning verification abstention": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "verification abstention hallucination detection": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "scientific question answering boolean question answering reasoning verification": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "boolean question answering reasoning verification abstention": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "reasoning verification abstention hallucination detection": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "scientific question answering boolean question answering reasoning verification abstention": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "boolean question answering reasoning verification abstention hallucination detection": ["Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators"], "reading comprehension language modeling": ["LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training"], "language modeling world knowledge": ["LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training"], "commonsense reasoning reading comprehension language modeling": ["LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training"], "reading comprehension language modeling world knowledge": ["LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training"], "commonsense reasoning reading comprehension language modeling world knowledge": ["LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training"], "question answering evaluation": ["Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability", "TuringQ: Benchmarking AI Comprehension in Theory of Computation"], "nlg evaluation summarization": ["Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"], "summarization story generation": ["Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"], "story generation question answering evaluation": ["Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"], "nlg evaluation summarization story generation": ["Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"], "summarization story generation question answering evaluation": ["Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"], "nlg evaluation summarization story generation question answering evaluation": ["Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"], "code-generating": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "instruction-following mathematical reasoning": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "mathematical reasoning code-generating": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "code-generating text classification": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "text classification textual entailment": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "instruction-following mathematical reasoning code-generating": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "mathematical reasoning code-generating text classification": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "code-generating text classification textual entailment": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "instruction-following mathematical reasoning code-generating text classification": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "mathematical reasoning code-generating text classification textual entailment": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "instruction-following mathematical reasoning code-generating text classification textual entailment": ["Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging"], "grounded language learning": ["Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning"], "compositional generalization": ["Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning", "Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems", "In-Context Compositional Generalization for Large Vision-Language Models"], "grounded language learning compositional generalization": ["Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning"], "compositional generalization in-context learning": ["Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning"], "grounded language learning compositional generalization in-context learning": ["Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning"], "cloze test": ["FAME: Towards Factual Multi-Task Model Editing"], "fact check": ["FAME: Towards Factual Multi-Task Model Editing"], "locality test": ["FAME: Towards Factual Multi-Task Model Editing"], "dialogues": ["FAME: Towards Factual Multi-Task Model Editing"], "qa sentence completion": ["FAME: Towards Factual Multi-Task Model Editing"], "sentence completion cloze test": ["FAME: Towards Factual Multi-Task Model Editing"], "cloze test multiple-choice questions": ["FAME: Towards Factual Multi-Task Model Editing"], "multiple-choice questions fact check": ["FAME: Towards Factual Multi-Task Model Editing"], "fact check locality test": ["FAME: Towards Factual Multi-Task Model Editing"], "locality test multi-hop qa": ["FAME: Towards Factual Multi-Task Model Editing"], "multi-hop qa dialogues": ["FAME: Towards Factual Multi-Task Model Editing"], "qa sentence completion cloze test": ["FAME: Towards Factual Multi-Task Model Editing"], "sentence completion cloze test multiple-choice questions": ["FAME: Towards Factual Multi-Task Model Editing"], "cloze test multiple-choice questions fact check": ["FAME: Towards Factual Multi-Task Model Editing"], "multiple-choice questions fact check locality test": ["FAME: Towards Factual Multi-Task Model Editing"], "fact check locality test multi-hop qa": ["FAME: Towards Factual Multi-Task Model Editing"], "locality test multi-hop qa dialogues": ["FAME: Towards Factual Multi-Task Model Editing"], "qa sentence completion cloze test multiple-choice questions": ["FAME: Towards Factual Multi-Task Model Editing"], "sentence completion cloze test multiple-choice questions fact check": ["FAME: Towards Factual Multi-Task Model Editing"], "cloze test multiple-choice questions fact check locality test": ["FAME: Towards Factual Multi-Task Model Editing"], "multiple-choice questions fact check locality test multi-hop qa": ["FAME: Towards Factual Multi-Task Model Editing"], "fact check locality test multi-hop qa dialogues": ["FAME: Towards Factual Multi-Task Model Editing"], "qa sentence completion cloze test multiple-choice questions fact check": ["FAME: Towards Factual Multi-Task Model Editing"], "sentence completion cloze test multiple-choice questions fact check locality test": ["FAME: Towards Factual Multi-Task Model Editing"], "cloze test multiple-choice questions fact check locality test multi-hop qa": ["FAME: Towards Factual Multi-Task Model Editing"], "multiple-choice questions fact check locality test multi-hop qa dialogues": ["FAME: Towards Factual Multi-Task Model Editing"], "multimodal LLMs  safety": ["MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"], "response detoxification": ["MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"], "multimodal LLMs  safety harmful response detection": ["MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"], "harmful response detection response detoxification": ["MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"], "multimodal LLMs  safety harmful response detection response detoxification": ["MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"], "natural language generation  evaluation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "general generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "natural language generation  evaluation machine translation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "machine translation text summarization": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "Exploring the Relationship between In-Context Learning and Instruction Tuning"], "text summarization dialogue generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "dialogue generation image captioning": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "image captioning data-to-text generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "data-to-text generation story generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "story generation general generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "natural language generation  evaluation machine translation text summarization": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "machine translation text summarization dialogue generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "text summarization dialogue generation image captioning": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "dialogue generation image captioning data-to-text generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "image captioning data-to-text generation story generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "data-to-text generation story generation general generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "natural language generation  evaluation machine translation text summarization dialogue generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "machine translation text summarization dialogue generation image captioning": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "text summarization dialogue generation image captioning data-to-text generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "dialogue generation image captioning data-to-text generation story generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "image captioning data-to-text generation story generation general generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "natural language generation  evaluation machine translation text summarization dialogue generation image captioning": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "machine translation text summarization dialogue generation image captioning data-to-text generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "text summarization dialogue generation image captioning data-to-text generation story generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "dialogue generation image captioning data-to-text generation story generation general generation": ["Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"], "multi-document qa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "single-document qa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "qasper": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "synthetic code": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "2wikimqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multinews": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "triviaqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning", "Regression-aware Inference with LLMs", "OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "samsum": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "govreport": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multi-document qa hotpotqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "hotpotqa single-document qa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "single-document qa qasper": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "qasper few-shot learning": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "few-shot learning synthetic code": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs", "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "synthetic code summarization": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "summarization 2wikimqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "2wikimqa multinews": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multinews trec": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "trec triviaqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "triviaqa samsum": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "samsum musique": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "musique govreport": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multi-document qa hotpotqa single-document qa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "hotpotqa single-document qa qasper": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "single-document qa qasper few-shot learning": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "qasper few-shot learning synthetic code": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "few-shot learning synthetic code summarization": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "synthetic code summarization 2wikimqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "summarization 2wikimqa multinews": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "2wikimqa multinews trec": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multinews trec triviaqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "trec triviaqa samsum": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "triviaqa samsum musique": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "samsum musique govreport": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multi-document qa hotpotqa single-document qa qasper": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "hotpotqa single-document qa qasper few-shot learning": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "single-document qa qasper few-shot learning synthetic code": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "qasper few-shot learning synthetic code summarization": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "few-shot learning synthetic code summarization 2wikimqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "synthetic code summarization 2wikimqa multinews": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "summarization 2wikimqa multinews trec": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "2wikimqa multinews trec triviaqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multinews trec triviaqa samsum": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "trec triviaqa samsum musique": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "triviaqa samsum musique govreport": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multi-document qa hotpotqa single-document qa qasper few-shot learning": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "hotpotqa single-document qa qasper few-shot learning synthetic code": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "single-document qa qasper few-shot learning synthetic code summarization": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "qasper few-shot learning synthetic code summarization 2wikimqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "few-shot learning synthetic code summarization 2wikimqa multinews": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "synthetic code summarization 2wikimqa multinews trec": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "summarization 2wikimqa multinews trec triviaqa": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "2wikimqa multinews trec triviaqa samsum": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "multinews trec triviaqa samsum musique": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "trec triviaqa samsum musique govreport": ["InfiniPot: Infinite Context Processing on Memory-Constrained LLMs"], "text-video retrieval": ["VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models"], "long video description understanding": ["VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models"], "text-video retrieval long video description understanding": ["VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models"], "dataset generation": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "dataset generation text classification": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "text classification humor detection": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "humor detection sentiment analysis": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "dataset generation text classification humor detection": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "text classification humor detection sentiment analysis": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "humor detection sentiment analysis topic classification": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "dataset generation text classification humor detection sentiment analysis": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "text classification humor detection sentiment analysis topic classification": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "dataset generation text classification humor detection sentiment analysis topic classification": ["CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs"], "knowledge claims verification in LLMs": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "knowledge definition formalization for LLMs": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "survey on knowledge definitions": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "evaluation protocol suggestion for LLMs": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "knowledge claims verification in LLMs knowledge definition formalization for LLMs": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "knowledge definition formalization for LLMs survey on knowledge definitions": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "survey on knowledge definitions evaluation protocol suggestion for LLMs": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "knowledge claims verification in LLMs knowledge definition formalization for LLMs survey on knowledge definitions": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "knowledge definition formalization for LLMs survey on knowledge definitions evaluation protocol suggestion for LLMs": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "knowledge claims verification in LLMs knowledge definition formalization for LLMs survey on knowledge definitions evaluation protocol suggestion for LLMs": ["Defining Knowledge: Bridging Epistemology and Large Language Models"], "knowledge graph generation": ["TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs"], "text-to-table generation knowledge graph generation": ["TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs"], "knowledge graph generation information extraction": ["TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs"], "text-to-table generation knowledge graph generation information extraction": ["TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs"], "document formatting": ["Free your mouse! Command Large Language Models to Generate Code to Format Word Documents"], "text-to-format conversion": ["Free your mouse! Command Large Language Models to Generate Code to Format Word Documents"], "code generation document formatting": ["Free your mouse! Command Large Language Models to Generate Code to Format Word Documents"], "document formatting text-to-format conversion": ["Free your mouse! Command Large Language Models to Generate Code to Format Word Documents"], "code generation document formatting text-to-format conversion": ["Free your mouse! Command Large Language Models to Generate Code to Format Word Documents"], "data mixture ratio optimization": ["CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models"], "continual pre-training data mixture ratio optimization": ["CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models"], "answer verification": ["Rationale-Aware Answer Verification by Pairwise Self-Evaluation"], "rationale quality assessment": ["Rationale-Aware Answer Verification by Pairwise Self-Evaluation"], "pairwise self-evaluation": ["Rationale-Aware Answer Verification by Pairwise Self-Evaluation"], "answer verification rationale quality assessment": ["Rationale-Aware Answer Verification by Pairwise Self-Evaluation"], "rationale quality assessment pairwise self-evaluation": ["Rationale-Aware Answer Verification by Pairwise Self-Evaluation"], "answer verification rationale quality assessment pairwise self-evaluation": ["Rationale-Aware Answer Verification by Pairwise Self-Evaluation"], "model editing robustness evaluation": ["On the Robustness of Editing Large Language Models"], "advglue": ["IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method"], "natural language processing glue": ["IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method"], "glue advglue": ["IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method"], "natural language processing glue advglue": ["IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method"], "extreme multi-label classification": ["Exploring Space Efficiency in a Tree-based Linear Model for Extreme Multi-label Classification"], "lexicographic analysis of anxiety": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "tracking anxiety in text streams": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "studying relationship between anxiety and other emotions": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "determining age of anxiety word acquisition": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "lexicographic analysis of anxiety tracking anxiety in text streams": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "tracking anxiety in text streams studying relationship between anxiety and other emotions": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "studying relationship between anxiety and other emotions determining age of anxiety word acquisition": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "lexicographic analysis of anxiety tracking anxiety in text streams studying relationship between anxiety and other emotions": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "tracking anxiety in text streams studying relationship between anxiety and other emotions determining age of anxiety word acquisition": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "lexicographic analysis of anxiety tracking anxiety in text streams studying relationship between anxiety and other emotions determining age of anxiety word acquisition": ["Worry Words: Norms of Anxiety Association for over 44k English Words"], "factual accuracy assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "instruction following assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "coherence assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "reasoning proficiency assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "LLM evaluation text generation": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "text generation factual accuracy assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "factual accuracy assessment instruction following assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "instruction following assessment coherence assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "coherence assessment reasoning proficiency assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "LLM evaluation text generation factual accuracy assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "text generation factual accuracy assessment instruction following assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "factual accuracy assessment instruction following assessment coherence assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "instruction following assessment coherence assessment reasoning proficiency assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "LLM evaluation text generation factual accuracy assessment instruction following assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "text generation factual accuracy assessment instruction following assessment coherence assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "factual accuracy assessment instruction following assessment coherence assessment reasoning proficiency assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "LLM evaluation text generation factual accuracy assessment instruction following assessment coherence assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "text generation factual accuracy assessment instruction following assessment coherence assessment reasoning proficiency assessment": ["Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"], "argument evaluation": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "text analysis": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments", "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "persuasion argument evaluation": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "argument evaluation causal inference": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "causal inference topic modeling": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "topic modeling text analysis": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "persuasion argument evaluation causal inference": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "argument evaluation causal inference topic modeling": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "causal inference topic modeling text analysis": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "persuasion argument evaluation causal inference topic modeling": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "argument evaluation causal inference topic modeling text analysis": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "persuasion argument evaluation causal inference topic modeling text analysis": ["AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments"], "cross-cultural machine translation": ["Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs"], "problem solving": ["Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"], "mathematical reasoning compositional generalization": ["Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"], "compositional generalization logical reasoning": ["Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"], "logical reasoning problem solving": ["Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"], "mathematical reasoning compositional generalization logical reasoning": ["Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"], "compositional generalization logical reasoning problem solving": ["Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"], "mathematical reasoning compositional generalization logical reasoning problem solving": ["Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"], "language modeling commonsense reasoning": ["Scaling Laws for Linear Complexity Language Models"], "commonsense reasoning information retrieval": ["Scaling Laws for Linear Complexity Language Models"], "information retrieval text generation": ["Scaling Laws for Linear Complexity Language Models"], "language modeling commonsense reasoning information retrieval": ["Scaling Laws for Linear Complexity Language Models"], "commonsense reasoning information retrieval text generation": ["Scaling Laws for Linear Complexity Language Models"], "language modeling commonsense reasoning information retrieval text generation": ["Scaling Laws for Linear Complexity Language Models"], "automated essay scoring": ["Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards", "Automated Essay Scoring: A Reflection on the State of the Art", "Unleashing Large Language Models' Proficiency in Zero-shot Essay Scoring", "Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals"], "multi-trait assessment": ["Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards"], "automated essay scoring multi-trait assessment": ["Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards"], "gender bias mitigation": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis", "Does Context Help Mitigate Gender Bias in Neural Machine Translation?"], "stereotype reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "language generation multi-choice question answering": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "multi-choice question answering gender bias mitigation": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "gender bias mitigation stereotype reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "stereotype reduction toxicity reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "language generation multi-choice question answering gender bias mitigation": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "multi-choice question answering gender bias mitigation stereotype reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "gender bias mitigation stereotype reduction toxicity reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "language generation multi-choice question answering gender bias mitigation stereotype reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "multi-choice question answering gender bias mitigation stereotype reduction toxicity reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "language generation multi-choice question answering gender bias mitigation stereotype reduction toxicity reduction": ["Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"], "commonsense knowledge graph completion": ["ATAP: Automatic Template-Augmented Commonsense Knowledge Graph Completion via Pre-Trained Language Models"], "commonsense knowledge graph completion link prediction": ["ATAP: Automatic Template-Augmented Commonsense Knowledge Graph Completion via Pre-Trained Language Models"], "chemistry problem solving": ["LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning"], "complex reasoning mathematical reasoning": ["LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning"], "mathematical reasoning medical question answering": ["LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning"], "medical question answering chemistry problem solving": ["LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning"], "complex reasoning mathematical reasoning medical question answering": ["LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning"], "mathematical reasoning medical question answering chemistry problem solving": ["LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning"], "complex reasoning mathematical reasoning medical question answering chemistry problem solving": ["LM\u00b2: A Simple Society of Language Models Solves Complex Reasoning"], "knowledge-aware visual question answering about entities": ["Multi-Level Information Retrieval Augmented Generation for Knowledge-based Visual Question Answering"], "uncertainty estimation": ["Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?", "Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?"], "text summarization uncertainty estimation": ["Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?"], "long-context evaluation": ["Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP"], "task design": ["Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP"], "taxonomy": ["Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP", "The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "long-context evaluation task design": ["Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP"], "task design taxonomy": ["Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP"], "long-context evaluation task design taxonomy": ["Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP"], "vocabulary refinement": ["BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training"], "machine translation tokenization": ["BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training"], "tokenization vocabulary refinement": ["BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training"], "machine translation tokenization vocabulary refinement": ["BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training"], "long document question answering": ["SEGMENT+: Long Text Processing with Short-Context Language Models", "LLOCO: Learning Long Contexts Offline", "LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "needle-in-a-haystack": ["SEGMENT+: Long Text Processing with Short-Context Language Models", "A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression"], "long document question answering needle-in-a-haystack": ["SEGMENT+: Long Text Processing with Short-Context Language Models"], "word math problems": ["Explicit Memory Learning with Expectation Maximization"], "symbolic understanding": ["Explicit Memory Learning with Expectation Maximization"], "streaming inference": ["Explicit Memory Learning with Expectation Maximization"], "word math problems commonsense qa": ["Explicit Memory Learning with Expectation Maximization"], "commonsense qa symbolic understanding": ["Explicit Memory Learning with Expectation Maximization"], "symbolic understanding streaming inference": ["Explicit Memory Learning with Expectation Maximization"], "word math problems commonsense qa symbolic understanding": ["Explicit Memory Learning with Expectation Maximization"], "commonsense qa symbolic understanding streaming inference": ["Explicit Memory Learning with Expectation Maximization"], "word math problems commonsense qa symbolic understanding streaming inference": ["Explicit Memory Learning with Expectation Maximization"], "student revision simulation": ["Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions"], "feedback generation student revision simulation": ["Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions"], "result summarization": ["Small LLMs Are Weak Tool Learners: A Multi-LLM Agent"], "tool learning task planning": ["Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "tool invocation result summarization": ["Small LLMs Are Weak Tool Learners: A Multi-LLM Agent"], "tool learning task planning tool invocation": ["Small LLMs Are Weak Tool Learners: A Multi-LLM Agent"], "task planning tool invocation result summarization": ["Small LLMs Are Weak Tool Learners: A Multi-LLM Agent"], "tool learning task planning tool invocation result summarization": ["Small LLMs Are Weak Tool Learners: A Multi-LLM Agent"], "context understanding": ["Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions"], "natural language processing mechanistic interpretability": ["Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions"], "mechanistic interpretability text generation": ["Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions"], "text generation context understanding": ["Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions"], "natural language processing mechanistic interpretability text generation": ["Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions"], "mechanistic interpretability text generation context understanding": ["Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions"], "natural language processing mechanistic interpretability text generation context understanding": ["Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions"], "depression-anxiety comorbidity diagnosis": ["Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis"], "depression-anxiety comorbidity diagnosis multi-label classification": ["Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis"], "multi-label classification binary classification": ["Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis"], "depression-anxiety comorbidity diagnosis multi-label classification binary classification": ["Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis"], "commonsense causality understanding": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "acquisition methods": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "qualitative reasoning": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "quantitative measurements": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "commonsense causality understanding taxonomy": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "taxonomy benchmark": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "benchmark acquisition methods": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "acquisition methods qualitative reasoning": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "qualitative reasoning quantitative measurements": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "commonsense causality understanding taxonomy benchmark": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "taxonomy benchmark acquisition methods": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "benchmark acquisition methods qualitative reasoning": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "acquisition methods qualitative reasoning quantitative measurements": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "commonsense causality understanding taxonomy benchmark acquisition methods": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "taxonomy benchmark acquisition methods qualitative reasoning": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "benchmark acquisition methods qualitative reasoning quantitative measurements": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "commonsense causality understanding taxonomy benchmark acquisition methods qualitative reasoning": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "taxonomy benchmark acquisition methods qualitative reasoning quantitative measurements": ["The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning"], "complex word identification": ["Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"], "lexical complexity prediction": ["Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"], "multi-word expression complexity evaluation": ["Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"], "complex word identification lexical complexity prediction": ["Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"], "lexical complexity prediction multi-word expression complexity evaluation": ["Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"], "complex word identification lexical complexity prediction multi-word expression complexity evaluation": ["Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"], "closed-domain question answering": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "dialogue": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness"], "reasoning natural language inference": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "natural language inference open-domain question answering": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "open-domain question answering closed-domain question answering": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "closed-domain question answering dialogue": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "dialogue summarization": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue", "MUSCLE: A Model Update Strategy for Compatible LLM Evolution"], "summarization named entity recognition": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "named entity recognition sentiment analysis": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "reasoning natural language inference open-domain question answering": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "natural language inference open-domain question answering closed-domain question answering": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "open-domain question answering closed-domain question answering dialogue": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "closed-domain question answering dialogue summarization": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "dialogue summarization named entity recognition": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "summarization named entity recognition sentiment analysis": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "reasoning natural language inference open-domain question answering closed-domain question answering": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "natural language inference open-domain question answering closed-domain question answering dialogue": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "open-domain question answering closed-domain question answering dialogue summarization": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "closed-domain question answering dialogue summarization named entity recognition": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "dialogue summarization named entity recognition sentiment analysis": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "reasoning natural language inference open-domain question answering closed-domain question answering dialogue": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "natural language inference open-domain question answering closed-domain question answering dialogue summarization": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "open-domain question answering closed-domain question answering dialogue summarization named entity recognition": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "closed-domain question answering dialogue summarization named entity recognition sentiment analysis": ["Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue"], "personalization learning": ["Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!"], "summarization in-context learning": ["Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!"], "in-context learning personalization learning": ["Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!"], "summarization in-context learning personalization learning": ["Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!"], "policy learning": ["MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations"], "natural language understanding policy learning": ["MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations"], "policy learning natural language generation": ["MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations"], "natural language understanding policy learning natural language generation": ["MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations"], "satirical image detection": ["YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models"], "satirical image understanding": ["YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models"], "satirical image completion": ["YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models"], "satirical image detection satirical image understanding": ["YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models"], "satirical image understanding satirical image completion": ["YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models"], "satirical image detection satirical image understanding satirical image completion": ["YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models"], "n-back tasks": ["Working Memory Identifies Reasoning Limits in Language Models"], "big-bench hard  tasks": ["Working Memory Identifies Reasoning Limits in Language Models"], "disambiguation qa": ["Working Memory Identifies Reasoning Limits in Language Models", "Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "sports understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "movie recommendation": ["Working Memory Identifies Reasoning Limits in Language Models", "Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "ruin names": ["Working Memory Identifies Reasoning Limits in Language Models"], "salient translation error detection": ["Working Memory Identifies Reasoning Limits in Language Models"], "causal judgement": ["Working Memory Identifies Reasoning Limits in Language Models"], "object counting": ["Working Memory Identifies Reasoning Limits in Language Models", "Tree of Problems: Improving structured problem solving with compositionality", "Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "n-back tasks big-bench hard  tasks": ["Working Memory Identifies Reasoning Limits in Language Models"], "big-bench hard  tasks disambiguation qa": ["Working Memory Identifies Reasoning Limits in Language Models"], "disambiguation qa sports understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "sports understanding movie recommendation": ["Working Memory Identifies Reasoning Limits in Language Models"], "movie recommendation ruin names": ["Working Memory Identifies Reasoning Limits in Language Models"], "ruin names salient translation error detection": ["Working Memory Identifies Reasoning Limits in Language Models"], "salient translation error detection causal judgement": ["Working Memory Identifies Reasoning Limits in Language Models"], "causal judgement date understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "date understanding object counting": ["Working Memory Identifies Reasoning Limits in Language Models"], "n-back tasks big-bench hard  tasks disambiguation qa": ["Working Memory Identifies Reasoning Limits in Language Models"], "big-bench hard  tasks disambiguation qa sports understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "disambiguation qa sports understanding movie recommendation": ["Working Memory Identifies Reasoning Limits in Language Models"], "sports understanding movie recommendation ruin names": ["Working Memory Identifies Reasoning Limits in Language Models"], "movie recommendation ruin names salient translation error detection": ["Working Memory Identifies Reasoning Limits in Language Models"], "ruin names salient translation error detection causal judgement": ["Working Memory Identifies Reasoning Limits in Language Models"], "salient translation error detection causal judgement date understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "causal judgement date understanding object counting": ["Working Memory Identifies Reasoning Limits in Language Models"], "n-back tasks big-bench hard  tasks disambiguation qa sports understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "big-bench hard  tasks disambiguation qa sports understanding movie recommendation": ["Working Memory Identifies Reasoning Limits in Language Models"], "disambiguation qa sports understanding movie recommendation ruin names": ["Working Memory Identifies Reasoning Limits in Language Models"], "sports understanding movie recommendation ruin names salient translation error detection": ["Working Memory Identifies Reasoning Limits in Language Models"], "movie recommendation ruin names salient translation error detection causal judgement": ["Working Memory Identifies Reasoning Limits in Language Models"], "ruin names salient translation error detection causal judgement date understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "salient translation error detection causal judgement date understanding object counting": ["Working Memory Identifies Reasoning Limits in Language Models"], "n-back tasks big-bench hard  tasks disambiguation qa sports understanding movie recommendation": ["Working Memory Identifies Reasoning Limits in Language Models"], "big-bench hard  tasks disambiguation qa sports understanding movie recommendation ruin names": ["Working Memory Identifies Reasoning Limits in Language Models"], "disambiguation qa sports understanding movie recommendation ruin names salient translation error detection": ["Working Memory Identifies Reasoning Limits in Language Models"], "sports understanding movie recommendation ruin names salient translation error detection causal judgement": ["Working Memory Identifies Reasoning Limits in Language Models"], "movie recommendation ruin names salient translation error detection causal judgement date understanding": ["Working Memory Identifies Reasoning Limits in Language Models"], "ruin names salient translation error detection causal judgement date understanding object counting": ["Working Memory Identifies Reasoning Limits in Language Models"], "LLM detection": ["RAFT: Realistic Attacks to Fool Text Detectors", "On the Generalization of Training-based ChatGPT Detection Methods"], "text perturbation": ["RAFT: Realistic Attacks to Fool Text Detectors"], "LLM detection adversarial attack": ["RAFT: Realistic Attacks to Fool Text Detectors"], "adversarial attack text perturbation": ["RAFT: Realistic Attacks to Fool Text Detectors"], "LLM detection adversarial attack text perturbation": ["RAFT: Realistic Attacks to Fool Text Detectors"], "multi-turn interaction capabilities": ["LLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks"], "language understanding math problem solving": ["LLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks"], "math problem solving multi-turn interaction capabilities": ["LLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks"], "language understanding math problem solving multi-turn interaction capabilities": ["LLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks"], "factoid-qa": ["FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping"], "factoid-qa multi-turn conversation": ["FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping"], "multi-turn conversation text summarization": ["FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping"], "factoid-qa multi-turn conversation text summarization": ["FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping"], "code-switched text generation": ["LLM-based Code-Switched Text Generation for Grammatical Error Correction"], "grammatical error correction code-switched text generation": ["LLM-based Code-Switched Text Generation for Grammatical Error Correction"], "knowledge-intensive tasks question answering": ["Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models"], "document vqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "chart vqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "infographic vqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-2-plus": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-img": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mmstar": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "hallusionbench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "ai2d": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mathvista-testmini": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "llava-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "parsing-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "document vqa chart vqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "chart vqa infographic vqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "infographic vqa seed-2-plus": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-2-plus seed-img": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-img mmstar": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mmstar scienceqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "scienceqa hallusionbench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "hallusionbench ai2d": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "ai2d mathvista-testmini": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mathvista-testmini llava-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "llava-bench parsing-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "document vqa chart vqa infographic vqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "chart vqa infographic vqa seed-2-plus": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "infographic vqa seed-2-plus seed-img": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-2-plus seed-img mmstar": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-img mmstar scienceqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mmstar scienceqa hallusionbench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "scienceqa hallusionbench ai2d": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "hallusionbench ai2d mathvista-testmini": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "ai2d mathvista-testmini llava-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mathvista-testmini llava-bench parsing-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "document vqa chart vqa infographic vqa seed-2-plus": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "chart vqa infographic vqa seed-2-plus seed-img": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "infographic vqa seed-2-plus seed-img mmstar": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-2-plus seed-img mmstar scienceqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-img mmstar scienceqa hallusionbench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mmstar scienceqa hallusionbench ai2d": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "scienceqa hallusionbench ai2d mathvista-testmini": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "hallusionbench ai2d mathvista-testmini llava-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "ai2d mathvista-testmini llava-bench parsing-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "document vqa chart vqa infographic vqa seed-2-plus seed-img": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "chart vqa infographic vqa seed-2-plus seed-img mmstar": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "infographic vqa seed-2-plus seed-img mmstar scienceqa": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-2-plus seed-img mmstar scienceqa hallusionbench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "seed-img mmstar scienceqa hallusionbench ai2d": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "mmstar scienceqa hallusionbench ai2d mathvista-testmini": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "scienceqa hallusionbench ai2d mathvista-testmini llava-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "hallusionbench ai2d mathvista-testmini llava-bench parsing-bench": ["On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning"], "instruction generation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities", "Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues"], "community representation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "survey automation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "belief elicitation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "instruction generation language model alignment": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "language model alignment community representation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "community representation survey automation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "survey automation belief elicitation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "instruction generation language model alignment community representation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "language model alignment community representation survey automation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "community representation survey automation belief elicitation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "instruction generation language model alignment community representation survey automation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "language model alignment community representation survey automation belief elicitation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "instruction generation language model alignment community representation survey automation belief elicitation": ["COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"], "ruleset interpretation": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models"], "problem-solving": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models", "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models", "From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions", "The Effect of Sampling Temperature on Problem Solving in Large Language Models"], "mathematical reasoning ruleset interpretation": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models"], "ruleset interpretation planning": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models"], "planning problem-solving": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models"], "mathematical reasoning ruleset interpretation planning": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models"], "ruleset interpretation planning problem-solving": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models"], "mathematical reasoning ruleset interpretation planning problem-solving": ["Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models"], "quantitative spatial reasoning": ["Reasoning Paths with Reference Objects Elicit Quantitative Spatial Reasoning in Large Vision-Language Models"], "quantitative spatial reasoning visual question answering": ["Reasoning Paths with Reference Objects Elicit Quantitative Spatial Reasoning in Large Vision-Language Models"], "long-context language models": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "synthesis": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "long-context language models claim verification": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "claim verification reasoning": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "reasoning information retrieval": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "information retrieval synthesis": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "long-context language models claim verification reasoning": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "claim verification reasoning information retrieval": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "reasoning information retrieval synthesis": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "long-context language models claim verification reasoning information retrieval": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "claim verification reasoning information retrieval synthesis": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "long-context language models claim verification reasoning information retrieval synthesis": ["One Thousand and One Pairs: A \u201cnovel\u201d challenge for long-context language models"], "quality assessment": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "summarization quality": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "ai assistant evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "reward model evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "autorater bias reduction": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "task definition": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "evaluation instructions": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "text-to-text conversion": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "multitask training": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "quality assessment summarization quality": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "summarization quality ai assistant evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "ai assistant evaluation human preference alignment": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "human preference alignment reward model evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "reward model evaluation autorater bias reduction": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "autorater bias reduction task definition": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "task definition evaluation instructions": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "evaluation instructions text-to-text conversion": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "text-to-text conversion multitask training": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "quality assessment summarization quality ai assistant evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "summarization quality ai assistant evaluation human preference alignment": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "ai assistant evaluation human preference alignment reward model evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "human preference alignment reward model evaluation autorater bias reduction": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "reward model evaluation autorater bias reduction task definition": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "autorater bias reduction task definition evaluation instructions": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "task definition evaluation instructions text-to-text conversion": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "evaluation instructions text-to-text conversion multitask training": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "quality assessment summarization quality ai assistant evaluation human preference alignment": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "summarization quality ai assistant evaluation human preference alignment reward model evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "ai assistant evaluation human preference alignment reward model evaluation autorater bias reduction": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "human preference alignment reward model evaluation autorater bias reduction task definition": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "reward model evaluation autorater bias reduction task definition evaluation instructions": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "autorater bias reduction task definition evaluation instructions text-to-text conversion": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "task definition evaluation instructions text-to-text conversion multitask training": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "quality assessment summarization quality ai assistant evaluation human preference alignment reward model evaluation": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "summarization quality ai assistant evaluation human preference alignment reward model evaluation autorater bias reduction": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "ai assistant evaluation human preference alignment reward model evaluation autorater bias reduction task definition": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "human preference alignment reward model evaluation autorater bias reduction task definition evaluation instructions": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "reward model evaluation autorater bias reduction task definition evaluation instructions text-to-text conversion": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "autorater bias reduction task definition evaluation instructions text-to-text conversion multitask training": ["Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"], "syntactic evaluation": ["Do LLMs learn a true syntactic universal?"], "language modeling syntactic evaluation": ["Do LLMs learn a true syntactic universal?"], "dialogue generation summarization": ["GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets"], "ideological manipulation": ["How Susceptible are Large Language Models to Ideological Manipulation?"], "ideological manipulation instruction tuning": ["How Susceptible are Large Language Models to Ideological Manipulation?"], "evaluation of story quality": ["Measuring Psychological Depth in Language Models"], "psychological depth assessment": ["Measuring Psychological Depth in Language Models"], "story generation evaluation of story quality": ["Measuring Psychological Depth in Language Models"], "evaluation of story quality psychological depth assessment": ["Measuring Psychological Depth in Language Models"], "story generation evaluation of story quality psychological depth assessment": ["Measuring Psychological Depth in Language Models"], "media attitude detection": ["Media Attitude Detection via Framing Analysis with Events and their Relations"], "natural language processing sentiment analysis": ["Fill In The Gaps: Model Calibration and Generalization with Synthetic Data", "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "named entity recognition text classification": ["Fill In The Gaps: Model Calibration and Generalization with Synthetic Data", "GottBERT: a pure German Language Model"], "natural language processing sentiment analysis named entity recognition": ["Fill In The Gaps: Model Calibration and Generalization with Synthetic Data"], "sentiment analysis named entity recognition text classification": ["Fill In The Gaps: Model Calibration and Generalization with Synthetic Data"], "natural language processing sentiment analysis named entity recognition text classification": ["Fill In The Gaps: Model Calibration and Generalization with Synthetic Data"], "knowledge conflicts resolution": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "source citation generation": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "question answering knowledge conflicts resolution": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "knowledge conflicts resolution source citation generation": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "source citation generation multi-hop reasoning": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "question answering knowledge conflicts resolution source citation generation": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "knowledge conflicts resolution source citation generation multi-hop reasoning": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "source citation generation multi-hop reasoning reading comprehension": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "question answering knowledge conflicts resolution source citation generation multi-hop reasoning": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "knowledge conflicts resolution source citation generation multi-hop reasoning reading comprehension": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "question answering knowledge conflicts resolution source citation generation multi-hop reasoning reading comprehension": ["Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"], "image geolocation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "multimodal moderation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "conversational geolocation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "image geolocation privacy protection": ["Granular Privacy Control for Geolocation with Vision Language Models"], "privacy protection multimodal moderation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "multimodal moderation conversational geolocation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "image geolocation privacy protection multimodal moderation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "privacy protection multimodal moderation conversational geolocation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "image geolocation privacy protection multimodal moderation conversational geolocation": ["Granular Privacy Control for Geolocation with Vision Language Models"], "sentence readability assessment": ["MEDREADME: A Systematic Study for Fine-grained Sentence Readability in Medical Domain"], "complex span identification": ["MEDREADME: A Systematic Study for Fine-grained Sentence Readability in Medical Domain"], "sentence readability assessment complex span identification": ["MEDREADME: A Systematic Study for Fine-grained Sentence Readability in Medical Domain"], "detection of hate speech": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "classifying the targets of hate speech": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "classification of topical stance": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "detection of intended humor": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "detection of hate speech classifying the targets of hate speech": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "classifying the targets of hate speech classification of topical stance": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "classification of topical stance detection of intended humor": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "detection of hate speech classifying the targets of hate speech classification of topical stance": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "classifying the targets of hate speech classification of topical stance detection of intended humor": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "detection of hate speech classifying the targets of hate speech classification of topical stance detection of intended humor": ["MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification"], "rlhf": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization", "Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "dpo": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "constrained optimization": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "preference alignment rlhf": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "rlhf dpo": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "dpo constrained optimization": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "preference alignment rlhf dpo": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "rlhf dpo constrained optimization": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "preference alignment rlhf dpo constrained optimization": ["FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization"], "qa pair generation": ["StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning"], "story-based learning": ["StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning"], "knowledge infusion": ["StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning"], "qa pair generation story-based learning": ["StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning"], "story-based learning knowledge infusion": ["StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning"], "qa pair generation story-based learning knowledge infusion": ["StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning"], "conditional semantic textual similarity": ["Varying Sentence Representations via Condition-Specified Routers", "SEAVER: Attention Reallocation for Mitigating Distractions in Language Models for Conditional Semantic Textual Similarity Measurement"], "conditional semantic textual similarity knowledge graph completion": ["Varying Sentence Representations via Condition-Specified Routers"], "instruction generation answer generation": ["Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues"], "language model interpretation": ["Information Flow Routes: Automatically Interpreting Language Models at Scale"], "model analysis": ["Information Flow Routes: Automatically Interpreting Language Models at Scale"], "language model interpretation model analysis": ["Information Flow Routes: Automatically Interpreting Language Models at Scale"], "model analysis mechanistic interpretability": ["Information Flow Routes: Automatically Interpreting Language Models at Scale"], "language model interpretation model analysis mechanistic interpretability": ["Information Flow Routes: Automatically Interpreting Language Models at Scale"], "chinese spelling correction": ["A Simple yet Effective Training-free Prompt-free Approach to Chinese Spelling Correction Based on Large Language Models"], "in-context entity tracking": ["Representational Analysis of Binding in Language Models"], "attribute prediction": ["Representational Analysis of Binding in Language Models"], "entity tracking in-context entity tracking": ["Representational Analysis of Binding in Language Models"], "in-context entity tracking attribute prediction": ["Representational Analysis of Binding in Language Models"], "entity tracking in-context entity tracking attribute prediction": ["Representational Analysis of Binding in Language Models"], "dialogue coreference": ["CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference"], "LLM safety evaluation": ["CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference", "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"], "dialogue coreference LLM safety evaluation": ["CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference"], "LLM safety evaluation red teaming": ["CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference"], "dialogue coreference LLM safety evaluation red teaming": ["CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference"], "benchmarking": ["ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures", "NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition", "FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents", "A Recipe to Train Powerful Romanian LLMs with English Instructions", "Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks", "BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "information retrieval dataset creation": ["ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures"], "dataset creation benchmarking": ["ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures"], "information retrieval dataset creation benchmarking": ["ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures"], "few-shot relation learning": ["Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs"], "few-shot relation learning knowledge graph completion": ["Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs"], "multimodal intent detection": ["Dual-oriented Disentangled Network with Counterfactual Intervention for Multimodal Intent Detection"], "jailbreak attack jailbreak defense": ["From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking"], "constraint satisfaction": ["Symbolic Working Memory Enhances Language Models for Complex Rule Application", "LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "object state tracking": ["Symbolic Working Memory Enhances Language Models for Complex Rule Application"], "logical reasoning constraint satisfaction": ["Symbolic Working Memory Enhances Language Models for Complex Rule Application"], "constraint satisfaction object state tracking": ["Symbolic Working Memory Enhances Language Models for Complex Rule Application"], "logical reasoning constraint satisfaction object state tracking": ["Symbolic Working Memory Enhances Language Models for Complex Rule Application"], "context compression": ["LLOCO: Learning Long Contexts Offline", "COMPACT: Compressing Retrieved Documents Actively for Question Answering", "In-Context Former: Lightning-fast Compressing Context for Large Language Model"], "parameter-efficient finetuning": ["LLOCO: Learning Long Contexts Offline"], "long document question answering context compression": ["LLOCO: Learning Long Contexts Offline"], "context compression parameter-efficient finetuning": ["LLOCO: Learning Long Contexts Offline"], "long document question answering context compression parameter-efficient finetuning": ["LLOCO: Learning Long Contexts Offline"], "ai assistant": ["Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration", "Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "ai assistant summarization": ["Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration"], "commonsenseqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "tracking shuffled objects": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Tree of Problems: Improving structured problem solving with compositionality"], "last letter concatenation": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Tree of Problems: Improving structured problem solving with compositionality", "Skills-in-Context: Unlocking Compositionality in Large Language Models"], "arithmetic reasoning logical reasoning": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "logical reasoning symbolic reasoning": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners", "Learning to Plan by Updating Natural Language"], "symbolic reasoning strategyqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "strategyqa commonsenseqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "commonsenseqa gsm8k": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "gsm8k asdiv": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "asdiv svamp": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "svamp tracking shuffled objects": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "tracking shuffled objects date understanding": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "date understanding last letter concatenation": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "commonsense reasoning arithmetic reasoning logical reasoning": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "arithmetic reasoning logical reasoning symbolic reasoning": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "logical reasoning symbolic reasoning strategyqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "symbolic reasoning strategyqa commonsenseqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "strategyqa commonsenseqa gsm8k": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "commonsenseqa gsm8k asdiv": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "gsm8k asdiv svamp": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "asdiv svamp tracking shuffled objects": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "svamp tracking shuffled objects date understanding": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "tracking shuffled objects date understanding last letter concatenation": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "commonsense reasoning arithmetic reasoning logical reasoning symbolic reasoning": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "arithmetic reasoning logical reasoning symbolic reasoning strategyqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "logical reasoning symbolic reasoning strategyqa commonsenseqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "symbolic reasoning strategyqa commonsenseqa gsm8k": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "strategyqa commonsenseqa gsm8k asdiv": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "commonsenseqa gsm8k asdiv svamp": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "gsm8k asdiv svamp tracking shuffled objects": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "asdiv svamp tracking shuffled objects date understanding": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "svamp tracking shuffled objects date understanding last letter concatenation": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "commonsense reasoning arithmetic reasoning logical reasoning symbolic reasoning strategyqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "arithmetic reasoning logical reasoning symbolic reasoning strategyqa commonsenseqa": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "logical reasoning symbolic reasoning strategyqa commonsenseqa gsm8k": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "symbolic reasoning strategyqa commonsenseqa gsm8k asdiv": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "strategyqa commonsenseqa gsm8k asdiv svamp": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "commonsenseqa gsm8k asdiv svamp tracking shuffled objects": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "gsm8k asdiv svamp tracking shuffled objects date understanding": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "asdiv svamp tracking shuffled objects date understanding last letter concatenation": ["Mentor-KD: Making Small Language Models Better Multi-step Reasoners"], "storytelling": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "discourse understanding": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "story arc identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "turning point identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "narrative analysis storytelling": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "storytelling discourse understanding": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "discourse understanding story arc identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "story arc identification turning point identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "narrative analysis storytelling discourse understanding": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "storytelling discourse understanding story arc identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "discourse understanding story arc identification turning point identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "narrative analysis storytelling discourse understanding story arc identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "storytelling discourse understanding story arc identification turning point identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "narrative analysis storytelling discourse understanding story arc identification turning point identification": ["Are Large Language Models Capable of Generating Human-Level Narratives?"], "conversational question-answering data generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic shift dialogue generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic segmentation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs", "Recent Trends in Linear Text Segmentation: A Survey", "Topic Modeling: Contextual Token Embeddings Are All You Need"], "topic shift detection": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "convqa response generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "conversational question-answering data generation topic shift dialogue generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic shift dialogue generation topic segmentation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic segmentation topic shift detection": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic shift detection convqa response generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "conversational question-answering data generation topic shift dialogue generation topic segmentation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic shift dialogue generation topic segmentation topic shift detection": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic segmentation topic shift detection convqa response generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "conversational question-answering data generation topic shift dialogue generation topic segmentation topic shift detection": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "topic shift dialogue generation topic segmentation topic shift detection convqa response generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "conversational question-answering data generation topic shift dialogue generation topic segmentation topic shift detection convqa response generation": ["MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"], "disease comorbidity prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease progression prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "graph analysis": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "healthcare prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease comorbidity prediction disease progression prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease progression prediction link prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "link prediction graph analysis": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "graph analysis healthcare prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease comorbidity prediction disease progression prediction link prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease progression prediction link prediction graph analysis": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "link prediction graph analysis healthcare prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease comorbidity prediction disease progression prediction link prediction graph analysis": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease progression prediction link prediction graph analysis healthcare prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "disease comorbidity prediction disease progression prediction link prediction graph analysis healthcare prediction": ["Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction"], "multimodal content generation": ["Searching for Best Practices in Retrieval-Augmented Generation"], "RAG knowledge-intensive tasks": ["Searching for Best Practices in Retrieval-Augmented Generation"], "knowledge-intensive tasks multimodal content generation": ["Searching for Best Practices in Retrieval-Augmented Generation"], "question answering RAG knowledge-intensive tasks": ["Searching for Best Practices in Retrieval-Augmented Generation"], "RAG knowledge-intensive tasks multimodal content generation": ["Searching for Best Practices in Retrieval-Augmented Generation"], "question answering RAG knowledge-intensive tasks multimodal content generation": ["Searching for Best Practices in Retrieval-Augmented Generation"], "moral foundations analysis": ["Moral Foundations of Large Language Models"], "downstream task evaluation": ["Moral Foundations of Large Language Models", "Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "political stance analysis": ["Moral Foundations of Large Language Models"], "moral foundations analysis bias detection": ["Moral Foundations of Large Language Models"], "bias detection prompt engineering": ["Moral Foundations of Large Language Models"], "prompt engineering downstream task evaluation": ["Moral Foundations of Large Language Models"], "downstream task evaluation political stance analysis": ["Moral Foundations of Large Language Models"], "moral foundations analysis bias detection prompt engineering": ["Moral Foundations of Large Language Models"], "bias detection prompt engineering downstream task evaluation": ["Moral Foundations of Large Language Models"], "prompt engineering downstream task evaluation political stance analysis": ["Moral Foundations of Large Language Models"], "moral foundations analysis bias detection prompt engineering downstream task evaluation": ["Moral Foundations of Large Language Models"], "bias detection prompt engineering downstream task evaluation political stance analysis": ["Moral Foundations of Large Language Models"], "moral foundations analysis bias detection prompt engineering downstream task evaluation political stance analysis": ["Moral Foundations of Large Language Models"], "low-resource languages analysis": ["The Zeno's Paradox of \u2018Low-Resource' Languages"], "counseling note generation": ["Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization"], "summarization counseling note generation": ["Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization"], "post-hoc attribution": ["Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition"], "answer decomposition": ["Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition"], "post-hoc attribution answer decomposition": ["Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition"], "answer decomposition question answering": ["Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition"], "post-hoc attribution answer decomposition question answering": ["Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition"], "hallucination analysis": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment", "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "generative caption enrichment": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment"], "image captioning bias analysis": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment"], "bias analysis hallucination analysis": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment"], "hallucination analysis generative caption enrichment": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment"], "image captioning bias analysis hallucination analysis": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment"], "bias analysis hallucination analysis generative caption enrichment": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment"], "image captioning bias analysis hallucination analysis generative caption enrichment": ["From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment"], "pruning": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging", "xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics", "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy"], "layer merging": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging"], "model compression pruning": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging", "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy"], "pruning layer merging": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging"], "layer merging knowledge alignment": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging"], "model compression pruning layer merging": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging"], "pruning layer merging knowledge alignment": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging"], "model compression pruning layer merging knowledge alignment": ["Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging"], "emoji generation": ["Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training"], "popularity prediction": ["Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training"], "sentiment analysis emoji generation": ["Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training"], "emoji generation popularity prediction": ["Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training"], "sentiment analysis emoji generation popularity prediction": ["Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training"], "contamination detection": ["Data Contamination Can Cross Language Barriers"], "multilingual language models": ["Data Contamination Can Cross Language Barriers", "Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models"], "contamination detection multilingual language models": ["Data Contamination Can Cross Language Barriers"], "multilingual language models transfer learning": ["Data Contamination Can Cross Language Barriers"], "transfer learning generalization": ["Data Contamination Can Cross Language Barriers"], "contamination detection multilingual language models transfer learning": ["Data Contamination Can Cross Language Barriers"], "multilingual language models transfer learning generalization": ["Data Contamination Can Cross Language Barriers"], "contamination detection multilingual language models transfer learning generalization": ["Data Contamination Can Cross Language Barriers"], "commonsense machine translation": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "counter-intuitive arithmetic reasoning": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "commonsense machine translation counter-intuitive arithmetic reasoning": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "counter-intuitive arithmetic reasoning natural language generation": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "natural language generation natural language understanding": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "commonsense machine translation counter-intuitive arithmetic reasoning natural language generation": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "counter-intuitive arithmetic reasoning natural language generation natural language understanding": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "commonsense machine translation counter-intuitive arithmetic reasoning natural language generation natural language understanding": ["Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"], "knowledge-intensive nlp tasks": ["Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"], "RAG knowledge-intensive nlp tasks": ["Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"], "knowledge-intensive nlp tasks question answering": ["Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"], "RAG knowledge-intensive nlp tasks question answering": ["Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"], "mental disorder detection": ["CURE: Context- and Uncertainty-Aware Mental Disorder Detection"], "click-through rate prediction": ["PepRec: Progressive Enhancement of Prompting for Recommendation"], "recommendation systems click-through rate prediction": ["PepRec: Progressive Enhancement of Prompting for Recommendation"], "visual question answering compositional generalization": ["In-Context Compositional Generalization for Large Vision-Language Models"], "re-ranking open-domain question answering": ["Improving Zero-shot LLM Re-Ranker with Risk Minimization"], "cross-modal understanding": ["Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory"], "visual hallucination mitigation": ["Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory"], "visual question answering cross-modal understanding": ["Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory"], "cross-modal understanding visual hallucination mitigation": ["Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory"], "visual question answering cross-modal understanding visual hallucination mitigation": ["Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory"], "multi-level sentence simplification": ["Label Confidence Weighted Learning for Target-level Sentence Simplification"], "navigate": ["Tree of Problems: Improving structured problem solving with compositionality", "Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "set intersection": ["Tree of Problems: Improving structured problem solving with compositionality"], "keyword counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "boolean expressions": ["Tree of Problems: Improving structured problem solving with compositionality"], "hyperbaton": ["Tree of Problems: Improving structured problem solving with compositionality"], "multi-step arithmetic two": ["Tree of Problems: Improving structured problem solving with compositionality"], "web of lies": ["Tree of Problems: Improving structured problem solving with compositionality", "Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "word sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "last letter concatenation navigate": ["Tree of Problems: Improving structured problem solving with compositionality"], "navigate sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "sorting set intersection": ["Tree of Problems: Improving structured problem solving with compositionality"], "set intersection keyword counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "keyword counting boolean expressions": ["Tree of Problems: Improving structured problem solving with compositionality"], "boolean expressions hyperbaton": ["Tree of Problems: Improving structured problem solving with compositionality"], "hyperbaton multi-step arithmetic two": ["Tree of Problems: Improving structured problem solving with compositionality"], "multi-step arithmetic two object counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "object counting tracking shuffled objects": ["Tree of Problems: Improving structured problem solving with compositionality"], "tracking shuffled objects web of lies": ["Tree of Problems: Improving structured problem solving with compositionality"], "web of lies word sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "word sorting coin flip": ["Tree of Problems: Improving structured problem solving with compositionality"], "last letter concatenation navigate sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "navigate sorting set intersection": ["Tree of Problems: Improving structured problem solving with compositionality"], "sorting set intersection keyword counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "set intersection keyword counting boolean expressions": ["Tree of Problems: Improving structured problem solving with compositionality"], "keyword counting boolean expressions hyperbaton": ["Tree of Problems: Improving structured problem solving with compositionality"], "boolean expressions hyperbaton multi-step arithmetic two": ["Tree of Problems: Improving structured problem solving with compositionality"], "hyperbaton multi-step arithmetic two object counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "multi-step arithmetic two object counting tracking shuffled objects": ["Tree of Problems: Improving structured problem solving with compositionality"], "object counting tracking shuffled objects web of lies": ["Tree of Problems: Improving structured problem solving with compositionality"], "tracking shuffled objects web of lies word sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "web of lies word sorting coin flip": ["Tree of Problems: Improving structured problem solving with compositionality"], "last letter concatenation navigate sorting set intersection": ["Tree of Problems: Improving structured problem solving with compositionality"], "navigate sorting set intersection keyword counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "sorting set intersection keyword counting boolean expressions": ["Tree of Problems: Improving structured problem solving with compositionality"], "set intersection keyword counting boolean expressions hyperbaton": ["Tree of Problems: Improving structured problem solving with compositionality"], "keyword counting boolean expressions hyperbaton multi-step arithmetic two": ["Tree of Problems: Improving structured problem solving with compositionality"], "boolean expressions hyperbaton multi-step arithmetic two object counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "hyperbaton multi-step arithmetic two object counting tracking shuffled objects": ["Tree of Problems: Improving structured problem solving with compositionality"], "multi-step arithmetic two object counting tracking shuffled objects web of lies": ["Tree of Problems: Improving structured problem solving with compositionality"], "object counting tracking shuffled objects web of lies word sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "tracking shuffled objects web of lies word sorting coin flip": ["Tree of Problems: Improving structured problem solving with compositionality"], "last letter concatenation navigate sorting set intersection keyword counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "navigate sorting set intersection keyword counting boolean expressions": ["Tree of Problems: Improving structured problem solving with compositionality"], "sorting set intersection keyword counting boolean expressions hyperbaton": ["Tree of Problems: Improving structured problem solving with compositionality"], "set intersection keyword counting boolean expressions hyperbaton multi-step arithmetic two": ["Tree of Problems: Improving structured problem solving with compositionality"], "keyword counting boolean expressions hyperbaton multi-step arithmetic two object counting": ["Tree of Problems: Improving structured problem solving with compositionality"], "boolean expressions hyperbaton multi-step arithmetic two object counting tracking shuffled objects": ["Tree of Problems: Improving structured problem solving with compositionality"], "hyperbaton multi-step arithmetic two object counting tracking shuffled objects web of lies": ["Tree of Problems: Improving structured problem solving with compositionality"], "multi-step arithmetic two object counting tracking shuffled objects web of lies word sorting": ["Tree of Problems: Improving structured problem solving with compositionality"], "object counting tracking shuffled objects web of lies word sorting coin flip": ["Tree of Problems: Improving structured problem solving with compositionality"], "gender bias analysis": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study", "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models"], "human-centered evaluation": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "post-editing": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "machine translation gender bias analysis": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "gender bias analysis human-centered evaluation": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "human-centered evaluation post-editing": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "machine translation gender bias analysis human-centered evaluation": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "gender bias analysis human-centered evaluation post-editing": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "machine translation gender bias analysis human-centered evaluation post-editing": ["What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study"], "document logical structuring": ["SEG2ACT: Global Context-aware Action Generation for Document Logical Structuring"], "calibration data selection": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "LLM pruning calibration data selection": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "calibration data selection downstream task evaluation": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "downstream task evaluation arithmetic reasoning": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "arithmetic reasoning natural language inference": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "natural language inference commonsense reasoning": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "LLM pruning calibration data selection downstream task evaluation": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "calibration data selection downstream task evaluation arithmetic reasoning": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "downstream task evaluation arithmetic reasoning natural language inference": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "arithmetic reasoning natural language inference commonsense reasoning": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "LLM pruning calibration data selection downstream task evaluation arithmetic reasoning": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "calibration data selection downstream task evaluation arithmetic reasoning natural language inference": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "downstream task evaluation arithmetic reasoning natural language inference commonsense reasoning": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "LLM pruning calibration data selection downstream task evaluation arithmetic reasoning natural language inference": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "calibration data selection downstream task evaluation arithmetic reasoning natural language inference commonsense reasoning": ["Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning"], "watermark robustness analysis": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "paraphrasing attack evaluation": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "green list estimation": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "reverse engineering watermarking": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "watermark detection evasion": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "watermark robustness analysis paraphrasing attack evaluation": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "paraphrasing attack evaluation green list estimation": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "green list estimation reverse engineering watermarking": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "reverse engineering watermarking watermark detection evasion": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "watermark robustness analysis paraphrasing attack evaluation green list estimation": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "paraphrasing attack evaluation green list estimation reverse engineering watermarking": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "green list estimation reverse engineering watermarking watermark detection evasion": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "watermark robustness analysis paraphrasing attack evaluation green list estimation reverse engineering watermarking": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "paraphrasing attack evaluation green list estimation reverse engineering watermarking watermark detection evasion": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "watermark robustness analysis paraphrasing attack evaluation green list estimation reverse engineering watermarking watermark detection evasion": ["Revisiting the Robustness of Watermarking to Paraphrasing Attacks"], "ontology expansion": ["A Survey of Ontology Expansion for Conversational Understanding"], "new intent discovery": ["A Survey of Ontology Expansion for Conversational Understanding"], "new slot-value discovery": ["A Survey of Ontology Expansion for Conversational Understanding"], "joint ontology expansion": ["A Survey of Ontology Expansion for Conversational Understanding"], "ontology expansion new intent discovery": ["A Survey of Ontology Expansion for Conversational Understanding"], "new intent discovery new slot-value discovery": ["A Survey of Ontology Expansion for Conversational Understanding"], "new slot-value discovery joint ontology expansion": ["A Survey of Ontology Expansion for Conversational Understanding"], "ontology expansion new intent discovery new slot-value discovery": ["A Survey of Ontology Expansion for Conversational Understanding"], "new intent discovery new slot-value discovery joint ontology expansion": ["A Survey of Ontology Expansion for Conversational Understanding"], "ontology expansion new intent discovery new slot-value discovery joint ontology expansion": ["A Survey of Ontology Expansion for Conversational Understanding"], "multiple choice evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "free response evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "calibration language modeling": ["Calibrating Language Models with Adaptive Temperature Scaling"], "language modeling natural language processing": ["Calibrating Language Models with Adaptive Temperature Scaling"], "natural language processing multiple choice evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "multiple choice evaluation free response evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "calibration language modeling natural language processing": ["Calibrating Language Models with Adaptive Temperature Scaling"], "language modeling natural language processing multiple choice evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "natural language processing multiple choice evaluation free response evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "calibration language modeling natural language processing multiple choice evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "language modeling natural language processing multiple choice evaluation free response evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "calibration language modeling natural language processing multiple choice evaluation free response evaluation": ["Calibrating Language Models with Adaptive Temperature Scaling"], "formal logic deduction": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "babi": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "glue benchmark": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation", "Stochastic Fine-Tuning of Language Models Using Masked Gradients"], "formal logic deduction babi": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "babi glue benchmark": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "glue benchmark mnli": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "formal logic deduction babi glue benchmark": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "babi glue benchmark mnli": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "glue benchmark mnli qnli": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "formal logic deduction babi glue benchmark mnli": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "babi glue benchmark mnli qnli": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "glue benchmark mnli qnli rte": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "formal logic deduction babi glue benchmark mnli qnli": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "babi glue benchmark mnli qnli rte": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "glue benchmark mnli qnli rte mrpc": ["Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?"], "word informativeness measurement": ["Why do objects have many names? A study on word informativeness in language use and lexical systems"], "lexical system analysis": ["Why do objects have many names? A study on word informativeness in language use and lexical systems"], "contextual adaptation analysis": ["Why do objects have many names? A study on word informativeness in language use and lexical systems"], "word informativeness measurement lexical system analysis": ["Why do objects have many names? A study on word informativeness in language use and lexical systems"], "lexical system analysis contextual adaptation analysis": ["Why do objects have many names? A study on word informativeness in language use and lexical systems"], "word informativeness measurement lexical system analysis contextual adaptation analysis": ["Why do objects have many names? A study on word informativeness in language use and lexical systems"], "knowledge distillation instruction following": ["Dual-Space Knowledge Distillation for Large Language Models"], "noise-robust learning": ["NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"], "named entity recognition noise-robust learning": ["NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"], "noise-robust learning benchmarking": ["NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"], "benchmarking error analysis": ["NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"], "named entity recognition noise-robust learning benchmarking": ["NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"], "noise-robust learning benchmarking error analysis": ["NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"], "named entity recognition noise-robust learning benchmarking error analysis": ["NOISEBENCH: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"], "truthfulness probing": ["On the Universal Truthfulness Hyperplane Inside LLMS"], "truthfulness probing hallucination detection": ["On the Universal Truthfulness Hyperplane Inside LLMS"], "dense retrieval knowledge distillation": ["PAIRDISTILL: Pairwise Relevance Distillation for Dense Retrieval"], "user inference": ["User Inference Attacks on Large Language Models"], "instruction fine-tuning": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy", "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "LongAlign: A Recipe for Long Context Alignment of Large Language Models", "Revisiting Catastrophic Forgetting in Large Language Model Tuning", "LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"], "instruction fine-tuning classification": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "generation question answering": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "question answering inference": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "instruction fine-tuning classification generation": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "classification generation question answering": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "generation question answering inference": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "instruction fine-tuning classification generation question answering": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "classification generation question answering inference": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "instruction fine-tuning classification generation question answering inference": ["HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy"], "object hallucination detection": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization"], "autonomous agents": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "object hallucination detection image captioning": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "visual grounding autonomous agents": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "object hallucination detection image captioning visual question answering": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "image captioning visual question answering visual grounding": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "visual question answering visual grounding autonomous agents": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "object hallucination detection image captioning visual question answering visual grounding": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "image captioning visual question answering visual grounding autonomous agents": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "object hallucination detection image captioning visual question answering visual grounding autonomous agents": ["Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models"], "simultaneous translation": ["Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in Fine-tuning LLMs for Simultaneous Translation"], "tool-augmented LLMs": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "multi-granularity instruction following": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "path planning": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback", "LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning"], "feedback mechanism": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "task completion": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback", "Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "tool-augmented LLMs multi-granularity instruction following": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "multi-granularity instruction following path planning": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "path planning feedback mechanism": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "feedback mechanism task completion": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "tool-augmented LLMs multi-granularity instruction following path planning": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "multi-granularity instruction following path planning feedback mechanism": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "path planning feedback mechanism task completion": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "tool-augmented LLMs multi-granularity instruction following path planning feedback mechanism": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "multi-granularity instruction following path planning feedback mechanism task completion": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "tool-augmented LLMs multi-granularity instruction following path planning feedback mechanism task completion": ["ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback"], "offensive speech identification": ["Please note that I'm just an AI: Analysis of Behavior Patterns of LLMs in (Non-)offensive Speech Identification"], "probability estimation": ["How to Compute the Probability of a Word"], "sentence comprehension": ["How to Compute the Probability of a Word"], "lexical optimisation": ["How to Compute the Probability of a Word"], "language modeling probability estimation": ["How to Compute the Probability of a Word"], "probability estimation sentence comprehension": ["How to Compute the Probability of a Word"], "sentence comprehension lexical optimisation": ["How to Compute the Probability of a Word"], "language modeling probability estimation sentence comprehension": ["How to Compute the Probability of a Word"], "probability estimation sentence comprehension lexical optimisation": ["How to Compute the Probability of a Word"], "language modeling probability estimation sentence comprehension lexical optimisation": ["How to Compute the Probability of a Word"], "guardrail model evaluation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "safety classification": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "prompt moderation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "conversation moderation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "guardrail model evaluation safety classification": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "safety classification prompt moderation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "prompt moderation conversation moderation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "conversation moderation multilingual evaluation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "guardrail model evaluation safety classification prompt moderation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "safety classification prompt moderation conversation moderation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "prompt moderation conversation moderation multilingual evaluation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "guardrail model evaluation safety classification prompt moderation conversation moderation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "safety classification prompt moderation conversation moderation multilingual evaluation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "guardrail model evaluation safety classification prompt moderation conversation moderation multilingual evaluation": ["GuardBench: A Large-Scale Benchmark for Guardrail Models"], "incomplete knowledge graph": ["Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering"], "knowledge graph question answering incomplete knowledge graph": ["Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering"], "incomplete knowledge graph question answering": ["Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering"], "knowledge graph question answering incomplete knowledge graph question answering": ["Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering"], "brain alignment": ["Language models and brains align due to more than next-word prediction and word-level information"], "next-word prediction": ["Language models and brains align due to more than next-word prediction and word-level information"], "fmri analysis": ["Language models and brains align due to more than next-word prediction and word-level information"], "brain alignment language modeling": ["Language models and brains align due to more than next-word prediction and word-level information"], "language modeling next-word prediction": ["Language models and brains align due to more than next-word prediction and word-level information"], "next-word prediction fmri analysis": ["Language models and brains align due to more than next-word prediction and word-level information"], "brain alignment language modeling next-word prediction": ["Language models and brains align due to more than next-word prediction and word-level information"], "language modeling next-word prediction fmri analysis": ["Language models and brains align due to more than next-word prediction and word-level information"], "brain alignment language modeling next-word prediction fmri analysis": ["Language models and brains align due to more than next-word prediction and word-level information"], "emotional clustering": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "domain-specific scenarios": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "text clustering topic modeling": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "topic modeling information retrieval": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "information retrieval intent classification": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "intent classification topic modeling": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "topic modeling emotional clustering": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "emotional clustering domain-specific scenarios": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "text clustering topic modeling information retrieval": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "topic modeling information retrieval intent classification": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "information retrieval intent classification topic modeling": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "intent classification topic modeling emotional clustering": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "topic modeling emotional clustering domain-specific scenarios": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "text clustering topic modeling information retrieval intent classification": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "topic modeling information retrieval intent classification topic modeling": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "information retrieval intent classification topic modeling emotional clustering": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "intent classification topic modeling emotional clustering domain-specific scenarios": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "text clustering topic modeling information retrieval intent classification topic modeling": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "topic modeling information retrieval intent classification topic modeling emotional clustering": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "information retrieval intent classification topic modeling emotional clustering domain-specific scenarios": ["LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement"], "argument component detection": ["CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "medical question answering argument mining": ["CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "argument mining argument component detection": ["CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "argument component detection sequence labeling": ["CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "medical question answering argument mining argument component detection": ["CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "argument mining argument component detection sequence labeling": ["CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "medical question answering argument mining argument component detection sequence labeling": ["CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"], "language modelling needle-in-a-haystack": ["A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression"], "needle-in-a-haystack passkey retrieval": ["A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression"], "language modelling needle-in-a-haystack passkey retrieval": ["A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression"], "figurative language illustration": ["GOME: Grounding-based Metaphor Binding With Conceptual Elaboration For Figurative Language Illustration"], "metaphor visualization": ["GOME: Grounding-based Metaphor Binding With Conceptual Elaboration For Figurative Language Illustration"], "figurative language illustration metaphor visualization": ["GOME: Grounding-based Metaphor Binding With Conceptual Elaboration For Figurative Language Illustration"], "offensiveness detection and evaluation": ["D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation"], "audio recognition": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "instrument classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "vocal sound classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "surveillance sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "acoustic scene classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "music analysis": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "audio recognition instrument classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "instrument classification sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "sound event classification emotion recognition": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "emotion recognition vocal sound classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "vocal sound classification surveillance sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "surveillance sound event classification acoustic scene classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "acoustic scene classification music analysis": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "audio recognition instrument classification sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "instrument classification sound event classification emotion recognition": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "sound event classification emotion recognition vocal sound classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "emotion recognition vocal sound classification surveillance sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "vocal sound classification surveillance sound event classification acoustic scene classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "surveillance sound event classification acoustic scene classification music analysis": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "audio recognition instrument classification sound event classification emotion recognition": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "instrument classification sound event classification emotion recognition vocal sound classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "sound event classification emotion recognition vocal sound classification surveillance sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "emotion recognition vocal sound classification surveillance sound event classification acoustic scene classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "vocal sound classification surveillance sound event classification acoustic scene classification music analysis": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "audio recognition instrument classification sound event classification emotion recognition vocal sound classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "instrument classification sound event classification emotion recognition vocal sound classification surveillance sound event classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "sound event classification emotion recognition vocal sound classification surveillance sound event classification acoustic scene classification": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "emotion recognition vocal sound classification surveillance sound event classification acoustic scene classification music analysis": ["PALM: Few-Shot Prompt Learning for Audio Language Models"], "annotator selection": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "subjective nlp tasks": ["Annotator-Centric Active Learning for Subjective NLP Tasks", "Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "moral value classification": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "safety judgments": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "active learning annotator selection": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "annotator selection subjective nlp tasks": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "subjective nlp tasks hate speech detection": ["Annotator-Centric Active Learning for Subjective NLP Tasks", "Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "hate speech detection moral value classification": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "moral value classification safety judgments": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "active learning annotator selection subjective nlp tasks": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "annotator selection subjective nlp tasks hate speech detection": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "subjective nlp tasks hate speech detection moral value classification": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "hate speech detection moral value classification safety judgments": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "active learning annotator selection subjective nlp tasks hate speech detection": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "annotator selection subjective nlp tasks hate speech detection moral value classification": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "subjective nlp tasks hate speech detection moral value classification safety judgments": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "active learning annotator selection subjective nlp tasks hate speech detection moral value classification": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "annotator selection subjective nlp tasks hate speech detection moral value classification safety judgments": ["Annotator-Centric Active Learning for Subjective NLP Tasks"], "eye-tracking data analysis": ["On the Proper Treatment of Tokenization in Psycholinguistics"], "skip rate prediction": ["On the Proper Treatment of Tokenization in Psycholinguistics"], "eye-tracking data analysis reading time prediction": ["On the Proper Treatment of Tokenization in Psycholinguistics"], "reading time prediction skip rate prediction": ["On the Proper Treatment of Tokenization in Psycholinguistics"], "eye-tracking data analysis reading time prediction skip rate prediction": ["On the Proper Treatment of Tokenization in Psycholinguistics"], "jailbreak attacks on LLMs": ["Jailbreaking LLMs with Arabic Transliteration and Arabizi"], "stereotype detection bias analysis": ["Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models"], "bias analysis language modeling": ["Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models"], "stereotype detection bias analysis language modeling": ["Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models"], "instruction tuning task selection": ["Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"], "task selection zero-shot learning": ["Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"], "zero-shot learning generalization": ["Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"], "instruction tuning task selection zero-shot learning": ["Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"], "task selection zero-shot learning generalization": ["Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"], "instruction tuning task selection zero-shot learning generalization": ["Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"], "hierarchical text rating": ["Recurrent Alignment with Hard Attention for Hierarchical Text Rating"], "text rating": ["Recurrent Alignment with Hard Attention for Hierarchical Text Rating"], "hierarchical text rating text rating": ["Recurrent Alignment with Hard Attention for Hierarchical Text Rating"], "arc challenge": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "Instruction Fine-Tuning: Does Prompt Loss Matter?"], "arc easy": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "hellaswag": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "openbookqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "sci-q": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "winogrande": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "Instruction Fine-Tuning: Does Prompt Loss Matter?", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "arc challenge arc easy": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "arc easy boolq": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "boolq hellaswag": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "hellaswag openbookqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "openbookqa piqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "piqa sci-q": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "sci-q winogrande": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "arc challenge arc easy boolq": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "arc easy boolq hellaswag": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "boolq hellaswag openbookqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "hellaswag openbookqa piqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "openbookqa piqa sci-q": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "piqa sci-q winogrande": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "arc challenge arc easy boolq hellaswag": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "arc easy boolq hellaswag openbookqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "boolq hellaswag openbookqa piqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "hellaswag openbookqa piqa sci-q": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "openbookqa piqa sci-q winogrande": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "arc challenge arc easy boolq hellaswag openbookqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "arc easy boolq hellaswag openbookqa piqa": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "boolq hellaswag openbookqa piqa sci-q": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "hellaswag openbookqa piqa sci-q winogrande": ["CHESS : Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification"], "graph path-finding": ["Semformer: Transformer Language Models with Semantic Planning"], "language modeling graph path-finding": ["Semformer: Transformer Language Models with Semantic Planning"], "graph path-finding in-context learning": ["Semformer: Transformer Language Models with Semantic Planning"], "in-context learning text summarization": ["Semformer: Transformer Language Models with Semantic Planning"], "language modeling graph path-finding in-context learning": ["Semformer: Transformer Language Models with Semantic Planning"], "graph path-finding in-context learning text summarization": ["Semformer: Transformer Language Models with Semantic Planning"], "language modeling graph path-finding in-context learning text summarization": ["Semformer: Transformer Language Models with Semantic Planning"], "nl-to-code generation": ["DocCGen: Document-based Controlled Code Generation"], "structured code generation": ["DocCGen: Document-based Controlled Code Generation"], "nl-to-code generation structured code generation": ["DocCGen: Document-based Controlled Code Generation"], "emoji semantics": ["Semantics and Sentiment: Cross-lingual Variations in Emoji Use"], "emoji semantics sentiment analysis": ["Semantics and Sentiment: Cross-lingual Variations in Emoji Use"], "language emergence": ["The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations"], "compositionality analysis": ["The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations"], "multi-entity referential game": ["The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations"], "language emergence compositionality analysis": ["The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations"], "compositionality analysis multi-entity referential game": ["The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations"], "language emergence compositionality analysis multi-entity referential game": ["The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations"], "long range understanding": ["Transformers are Multi-State RNNS"], "language modeling long range understanding": ["Transformers are Multi-State RNNS"], "long range understanding text generation": ["Transformers are Multi-State RNNS"], "language modeling long range understanding text generation": ["Transformers are Multi-State RNNS"], "xstorycloze": ["Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization", "Exploring Design Choices for Building Language-Specific LLMs"], "xnli": ["Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization", "Exploring Design Choices for Building Language-Specific LLMs"], "machine translation xstorycloze": ["Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization"], "xstorycloze xnli": ["Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization", "Exploring Design Choices for Building Language-Specific LLMs"], "machine translation xstorycloze xnli": ["Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization"], "generation natural language inference": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "sentiment analysis text classification": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "classification generation natural language inference": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "generation natural language inference sentiment analysis": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "natural language inference sentiment analysis text classification": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "classification generation natural language inference sentiment analysis": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "generation natural language inference sentiment analysis text classification": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "classification generation natural language inference sentiment analysis text classification": ["Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"], "long-form story generation": ["Collective Critics for Creative Story Generation", "SWAG: Storytelling With Action Guidance"], "surprisal prediction": ["Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse"], "abstractive summarization preference optimization": ["Model-based Preference Optimization in Abstractive Summarization without Human Feedback"], "preference optimization language model fine-tuning": ["Model-based Preference Optimization in Abstractive Summarization without Human Feedback"], "abstractive summarization preference optimization language model fine-tuning": ["Model-based Preference Optimization in Abstractive Summarization without Human Feedback"], "confidence calibration": ["Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?", "Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "named entity recognition uncertainty estimation": ["Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?"], "uncertainty estimation confidence calibration": ["Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?"], "named entity recognition uncertainty estimation confidence calibration": ["Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?"], "neurology": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "psychiatry": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "clinical trial summaries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "clinical trial registries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "named entity recognition neurology": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "neurology psychiatry": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "psychiatry clinical trial summaries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "clinical trial summaries clinical trial registries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "clinical trial registries data annotation": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "named entity recognition neurology psychiatry": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "neurology psychiatry clinical trial summaries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "psychiatry clinical trial summaries clinical trial registries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "clinical trial summaries clinical trial registries data annotation": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "named entity recognition neurology psychiatry clinical trial summaries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "neurology psychiatry clinical trial summaries clinical trial registries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "psychiatry clinical trial summaries clinical trial registries data annotation": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "named entity recognition neurology psychiatry clinical trial summaries clinical trial registries": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "neurology psychiatry clinical trial summaries clinical trial registries data annotation": ["NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries"], "chest x-ray analysis": ["Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"], "clinical decision support": ["Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"], "medical image analysis chest x-ray analysis": ["Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"], "chest x-ray analysis clinical decision support": ["Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"], "medical image analysis chest x-ray analysis clinical decision support": ["Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"], "knowledge graph explanation": ["Towards Faithful Knowledge Graph Explanation Through Deep Alignment in Commonsense Question Answering"], "commonsense question answering knowledge graph explanation": ["Towards Faithful Knowledge Graph Explanation Through Deep Alignment in Commonsense Question Answering"], "citation generation": ["Generation with Dynamic Vocabulary"], "language modeling domain adaptation": ["Generation with Dynamic Vocabulary", "Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?"], "domain adaptation citation generation": ["Generation with Dynamic Vocabulary"], "citation generation question answering": ["Generation with Dynamic Vocabulary"], "language modeling domain adaptation citation generation": ["Generation with Dynamic Vocabulary"], "domain adaptation citation generation question answering": ["Generation with Dynamic Vocabulary"], "language modeling domain adaptation citation generation question answering": ["Generation with Dynamic Vocabulary"], "discourse marker detection": ["Argument Relation Classification through Discourse Markers and Adversarial Training"], "argument relation classification discourse marker detection": ["Argument Relation Classification through Discourse Markers and Adversarial Training"], "morphological inflection": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "character-level sequence-to-sequence tasks": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "morphological inflection pretraining": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "pretraining multi-task learning": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "multi-task learning character-level sequence-to-sequence tasks": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "morphological inflection pretraining multi-task learning": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "pretraining multi-task learning character-level sequence-to-sequence tasks": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "morphological inflection pretraining multi-task learning character-level sequence-to-sequence tasks": ["Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection"], "query augmentation": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval", "A Semantic Search Engine for Mathlib4"], "document linking": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"], "information retrieval zero-shot learning": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"], "zero-shot learning query augmentation": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"], "query augmentation document linking": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"], "information retrieval zero-shot learning query augmentation": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"], "zero-shot learning query augmentation document linking": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"], "information retrieval zero-shot learning query augmentation document linking": ["Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"], "text classification cross-lingual transfer": ["Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models"], "cross-lingual transfer zero-shot learning": ["Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models"], "text classification cross-lingual transfer zero-shot learning": ["Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models"], "argumentative essay generation": ["Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation"], "multimodal reasoning": ["TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning", "CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models", "Improving Multi-Agent Debate with Sparse Communication Topology", "Large Language Models Are Challenged by Habitat-Centered Reasoning", "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "entailment tree generation": ["TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning"], "video question answering multimodal reasoning": ["TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning"], "multimodal reasoning entailment tree generation": ["TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning"], "video question answering multimodal reasoning entailment tree generation": ["TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning"], "dialogue policy extraction": ["Unsupervised Extraction of Dialogue Policies from Conversations"], "zero-shot temporal action localization": ["GRIZAL: Generative Prior-guided Zero-Shot Temporal Action Localization"], "vision-language compositionality": ["Preserving Multi-Modal Capabilities of Pre-trained VLMS for Improving Vision-Linguistic Compositionality"], "zero-shot recognition": ["Preserving Multi-Modal Capabilities of Pre-trained VLMS for Improving Vision-Linguistic Compositionality"], "vision-language compositionality zero-shot recognition": ["Preserving Multi-Modal Capabilities of Pre-trained VLMS for Improving Vision-Linguistic Compositionality"], "zero-shot recognition image-text retrieval": ["Preserving Multi-Modal Capabilities of Pre-trained VLMS for Improving Vision-Linguistic Compositionality"], "vision-language compositionality zero-shot recognition image-text retrieval": ["Preserving Multi-Modal Capabilities of Pre-trained VLMS for Improving Vision-Linguistic Compositionality"], "multi-image vqa": ["FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture"], "single-image vqa": ["FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture"], "text qa": ["FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture"], "multi-image vqa single-image vqa": ["FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture"], "single-image vqa text qa": ["FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture"], "multi-image vqa single-image vqa text qa": ["FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture"], "g2p": ["A Two-Step Approach for Data-Efficient French Pronunciation Learning"], "post-lexical processing": ["A Two-Step Approach for Data-Efficient French Pronunciation Learning"], "pronunciation learning": ["A Two-Step Approach for Data-Efficient French Pronunciation Learning"], "g2p post-lexical processing": ["A Two-Step Approach for Data-Efficient French Pronunciation Learning"], "post-lexical processing pronunciation learning": ["A Two-Step Approach for Data-Efficient French Pronunciation Learning"], "g2p post-lexical processing pronunciation learning": ["A Two-Step Approach for Data-Efficient French Pronunciation Learning"], "consistency analysis of semantic axes in multilingual embeddings": ["Exploring Intra and Inter-language Consistency in Embeddings with ICA"], "connective language detection": ["Comparing a BERT Classifier and a GPT classifier for Detecting Connective Language Across Multiple Social Media"], "language modeling question answering": ["ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models"], "language modeling question answering in-context learning": ["ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models"], "mental health condition classification": ["Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health"], "mental health condition classification emotion recognition": ["Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health"], "speech emotion recognition": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "empathetic response generation": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "speech emotion recognition empathetic response generation": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "empathetic response generation instruction following": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "instruction following conversation": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "speech emotion recognition empathetic response generation instruction following": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "empathetic response generation instruction following conversation": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "speech emotion recognition empathetic response generation instruction following conversation": ["BLSP-Emo: Towards Empathetic Large Speech-Language Models"], "dataset synthesis": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "teacher-student distillation": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "tone detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "text classification dataset synthesis": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "dataset synthesis teacher-student distillation": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "teacher-student distillation topic classification": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "sentiment analysis tone detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "tone detection humor detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "text classification dataset synthesis teacher-student distillation": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "dataset synthesis teacher-student distillation topic classification": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "teacher-student distillation topic classification sentiment analysis": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "topic classification sentiment analysis tone detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "sentiment analysis tone detection humor detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "text classification dataset synthesis teacher-student distillation topic classification": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "dataset synthesis teacher-student distillation topic classification sentiment analysis": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "teacher-student distillation topic classification sentiment analysis tone detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "topic classification sentiment analysis tone detection humor detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "text classification dataset synthesis teacher-student distillation topic classification sentiment analysis": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "dataset synthesis teacher-student distillation topic classification sentiment analysis tone detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "teacher-student distillation topic classification sentiment analysis tone detection humor detection": ["SYNTHESIZRR: Generating Diverse Datasets with Retrieval Augmentation"], "abstract image understanding": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "spatial relations reasoning": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual element induction": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "chart interpretation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "map navigation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual puzzles": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "mathematical geometry problems": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "abstract image understanding visual reasoning": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual reasoning spatial relations reasoning": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "spatial relations reasoning visual element induction": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual element induction chart interpretation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "chart interpretation map navigation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "map navigation visual puzzles": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual puzzles mathematical geometry problems": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "abstract image understanding visual reasoning spatial relations reasoning": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual reasoning spatial relations reasoning visual element induction": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "spatial relations reasoning visual element induction chart interpretation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual element induction chart interpretation map navigation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "chart interpretation map navigation visual puzzles": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "map navigation visual puzzles mathematical geometry problems": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "abstract image understanding visual reasoning spatial relations reasoning visual element induction": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual reasoning spatial relations reasoning visual element induction chart interpretation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "spatial relations reasoning visual element induction chart interpretation map navigation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual element induction chart interpretation map navigation visual puzzles": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "chart interpretation map navigation visual puzzles mathematical geometry problems": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "abstract image understanding visual reasoning spatial relations reasoning visual element induction chart interpretation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual reasoning spatial relations reasoning visual element induction chart interpretation map navigation": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "spatial relations reasoning visual element induction chart interpretation map navigation visual puzzles": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "visual element induction chart interpretation map navigation visual puzzles mathematical geometry problems": ["Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"], "data story generation": ["DATANARRATIVE: Automated Data-Driven Storytelling with Visualizations and Texts"], "multi-task fine tuning": ["DEM: Distribution Edited Model for Training with Mixed Data Distributions"], "multi-task fine tuning instruction following": ["DEM: Distribution Edited Model for Training with Mixed Data Distributions"], "zero-shot image classification": ["Altogether: Image Captioning via Re-aligning Alt-text"], "image captioning text-to-image generation": ["Altogether: Image Captioning via Re-aligning Alt-text"], "text-to-image generation zero-shot image classification": ["Altogether: Image Captioning via Re-aligning Alt-text"], "zero-shot image classification image retrieval": ["Altogether: Image Captioning via Re-aligning Alt-text"], "image captioning text-to-image generation zero-shot image classification": ["Altogether: Image Captioning via Re-aligning Alt-text"], "text-to-image generation zero-shot image classification image retrieval": ["Altogether: Image Captioning via Re-aligning Alt-text"], "image captioning text-to-image generation zero-shot image classification image retrieval": ["Altogether: Image Captioning via Re-aligning Alt-text"], "step order prediction": ["CAT-BENCH: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans"], "step order prediction causal reasoning": ["CAT-BENCH: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans"], "causal reasoning temporal reasoning": ["CAT-BENCH: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans"], "step order prediction causal reasoning temporal reasoning": ["CAT-BENCH: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans"], "style analysis": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "persona-assigned LLMs": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "stylometry": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "style analysis persona-assigned LLMs": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "persona-assigned LLMs text generation": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "text generation stylometry": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "style analysis persona-assigned LLMs text generation": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "persona-assigned LLMs text generation stylometry": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "style analysis persona-assigned LLMs text generation stylometry": ["An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs"], "robotic manipulation": ["Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks"], "robotic manipulation generalization": ["Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks"], "generalization instruction following": ["Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks"], "robotic manipulation generalization instruction following": ["Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks"], "document question answering": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "query-based summarization": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "natural questions": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "narrativeqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "quality": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "qmsum": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "document question answering multiple-choice question answering": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "multiple-choice question answering query-based summarization": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "query-based summarization natural questions": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "natural questions triviaqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "triviaqa narrativeqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "narrativeqa qasper": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "qasper quality": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "quality qmsum": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "document question answering multiple-choice question answering query-based summarization": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "multiple-choice question answering query-based summarization natural questions": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "query-based summarization natural questions triviaqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "natural questions triviaqa narrativeqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "triviaqa narrativeqa qasper": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "narrativeqa qasper quality": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "qasper quality qmsum": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "document question answering multiple-choice question answering query-based summarization natural questions": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "multiple-choice question answering query-based summarization natural questions triviaqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "query-based summarization natural questions triviaqa narrativeqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "natural questions triviaqa narrativeqa qasper": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "triviaqa narrativeqa qasper quality": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "narrativeqa qasper quality qmsum": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "document question answering multiple-choice question answering query-based summarization natural questions triviaqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "multiple-choice question answering query-based summarization natural questions triviaqa narrativeqa": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "query-based summarization natural questions triviaqa narrativeqa qasper": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "natural questions triviaqa narrativeqa qasper quality": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "triviaqa narrativeqa qasper quality qmsum": ["GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"], "api function calling": ["Sequential API Function Calling Using GraphQL Schema"], "explanation": ["The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems", "Computational Meme Understanding: A Survey", "Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "visual question answering explanation": ["The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems"], "spatio-temporal video grounding": ["Video-Text Prompting for Weakly Supervised Spatio-Temporal Video Grounding"], "discontinuous named-entity recognition": ["A Fast and Sound Tagging Method for Discontinuous Named-Entity Recognition"], "factuality evaluation": ["Factuality of Large Language Models: A Survey", "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation"], "knowledge grounding": ["Factuality of Large Language Models: A Survey"], "factuality evaluation hallucination detection": ["Factuality of Large Language Models: A Survey"], "hallucination detection knowledge grounding": ["Factuality of Large Language Models: A Survey"], "knowledge grounding open-ended generation": ["Factuality of Large Language Models: A Survey"], "factuality evaluation hallucination detection knowledge grounding": ["Factuality of Large Language Models: A Survey"], "hallucination detection knowledge grounding open-ended generation": ["Factuality of Large Language Models: A Survey"], "factuality evaluation hallucination detection knowledge grounding open-ended generation": ["Factuality of Large Language Models: A Survey"], "model explanation": ["Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation"], "information retrieval model explanation": ["Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation"], "model explanation bias detection": ["Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation"], "information retrieval model explanation bias detection": ["Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation"], "explainable detection of online sexism": ["Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"], "model improvement": ["DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers"], "text classification error analysis": ["DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers"], "error analysis model improvement": ["DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers"], "text classification error analysis model improvement": ["DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers"], "base-to-novel class generalization": ["IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning"], "domain generalization": ["IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning", "Scalable and Domain-General Abstractive Proposition Segmentation"], "base-to-novel class generalization domain generalization": ["IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning"], "drt parsing": ["Scope-enhanced Compositional Semantic Parsing for DRT"], "drt parsing semantic parsing": ["Scope-enhanced Compositional Semantic Parsing for DRT"], "value alignment": ["The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models", "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models", "LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models"], "value alignment bias detection": ["The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models"], "longitudinal stance switch detection": ["TempoFormer: A Transformer for Temporally-aware Representations in Change Detection"], "moments of change": ["TempoFormer: A Transformer for Temporally-aware Representations in Change Detection"], "conversation topic shift": ["TempoFormer: A Transformer for Temporally-aware Representations in Change Detection"], "longitudinal stance switch detection moments of change": ["TempoFormer: A Transformer for Temporally-aware Representations in Change Detection"], "moments of change conversation topic shift": ["TempoFormer: A Transformer for Temporally-aware Representations in Change Detection"], "longitudinal stance switch detection moments of change conversation topic shift": ["TempoFormer: A Transformer for Temporally-aware Representations in Change Detection"], "creative writing": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "ai vs human evaluation": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "literary criticism": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "creative writing text generation": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "text generation ai vs human evaluation": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "ai vs human evaluation literary criticism": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "creative writing text generation ai vs human evaluation": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "text generation ai vs human evaluation literary criticism": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "creative writing text generation ai vs human evaluation literary criticism": ["Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"], "poetry generation": ["Evaluating Diversity in Automatic Poetry Generation"], "diversity evaluation": ["Evaluating Diversity in Automatic Poetry Generation"], "poetry generation diversity evaluation": ["Evaluating Diversity in Automatic Poetry Generation"], "diversity evaluation natural language generation": ["Evaluating Diversity in Automatic Poetry Generation"], "poetry generation diversity evaluation natural language generation": ["Evaluating Diversity in Automatic Poetry Generation"], "social bias evaluation": ["Evaluating Short-Term Temporal Fluctuations of Social Biases in Social Media Data and Masked Language Models"], "referring expression generation": ["Grounding Language in Multi-Perspective Referential Communication"], "multi-agent interaction": ["Grounding Language in Multi-Perspective Referential Communication", "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions"], "embodied environment": ["Grounding Language in Multi-Perspective Referential Communication"], "spatial reasoning": ["Grounding Language in Multi-Perspective Referential Communication", "Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities", "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models", "Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation", "ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "referring expression generation referring expression comprehension": ["Grounding Language in Multi-Perspective Referential Communication"], "referring expression comprehension multi-agent interaction": ["Grounding Language in Multi-Perspective Referential Communication"], "multi-agent interaction embodied environment": ["Grounding Language in Multi-Perspective Referential Communication"], "embodied environment spatial reasoning": ["Grounding Language in Multi-Perspective Referential Communication"], "referring expression generation referring expression comprehension multi-agent interaction": ["Grounding Language in Multi-Perspective Referential Communication"], "referring expression comprehension multi-agent interaction embodied environment": ["Grounding Language in Multi-Perspective Referential Communication"], "multi-agent interaction embodied environment spatial reasoning": ["Grounding Language in Multi-Perspective Referential Communication"], "referring expression generation referring expression comprehension multi-agent interaction embodied environment": ["Grounding Language in Multi-Perspective Referential Communication"], "referring expression comprehension multi-agent interaction embodied environment spatial reasoning": ["Grounding Language in Multi-Perspective Referential Communication"], "referring expression generation referring expression comprehension multi-agent interaction embodied environment spatial reasoning": ["Grounding Language in Multi-Perspective Referential Communication"], "machine translation error analysis": ["Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation", "A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations"], "disinformation detection": ["MIPD: Exploring Manipulation and Intention in A Novel Corpus of Polish Disinformation", "EU DisinfoTest: a Benchmark for Evaluating Language Models' Ability to Detect Disinformation Narratives"], "manipulation techniques classification": ["MIPD: Exploring Manipulation and Intention in A Novel Corpus of Polish Disinformation"], "intention types classification": ["MIPD: Exploring Manipulation and Intention in A Novel Corpus of Polish Disinformation"], "disinformation detection manipulation techniques classification": ["MIPD: Exploring Manipulation and Intention in A Novel Corpus of Polish Disinformation"], "manipulation techniques classification intention types classification": ["MIPD: Exploring Manipulation and Intention in A Novel Corpus of Polish Disinformation"], "disinformation detection manipulation techniques classification intention types classification": ["MIPD: Exploring Manipulation and Intention in A Novel Corpus of Polish Disinformation"], "fingerspelling tokenization": ["Unsupervised Discrete Representations of American Sign Language"], "gesture representation": ["Unsupervised Discrete Representations of American Sign Language"], "fingerspelling tokenization sign language translation": ["Unsupervised Discrete Representations of American Sign Language"], "sign language translation gesture representation": ["Unsupervised Discrete Representations of American Sign Language"], "fingerspelling tokenization sign language translation gesture representation": ["Unsupervised Discrete Representations of American Sign Language"], "perception inference": ["Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models"], "perception-to-belief inference": ["Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models"], "theory of mind perception inference": ["Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models"], "perception inference perception-to-belief inference": ["Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models"], "theory of mind perception inference perception-to-belief inference": ["Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models"], "extractive summarization": ["Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs"], "coherence enhancement": ["Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs"], "user intent alignment": ["Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs"], "extractive summarization coherence enhancement": ["Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs"], "coherence enhancement user intent alignment": ["Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs"], "extractive summarization coherence enhancement user intent alignment": ["Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs"], "contextual multi-armed bandits": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "online learning": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "contextual multi-armed bandits personalization": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "personalization recommendation systems": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "recommendation systems online learning": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "contextual multi-armed bandits personalization recommendation systems": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "personalization recommendation systems online learning": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "contextual multi-armed bandits personalization recommendation systems online learning": ["Jump Starting Bandits with LLM-Generated Prior Knowledge"], "perplexity evaluation": ["Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?", "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "domain adaptation perplexity evaluation": ["Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?"], "language modeling domain adaptation perplexity evaluation": ["Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?"], "time-sensitive qa": ["Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation"], "misinformation polluted qa": ["Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation"], "open-domain qa time-sensitive qa": ["Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation"], "time-sensitive qa misinformation polluted qa": ["Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation"], "open-domain qa time-sensitive qa misinformation polluted qa": ["Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation"], "human behavior simulation": ["Virtual Personas for Language Models via an Anthology of Backstories", "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks"], "survey response prediction": ["Virtual Personas for Language Models via an Anthology of Backstories"], "virtual persona creation": ["Virtual Personas for Language Models via an Anthology of Backstories"], "human behavior simulation survey response prediction": ["Virtual Personas for Language Models via an Anthology of Backstories"], "survey response prediction virtual persona creation": ["Virtual Personas for Language Models via an Anthology of Backstories"], "human behavior simulation survey response prediction virtual persona creation": ["Virtual Personas for Language Models via an Anthology of Backstories"], "logical reasoning error analysis": ["Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?"], "puzzle solving logical reasoning error analysis": ["Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?"], "reasoning math": ["Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies", "AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "math commonsense reasoning": ["Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies"], "commonsense reasoning multi-hop reasoning": ["Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies"], "reasoning math commonsense reasoning": ["Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies"], "math commonsense reasoning multi-hop reasoning": ["Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies"], "reasoning math commonsense reasoning multi-hop reasoning": ["Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies"], "narrative detection": ["The Empirical Variability of Narrative Perceptions of Social Media Texts"], "question salience prediction": ["Which questions should I answer? Salience Prediction of Inquisitive Questions"], "inquisitive question generation": ["Which questions should I answer? Salience Prediction of Inquisitive Questions"], "summarization quality indicator": ["Which questions should I answer? Salience Prediction of Inquisitive Questions"], "question salience prediction inquisitive question generation": ["Which questions should I answer? Salience Prediction of Inquisitive Questions"], "inquisitive question generation summarization quality indicator": ["Which questions should I answer? Salience Prediction of Inquisitive Questions"], "question salience prediction inquisitive question generation summarization quality indicator": ["Which questions should I answer? Salience Prediction of Inquisitive Questions"], "explainable personality state recognition": ["Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues"], "explainable personality trait recognition": ["Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues"], "explainable personality state recognition explainable personality trait recognition": ["Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues"], "asr test-time adaptation": ["Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech"], "ascii understanding": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "navigation": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "visual reasoning spatial reasoning": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "spatial reasoning ascii understanding": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "ascii understanding navigation": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "visual reasoning spatial reasoning ascii understanding": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "spatial reasoning ascii understanding navigation": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "visual reasoning spatial reasoning ascii understanding navigation": ["Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities"], "code generation evaluation": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "semantic correctness assessment": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "code quality assessment": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "fault localization": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "code generation evaluation semantic correctness assessment": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "semantic correctness assessment code quality assessment": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "code quality assessment fault localization": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "code generation evaluation semantic correctness assessment code quality assessment": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "semantic correctness assessment code quality assessment fault localization": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "code generation evaluation semantic correctness assessment code quality assessment fault localization": ["CODEJUDGE: Evaluating Code Generation with Large Language Models"], "clinical note summarization": ["SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization"], "factual alignment": ["SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization"], "clinical note summarization factual alignment": ["SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization"], "factual alignment hallucination reduction": ["SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization"], "clinical note summarization factual alignment hallucination reduction": ["SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization"], "practice identification": ["Detecting Online Community Practices with Large Language Models: A Case Study of Pro-Ukrainian Publics on Twitter"], "multilingual classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "cross-lingual classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "topic classification multilingual classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "multilingual classification cross-lingual classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "cross-lingual classification tweet classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "topic classification multilingual classification cross-lingual classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "multilingual classification cross-lingual classification tweet classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "topic classification multilingual classification cross-lingual classification tweet classification": ["Multilingual Topic Classification in X: Dataset and Analysis"], "multi-turn conversation evaluation": ["MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models"], "image-text similarity": ["Updating CLIP to Prefer Descriptions Over Captions"], "clip model fine-tuning": ["Updating CLIP to Prefer Descriptions Over Captions"], "alt-text evaluation": ["Updating CLIP to Prefer Descriptions Over Captions"], "accessibility": ["Updating CLIP to Prefer Descriptions Over Captions"], "image-text similarity clip model fine-tuning": ["Updating CLIP to Prefer Descriptions Over Captions"], "clip model fine-tuning alt-text evaluation": ["Updating CLIP to Prefer Descriptions Over Captions"], "alt-text evaluation accessibility": ["Updating CLIP to Prefer Descriptions Over Captions"], "image-text similarity clip model fine-tuning alt-text evaluation": ["Updating CLIP to Prefer Descriptions Over Captions"], "clip model fine-tuning alt-text evaluation accessibility": ["Updating CLIP to Prefer Descriptions Over Captions"], "image-text similarity clip model fine-tuning alt-text evaluation accessibility": ["Updating CLIP to Prefer Descriptions Over Captions"], "command-line embedding": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "cybersecurity": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "malicious command-line detection": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "similar command-line retrieval": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "command-line classification": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "command-line embedding cybersecurity": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "cybersecurity malicious command-line detection": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "malicious command-line detection similar command-line retrieval": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "similar command-line retrieval command-line classification": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "command-line embedding cybersecurity malicious command-line detection": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "cybersecurity malicious command-line detection similar command-line retrieval": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "malicious command-line detection similar command-line retrieval command-line classification": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "command-line embedding cybersecurity malicious command-line detection similar command-line retrieval": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "cybersecurity malicious command-line detection similar command-line retrieval command-line classification": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "command-line embedding cybersecurity malicious command-line detection similar command-line retrieval command-line classification": ["CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research"], "entity-aware video captioning": ["VIEWS: Entity-Aware News Video Captioning"], "news video summarization": ["VIEWS: Entity-Aware News Video Captioning"], "entity-aware video captioning news video summarization": ["VIEWS: Entity-Aware News Video Captioning"], "dialogue response generation": ["Towards Aligning Language Models with Textual Feedback", "Guided Profile Generation Improves Personalization with LLMs", "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "toxicity reduction summarization": ["Towards Aligning Language Models with Textual Feedback"], "summarization dialogue response generation": ["Towards Aligning Language Models with Textual Feedback"], "toxicity reduction summarization dialogue response generation": ["Towards Aligning Language Models with Textual Feedback"], "prompt engineering text classification": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "text classification sentiment classification": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "sentiment classification reading comprehension": ["AMPO: Automatic Multi-Branched Prompt Optimization", "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "reading comprehension medical question answering": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "prompt engineering text classification sentiment classification": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "text classification sentiment classification reading comprehension": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "sentiment classification reading comprehension medical question answering": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "prompt engineering text classification sentiment classification reading comprehension": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "text classification sentiment classification reading comprehension medical question answering": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "prompt engineering text classification sentiment classification reading comprehension medical question answering": ["AMPO: Automatic Multi-Branched Prompt Optimization"], "context-aware neural machine translation": ["DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators"], "discourse modeling": ["DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators"], "context-aware neural machine translation discourse modeling": ["DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators"], "coherence": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "clarity": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "grammar correction": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing", "EDEN: Empathetic Dialogues for English Learning"], "neutralization": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "text simplification coherence": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "coherence clarity": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "clarity fluency": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "fluency grammar correction": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "grammar correction neutralization": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "text simplification coherence clarity": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "coherence clarity fluency": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "clarity fluency grammar correction": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "fluency grammar correction neutralization": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "text simplification coherence clarity fluency": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "coherence clarity fluency grammar correction": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "clarity fluency grammar correction neutralization": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "text simplification coherence clarity fluency grammar correction": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "coherence clarity fluency grammar correction neutralization": ["DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"], "brain activity prediction": ["Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models"], "semantic representation analysis": ["Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models"], "multi-modal representation analysis": ["Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models"], "brain activity prediction semantic representation analysis": ["Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models"], "semantic representation analysis multi-modal representation analysis": ["Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models"], "brain activity prediction semantic representation analysis multi-modal representation analysis": ["Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models"], "LLM bias detection": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "covert harm analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "social threat assessment": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "recruitment bias analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "conversation analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "LLM bias detection covert harm analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "covert harm analysis social threat assessment": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "social threat assessment recruitment bias analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "recruitment bias analysis conversation analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "LLM bias detection covert harm analysis social threat assessment": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "covert harm analysis social threat assessment recruitment bias analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "social threat assessment recruitment bias analysis conversation analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "LLM bias detection covert harm analysis social threat assessment recruitment bias analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "covert harm analysis social threat assessment recruitment bias analysis conversation analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "LLM bias detection covert harm analysis social threat assessment recruitment bias analysis conversation analysis": ["\u201cThey are uncultured\u201d: Unveiling Covert Harms and Social Threats in LLM Generated Conversations"], "hurtfulness reduction": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "informativeness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "usefulness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "expert response aggregation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "truthfulness factuality": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "factuality toxicity reduction": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "toxicity reduction hurtfulness reduction": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "hurtfulness reduction informativeness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "informativeness enhancement usefulness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "usefulness enhancement long-form generation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "long-form generation expert response aggregation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "truthfulness factuality toxicity reduction": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "factuality toxicity reduction hurtfulness reduction": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "toxicity reduction hurtfulness reduction informativeness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "hurtfulness reduction informativeness enhancement usefulness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "informativeness enhancement usefulness enhancement long-form generation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "usefulness enhancement long-form generation expert response aggregation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "truthfulness factuality toxicity reduction hurtfulness reduction": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "factuality toxicity reduction hurtfulness reduction informativeness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "toxicity reduction hurtfulness reduction informativeness enhancement usefulness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "hurtfulness reduction informativeness enhancement usefulness enhancement long-form generation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "informativeness enhancement usefulness enhancement long-form generation expert response aggregation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "truthfulness factuality toxicity reduction hurtfulness reduction informativeness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "factuality toxicity reduction hurtfulness reduction informativeness enhancement usefulness enhancement": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "toxicity reduction hurtfulness reduction informativeness enhancement usefulness enhancement long-form generation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "hurtfulness reduction informativeness enhancement usefulness enhancement long-form generation expert response aggregation": ["Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models"], "temporal relation classification": ["Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?"], "few-shot video narration": ["Eliciting In-Context Learning in Vision-Language Models for Videos Through Curated Data Distributional Properties"], "text watermarking": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "data provenance": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "intellectual property protection": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs", "CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "plagiarism detection": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "code watermarking": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "LLM data provenance": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "text watermarking data provenance": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "data provenance intellectual property protection": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "intellectual property protection plagiarism detection": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "plagiarism detection code watermarking": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "code watermarking LLM data provenance": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "text watermarking data provenance intellectual property protection": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "data provenance intellectual property protection plagiarism detection": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "intellectual property protection plagiarism detection code watermarking": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "plagiarism detection code watermarking LLM data provenance": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "text watermarking data provenance intellectual property protection plagiarism detection": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "data provenance intellectual property protection plagiarism detection code watermarking": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "intellectual property protection plagiarism detection code watermarking LLM data provenance": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "text watermarking data provenance intellectual property protection plagiarism detection code watermarking": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "data provenance intellectual property protection plagiarism detection code watermarking LLM data provenance": ["Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs"], "affective state identification": ["MASIVE: Open-Ended Affective State Identification in English and Spanish"], "question answering information retrieval": ["You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions"], "language processing": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "language processing reasoning": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "reasoning glue": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "glue scienceqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "scienceqa commonsenseqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "commonsenseqa openbookqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "openbookqa addsub": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "svamp gsm8k": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "language processing reasoning glue": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "reasoning glue scienceqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "glue scienceqa commonsenseqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "scienceqa commonsenseqa openbookqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality", "AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "commonsenseqa openbookqa addsub": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "openbookqa addsub multiarith": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "addsub multiarith svamp": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "multiarith svamp gsm8k": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "language processing reasoning glue scienceqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "reasoning glue scienceqa commonsenseqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "glue scienceqa commonsenseqa openbookqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "scienceqa commonsenseqa openbookqa addsub": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "commonsenseqa openbookqa addsub multiarith": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "openbookqa addsub multiarith svamp": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "addsub multiarith svamp gsm8k": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "language processing reasoning glue scienceqa commonsenseqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "reasoning glue scienceqa commonsenseqa openbookqa": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "glue scienceqa commonsenseqa openbookqa addsub": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "scienceqa commonsenseqa openbookqa addsub multiarith": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "commonsenseqa openbookqa addsub multiarith svamp": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "openbookqa addsub multiarith svamp gsm8k": ["AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality"], "argument quality scoring": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "template selection": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling", "Designing Logic Pattern Templates for Counter-Argument Logical Structure Analysis"], "fallacy classification argument quality scoring": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "argument quality scoring fallacy detection": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "fallacy detection template selection": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "template selection slot filling": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling", "Designing Logic Pattern Templates for Counter-Argument Logical Structure Analysis"], "fallacy classification argument quality scoring fallacy detection": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "argument quality scoring fallacy detection template selection": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "fallacy detection template selection slot filling": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "fallacy classification argument quality scoring fallacy detection template selection": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "argument quality scoring fallacy detection template selection slot filling": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "fallacy classification argument quality scoring fallacy detection template selection slot filling": ["Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling"], "social intelligence": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions", "Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues"], "ai agents": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "learning": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "perception": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "affective computing": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "social intelligence ai agents": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "ai agents reasoning": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "reasoning learning": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "learning perception": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "perception affective computing": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "social intelligence ai agents reasoning": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "ai agents reasoning learning": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "reasoning learning perception": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "learning perception affective computing": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "social intelligence ai agents reasoning learning": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "ai agents reasoning learning perception": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "reasoning learning perception affective computing": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "social intelligence ai agents reasoning learning perception": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "ai agents reasoning learning perception affective computing": ["Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions"], "text-to-image prompt refinement": ["RAt: Injecting Implicit Bias for Text-To-Image Prompt Refinement Models"], "text-to-image prompt refinement adversarial attack": ["RAt: Injecting Implicit Bias for Text-To-Image Prompt Refinement Models"], "qa data generation": ["Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese"], "grammatical knowledge induction": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "sentence acceptability judgment": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor gender agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor number agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "transitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "intransitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "determiner-noun agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "subject-verb agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?", "On the Similarity of Circuits across Languages: A Case Study on the Subject-verb Agreement Task"], "grammatical knowledge induction sentence acceptability judgment": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "sentence acceptability judgment anaphor gender agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor gender agreement anaphor number agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor number agreement transitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "transitivity intransitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "intransitivity determiner-noun agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "determiner-noun agreement subject-verb agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "grammatical knowledge induction sentence acceptability judgment anaphor gender agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "sentence acceptability judgment anaphor gender agreement anaphor number agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor gender agreement anaphor number agreement transitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor number agreement transitivity intransitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "transitivity intransitivity determiner-noun agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "intransitivity determiner-noun agreement subject-verb agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "grammatical knowledge induction sentence acceptability judgment anaphor gender agreement anaphor number agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "sentence acceptability judgment anaphor gender agreement anaphor number agreement transitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor gender agreement anaphor number agreement transitivity intransitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor number agreement transitivity intransitivity determiner-noun agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "transitivity intransitivity determiner-noun agreement subject-verb agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "grammatical knowledge induction sentence acceptability judgment anaphor gender agreement anaphor number agreement transitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "sentence acceptability judgment anaphor gender agreement anaphor number agreement transitivity intransitivity": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor gender agreement anaphor number agreement transitivity intransitivity determiner-noun agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "anaphor number agreement transitivity intransitivity determiner-noun agreement subject-verb agreement": ["Can Language Models Induce Grammatical Knowledge from Indirect Evidence?"], "copyright compliance evaluation": ["Do LLMs Know to Respect Copyright Notice?"], "LLMs inference acceleration": ["SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding"], "spoken language understanding": ["Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding", "PRoDeliberation: Parallel Robust Deliberation for End-to-End Spoken Language Understanding"], "spoken language understanding automatic speech recognition": ["Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding"], "language model alignment reinforcement learning from human feedback": ["Rethinking the Role of Proxy Rewards in Language Model Alignment"], "text-kvqa": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "visual text recognition": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "knowledge-aware reasoning": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant", "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "text-kvqa visual question answering": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "visual question answering visual text recognition": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "visual text recognition entity linking": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "entity linking knowledge-aware reasoning": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "text-kvqa visual question answering visual text recognition": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "visual question answering visual text recognition entity linking": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "visual text recognition entity linking knowledge-aware reasoning": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "text-kvqa visual question answering visual text recognition entity linking": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "visual question answering visual text recognition entity linking knowledge-aware reasoning": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "text-kvqa visual question answering visual text recognition entity linking knowledge-aware reasoning": ["Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant"], "mt evaluation metrics": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "data filtering": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "translation re-ranking": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "quality estimation re-ranking": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "minimum bayes risk decoding": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "mt evaluation metrics data filtering": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "data filtering translation re-ranking": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "translation re-ranking quality estimation re-ranking": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "quality estimation re-ranking minimum bayes risk decoding": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "mt evaluation metrics data filtering translation re-ranking": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "data filtering translation re-ranking quality estimation re-ranking": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "translation re-ranking quality estimation re-ranking minimum bayes risk decoding": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "mt evaluation metrics data filtering translation re-ranking quality estimation re-ranking": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "data filtering translation re-ranking quality estimation re-ranking minimum bayes risk decoding": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "mt evaluation metrics data filtering translation re-ranking quality estimation re-ranking minimum bayes risk decoding": ["Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"], "video captioning": ["IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning", "ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "image captioning zero-shot learning": ["IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning", "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "zero-shot learning video captioning": ["IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning"], "video captioning RAG": ["IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning"], "image captioning zero-shot learning video captioning": ["IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning"], "zero-shot learning video captioning RAG": ["IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning"], "image captioning zero-shot learning video captioning RAG": ["IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning"], "spreadsheet table detection": ["Encoding Spreadsheets for Large Language Models"], "spreadsheet qa": ["Encoding Spreadsheets for Large Language Models"], "spreadsheet table detection spreadsheet qa": ["Encoding Spreadsheets for Large Language Models"], "argumentation quality assessment": ["Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment"], "dataset survey": ["Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment"], "research gap analysis": ["Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment"], "argumentation quality assessment dataset survey": ["Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment"], "dataset survey research gap analysis": ["Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment"], "argumentation quality assessment dataset survey research gap analysis": ["Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment"], "sentence segmentation sequence labeling": ["Automatic sentence segmentation of clinical record narratives in real-world data"], "emergent communication": ["One-to-Many Communication and Compositionality in Emergent Communication"], "compositionality": ["One-to-Many Communication and Compositionality in Emergent Communication"], "emergent communication compositionality": ["One-to-Many Communication and Compositionality in Emergent Communication"], "speech recognition text classification": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "sentiment analysis text-to-sql": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "text-to-sql visual question answering": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "speech recognition text classification sentiment analysis": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "text classification sentiment analysis text-to-sql": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "sentiment analysis text-to-sql visual question answering": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "speech recognition text classification sentiment analysis text-to-sql": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "text classification sentiment analysis text-to-sql visual question answering": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "speech recognition text classification sentiment analysis text-to-sql visual question answering": ["Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities"], "multilingual instruction-tuning": ["Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?"], "multilingual instruction-tuning instruction following": ["Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?"], "logical reasoning question answering": ["Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models"], "question answering binary classification": ["Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models"], "logical reasoning question answering binary classification": ["Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models"], "fine-grained emotion classification": ["Linear Layer Extrapolation for Fine-Grained Emotion Classification"], "query rewrites": ["Task Oriented In-Domain Data Augmentation"], "query-landing page relevance": ["Task Oriented In-Domain Data Augmentation"], "query-adcopy relevance": ["Task Oriented In-Domain Data Augmentation"], "query-landingpage relevance": ["Task Oriented In-Domain Data Augmentation"], "ad copy generation": ["Task Oriented In-Domain Data Augmentation"], "description generation": ["Task Oriented In-Domain Data Augmentation", "Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga dataset and Its Challenging Tasks"], "title rewriting": ["Task Oriented In-Domain Data Augmentation"], "sat": ["Task Oriented In-Domain Data Augmentation"], "mawps": ["Task Oriented In-Domain Data Augmentation"], "tab": ["Task Oriented In-Domain Data Augmentation"], "mqa": ["Task Oriented In-Domain Data Augmentation"], "mMLu-stem": ["Task Oriented In-Domain Data Augmentation"], "query rewrites query-landing page relevance": ["Task Oriented In-Domain Data Augmentation"], "query-landing page relevance query-adcopy relevance": ["Task Oriented In-Domain Data Augmentation"], "query-adcopy relevance query-landingpage relevance": ["Task Oriented In-Domain Data Augmentation"], "query-landingpage relevance ad copy generation": ["Task Oriented In-Domain Data Augmentation"], "ad copy generation description generation": ["Task Oriented In-Domain Data Augmentation"], "description generation title generation": ["Task Oriented In-Domain Data Augmentation"], "title generation title rewriting": ["Task Oriented In-Domain Data Augmentation"], "title rewriting gsm8k": ["Task Oriented In-Domain Data Augmentation"], "gsm8k sat": ["Task Oriented In-Domain Data Augmentation"], "sat svamp": ["Task Oriented In-Domain Data Augmentation"], "asdiv mawps": ["Task Oriented In-Domain Data Augmentation"], "mawps tab": ["Task Oriented In-Domain Data Augmentation"], "tab mqa": ["Task Oriented In-Domain Data Augmentation"], "mqa mMLu-stem": ["Task Oriented In-Domain Data Augmentation"], "query rewrites query-landing page relevance query-adcopy relevance": ["Task Oriented In-Domain Data Augmentation"], "query-landing page relevance query-adcopy relevance query-landingpage relevance": ["Task Oriented In-Domain Data Augmentation"], "query-adcopy relevance query-landingpage relevance ad copy generation": ["Task Oriented In-Domain Data Augmentation"], "query-landingpage relevance ad copy generation description generation": ["Task Oriented In-Domain Data Augmentation"], "ad copy generation description generation title generation": ["Task Oriented In-Domain Data Augmentation"], "description generation title generation title rewriting": ["Task Oriented In-Domain Data Augmentation"], "title generation title rewriting gsm8k": ["Task Oriented In-Domain Data Augmentation"], "title rewriting gsm8k sat": ["Task Oriented In-Domain Data Augmentation"], "gsm8k sat svamp": ["Task Oriented In-Domain Data Augmentation"], "sat svamp asdiv": ["Task Oriented In-Domain Data Augmentation"], "svamp asdiv mawps": ["Task Oriented In-Domain Data Augmentation"], "asdiv mawps tab": ["Task Oriented In-Domain Data Augmentation"], "mawps tab mqa": ["Task Oriented In-Domain Data Augmentation"], "tab mqa mMLu-stem": ["Task Oriented In-Domain Data Augmentation"], "query rewrites query-landing page relevance query-adcopy relevance query-landingpage relevance": ["Task Oriented In-Domain Data Augmentation"], "query-landing page relevance query-adcopy relevance query-landingpage relevance ad copy generation": ["Task Oriented In-Domain Data Augmentation"], "query-adcopy relevance query-landingpage relevance ad copy generation description generation": ["Task Oriented In-Domain Data Augmentation"], "query-landingpage relevance ad copy generation description generation title generation": ["Task Oriented In-Domain Data Augmentation"], "ad copy generation description generation title generation title rewriting": ["Task Oriented In-Domain Data Augmentation"], "description generation title generation title rewriting gsm8k": ["Task Oriented In-Domain Data Augmentation"], "title generation title rewriting gsm8k sat": ["Task Oriented In-Domain Data Augmentation"], "title rewriting gsm8k sat svamp": ["Task Oriented In-Domain Data Augmentation"], "gsm8k sat svamp asdiv": ["Task Oriented In-Domain Data Augmentation"], "sat svamp asdiv mawps": ["Task Oriented In-Domain Data Augmentation"], "svamp asdiv mawps tab": ["Task Oriented In-Domain Data Augmentation"], "asdiv mawps tab mqa": ["Task Oriented In-Domain Data Augmentation"], "mawps tab mqa mMLu-stem": ["Task Oriented In-Domain Data Augmentation"], "query rewrites query-landing page relevance query-adcopy relevance query-landingpage relevance ad copy generation": ["Task Oriented In-Domain Data Augmentation"], "query-landing page relevance query-adcopy relevance query-landingpage relevance ad copy generation description generation": ["Task Oriented In-Domain Data Augmentation"], "query-adcopy relevance query-landingpage relevance ad copy generation description generation title generation": ["Task Oriented In-Domain Data Augmentation"], "query-landingpage relevance ad copy generation description generation title generation title rewriting": ["Task Oriented In-Domain Data Augmentation"], "ad copy generation description generation title generation title rewriting gsm8k": ["Task Oriented In-Domain Data Augmentation"], "description generation title generation title rewriting gsm8k sat": ["Task Oriented In-Domain Data Augmentation"], "title generation title rewriting gsm8k sat svamp": ["Task Oriented In-Domain Data Augmentation"], "title rewriting gsm8k sat svamp asdiv": ["Task Oriented In-Domain Data Augmentation"], "gsm8k sat svamp asdiv mawps": ["Task Oriented In-Domain Data Augmentation"], "sat svamp asdiv mawps tab": ["Task Oriented In-Domain Data Augmentation"], "svamp asdiv mawps tab mqa": ["Task Oriented In-Domain Data Augmentation"], "asdiv mawps tab mqa mMLu-stem": ["Task Oriented In-Domain Data Augmentation"], "scientific qa": ["SCIDQA: A Deep Reading Comprehension Dataset over Scientific Papers"], "reading comprehension scientific qa": ["SCIDQA: A Deep Reading Comprehension Dataset over Scientific Papers"], "question answering reading comprehension scientific qa": ["SCIDQA: A Deep Reading Comprehension Dataset over Scientific Papers"], "xsum": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "text understanding": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "language modeling glue": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "glue xsum": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "xsum text understanding": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "text understanding text generation": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "language modeling glue xsum": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "glue xsum text understanding": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "xsum text understanding text generation": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "language modeling glue xsum text understanding": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "glue xsum text understanding text generation": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "language modeling glue xsum text understanding text generation": ["Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules"], "multilingual affective image captioning": ["No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages"], "hate speech detection generalization": ["PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection"], "speaker change detection": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "endpointing": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "asr speaker change detection": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "speaker change detection endpointing": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "endpointing named entity recognition": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "asr speaker change detection endpointing": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "speaker change detection endpointing named entity recognition": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "asr speaker change detection endpointing named entity recognition": ["TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"], "natural language understanding language modeling": ["ApiQ: Finetuning of 2-Bit Quantized Large Language Model"], "language modeling arithmetic reasoning": ["ApiQ: Finetuning of 2-Bit Quantized Large Language Model"], "natural language understanding language modeling arithmetic reasoning": ["ApiQ: Finetuning of 2-Bit Quantized Large Language Model"], "language modeling arithmetic reasoning commonsense reasoning": ["ApiQ: Finetuning of 2-Bit Quantized Large Language Model"], "natural language understanding language modeling arithmetic reasoning commonsense reasoning": ["ApiQ: Finetuning of 2-Bit Quantized Large Language Model"], "long-context language modeling": ["Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk"], "prefilling optimization": ["Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk"], "memory management": ["Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk", "Mixed-Session Conversation with Egocentric Memory"], "long-context language modeling prefilling optimization": ["Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk"], "prefilling optimization memory management": ["Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk"], "long-context language modeling prefilling optimization memory management": ["Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk"], "natural language inference text classification": ["A Morphology-Based Investigation of Positional Encodings"], "text classification named entity recognition": ["A Morphology-Based Investigation of Positional Encodings", "Efficient Active Learning with Adapters"], "named entity recognition part-of-speech tagging": ["A Morphology-Based Investigation of Positional Encodings"], "part-of-speech tagging dependency parsing": ["A Morphology-Based Investigation of Positional Encodings"], "natural language inference text classification named entity recognition": ["A Morphology-Based Investigation of Positional Encodings"], "text classification named entity recognition part-of-speech tagging": ["A Morphology-Based Investigation of Positional Encodings"], "named entity recognition part-of-speech tagging dependency parsing": ["A Morphology-Based Investigation of Positional Encodings"], "natural language inference text classification named entity recognition part-of-speech tagging": ["A Morphology-Based Investigation of Positional Encodings"], "text classification named entity recognition part-of-speech tagging dependency parsing": ["A Morphology-Based Investigation of Positional Encodings"], "natural language inference text classification named entity recognition part-of-speech tagging dependency parsing": ["A Morphology-Based Investigation of Positional Encodings"], "opinion mining": ["I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining", "LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models"], "semantic search": ["I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining", "A Semantic Search Engine for Mathlib4"], "opinion mining stance detection": ["I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"], "stance detection semantic search": ["I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"], "opinion mining stance detection semantic search": ["I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"], "toxic content detection": ["Bias Wipe: Mitigating Unintended Bias in Text Classifiers through Model Interpretability"], "propaganda detection": ["ArMeme: Propagandistic Content in Arabic Memes", "Large Language Models for Propaganda Span Annotation"], "misogyny detection": ["Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts"], "argumentative reasoning": ["Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts"], "misogyny detection argumentative reasoning": ["Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts"], "target-driven conversation planning": ["Thoughts to Target: Enhance Planning for Target-driven Conversation"], "conversation dataset collection": ["Thoughts to Target: Enhance Planning for Target-driven Conversation"], "target-driven conversation planning conversation dataset collection": ["Thoughts to Target: Enhance Planning for Target-driven Conversation"], "conversation dataset collection response generation": ["Thoughts to Target: Enhance Planning for Target-driven Conversation"], "target-driven conversation planning conversation dataset collection response generation": ["Thoughts to Target: Enhance Planning for Target-driven Conversation"], "data ablation study": ["Scalable Data Ablation Approximations for Language Models through Modular Training and Merging"], "pre-training data composition": ["Scalable Data Ablation Approximations for Language Models through Modular Training and Merging"], "language modeling data ablation study": ["Scalable Data Ablation Approximations for Language Models through Modular Training and Merging"], "data ablation study pre-training data composition": ["Scalable Data Ablation Approximations for Language Models through Modular Training and Merging"], "language modeling data ablation study pre-training data composition": ["Scalable Data Ablation Approximations for Language Models through Modular Training and Merging"], "multilingual neural machine translation": ["Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation"], "synthetic": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "single-document qa multi-document qa": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "multi-document qa summarization": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "summarization few-shot learning": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters", "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches", "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "few-shot learning synthetic": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "single-document qa multi-document qa summarization": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "multi-document qa summarization few-shot learning": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "summarization few-shot learning synthetic": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "single-document qa multi-document qa summarization few-shot learning": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "multi-document qa summarization few-shot learning synthetic": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "summarization few-shot learning synthetic code": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "single-document qa multi-document qa summarization few-shot learning synthetic": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "multi-document qa summarization few-shot learning synthetic code": ["Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"], "knowledge graph-grounded dialog generation": ["Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation"], "subgraph retrieval": ["Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation", "Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA"], "knowledge graph-grounded dialog generation subgraph retrieval": ["Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation"], "adversarial robustness": ["ADAPTERS MIXUP: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers", "Authorship Obfuscation in Multilingual Machine-Generated Text Detection", "PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion"], "text classification adversarial robustness": ["ADAPTERS MIXUP: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers"], "sequence tagging": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "de-identification": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "sequence tagging named entity recognition": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "named entity recognition data augmentation": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "data augmentation de-identification": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "sequence tagging named entity recognition data augmentation": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "named entity recognition data augmentation de-identification": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "sequence tagging named entity recognition data augmentation de-identification": ["Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4"], "word association": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "abstract reasoning language understanding": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "language understanding word association": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "word association commonsense reasoning": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "commonsense reasoning pattern recognition": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "abstract reasoning language understanding word association": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "language understanding word association commonsense reasoning": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "word association commonsense reasoning pattern recognition": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "abstract reasoning language understanding word association commonsense reasoning": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "language understanding word association commonsense reasoning pattern recognition": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "abstract reasoning language understanding word association commonsense reasoning pattern recognition": ["Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game"], "named entity recognition text classification natural language inference": ["GottBERT: a pure German Language Model"], "interpretation": ["Computational Meme Understanding: A Survey"], "classification interpretation": ["Computational Meme Understanding: A Survey"], "interpretation explanation": ["Computational Meme Understanding: A Survey"], "classification interpretation explanation": ["Computational Meme Understanding: A Survey"], "summarization math reasoning": ["CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "topic classification sentiment analysis natural language inference": ["CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "sentiment analysis natural language inference summarization": ["CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "natural language inference summarization math reasoning": ["CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "topic classification sentiment analysis natural language inference summarization": ["CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "sentiment analysis natural language inference summarization math reasoning": ["CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "topic classification sentiment analysis natural language inference summarization math reasoning": ["CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage"], "zero-shot learning low-resource learning": ["Retrieval-enriched zero-shot image classification in low-resource domains"], "image classification zero-shot learning low-resource learning": ["Retrieval-enriched zero-shot image classification in low-resource domains"], "item personalization": ["I-AM-G: Interest Augmented Multimodal Generator for Item Personalization"], "multimodal generation": ["I-AM-G: Interest Augmented Multimodal Generator for Item Personalization"], "item personalization multimodal generation": ["I-AM-G: Interest Augmented Multimodal Generator for Item Personalization"], "multimodal generation recommendation systems": ["I-AM-G: Interest Augmented Multimodal Generator for Item Personalization"], "item personalization multimodal generation recommendation systems": ["I-AM-G: Interest Augmented Multimodal Generator for Item Personalization"], "reinforcement learning with human feedback": ["Enhancing Language Model Alignment: A Confidence-Based Approach to Label Smoothing"], "language model alignment reinforcement learning with human feedback": ["Enhancing Language Model Alignment: A Confidence-Based Approach to Label Smoothing"], "LLM alignment summarization": ["Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion"], "plan-following": ["Show and Guide: Instructional-Plan Grounded Vision and Language Model"], "conversational video moment retrieval": ["Show and Guide: Instructional-Plan Grounded Vision and Language Model"], "visually-informed step generation": ["Show and Guide: Instructional-Plan Grounded Vision and Language Model"], "plan-following conversational video moment retrieval": ["Show and Guide: Instructional-Plan Grounded Vision and Language Model"], "conversational video moment retrieval visually-informed step generation": ["Show and Guide: Instructional-Plan Grounded Vision and Language Model"], "plan-following conversational video moment retrieval visually-informed step generation": ["Show and Guide: Instructional-Plan Grounded Vision and Language Model"], "spoken dialogue modeling": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "full-duplex dialogue": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "synchronous LLMs": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "meaningful dialogue generation": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "natural turn-taking": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "latency tolerance": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "voice interaction": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "spoken dialogue modeling full-duplex dialogue": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "full-duplex dialogue synchronous LLMs": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "synchronous LLMs meaningful dialogue generation": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "meaningful dialogue generation natural turn-taking": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "natural turn-taking latency tolerance": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "latency tolerance voice interaction": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "spoken dialogue modeling full-duplex dialogue synchronous LLMs": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "full-duplex dialogue synchronous LLMs meaningful dialogue generation": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "synchronous LLMs meaningful dialogue generation natural turn-taking": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "meaningful dialogue generation natural turn-taking latency tolerance": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "natural turn-taking latency tolerance voice interaction": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "spoken dialogue modeling full-duplex dialogue synchronous LLMs meaningful dialogue generation": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "full-duplex dialogue synchronous LLMs meaningful dialogue generation natural turn-taking": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "synchronous LLMs meaningful dialogue generation natural turn-taking latency tolerance": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "meaningful dialogue generation natural turn-taking latency tolerance voice interaction": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "spoken dialogue modeling full-duplex dialogue synchronous LLMs meaningful dialogue generation natural turn-taking": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "full-duplex dialogue synchronous LLMs meaningful dialogue generation natural turn-taking latency tolerance": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "synchronous LLMs meaningful dialogue generation natural turn-taking latency tolerance voice interaction": ["Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"], "text-based game": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "beir": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "search engine": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "interactive RAG": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "zero-shot retrieval": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "reasoning derailment": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "alfworld text-based game": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "text-based game beir": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "beir search engine": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "search engine interactive RAG": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "interactive RAG rag": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "rag zero-shot retrieval": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "zero-shot retrieval reasoning derailment": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "alfworld text-based game beir": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "text-based game beir search engine": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "beir search engine interactive RAG": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "search engine interactive RAG rag": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "interactive RAG rag zero-shot retrieval": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "rag zero-shot retrieval reasoning derailment": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "alfworld text-based game beir search engine": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "text-based game beir search engine interactive RAG": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "beir search engine interactive RAG rag": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "search engine interactive RAG rag zero-shot retrieval": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "interactive RAG rag zero-shot retrieval reasoning derailment": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "alfworld text-based game beir search engine interactive RAG": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "text-based game beir search engine interactive RAG rag": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "beir search engine interactive RAG rag zero-shot retrieval": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "search engine interactive RAG rag zero-shot retrieval reasoning derailment": ["QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning"], "multi-document question answering": ["COMPACT: Compressing Retrieved Documents Actively for Question Answering", "QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism", "Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell", "Can We Instruct LLMs to Compensate for Position Bias?"], "multi-document question answering context compression": ["COMPACT: Compressing Retrieved Documents Actively for Question Answering"], "context compression RAG": ["COMPACT: Compressing Retrieved Documents Actively for Question Answering"], "multi-document question answering context compression RAG": ["COMPACT: Compressing Retrieved Documents Actively for Question Answering"], "spatial understanding": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "visual question answering spatial understanding": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "spatial understanding multi-hop reasoning": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "multi-hop reasoning object detection": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "object detection scene graph generation": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "visual question answering spatial understanding multi-hop reasoning": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "spatial understanding multi-hop reasoning object detection": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "multi-hop reasoning object detection scene graph generation": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "visual question answering spatial understanding multi-hop reasoning object detection": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "spatial understanding multi-hop reasoning object detection scene graph generation": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "visual question answering spatial understanding multi-hop reasoning object detection scene graph generation": ["An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models"], "knowledge refinement": ["Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models"], "question answering knowledge injection": ["Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models"], "knowledge injection knowledge refinement": ["Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models"], "question answering knowledge injection knowledge refinement": ["Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models"], "bias mitigation model editing": ["Local Contrastive Editing of Gender Stereotypes"], "model editing knowledge localization": ["Local Contrastive Editing of Gender Stereotypes"], "bias mitigation model editing knowledge localization": ["Local Contrastive Editing of Gender Stereotypes"], "pii detection": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "data de-identification": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "document classification information extraction": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "information extraction visual question answering": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "visual question answering pii detection": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "pii detection data de-identification": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "document classification information extraction visual question answering": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "information extraction visual question answering pii detection": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "visual question answering pii detection data de-identification": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "document classification information extraction visual question answering pii detection": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "information extraction visual question answering pii detection data de-identification": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "document classification information extraction visual question answering pii detection data de-identification": ["De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP"], "code generation low-resource languages": ["RAR: Retrieval-augmented retrieval for code generation in low-resource languages"], "low-resource languages RAG": ["RAR: Retrieval-augmented retrieval for code generation in low-resource languages"], "code generation low-resource languages RAG": ["RAR: Retrieval-augmented retrieval for code generation in low-resource languages"], "ai safety": ["STAR: SocioTechnical Approach to Red Teaming Language Models"], "red teaming ai safety": ["STAR: SocioTechnical Approach to Red Teaming Language Models"], "human-ai complementarity analysis": ["Do great minds think alike? Investigating Human-AI Complementarity in Question Answering with CAIMIRA"], "question answering human-ai complementarity analysis": ["Do great minds think alike? Investigating Human-AI Complementarity in Question Answering with CAIMIRA"], "nearest neighbor analysis": ["Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories"], "concept representation": ["Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories"], "image classification nearest neighbor analysis": ["Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories"], "nearest neighbor analysis concept representation": ["Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories"], "image classification nearest neighbor analysis concept representation": ["Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories"], "feature detection": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature classification": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "time series description": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature detection feature classification": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature classification information retrieval": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "information retrieval arithmetic reasoning": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "arithmetic reasoning time series description": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature detection feature classification information retrieval": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature classification information retrieval arithmetic reasoning": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "information retrieval arithmetic reasoning time series description": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature detection feature classification information retrieval arithmetic reasoning": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature classification information retrieval arithmetic reasoning time series description": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "feature detection feature classification information retrieval arithmetic reasoning time series description": ["Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"], "keyword-focused document summarization": ["Preference-Guided Reflective Sampling for Aligning Language Models"], "instruction following keyword-focused document summarization": ["Preference-Guided Reflective Sampling for Aligning Language Models"], "bias measures analysis": ["Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP\\"], "bias measures analysis bias evaluation": ["Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP\\"], "social simulation": ["Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs", "Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "information asymmetry": ["Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs"], "social simulation LLM evaluation": ["Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs"], "LLM evaluation information asymmetry": ["Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs"], "social simulation LLM evaluation information asymmetry": ["Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs"], "long-range video question-answering": ["A Simple LLM Framework for Long-Range Video Question-Answering"], "long-range video question-answering video understanding": ["A Simple LLM Framework for Long-Range Video Question-Answering"], "sequential editing": ["Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing"], "model editing knowledge editing": ["Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing"], "knowledge editing sequential editing": ["Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing"], "model editing knowledge editing sequential editing": ["Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing"], "code-switching": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition", "On Creating an English-Thai Code-switched Machine Translation in Medical Domain", "PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition"], "gender identification": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition"], "speech recognition code-switching": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition", "PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition"], "code-switching dialect identification": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition"], "dialect identification gender identification": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition"], "speech recognition code-switching dialect identification": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition"], "code-switching dialect identification gender identification": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition"], "speech recognition code-switching dialect identification gender identification": ["Casablanca: Data and Models for Multidialectal Arabic Speech Recognition"], "safety alignment of LLMs": ["Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations"], "harmful content generation mitigation": ["Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations"], "safety alignment of LLMs harmful content generation mitigation": ["Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations"], "communication": ["Communicating with Speakers and Listeners of Different Pragmatic Levels"], "language learning communication": ["Communicating with Speakers and Listeners of Different Pragmatic Levels"], "generalized referring expression comprehension": ["RECANTFormer: Referring Expression Comprehension with Varying Numbers of Targets"], "generalized referring expression comprehension referring expression comprehension": ["RECANTFormer: Referring Expression Comprehension with Varying Numbers of Targets"], "LLM inference carbon footprint reduction": ["SPROUT: Green Generative AI with Carbon-Efficient LLM Inference"], "generative ai": ["SPROUT: Green Generative AI with Carbon-Efficient LLM Inference"], "LLM inference carbon footprint reduction generative ai": ["SPROUT: Green Generative AI with Carbon-Efficient LLM Inference"], "contrastive summarization": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "angle recommendation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "source recommendation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "creative planning evaluation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "contrastive summarization angle recommendation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "angle recommendation source recommendation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "source recommendation creative planning evaluation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "contrastive summarization angle recommendation source recommendation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "angle recommendation source recommendation creative planning evaluation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "contrastive summarization angle recommendation source recommendation creative planning evaluation": ["Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"], "speech translation quality estimation": ["SpeechQE: Estimating the Quality of Direct Speech Translation"], "error span detection": ["SpeechQE: Estimating the Quality of Direct Speech Translation"], "speech translation quality estimation direct assessment": ["SpeechQE: Estimating the Quality of Direct Speech Translation"], "direct assessment error span detection": ["SpeechQE: Estimating the Quality of Direct Speech Translation"], "speech translation quality estimation direct assessment error span detection": ["SpeechQE: Estimating the Quality of Direct Speech Translation"], "task utility assessment": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "multi-agent system evaluation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "criteria generation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "household task automation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "task utility assessment LLM evaluation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "LLM evaluation multi-agent system evaluation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "multi-agent system evaluation criteria generation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "criteria generation robustness analysis": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "robustness analysis math problem solving": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "math problem solving household task automation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "task utility assessment LLM evaluation multi-agent system evaluation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "LLM evaluation multi-agent system evaluation criteria generation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "multi-agent system evaluation criteria generation robustness analysis": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "criteria generation robustness analysis math problem solving": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "robustness analysis math problem solving household task automation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "task utility assessment LLM evaluation multi-agent system evaluation criteria generation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "LLM evaluation multi-agent system evaluation criteria generation robustness analysis": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "multi-agent system evaluation criteria generation robustness analysis math problem solving": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "criteria generation robustness analysis math problem solving household task automation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "task utility assessment LLM evaluation multi-agent system evaluation criteria generation robustness analysis": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "LLM evaluation multi-agent system evaluation criteria generation robustness analysis math problem solving": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "multi-agent system evaluation criteria generation robustness analysis math problem solving household task automation": ["Assessing and Verifying Task Utility in LLM-Powered Applications"], "alignment": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States", "Better Alignment with Instruction Back-and-Forth Translation"], "self-improvement": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "SELF-EXPLORE: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards"], "alignment self-improvement": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models"], "self-improvement instruction following": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models"], "instruction following generation": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models"], "alignment self-improvement instruction following": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models"], "self-improvement instruction following generation": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models"], "alignment self-improvement instruction following generation": ["Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models"], "annotator rating prediction": ["Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree"], "individual rating prediction": ["Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree"], "toxicity prediction annotator rating prediction": ["Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree"], "annotator rating prediction individual rating prediction": ["Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree"], "toxicity prediction annotator rating prediction individual rating prediction": ["Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree"], "dementia detection": ["Adversarial Text Generation using Large Language Models for Dementia Detection"], "adversarial training": ["Adversarial Text Generation using Large Language Models for Dementia Detection", "Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants"], "dementia detection text generation": ["Adversarial Text Generation using Large Language Models for Dementia Detection"], "text generation adversarial training": ["Adversarial Text Generation using Large Language Models for Dementia Detection"], "adversarial training classification": ["Adversarial Text Generation using Large Language Models for Dementia Detection"], "dementia detection text generation adversarial training": ["Adversarial Text Generation using Large Language Models for Dementia Detection"], "text generation adversarial training classification": ["Adversarial Text Generation using Large Language Models for Dementia Detection"], "dementia detection text generation adversarial training classification": ["Adversarial Text Generation using Large Language Models for Dementia Detection"], "mt evaluation": ["xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"], "mt evaluation knowledge distillation": ["xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"], "knowledge distillation quantization": ["xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"], "quantization pruning": ["xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"], "mt evaluation knowledge distillation quantization": ["xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"], "knowledge distillation quantization pruning": ["xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"], "mt evaluation knowledge distillation quantization pruning": ["xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"], "moral judgment": ["The Greatest Good Benchmark: Measuring LLMs\u2019 Alignment with Utilitarian Moral Dilemmas"], "utilitarian dilemmas": ["The Greatest Good Benchmark: Measuring LLMs\u2019 Alignment with Utilitarian Moral Dilemmas"], "moral judgment utilitarian dilemmas": ["The Greatest Good Benchmark: Measuring LLMs\u2019 Alignment with Utilitarian Moral Dilemmas"], "natural language understanding natural language inference": ["FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding"], "paraphrase identification relation extraction": ["FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding"], "natural language understanding natural language inference paraphrase identification": ["FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding"], "natural language inference paraphrase identification relation extraction": ["FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding"], "natural language understanding natural language inference paraphrase identification relation extraction": ["FAIRFLOW: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding"], "linguistic style classification": ["Style-Shifting Behaviour of the Manosphere on Reddit"], "style-shifting analysis": ["Style-Shifting Behaviour of the Manosphere on Reddit"], "linguistic style classification style-shifting analysis": ["Style-Shifting Behaviour of the Manosphere on Reddit"], "LLMs  analysis": ["The Death and Life of Great Prompts: Analyzing the Evolution of LLM Prompts from the Structural Perspective"], "prompt engineering LLMs  analysis": ["The Death and Life of Great Prompts: Analyzing the Evolution of LLM Prompts from the Structural Perspective"], "interleaved text-and-image generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "creative generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "multimodal script generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "visual storytelling": ["Holistic Evaluation for Interleaved Text-and-Image Generation", "Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition"], "marketing material generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "education content generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "activity generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "sequential image editing": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "multi-concept image composition": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "interleaved text-and-image generation creative generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "creative generation multimodal script generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "multimodal script generation visual storytelling": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "visual storytelling marketing material generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "marketing material generation report generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "report generation education content generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "education content generation activity generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "activity generation sequential image editing": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "sequential image editing multi-concept image composition": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "interleaved text-and-image generation creative generation multimodal script generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "creative generation multimodal script generation visual storytelling": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "multimodal script generation visual storytelling marketing material generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "visual storytelling marketing material generation report generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "marketing material generation report generation education content generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "report generation education content generation activity generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "education content generation activity generation sequential image editing": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "activity generation sequential image editing multi-concept image composition": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "interleaved text-and-image generation creative generation multimodal script generation visual storytelling": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "creative generation multimodal script generation visual storytelling marketing material generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "multimodal script generation visual storytelling marketing material generation report generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "visual storytelling marketing material generation report generation education content generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "marketing material generation report generation education content generation activity generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "report generation education content generation activity generation sequential image editing": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "education content generation activity generation sequential image editing multi-concept image composition": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "interleaved text-and-image generation creative generation multimodal script generation visual storytelling marketing material generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "creative generation multimodal script generation visual storytelling marketing material generation report generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "multimodal script generation visual storytelling marketing material generation report generation education content generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "visual storytelling marketing material generation report generation education content generation activity generation": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "marketing material generation report generation education content generation activity generation sequential image editing": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "report generation education content generation activity generation sequential image editing multi-concept image composition": ["Holistic Evaluation for Interleaved Text-and-Image Generation"], "nl-fol translation": ["FOLIO: Natural Language Reasoning with First-Order Logic"], "natural language reasoning nl-fol translation": ["FOLIO: Natural Language Reasoning with First-Order Logic"], "topic discovery": ["The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?"], "topic assignment": ["The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?"], "topic discovery topic assignment": ["The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?"], "syntactic knowledge evaluation": ["Is Child-Directed Speech Effective Training Data for Language Models?"], "semantic knowledge evaluation": ["Is Child-Directed Speech Effective Training Data for Language Models?"], "language modeling syntactic knowledge evaluation": ["Is Child-Directed Speech Effective Training Data for Language Models?"], "syntactic knowledge evaluation semantic knowledge evaluation": ["Is Child-Directed Speech Effective Training Data for Language Models?"], "language modeling syntactic knowledge evaluation semantic knowledge evaluation": ["Is Child-Directed Speech Effective Training Data for Language Models?"], "natural language processing sentiment classification": ["RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference"], "sentiment classification paraphrase detection": ["RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference"], "paraphrase detection natural language inference": ["RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference"], "natural language processing sentiment classification paraphrase detection": ["RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference"], "sentiment classification paraphrase detection natural language inference": ["RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference"], "natural language processing sentiment classification paraphrase detection natural language inference": ["RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference"], "natural language inference abstract reasoning": ["Inference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs"], "abstract reasoning common sense reasoning": ["Inference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs"], "natural language inference abstract reasoning common sense reasoning": ["Inference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs"], "misogynous meme identification": ["M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought"], "jailbreaking LLMs red-teaming": ["GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation"], "tabular nli": ["Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets"], "tabular nli natural language inference": ["Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets"], "simultaneous speech translation": ["Simul-MuST-C: Simultaneous Multilingual Speech Translation Corpus Using Large Language Model"], "table generation evaluation": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "table understanding": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text", "Schema-Driven Information Extraction from Heterogeneous Tables"], "semantic quality assessment": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "table generation evaluation natural language inference": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "natural language inference table understanding": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "table understanding semantic quality assessment": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "table generation evaluation natural language inference table understanding": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "natural language inference table understanding semantic quality assessment": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "table generation evaluation natural language inference table understanding semantic quality assessment": ["Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text"], "sentence similarity": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "paper recommendation": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "information retrieval sentence similarity": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "sentence similarity question answering": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "question answering entity linking": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "entity linking paper recommendation": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "information retrieval sentence similarity question answering": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "sentence similarity question answering entity linking": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "question answering entity linking paper recommendation": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "information retrieval sentence similarity question answering entity linking": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "sentence similarity question answering entity linking paper recommendation": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "information retrieval sentence similarity question answering entity linking paper recommendation": ["BMRETRIEVER: Tuning Large Language Models as Better Biomedical Text Retrievers"], "passage ranking": ["Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval", "Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "dialogue ranking": ["Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval"], "entity linking passage ranking": ["Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval"], "passage ranking dialogue ranking": ["Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval"], "entity linking passage ranking dialogue ranking": ["Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval"], "inconsistency detection": ["M\u00b3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection"], "entailment prediction": ["M\u00b3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection"], "fact-checking inconsistency detection": ["M\u00b3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection"], "inconsistency detection entailment prediction": ["M\u00b3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection"], "fact-checking inconsistency detection entailment prediction": ["M\u00b3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection"], "biomedical qa": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning", "Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering"], "mednli": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mediqa-rqe": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "pubhealth": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "health fact-checking": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "medical reasoning biomedical qa": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "biomedical qa mednli": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mednli mediqa-rqe": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mediqa-rqe pubhealth": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "pubhealth information retrieval": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "information retrieval machine reading comprehension": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "machine reading comprehension health fact-checking": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "medical reasoning biomedical qa mednli": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "biomedical qa mednli mediqa-rqe": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mednli mediqa-rqe pubhealth": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mediqa-rqe pubhealth information retrieval": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "pubhealth information retrieval machine reading comprehension": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "information retrieval machine reading comprehension health fact-checking": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "medical reasoning biomedical qa mednli mediqa-rqe": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "biomedical qa mednli mediqa-rqe pubhealth": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mednli mediqa-rqe pubhealth information retrieval": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mediqa-rqe pubhealth information retrieval machine reading comprehension": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "pubhealth information retrieval machine reading comprehension health fact-checking": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "medical reasoning biomedical qa mednli mediqa-rqe pubhealth": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "biomedical qa mednli mediqa-rqe pubhealth information retrieval": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mednli mediqa-rqe pubhealth information retrieval machine reading comprehension": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "mediqa-rqe pubhealth information retrieval machine reading comprehension health fact-checking": ["MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"], "multi-tabular reasoning on ehrs": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "tool-use planning": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "interactive coding": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "multi-tabular reasoning on ehrs code generation": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "code generation tool-use planning": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "tool-use planning interactive coding": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "interactive coding error correction": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "multi-tabular reasoning on ehrs code generation tool-use planning": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "code generation tool-use planning interactive coding": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "tool-use planning interactive coding error correction": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "multi-tabular reasoning on ehrs code generation tool-use planning interactive coding": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "code generation tool-use planning interactive coding error correction": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "multi-tabular reasoning on ehrs code generation tool-use planning interactive coding error correction": ["EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"], "text generation detection": ["SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation"], "human-written text discrimination": ["SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation"], "text generation detection LLM-generated text detection": ["SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation"], "LLM-generated text detection human-written text discrimination": ["SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation"], "text generation detection LLM-generated text detection human-written text discrimination": ["SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation"], "causality identification": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causal attribution": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "collider bias": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "confounder identification": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "backdoor adjustment set": ["CELLO: Causal Evaluation of Large Vision-Language Models", "CLEAR: Can Language Models Really Understand Causal Graphs?"], "controlled direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "natural direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "natural indirect effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "sufficient cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "necessary cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causality identification causal attribution": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causal attribution abstract reasoning": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "abstract reasoning collider bias": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "collider bias confounder identification": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "confounder identification backdoor adjustment set": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "backdoor adjustment set controlled direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "controlled direct effect counterfactual reasoning": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "counterfactual reasoning natural direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "natural direct effect natural indirect effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "natural indirect effect sufficient cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "sufficient cause necessary cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causality identification causal attribution abstract reasoning": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causal attribution abstract reasoning collider bias": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "abstract reasoning collider bias confounder identification": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "collider bias confounder identification backdoor adjustment set": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "confounder identification backdoor adjustment set controlled direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "backdoor adjustment set controlled direct effect counterfactual reasoning": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "controlled direct effect counterfactual reasoning natural direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "counterfactual reasoning natural direct effect natural indirect effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "natural direct effect natural indirect effect sufficient cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "natural indirect effect sufficient cause necessary cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causality identification causal attribution abstract reasoning collider bias": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causal attribution abstract reasoning collider bias confounder identification": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "abstract reasoning collider bias confounder identification backdoor adjustment set": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "collider bias confounder identification backdoor adjustment set controlled direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "confounder identification backdoor adjustment set controlled direct effect counterfactual reasoning": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "backdoor adjustment set controlled direct effect counterfactual reasoning natural direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "controlled direct effect counterfactual reasoning natural direct effect natural indirect effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "counterfactual reasoning natural direct effect natural indirect effect sufficient cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "natural direct effect natural indirect effect sufficient cause necessary cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causality identification causal attribution abstract reasoning collider bias confounder identification": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "causal attribution abstract reasoning collider bias confounder identification backdoor adjustment set": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "abstract reasoning collider bias confounder identification backdoor adjustment set controlled direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "collider bias confounder identification backdoor adjustment set controlled direct effect counterfactual reasoning": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "confounder identification backdoor adjustment set controlled direct effect counterfactual reasoning natural direct effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "backdoor adjustment set controlled direct effect counterfactual reasoning natural direct effect natural indirect effect": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "controlled direct effect counterfactual reasoning natural direct effect natural indirect effect sufficient cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "counterfactual reasoning natural direct effect natural indirect effect sufficient cause necessary cause": ["CELLO: Causal Evaluation of Large Vision-Language Models"], "simt": ["Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair"], "corpus construction": ["Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair"], "simt corpus construction": ["Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair"], "multimodal dialogue": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "video question answering visual question answering": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "visual reasoning multimodal dialogue": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "video question answering visual question answering image captioning": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "visual question answering image captioning visual reasoning": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "image captioning visual reasoning multimodal dialogue": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "video question answering visual question answering image captioning visual reasoning": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "visual question answering image captioning visual reasoning multimodal dialogue": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "video question answering visual question answering image captioning visual reasoning multimodal dialogue": ["Training-free Deep Concept Injection Enables Language Models for Video Question Answering"], "multi-image instruction": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal knowledge-seeking": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal in-context learning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "general comparison": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "subtle difference": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "visual referring": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "fine-grained visual recognition": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "text-rich images": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multi-image instruction multimodal knowledge-seeking": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal knowledge-seeking multimodal in-context learning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal in-context learning general comparison": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "general comparison subtle difference": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "subtle difference visual referring": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "visual referring temporal reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "temporal reasoning logical reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "logical reasoning fine-grained visual recognition": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "fine-grained visual recognition text-rich images": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multi-image instruction multimodal knowledge-seeking multimodal in-context learning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal knowledge-seeking multimodal in-context learning general comparison": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal in-context learning general comparison subtle difference": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "general comparison subtle difference visual referring": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "subtle difference visual referring temporal reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "visual referring temporal reasoning logical reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "temporal reasoning logical reasoning fine-grained visual recognition": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "logical reasoning fine-grained visual recognition text-rich images": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multi-image instruction multimodal knowledge-seeking multimodal in-context learning general comparison": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal knowledge-seeking multimodal in-context learning general comparison subtle difference": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal in-context learning general comparison subtle difference visual referring": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "general comparison subtle difference visual referring temporal reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "subtle difference visual referring temporal reasoning logical reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "visual referring temporal reasoning logical reasoning fine-grained visual recognition": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "temporal reasoning logical reasoning fine-grained visual recognition text-rich images": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multi-image instruction multimodal knowledge-seeking multimodal in-context learning general comparison subtle difference": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal knowledge-seeking multimodal in-context learning general comparison subtle difference visual referring": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "multimodal in-context learning general comparison subtle difference visual referring temporal reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "general comparison subtle difference visual referring temporal reasoning logical reasoning": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "subtle difference visual referring temporal reasoning logical reasoning fine-grained visual recognition": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "visual referring temporal reasoning logical reasoning fine-grained visual recognition text-rich images": ["MIBench: Evaluating Multimodal Large Language Models over Multiple Images"], "obqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-challenge": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "wg": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "commonsenseqa 2.0": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "csqa2": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "qasc": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "commonsense question answering csqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "csqa openbookqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "openbookqa obqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "obqa arc-easy": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-easy arc-challenge": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "arc-challenge piqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "piqa winogrande": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "winogrande wg": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "wg commonsenseqa 2.0": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "commonsenseqa 2.0 csqa2": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "csqa2 qasc": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "commonsense question answering csqa openbookqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "csqa openbookqa obqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "openbookqa obqa arc-easy": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "obqa arc-easy arc-challenge": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-easy arc-challenge piqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-challenge piqa winogrande": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "piqa winogrande wg": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "winogrande wg commonsenseqa 2.0": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "wg commonsenseqa 2.0 csqa2": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "commonsenseqa 2.0 csqa2 qasc": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "commonsense question answering csqa openbookqa obqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "csqa openbookqa obqa arc-easy": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "openbookqa obqa arc-easy arc-challenge": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "obqa arc-easy arc-challenge piqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-easy arc-challenge piqa winogrande": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-challenge piqa winogrande wg": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "piqa winogrande wg commonsenseqa 2.0": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "winogrande wg commonsenseqa 2.0 csqa2": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "wg commonsenseqa 2.0 csqa2 qasc": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "commonsense question answering csqa openbookqa obqa arc-easy": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "csqa openbookqa obqa arc-easy arc-challenge": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "openbookqa obqa arc-easy arc-challenge piqa": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "obqa arc-easy arc-challenge piqa winogrande": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-easy arc-challenge piqa winogrande wg": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "arc-challenge piqa winogrande wg commonsenseqa 2.0": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "piqa winogrande wg commonsenseqa 2.0 csqa2": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "winogrande wg commonsenseqa 2.0 csqa2 qasc": ["ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering"], "conversational support system for physical disabilities": ["ABLE: Personalized Disability Support with Politeness and Empathy Integration"], "algorithmic reasoning tasks": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "dyck languages": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "geometric shapes": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models", "Dual-Phase Accelerated Prompt Optimization"], "reasoning about colored objects": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "temporal sequences": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "tracking shuffled objectives": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "algorithmic reasoning tasks dyck languages": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "dyck languages geometric shapes": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "geometric shapes navigate": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "navigate reasoning about colored objects": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "reasoning about colored objects temporal sequences": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "temporal sequences tracking shuffled objectives": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "tracking shuffled objectives web of lies": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "algorithmic reasoning tasks dyck languages geometric shapes": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "dyck languages geometric shapes navigate": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "geometric shapes navigate reasoning about colored objects": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "navigate reasoning about colored objects temporal sequences": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "reasoning about colored objects temporal sequences tracking shuffled objectives": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "temporal sequences tracking shuffled objectives web of lies": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "algorithmic reasoning tasks dyck languages geometric shapes navigate": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "dyck languages geometric shapes navigate reasoning about colored objects": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "geometric shapes navigate reasoning about colored objects temporal sequences": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "navigate reasoning about colored objects temporal sequences tracking shuffled objectives": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "reasoning about colored objects temporal sequences tracking shuffled objectives web of lies": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "algorithmic reasoning tasks dyck languages geometric shapes navigate reasoning about colored objects": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "dyck languages geometric shapes navigate reasoning about colored objects temporal sequences": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "geometric shapes navigate reasoning about colored objects temporal sequences tracking shuffled objectives": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "navigate reasoning about colored objects temporal sequences tracking shuffled objectives web of lies": ["Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models"], "code editing": ["COFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code"], "natural language feedback generation": ["COFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code"], "code editing natural language feedback generation": ["COFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code"], "natural language feedback generation reinforcement learning": ["COFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code"], "code editing natural language feedback generation reinforcement learning": ["COFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code"], "text simplification machine translation": ["Improving Minimum Bayes Risk Decoding with Multi-Prompt"], "machine translation code generation": ["Improving Minimum Bayes Risk Decoding with Multi-Prompt"], "text simplification machine translation code generation": ["Improving Minimum Bayes Risk Decoding with Multi-Prompt"], "cognitive distortion detection": ["Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework"], "cognitive distortion reasoning": ["Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework"], "emotion prediction": ["Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework", "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models"], "cognitive distortion detection cognitive distortion reasoning": ["Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework"], "cognitive distortion reasoning emotion prediction": ["Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework"], "cognitive distortion detection cognitive distortion reasoning emotion prediction": ["Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework"], "text-to-image retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "image-to-text retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "visual question answering cross-modal retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "cross-modal retrieval text-to-image retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "text-to-image retrieval image-to-text retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "image captioning visual question answering cross-modal retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "visual question answering cross-modal retrieval text-to-image retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "cross-modal retrieval text-to-image retrieval image-to-text retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "image captioning visual question answering cross-modal retrieval text-to-image retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "visual question answering cross-modal retrieval text-to-image retrieval image-to-text retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "image captioning visual question answering cross-modal retrieval text-to-image retrieval image-to-text retrieval": ["Nearest Neighbor Normalization Improves Multimodal Retrieval"], "pragmatic question answering": ["Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning"], "image referential game with theory of mind": ["Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning"], "pragmatic question answering image referential game with theory of mind": ["Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning"], "long-context question answering": ["LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering", "Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell", "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "robustness against paraphrasing attacks": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "text quality": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "watermarking text generation": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "text generation robustness against paraphrasing attacks": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "robustness against paraphrasing attacks text quality": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "watermarking text generation robustness against paraphrasing attacks": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "text generation robustness against paraphrasing attacks text quality": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "watermarking text generation robustness against paraphrasing attacks text quality": ["Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models"], "knowledge augmentation": ["Knowledge Graph Enhanced Large Language Model Editing"], "model editing knowledge augmentation": ["Knowledge Graph Enhanced Large Language Model Editing"], "knowledge augmentation generalization": ["Knowledge Graph Enhanced Large Language Model Editing"], "model editing knowledge augmentation generalization": ["Knowledge Graph Enhanced Large Language Model Editing"], "ai-generated text detection": [" 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated Peer Reviews ", "Counter Turing Test (CT2): Investigating AI-Generated Text Detection for Hindi - Ranking LLMs based on Hindi AI Detectability Index (ADIhi)"], "peer review analysis": [" 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated Peer Reviews "], "ai-generated text detection peer review analysis": [" 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated Peer Reviews "], "peer review analysis text classification": [" 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated Peer Reviews "], "ai-generated text detection peer review analysis text classification": [" 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated Peer Reviews "], "open-vocabulary object detection": ["Mitigating Open-Vocabulary Caption Hallucinations"], "image captioning hallucination mitigation": ["Mitigating Open-Vocabulary Caption Hallucinations"], "hallucination mitigation open-vocabulary object detection": ["Mitigating Open-Vocabulary Caption Hallucinations"], "image captioning hallucination mitigation open-vocabulary object detection": ["Mitigating Open-Vocabulary Caption Hallucinations"], "language modeling boolq": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "boolq cb": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "cb copa": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "copa multirc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "multirc record": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "record rte": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "rte wic": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "wic wsc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "wsc superglue": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "language modeling boolq cb": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "boolq cb copa": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "cb copa multirc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "copa multirc record": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "multirc record rte": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "record rte wic": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "rte wic wsc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "wic wsc superglue": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "language modeling boolq cb copa": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "boolq cb copa multirc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "cb copa multirc record": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "copa multirc record rte": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "multirc record rte wic": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "record rte wic wsc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "rte wic wsc superglue": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "language modeling boolq cb copa multirc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "boolq cb copa multirc record": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "cb copa multirc record rte": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "copa multirc record rte wic": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "multirc record rte wic wsc": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "record rte wic wsc superglue": ["Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes"], "sentiment analysis natural language inference paraphrase detection": ["ALVIN: Active Learning Via INterpolation"], "language model alignment text generation": ["Filtered Direct Preference Optimization"], "reinforcement learning from human feedback language model alignment text generation": ["Filtered Direct Preference Optimization"], "truthfulqa-mc2": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-gen": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 en\u2192fr": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 fr\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192de": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 de\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192ro": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 ro\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "alpacaeval": ["Instruction Fine-Tuning: Does Prompt Loss Matter?", "Achieving Stronger Generation via Simple Contrastive Tuning"], "pandalm": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "arc challenge piqa": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "piqa truthfulqa-mc2": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-mc2 winogrande": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "winogrande truthfulqa-gen": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-gen wmt14 en\u2192fr": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 en\u2192fr wmt14 fr\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 fr\u2192en wmt16 en\u2192de": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192de wmt16 de\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 de\u2192en wmt16 en\u2192ro": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192ro wmt16 ro\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 ro\u2192en alpacaeval": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "alpacaeval pandalm": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "arc challenge piqa truthfulqa-mc2": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "piqa truthfulqa-mc2 winogrande": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-mc2 winogrande truthfulqa-gen": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "winogrande truthfulqa-gen wmt14 en\u2192fr": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-gen wmt14 en\u2192fr wmt14 fr\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 en\u2192fr wmt14 fr\u2192en wmt16 en\u2192de": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 fr\u2192en wmt16 en\u2192de wmt16 de\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192de wmt16 de\u2192en wmt16 en\u2192ro": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 de\u2192en wmt16 en\u2192ro wmt16 ro\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192ro wmt16 ro\u2192en alpacaeval": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 ro\u2192en alpacaeval pandalm": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "arc challenge piqa truthfulqa-mc2 winogrande": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "piqa truthfulqa-mc2 winogrande truthfulqa-gen": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-mc2 winogrande truthfulqa-gen wmt14 en\u2192fr": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "winogrande truthfulqa-gen wmt14 en\u2192fr wmt14 fr\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-gen wmt14 en\u2192fr wmt14 fr\u2192en wmt16 en\u2192de": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 en\u2192fr wmt14 fr\u2192en wmt16 en\u2192de wmt16 de\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 fr\u2192en wmt16 en\u2192de wmt16 de\u2192en wmt16 en\u2192ro": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192de wmt16 de\u2192en wmt16 en\u2192ro wmt16 ro\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 de\u2192en wmt16 en\u2192ro wmt16 ro\u2192en alpacaeval": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192ro wmt16 ro\u2192en alpacaeval pandalm": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "arc challenge piqa truthfulqa-mc2 winogrande truthfulqa-gen": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "piqa truthfulqa-mc2 winogrande truthfulqa-gen wmt14 en\u2192fr": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-mc2 winogrande truthfulqa-gen wmt14 en\u2192fr wmt14 fr\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "winogrande truthfulqa-gen wmt14 en\u2192fr wmt14 fr\u2192en wmt16 en\u2192de": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "truthfulqa-gen wmt14 en\u2192fr wmt14 fr\u2192en wmt16 en\u2192de wmt16 de\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 en\u2192fr wmt14 fr\u2192en wmt16 en\u2192de wmt16 de\u2192en wmt16 en\u2192ro": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt14 fr\u2192en wmt16 en\u2192de wmt16 de\u2192en wmt16 en\u2192ro wmt16 ro\u2192en": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 en\u2192de wmt16 de\u2192en wmt16 en\u2192ro wmt16 ro\u2192en alpacaeval": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "wmt16 de\u2192en wmt16 en\u2192ro wmt16 ro\u2192en alpacaeval pandalm": ["Instruction Fine-Tuning: Does Prompt Loss Matter?"], "entity insertion": ["Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "entity insertion multilingual learning": ["Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "multilingual learning information retrieval": ["Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "information retrieval passage ranking": ["Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "entity insertion multilingual learning information retrieval": ["Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "multilingual learning information retrieval passage ranking": ["Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "entity insertion multilingual learning information retrieval passage ranking": ["Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia"], "discourse analysis": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?", "Recent Trends in Linear Text Segmentation: A Survey"], "event relation extraction discourse analysis": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "temporal relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "causal relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "subevent relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "event relation extraction coreference resolution": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "coreference resolution temporal relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "temporal relation extraction causal relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "causal relation extraction subevent relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "event relation extraction coreference resolution temporal relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "coreference resolution temporal relation extraction causal relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "temporal relation extraction causal relation extraction subevent relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "event relation extraction coreference resolution temporal relation extraction causal relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "coreference resolution temporal relation extraction causal relation extraction subevent relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "event relation extraction coreference resolution temporal relation extraction causal relation extraction subevent relation extraction": ["Are LLMs Good Annotators for Discourse-level Event Relation Extraction?"], "semantic role labeling": ["Transferability of Syntax-Aware Graph Neural Networks in Zero-Shot Cross-Lingual Semantic Role Labeling", "When the Misidentified Adverbial Phrase Functions as a Complement"], "cross-lingual amr parsing": ["Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing"], "joint entity and relation extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "named entity recognition relation triplet extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "relation triplet extraction joint entity and relation extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "joint entity and relation extraction event detection": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "event detection event extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "event extraction aspect-based sentiment analysis": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "named entity recognition relation triplet extraction joint entity and relation extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "relation triplet extraction joint entity and relation extraction event detection": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "joint entity and relation extraction event detection event extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "event detection event extraction aspect-based sentiment analysis": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "named entity recognition relation triplet extraction joint entity and relation extraction event detection": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "relation triplet extraction joint entity and relation extraction event detection event extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "joint entity and relation extraction event detection event extraction aspect-based sentiment analysis": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "named entity recognition relation triplet extraction joint entity and relation extraction event detection event extraction": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "relation triplet extraction joint entity and relation extraction event detection event extraction aspect-based sentiment analysis": ["General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"], "task 1": ["\ub17c\ubb38 \uc81c\ubaa9"], "task 2": ["\ub17c\ubb38 \uc81c\ubaa9"], "...": ["\ub17c\ubb38 \uc81c\ubaa9"], "task 1 task 2": ["\ub17c\ubb38 \uc81c\ubaa9"], "task 2 ...": ["\ub17c\ubb38 \uc81c\ubaa9"], "task 1 task 2 ...": ["\ub17c\ubb38 \uc81c\ubaa9"], "aspect based sentiment analysis": ["Measuring the Robustness of NLP Models to Domain Shifts"], "natural language inference aspect based sentiment analysis": ["Measuring the Robustness of NLP Models to Domain Shifts"], "aspect based sentiment analysis question answering": ["Measuring the Robustness of NLP Models to Domain Shifts"], "question answering question generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "question generation abstractive summarization": ["Measuring the Robustness of NLP Models to Domain Shifts"], "abstractive summarization title generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "sentiment analysis natural language inference aspect based sentiment analysis": ["Measuring the Robustness of NLP Models to Domain Shifts"], "natural language inference aspect based sentiment analysis question answering": ["Measuring the Robustness of NLP Models to Domain Shifts"], "aspect based sentiment analysis question answering question generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "question answering question generation abstractive summarization": ["Measuring the Robustness of NLP Models to Domain Shifts"], "question generation abstractive summarization title generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "sentiment analysis natural language inference aspect based sentiment analysis question answering": ["Measuring the Robustness of NLP Models to Domain Shifts"], "natural language inference aspect based sentiment analysis question answering question generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "aspect based sentiment analysis question answering question generation abstractive summarization": ["Measuring the Robustness of NLP Models to Domain Shifts"], "question answering question generation abstractive summarization title generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "sentiment analysis natural language inference aspect based sentiment analysis question answering question generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "natural language inference aspect based sentiment analysis question answering question generation abstractive summarization": ["Measuring the Robustness of NLP Models to Domain Shifts"], "aspect based sentiment analysis question answering question generation abstractive summarization title generation": ["Measuring the Robustness of NLP Models to Domain Shifts"], "3d point cloud classification": ["Text2Model: Text-based Model Induction for Zero-shot Image Classification"], "image classification 3d point cloud classification": ["Text2Model: Text-based Model Induction for Zero-shot Image Classification"], "3d point cloud classification action recognition": ["Text2Model: Text-based Model Induction for Zero-shot Image Classification"], "image classification 3d point cloud classification action recognition": ["Text2Model: Text-based Model Induction for Zero-shot Image Classification"], "sentence insertion": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "graph neural networks": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "cross-domain learning": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "sentence insertion natural language processing": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "natural language processing graph neural networks": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "graph neural networks cross-domain learning": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "sentence insertion natural language processing graph neural networks": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "natural language processing graph neural networks cross-domain learning": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "sentence insertion natural language processing graph neural networks cross-domain learning": ["InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem"], "evidence detection": ["DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?"], "evidence detection multi-hop reasoning": ["DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?"], "multi-hop reasoning commonsense reasoning": ["DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?"], "commonsense reasoning question answering": ["DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?", "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "evidence detection multi-hop reasoning commonsense reasoning": ["DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?"], "multi-hop reasoning commonsense reasoning question answering": ["DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?"], "evidence detection multi-hop reasoning commonsense reasoning question answering": ["DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?"], "few-shot text classification": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "review classification": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "intent detection": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks", "Generate then Refine: Data Augmentation for Zero-shot Intent Detection"], "few-shot text classification news classification": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "news classification review classification": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "review classification intent detection": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "few-shot text classification news classification review classification": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "news classification review classification intent detection": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "few-shot text classification news classification review classification intent detection": ["Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks"], "attribution reasoning": ["CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity"], "question answering attribution reasoning": ["CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity"], "knowledge-based vqa": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM", "Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA", "Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective"], "long-tail entity handling": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "visual question answering entity recognition": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "entity recognition knowledge-based vqa": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "knowledge-based vqa long-tail entity handling": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "long-tail entity handling hallucination reduction": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "visual question answering entity recognition knowledge-based vqa": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "entity recognition knowledge-based vqa long-tail entity handling": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "knowledge-based vqa long-tail entity handling hallucination reduction": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "visual question answering entity recognition knowledge-based vqa long-tail entity handling": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "entity recognition knowledge-based vqa long-tail entity handling hallucination reduction": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "visual question answering entity recognition knowledge-based vqa long-tail entity handling hallucination reduction": ["SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM"], "policy simulation": ["SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"], "LLM-based agent": ["SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"], "resource allocation policy simulation": ["SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"], "policy simulation LLM-based agent": ["SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"], "resource allocation policy simulation LLM-based agent": ["SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"], "help-seeking post detection": ["Ukrainian Resilience: A Dataset for Detection of Help-Seeking Signals Amidst the Chaos of War"], "document hashing": ["Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model"], "similarity search": ["Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model", "QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "document hashing information retrieval": ["Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model"], "information retrieval similarity search": ["Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model"], "document hashing information retrieval similarity search": ["Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model"], "temporal fact reasoning": ["Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs"], "temporal fact reasoning knowledge graph completion": ["Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs"], "temporal fact reasoning knowledge graph completion link prediction": ["Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs"], "radiology report generation evaluation": ["GREEN: Generative Radiology Report Evaluation and Error Notation"], "explainable recommendation": ["XRec: Large Language Models for Explainable Recommendation"], "user behavior understanding": ["XRec: Large Language Models for Explainable Recommendation"], "collaborative filtering": ["XRec: Large Language Models for Explainable Recommendation"], "explainable recommendation user behavior understanding": ["XRec: Large Language Models for Explainable Recommendation"], "user behavior understanding collaborative filtering": ["XRec: Large Language Models for Explainable Recommendation"], "explainable recommendation user behavior understanding collaborative filtering": ["XRec: Large Language Models for Explainable Recommendation"], "psychiatric assessment": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "questionnaire completion": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "depression severity prediction": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "ptsd severity prediction": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "psychiatric assessment questionnaire completion": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "questionnaire completion depression severity prediction": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "depression severity prediction ptsd severity prediction": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "psychiatric assessment questionnaire completion depression severity prediction": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "questionnaire completion depression severity prediction ptsd severity prediction": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "psychiatric assessment questionnaire completion depression severity prediction ptsd severity prediction": ["LLM Questionnaire Completion for Automatic Psychiatric Assessment"], "dynamic aspect-based summarization": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "aspect identification": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "disordered text summarization": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "dynamic aspect-based summarization text summarization": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "text summarization aspect identification": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "aspect identification disordered text summarization": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "dynamic aspect-based summarization text summarization aspect identification": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "text summarization aspect identification disordered text summarization": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "dynamic aspect-based summarization text summarization aspect identification disordered text summarization": ["Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"], "text expansion": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "spell correction": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "news title generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "poem generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "religious lyrics generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "instruction fine-tuning sentiment analysis": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "sentiment analysis machine translation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "Exploring the Relationship between In-Context Learning and Instruction Tuning"], "text summarization text expansion": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "text expansion question answering": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "question answering named entity recognition": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "named entity recognition spell correction": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "spell correction news title generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "news title generation poem generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "poem generation religious lyrics generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "religious lyrics generation story generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "instruction fine-tuning sentiment analysis machine translation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "sentiment analysis machine translation text summarization": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets", "Exploring the Relationship between In-Context Learning and Instruction Tuning"], "machine translation text summarization text expansion": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "text summarization text expansion question answering": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "text expansion question answering named entity recognition": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "question answering named entity recognition spell correction": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "named entity recognition spell correction news title generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "spell correction news title generation poem generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "news title generation poem generation religious lyrics generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "poem generation religious lyrics generation story generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "instruction fine-tuning sentiment analysis machine translation text summarization": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "sentiment analysis machine translation text summarization text expansion": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "machine translation text summarization text expansion question answering": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "text summarization text expansion question answering named entity recognition": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "text expansion question answering named entity recognition spell correction": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "question answering named entity recognition spell correction news title generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "named entity recognition spell correction news title generation poem generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "spell correction news title generation poem generation religious lyrics generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "news title generation poem generation religious lyrics generation story generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "instruction fine-tuning sentiment analysis machine translation text summarization text expansion": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "sentiment analysis machine translation text summarization text expansion question answering": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "machine translation text summarization text expansion question answering named entity recognition": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "text summarization text expansion question answering named entity recognition spell correction": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "text expansion question answering named entity recognition spell correction news title generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "question answering named entity recognition spell correction news title generation poem generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "named entity recognition spell correction news title generation poem generation religious lyrics generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "spell correction news title generation poem generation religious lyrics generation story generation": ["Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"], "authorship verification": ["Can Large Language Models Identify Authorship?"], "authorship verification authorship attribution": ["Can Large Language Models Identify Authorship?"], "text-to-text translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "english-german translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "english-russian translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "simultaneous machine translation text-to-text translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "text-to-text translation speech-to-speech translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "speech-to-speech translation english-german translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "english-german translation english-russian translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "simultaneous machine translation text-to-text translation speech-to-speech translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "text-to-text translation speech-to-speech translation english-german translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "speech-to-speech translation english-german translation english-russian translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "simultaneous machine translation text-to-text translation speech-to-speech translation english-german translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "text-to-text translation speech-to-speech translation english-german translation english-russian translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "simultaneous machine translation text-to-text translation speech-to-speech translation english-german translation english-russian translation": ["TRANSLLAMA: LLM-based Simultaneous Translation System"], "word embedding": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "analogy": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "word similarity": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "categorization": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "word embedding interpretability": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "interpretability dimensionality reduction": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "dimensionality reduction analogy": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "analogy word similarity": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "word similarity categorization": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "word embedding interpretability dimensionality reduction": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "interpretability dimensionality reduction analogy": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "dimensionality reduction analogy word similarity": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "analogy word similarity categorization": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "word embedding interpretability dimensionality reduction analogy": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "interpretability dimensionality reduction analogy word similarity": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "dimensionality reduction analogy word similarity categorization": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "word embedding interpretability dimensionality reduction analogy word similarity": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "interpretability dimensionality reduction analogy word similarity categorization": ["Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings"], "data contamination analysis": ["An Open-Source Data Contamination Report for Large Language Models"], "benchmark contamination detection": ["An Open-Source Data Contamination Report for Large Language Models", "PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models"], "data contamination analysis LLM evaluation": ["An Open-Source Data Contamination Report for Large Language Models"], "LLM evaluation benchmark contamination detection": ["An Open-Source Data Contamination Report for Large Language Models"], "data contamination analysis LLM evaluation benchmark contamination detection": ["An Open-Source Data Contamination Report for Large Language Models"], "open-ended questions": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "chain of thought reasoning": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "medical diagnosis": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "medical question answering open-ended questions": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "open-ended questions chain of thought reasoning": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "chain of thought reasoning prompt engineering": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "prompt engineering medical diagnosis": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "medical question answering open-ended questions chain of thought reasoning": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "open-ended questions chain of thought reasoning prompt engineering": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "chain of thought reasoning prompt engineering medical diagnosis": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "medical question answering open-ended questions chain of thought reasoning prompt engineering": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "open-ended questions chain of thought reasoning prompt engineering medical diagnosis": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "medical question answering open-ended questions chain of thought reasoning prompt engineering medical diagnosis": ["Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering"], "brainstorming": ["Reformatted Alignment"], "rewriting": ["Reformatted Alignment", "SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "extraction": ["Reformatted Alignment"], "education": ["Reformatted Alignment"], "others": ["Reformatted Alignment"], "generation brainstorming": ["Reformatted Alignment"], "brainstorming code": ["Reformatted Alignment"], "code rewriting": ["Reformatted Alignment"], "rewriting extraction": ["Reformatted Alignment"], "extraction summarization": ["Reformatted Alignment"], "summarization conversation": ["Reformatted Alignment"], "conversation education": ["Reformatted Alignment"], "education classification": ["Reformatted Alignment"], "classification others": ["Reformatted Alignment"], "generation brainstorming code": ["Reformatted Alignment"], "brainstorming code rewriting": ["Reformatted Alignment"], "code rewriting extraction": ["Reformatted Alignment"], "rewriting extraction summarization": ["Reformatted Alignment"], "extraction summarization conversation": ["Reformatted Alignment"], "summarization conversation education": ["Reformatted Alignment"], "conversation education classification": ["Reformatted Alignment"], "education classification others": ["Reformatted Alignment"], "generation brainstorming code rewriting": ["Reformatted Alignment"], "brainstorming code rewriting extraction": ["Reformatted Alignment"], "code rewriting extraction summarization": ["Reformatted Alignment"], "rewriting extraction summarization conversation": ["Reformatted Alignment"], "extraction summarization conversation education": ["Reformatted Alignment"], "summarization conversation education classification": ["Reformatted Alignment"], "conversation education classification others": ["Reformatted Alignment"], "generation brainstorming code rewriting extraction": ["Reformatted Alignment"], "brainstorming code rewriting extraction summarization": ["Reformatted Alignment"], "code rewriting extraction summarization conversation": ["Reformatted Alignment"], "rewriting extraction summarization conversation education": ["Reformatted Alignment"], "extraction summarization conversation education classification": ["Reformatted Alignment"], "summarization conversation education classification others": ["Reformatted Alignment"], "keyphrase generation domain adaptation": ["Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"], "mental health support": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support", "Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "chatbot development": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"], "dialogue generation mental health support": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"], "mental health support data augmentation": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"], "data augmentation chatbot development": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"], "dialogue generation mental health support data augmentation": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"], "mental health support data augmentation chatbot development": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"], "dialogue generation mental health support data augmentation chatbot development": ["SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"], "document-level event extraction": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "event classification": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "event extraction document-level event extraction": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "document-level event extraction event classification": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "event classification event argument extraction": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "event extraction document-level event extraction event classification": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "document-level event extraction event classification event argument extraction": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "event extraction document-level event extraction event classification event argument extraction": ["DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"], "empirical evaluation": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "cultural context assessment": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "language understanding multitask learning": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "multitask learning benchmark creation": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "benchmark creation empirical evaluation": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "empirical evaluation cultural context assessment": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "language understanding multitask learning benchmark creation": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "multitask learning benchmark creation empirical evaluation": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "benchmark creation empirical evaluation cultural context assessment": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "language understanding multitask learning benchmark creation empirical evaluation": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "multitask learning benchmark creation empirical evaluation cultural context assessment": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "language understanding multitask learning benchmark creation empirical evaluation cultural context assessment": ["MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language"], "RAG  pipeline tuning": ["Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization"], "prompt compression": ["Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization", "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "instruction tuning RAG  pipeline tuning": ["Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization"], "RAG  pipeline tuning prompt compression": ["Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization"], "instruction tuning RAG  pipeline tuning prompt compression": ["Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization"], "dynamic peft composition": ["Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models"], "continual learning language models": ["Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models"], "language models parameter-efficient fine-tuning": ["Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models"], "parameter-efficient fine-tuning dynamic peft composition": ["Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models"], "continual learning language models parameter-efficient fine-tuning": ["Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models"], "language models parameter-efficient fine-tuning dynamic peft composition": ["Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models"], "continual learning language models parameter-efficient fine-tuning dynamic peft composition": ["Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models"], "ccg supertagging": ["Categorial Grammar Supertagging via Large Language Models"], "lcg supertagging": ["Categorial Grammar Supertagging via Large Language Models"], "ccg supertagging lcg supertagging": ["Categorial Grammar Supertagging via Large Language Models"], "lcg supertagging classification": ["Categorial Grammar Supertagging via Large Language Models"], "ccg supertagging lcg supertagging classification": ["Categorial Grammar Supertagging via Large Language Models"], "algorithmic problem solving": ["MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems"], "code generation multimodal learning": ["MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems"], "multimodal learning visual reasoning": ["MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems"], "visual reasoning algorithmic problem solving": ["MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems"], "code generation multimodal learning visual reasoning": ["MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems"], "multimodal learning visual reasoning algorithmic problem solving": ["MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems"], "code generation multimodal learning visual reasoning algorithmic problem solving": ["MMCode: Benchmarking Multimodal Large Language Models in Code Generation with Visually Rich Programming Problems"], "legal judgment prediction": ["Enabling Discriminative Reasoning in LLMs for Legal Judgment Prediction"], "causality graph event prediction": ["What Would Happen Next? Predicting Consequences from An Event Causality Graph"], "event prediction": ["What Would Happen Next? Predicting Consequences from An Event Causality Graph", "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "causality graph event prediction event prediction": ["What Would Happen Next? Predicting Consequences from An Event Causality Graph"], "math reasoning commonsense reasoning": ["Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks", "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "math reasoning commonsense reasoning gsm8k": ["Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "math reasoning commonsense reasoning gsm8k math": ["Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "math reasoning commonsense reasoning gsm8k math csqa": ["Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks"], "event temporal relation extraction": ["Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction"], "long-context generation": ["LONGGENBENCH: Long-context Generation Benchmark"], "long-context generation evaluation benchmark": ["LONGGENBENCH: Long-context Generation Benchmark"], "open-domain question answering query rewriting": ["RaFe: Ranking Feedback Improves Query Rewriting for RAG"], "web search user simulation": ["BASES: Large-scale Web Search User Simulation with Large Language Model based Agents"], "session search": ["BASES: Large-scale Web Search User Simulation with Large Language Model based Agents"], "click prediction": ["BASES: Large-scale Web Search User Simulation with Large Language Model based Agents"], "web search user simulation session search": ["BASES: Large-scale Web Search User Simulation with Large Language Model based Agents"], "session search click prediction": ["BASES: Large-scale Web Search User Simulation with Large Language Model based Agents"], "web search user simulation session search click prediction": ["BASES: Large-scale Web Search User Simulation with Large Language Model based Agents"], "recommendation ranking": ["Make Large Language Model a Better Ranker"], "ranking language generation": ["Make Large Language Model a Better Ranker"], "recommendation ranking language generation": ["Make Large Language Model a Better Ranker"], "checking": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "identification": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning", "Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "open generation": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "checking identification": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "identification rewriting": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "rewriting open generation": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "checking identification rewriting": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "identification rewriting open generation": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "checking identification rewriting open generation": ["SPECIALEX: A Benchmark for In-Context Specialized Lexicon Learning"], "LLM agents": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "introspection": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "action generation": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "web navigation LLM agents": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "LLM agents introspection": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "introspection task decomposition": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "task decomposition action generation": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "web navigation LLM agents introspection": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "LLM agents introspection task decomposition": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "introspection task decomposition action generation": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "web navigation LLM agents introspection task decomposition": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "LLM agents introspection task decomposition action generation": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "web navigation LLM agents introspection task decomposition action generation": ["DEVIL'S ADVOCATE: Anticipatory Reflection for LLM Agents"], "multi-choice question-answering": ["API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access"], "question answering multi-choice question-answering": ["API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access"], "code translation": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "neural compilation": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "program synthesis": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly", "Can LLMs Reason in the Wild with Programs?"], "code translation neural compilation": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "neural compilation decompilation": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "decompilation program synthesis": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "program synthesis code retrieval": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "code retrieval code completion": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "code translation neural compilation decompilation": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "neural compilation decompilation program synthesis": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "decompilation program synthesis code retrieval": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "program synthesis code retrieval code completion": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "code translation neural compilation decompilation program synthesis": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "neural compilation decompilation program synthesis code retrieval": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "decompilation program synthesis code retrieval code completion": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "code translation neural compilation decompilation program synthesis code retrieval": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "neural compilation decompilation program synthesis code retrieval code completion": ["Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly"], "harmfulness reduction": ["Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization"], "helpfulness maintenance": ["Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization", "FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "LLM alignment harmfulness reduction": ["Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization"], "harmfulness reduction helpfulness maintenance": ["Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization"], "LLM alignment harmfulness reduction helpfulness maintenance": ["Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization"], "judge model evaluation": ["OffsetBias: Leveraging Debiased Data for Tuning Evaluators"], "judge model evaluation bias mitigation": ["OffsetBias: Leveraging Debiased Data for Tuning Evaluators"], "bias mitigation meta-evaluation": ["OffsetBias: Leveraging Debiased Data for Tuning Evaluators"], "judge model evaluation bias mitigation meta-evaluation": ["OffsetBias: Leveraging Debiased Data for Tuning Evaluators"], "chinese event extraction": ["Employing Glyphic Information for Chinese Event Extraction with Vision-Language Model"], "chinese event extraction event extraction": ["Employing Glyphic Information for Chinese Event Extraction with Vision-Language Model"], "image editing": ["Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP", "A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models"], "image editing image generation": ["Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP"], "image generation visual question answering": ["Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP"], "visual question answering video understanding": ["Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP"], "image editing image generation visual question answering": ["Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP"], "image generation visual question answering video understanding": ["Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP"], "image editing image generation visual question answering video understanding": ["Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP"], "knowledge generation": ["Guided Knowledge Generation with Language Models for Commonsense Reasoning"], "question answering knowledge generation": ["Guided Knowledge Generation with Language Models for Commonsense Reasoning"], "commonsense reasoning question answering knowledge generation": ["Guided Knowledge Generation with Language Models for Commonsense Reasoning"], "e-commerce question answering": ["BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain"], "retrieval generation": ["BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain"], "generation e-commerce question answering": ["BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain"], "retrieval generation e-commerce question answering": ["BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain"], "implicit discourse relation recognition": ["NCPrompt: NSP-Based Prompt Learning and Contrastive Learning for Implicit Discourse Relation Recognition"], "safety evaluation": ["SAFETY-J: Evaluating Safety with Critique", "Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "text-to-sql in-context learning": ["Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL"], "bias evaluation question answering": ["A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models"], "question answering image generation": ["A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models"], "image generation image editing": ["A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models"], "bias evaluation question answering image generation": ["A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models"], "question answering image generation image editing": ["A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models"], "bias evaluation question answering image generation image editing": ["A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models"], "integrated multimodal ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "text-based ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "speech ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "multimodal ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "entity-aware text generation": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "integrated multimodal ner text-based ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "text-based ner speech ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "speech ner multimodal ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "multimodal ner entity-aware text generation": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "integrated multimodal ner text-based ner speech ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "text-based ner speech ner multimodal ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "speech ner multimodal ner entity-aware text generation": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "integrated multimodal ner text-based ner speech ner multimodal ner": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "text-based ner speech ner multimodal ner entity-aware text generation": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "integrated multimodal ner text-based ner speech ner multimodal ner entity-aware text generation": ["Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"], "gui comprehension": ["VGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning"], "gui comprehension vqa": ["VGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning"], "therapeutic alliance identification": ["Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs"], "automatic counseling evaluation": ["Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs"], "relationship-building skills enhancement": ["Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs"], "therapeutic alliance identification automatic counseling evaluation": ["Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs"], "automatic counseling evaluation relationship-building skills enhancement": ["Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs"], "therapeutic alliance identification automatic counseling evaluation relationship-building skills enhancement": ["Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs"], "gui automation": ["Dynamic Planning for LLM-based Graphical User Interface Automation"], "biomedical question answering": ["SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation"], "biomedical question answering RAG": ["SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation"], "RAG document retrieval": ["SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation"], "biomedical question answering RAG document retrieval": ["SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation"], "complex task solving": ["Large Language Model-based Human-Agent Collaboration for Complex Task Solving"], "human-agent collaboration": ["Large Language Model-based Human-Agent Collaboration for Complex Task Solving"], "complex task solving human-agent collaboration": ["Large Language Model-based Human-Agent Collaboration for Complex Task Solving"], "human-agent collaboration question answering": ["Large Language Model-based Human-Agent Collaboration for Complex Task Solving"], "complex task solving human-agent collaboration question answering": ["Large Language Model-based Human-Agent Collaboration for Complex Task Solving"], "human-agent collaboration question answering code generation": ["Large Language Model-based Human-Agent Collaboration for Complex Task Solving"], "complex task solving human-agent collaboration question answering code generation": ["Large Language Model-based Human-Agent Collaboration for Complex Task Solving"], "multimodal math reasoning evaluation": ["MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation and Fine-grained Classification"], "long context alignment": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "instruction fine-tuning long context alignment": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "long context alignment question answering": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "summarization coding": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "coding translation": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "instruction fine-tuning long context alignment question answering": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "long context alignment question answering summarization": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "question answering summarization coding": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "summarization coding translation": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "instruction fine-tuning long context alignment question answering summarization": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "long context alignment question answering summarization coding": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "question answering summarization coding translation": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "instruction fine-tuning long context alignment question answering summarization coding": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "long context alignment question answering summarization coding translation": ["LongAlign: A Recipe for Long Context Alignment of Large Language Models"], "node classification link prediction": ["Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning"], "link prediction conditional text generation": ["Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning"], "node classification link prediction conditional text generation": ["Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning"], "text-to-sql parsing": ["CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems"], "intent recognition": ["CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems"], "explanation request parsing": ["CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems"], "text-to-sql parsing intent recognition": ["CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems"], "intent recognition explanation request parsing": ["CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems"], "text-to-sql parsing intent recognition explanation request parsing": ["CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems"], "character trait measurement": ["Evaluating Language Model Character Traits"], "anti-lgbtq sentiment analysis": ["Evaluating Language Model Character Traits"], "logical coherence evaluation": ["Evaluating Language Model Character Traits"], "intent analysis": ["Evaluating Language Model Character Traits"], "stationary trait analysis": ["Evaluating Language Model Character Traits"], "reflective trait analysis": ["Evaluating Language Model Character Traits"], "character trait measurement anti-lgbtq sentiment analysis": ["Evaluating Language Model Character Traits"], "anti-lgbtq sentiment analysis logical coherence evaluation": ["Evaluating Language Model Character Traits"], "logical coherence evaluation intent analysis": ["Evaluating Language Model Character Traits"], "intent analysis stationary trait analysis": ["Evaluating Language Model Character Traits"], "stationary trait analysis reflective trait analysis": ["Evaluating Language Model Character Traits"], "character trait measurement anti-lgbtq sentiment analysis logical coherence evaluation": ["Evaluating Language Model Character Traits"], "anti-lgbtq sentiment analysis logical coherence evaluation intent analysis": ["Evaluating Language Model Character Traits"], "logical coherence evaluation intent analysis stationary trait analysis": ["Evaluating Language Model Character Traits"], "intent analysis stationary trait analysis reflective trait analysis": ["Evaluating Language Model Character Traits"], "character trait measurement anti-lgbtq sentiment analysis logical coherence evaluation intent analysis": ["Evaluating Language Model Character Traits"], "anti-lgbtq sentiment analysis logical coherence evaluation intent analysis stationary trait analysis": ["Evaluating Language Model Character Traits"], "logical coherence evaluation intent analysis stationary trait analysis reflective trait analysis": ["Evaluating Language Model Character Traits"], "character trait measurement anti-lgbtq sentiment analysis logical coherence evaluation intent analysis stationary trait analysis": ["Evaluating Language Model Character Traits"], "anti-lgbtq sentiment analysis logical coherence evaluation intent analysis stationary trait analysis reflective trait analysis": ["Evaluating Language Model Character Traits"], "fine-grained rewards": ["SELF-EXPLORE: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards"], "mathematical reasoning self-improvement": ["SELF-EXPLORE: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards"], "self-improvement fine-grained rewards": ["SELF-EXPLORE: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards"], "mathematical reasoning self-improvement fine-grained rewards": ["SELF-EXPLORE: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards"], "risk identification": ["R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"], "safety judgment": ["R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"], "LLM safety evaluation risk identification": ["R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"], "risk identification safety judgment": ["R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"], "LLM safety evaluation risk identification safety judgment": ["R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"], "product attribute value extraction": ["EAVE: Efficient Product Attribute Value Extraction via Lightweight Sparse-layer Interaction"], "alignment skills assessment": ["MULTISKILL: Evaluating Large Multimodal Models for Fine-grained Alignment Skills"], "multimodal evaluation alignment skills assessment": ["MULTISKILL: Evaluating Large Multimodal Models for Fine-grained Alignment Skills"], "copyrighted content unlearning": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "user privacy unlearning": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "general knowledge retention": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "knowledge unlearning copyrighted content unlearning": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "copyrighted content unlearning user privacy unlearning": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "user privacy unlearning general knowledge retention": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "knowledge unlearning copyrighted content unlearning user privacy unlearning": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "copyrighted content unlearning user privacy unlearning general knowledge retention": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "knowledge unlearning copyrighted content unlearning user privacy unlearning general knowledge retention": ["To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models"], "knowledge-based visual question answering": ["EchoSight: Advancing Visual-Language Models with Wiki Knowledge", "Diversity, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA"], "knowledge-based visual question answering visual question answering": ["EchoSight: Advancing Visual-Language Models with Wiki Knowledge"], "knowledge-based visual question answering zero-shot learning": ["Diversity, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA"], "confidence elicitation": ["Reconfidencing LLMs from the Grouping Loss Perspective", "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration"], "grouping loss reduction": ["Reconfidencing LLMs from the Grouping Loss Perspective"], "confidence elicitation calibration": ["Reconfidencing LLMs from the Grouping Loss Perspective", "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration"], "calibration grouping loss reduction": ["Reconfidencing LLMs from the Grouping Loss Perspective"], "confidence elicitation calibration grouping loss reduction": ["Reconfidencing LLMs from the Grouping Loss Perspective"], "complex problem solving": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "token structure probing": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "typographical variation": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "anagram": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "case sensitivity": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "length awareness": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "complex problem solving token structure probing": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "token structure probing typographical variation": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "typographical variation anagram": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "anagram case sensitivity": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "case sensitivity length awareness": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "complex problem solving token structure probing typographical variation": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "token structure probing typographical variation anagram": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "typographical variation anagram case sensitivity": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "anagram case sensitivity length awareness": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "complex problem solving token structure probing typographical variation anagram": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "token structure probing typographical variation anagram case sensitivity": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "typographical variation anagram case sensitivity length awareness": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "complex problem solving token structure probing typographical variation anagram case sensitivity": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "token structure probing typographical variation anagram case sensitivity length awareness": ["Tokenization Falling Short: On Subword Robustness in Large Language Models"], "historical facts": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "geography": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "social customs": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "art and cultural heritage": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "philosophy and religion": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "lexical pragmatics analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "allusions and idioms": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "sentence pauses": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "summarization and analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "poetry appreciation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "historical facts geography": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "geography social customs": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "social customs art and cultural heritage": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "art and cultural heritage philosophy and religion": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "philosophy and religion lexical pragmatics analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "lexical pragmatics analysis allusions and idioms": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "allusions and idioms word sense disambiguation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "word sense disambiguation translation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "translation event extraction": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "event extraction sentence pauses": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "sentence pauses summarization and analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "summarization and analysis poetry appreciation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "historical facts geography social customs": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "geography social customs art and cultural heritage": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "social customs art and cultural heritage philosophy and religion": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "art and cultural heritage philosophy and religion lexical pragmatics analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "philosophy and religion lexical pragmatics analysis allusions and idioms": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "lexical pragmatics analysis allusions and idioms word sense disambiguation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "allusions and idioms word sense disambiguation translation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "word sense disambiguation translation event extraction": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "translation event extraction sentence pauses": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "event extraction sentence pauses summarization and analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "sentence pauses summarization and analysis poetry appreciation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "historical facts geography social customs art and cultural heritage": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "geography social customs art and cultural heritage philosophy and religion": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "social customs art and cultural heritage philosophy and religion lexical pragmatics analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "art and cultural heritage philosophy and religion lexical pragmatics analysis allusions and idioms": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "philosophy and religion lexical pragmatics analysis allusions and idioms word sense disambiguation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "lexical pragmatics analysis allusions and idioms word sense disambiguation translation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "allusions and idioms word sense disambiguation translation event extraction": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "word sense disambiguation translation event extraction sentence pauses": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "translation event extraction sentence pauses summarization and analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "event extraction sentence pauses summarization and analysis poetry appreciation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "historical facts geography social customs art and cultural heritage philosophy and religion": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "geography social customs art and cultural heritage philosophy and religion lexical pragmatics analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "social customs art and cultural heritage philosophy and religion lexical pragmatics analysis allusions and idioms": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "art and cultural heritage philosophy and religion lexical pragmatics analysis allusions and idioms word sense disambiguation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "philosophy and religion lexical pragmatics analysis allusions and idioms word sense disambiguation translation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "lexical pragmatics analysis allusions and idioms word sense disambiguation translation event extraction": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "allusions and idioms word sense disambiguation translation event extraction sentence pauses": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "word sense disambiguation translation event extraction sentence pauses summarization and analysis": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "translation event extraction sentence pauses summarization and analysis poetry appreciation": ["AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models"], "anaphora resolution": ["MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos"], "multilingual": ["MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos"], "multimodal": ["MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos"], "anaphora resolution multilingual": ["MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos"], "multilingual multimodal": ["MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos"], "anaphora resolution multilingual multimodal": ["MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos"], "coping identification": ["Dealing with Controversy: An Emotion and Coping Strategy Corpus Based on Role Playing"], "image-long text retrieval": ["MATE: Meet At The Embedding - Connecting Images with Long Texts"], "image-long text retrieval cross-modal retrieval": ["MATE: Meet At The Embedding - Connecting Images with Long Texts"], "step-by-step reasoning": ["Mixed Distillation Helps Smaller Language Models Reason Better"], "mathematical reasoning common sense reasoning": ["Mixed Distillation Helps Smaller Language Models Reason Better"], "common sense reasoning step-by-step reasoning": ["Mixed Distillation Helps Smaller Language Models Reason Better"], "mathematical reasoning common sense reasoning step-by-step reasoning": ["Mixed Distillation Helps Smaller Language Models Reason Better"], "text modification": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "mathematics": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models", "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection", "AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models", "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "security rules": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "sequential instruction following": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "text modification question answering": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "question answering mathematics": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "mathematics security rules": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "security rules sequential instruction following": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "text modification question answering mathematics": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "question answering mathematics security rules": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "mathematics security rules sequential instruction following": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "text modification question answering mathematics security rules": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "question answering mathematics security rules sequential instruction following": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "text modification question answering mathematics security rules sequential instruction following": ["The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models"], "instruction tuning data synthesis": ["Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search"], "data synthesis language model alignment": ["Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search"], "instruction tuning data synthesis language model alignment": ["Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search"], "long-form text generation": ["Suri: Multi-constraint Instruction Following for Long-form Text Generation", "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation"], "multi-constraint instructions": ["Suri: Multi-constraint Instruction Following for Long-form Text Generation"], "long-form text generation instruction following": ["Suri: Multi-constraint Instruction Following for Long-form Text Generation"], "instruction following multi-constraint instructions": ["Suri: Multi-constraint Instruction Following for Long-form Text Generation"], "long-form text generation instruction following multi-constraint instructions": ["Suri: Multi-constraint Instruction Following for Long-form Text Generation"], "medical question answering biomedical qa": ["Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering"], "multilingual concept extraction": ["Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?"], "cross-lingual concept recognition": ["Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?"], "cross-lingual value alignment control": ["Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?"], "multilingual concept extraction cross-lingual concept recognition": ["Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?"], "cross-lingual concept recognition cross-lingual value alignment control": ["Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?"], "multilingual concept extraction cross-lingual concept recognition cross-lingual value alignment control": ["Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?"], "urban activity planning": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "management": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "spatio-temporal task decomposition": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "model matching": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "urban activity planning management": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "management spatio-temporal task decomposition": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "spatio-temporal task decomposition model matching": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "urban activity planning management spatio-temporal task decomposition": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "management spatio-temporal task decomposition model matching": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "urban activity planning management spatio-temporal task decomposition model matching": ["UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models"], "ensembling": ["Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling"], "language generation ensembling": ["Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling"], "auxiliary function utilization": ["Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation"], "code generation auxiliary function utilization": ["Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation"], "auxiliary function utilization instruction following": ["Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation"], "code generation auxiliary function utilization instruction following": ["Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation"], "evaluation of open-ended responses": ["AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses"], "question answering evaluation of open-ended responses": ["AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses"], "fine-grained image classification": ["Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models"], "information retrieval query expansion": ["Exploring the Best Practices of Query Expansion with Large Language Models"], "emotion-cause pair extraction": ["MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation", "Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction"], "emotion clause extraction": ["MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation"], "cause clause extraction": ["MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation"], "emotion-cause pair extraction emotion clause extraction": ["MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation"], "emotion clause extraction cause clause extraction": ["MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation"], "emotion-cause pair extraction emotion clause extraction cause clause extraction": ["MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation"], "information-seeking dialogs": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "response attribution": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "meeting transcripts": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "data generation information-seeking dialogs": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "information-seeking dialogs response attribution": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "response attribution meeting transcripts": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "data generation information-seeking dialogs response attribution": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "information-seeking dialogs response attribution meeting transcripts": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "data generation information-seeking dialogs response attribution meeting transcripts": ["Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts"], "visual question decomposition": ["Visual Question Decomposition on Multimodal Large Language Models"], "prompt sensitivity analysis": ["ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs"], "LLMs  evaluation": ["ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs", "Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "prompt sensitivity analysis LLMs  evaluation": ["ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs"], "parameter-efficient fine-tuning natural language processing": ["Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models"], "natural language processing commonsense reasoning": ["Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models"], "parameter-efficient fine-tuning natural language processing commonsense reasoning": ["Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models"], "natural language processing commonsense reasoning arithmetic reasoning": ["Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models"], "parameter-efficient fine-tuning natural language processing commonsense reasoning arithmetic reasoning": ["Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models"], "semantic reasoning": ["Abstraction-of-Thought Makes Language Models Better Reasoners"], "question answering logical reasoning": ["Abstraction-of-Thought Makes Language Models Better Reasoners"], "logical reasoning arithmetic": ["Abstraction-of-Thought Makes Language Models Better Reasoners"], "arithmetic semantic reasoning": ["Abstraction-of-Thought Makes Language Models Better Reasoners"], "question answering logical reasoning arithmetic": ["Abstraction-of-Thought Makes Language Models Better Reasoners"], "logical reasoning arithmetic semantic reasoning": ["Abstraction-of-Thought Makes Language Models Better Reasoners"], "question answering logical reasoning arithmetic semantic reasoning": ["Abstraction-of-Thought Makes Language Models Better Reasoners"], "LLM fine-tuning": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "social media analysis": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering", "Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter"], "financial domain": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "question answering LLM fine-tuning": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "LLM fine-tuning social media analysis": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "social media analysis financial domain": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "question answering LLM fine-tuning social media analysis": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "LLM fine-tuning social media analysis financial domain": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "question answering LLM fine-tuning social media analysis financial domain": ["LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Finance Communities in Long Form Question Answering"], "tone transcription": ["Automated Tone Transcription and Clustering with Tone2Vec"], "tone clustering": ["Automated Tone Transcription and Clustering with Tone2Vec"], "dialect clustering": ["Automated Tone Transcription and Clustering with Tone2Vec"], "variance analysis": ["Automated Tone Transcription and Clustering with Tone2Vec"], "tone transcription tone clustering": ["Automated Tone Transcription and Clustering with Tone2Vec"], "tone clustering dialect clustering": ["Automated Tone Transcription and Clustering with Tone2Vec"], "dialect clustering variance analysis": ["Automated Tone Transcription and Clustering with Tone2Vec"], "tone transcription tone clustering dialect clustering": ["Automated Tone Transcription and Clustering with Tone2Vec"], "tone clustering dialect clustering variance analysis": ["Automated Tone Transcription and Clustering with Tone2Vec"], "tone transcription tone clustering dialect clustering variance analysis": ["Automated Tone Transcription and Clustering with Tone2Vec"], "empathy measurement": ["Multi-dimensional Evaluation of Empathetic Dialogue Responses"], "empathy evaluation": ["Multi-dimensional Evaluation of Empathetic Dialogue Responses"], "empathy measurement empathy evaluation": ["Multi-dimensional Evaluation of Empathetic Dialogue Responses"], "empathy evaluation intent classification": ["Multi-dimensional Evaluation of Empathetic Dialogue Responses"], "empathy measurement empathy evaluation intent classification": ["Multi-dimensional Evaluation of Empathetic Dialogue Responses"], "web page ranking": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "machine translation data augmentation": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "data augmentation natural language inference": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "natural language inference web page ranking": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "web page ranking question generation": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "machine translation data augmentation natural language inference": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "data augmentation natural language inference web page ranking": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "natural language inference web page ranking question generation": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "machine translation data augmentation natural language inference web page ranking": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "data augmentation natural language inference web page ranking question generation": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "machine translation data augmentation natural language inference web page ranking question generation": ["Translation of Multifaceted Data without Re-Training of Machine Translation Systems"], "offline rlhf": ["Reward Difference Optimization For Sample Reweighting In Offline RLHF"], "LLM alignment offline rlhf": ["Reward Difference Optimization For Sample Reweighting In Offline RLHF"], "programming": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories", "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "embodied tasks": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "math programming": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "programming web navigation": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "web navigation embodied tasks": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "reasoning math programming": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "math programming web navigation": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "programming web navigation embodied tasks": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "reasoning math programming web navigation": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "math programming web navigation embodied tasks": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "reasoning math programming web navigation embodied tasks": ["AGENTBANK: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories"], "multi-objective finetuning": ["Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning"], "language model steering": ["Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning", "Activation Scaling for Steering and Interpreting Language Models"], "multi-objective finetuning language model steering": ["Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning"], "language model steering summarization": ["Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning"], "multi-objective finetuning language model steering summarization": ["Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning"], "co-augmentation": ["DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "question answering knowledge graph construction": ["DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "knowledge graph construction knowledge retrieval": ["DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "knowledge retrieval co-augmentation": ["DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "question answering knowledge graph construction knowledge retrieval": ["DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "knowledge graph construction knowledge retrieval co-augmentation": ["DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "question answering knowledge graph construction knowledge retrieval co-augmentation": ["DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"], "equity analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "empathy assessment": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "counterfactual analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "clinical evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "demographic auditing": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "mental health support LLM evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "LLM evaluation equity analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "equity analysis empathy assessment": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "empathy assessment bias detection": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "bias detection counterfactual analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "counterfactual analysis clinical evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "clinical evaluation automatic evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "automatic evaluation demographic auditing": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "demographic auditing bias mitigation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "mental health support LLM evaluation equity analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "LLM evaluation equity analysis empathy assessment": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "equity analysis empathy assessment bias detection": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "empathy assessment bias detection counterfactual analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "bias detection counterfactual analysis clinical evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "counterfactual analysis clinical evaluation automatic evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "clinical evaluation automatic evaluation demographic auditing": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "automatic evaluation demographic auditing bias mitigation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "mental health support LLM evaluation equity analysis empathy assessment": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "LLM evaluation equity analysis empathy assessment bias detection": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "equity analysis empathy assessment bias detection counterfactual analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "empathy assessment bias detection counterfactual analysis clinical evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "bias detection counterfactual analysis clinical evaluation automatic evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "counterfactual analysis clinical evaluation automatic evaluation demographic auditing": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "clinical evaluation automatic evaluation demographic auditing bias mitigation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "mental health support LLM evaluation equity analysis empathy assessment bias detection": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "LLM evaluation equity analysis empathy assessment bias detection counterfactual analysis": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "equity analysis empathy assessment bias detection counterfactual analysis clinical evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "empathy assessment bias detection counterfactual analysis clinical evaluation automatic evaluation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "bias detection counterfactual analysis clinical evaluation automatic evaluation demographic auditing": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "counterfactual analysis clinical evaluation automatic evaluation demographic auditing bias mitigation": ["Can AI Relate: Testing Large Language Model Response for Mental Health Support"], "extractive question answering": ["Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology", "Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "any-to-one voice conversion": ["Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion"], "cross-lingual voice conversion": ["Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion"], "polyglot voice creation": ["Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion"], "any-to-one voice conversion cross-lingual voice conversion": ["Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion"], "cross-lingual voice conversion polyglot voice creation": ["Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion"], "any-to-one voice conversion cross-lingual voice conversion polyglot voice creation": ["Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion"], "intentunderstand": ["INTENTIONQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce"], "intentutilize": ["INTENTIONQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce"], "intentunderstand intentutilize": ["INTENTIONQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce"], "LLM inference acceleration": ["Draft on the Fly: Adaptive Self-Speculative Decoding using Cosine Similarity"], "LLM inference acceleration speculative decoding": ["Draft on the Fly: Adaptive Self-Speculative Decoding using Cosine Similarity"], "sequential reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "economic reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "business reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "supply chain management reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "question answering sequential reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "sequential reasoning economic reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "economic reasoning logical reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "logical reasoning business reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "business reasoning supply chain management reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "question answering sequential reasoning economic reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "sequential reasoning economic reasoning logical reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "economic reasoning logical reasoning business reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "logical reasoning business reasoning supply chain management reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "question answering sequential reasoning economic reasoning logical reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "sequential reasoning economic reasoning logical reasoning business reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "economic reasoning logical reasoning business reasoning supply chain management reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "question answering sequential reasoning economic reasoning logical reasoning business reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "sequential reasoning economic reasoning logical reasoning business reasoning supply chain management reasoning": ["EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"], "mMLu language understanding": ["The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance"], "language understanding knowledge retrieval": ["The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance"], "mMLu language understanding knowledge retrieval": ["The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance"], "graph reasoning": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "pattern memorization": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "natural language graph reasoning": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "graph reasoning generalization": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "generalization pattern memorization": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "pattern memorization natural language graph reasoning": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "graph reasoning generalization pattern memorization": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "generalization pattern memorization natural language graph reasoning": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "graph reasoning generalization pattern memorization natural language graph reasoning": ["Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"], "multilingual summarization": ["Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets"], "generative tasks": ["Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets", "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "discriminative tasks": ["Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets", "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "multilingual summarization generative tasks": ["Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets"], "generative tasks discriminative tasks": ["Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets"], "multilingual summarization generative tasks discriminative tasks": ["Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets"], "aspect-sentiment triplet extraction": ["ASTE-Transformer: Modelling Dependencies in Aspect-Sentiment Triplet Extraction"], "image classification explanation": ["Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach"], "natural language explanation generation": ["Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach"], "image classification explanation natural language explanation generation": ["Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach"], "table question answering": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA", "PROTRIX: Building Models for Planning and Reasoning over Tables with Sentence Context", "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "end-to-end question answering": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "answer selection": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "table question answering text-to-sql": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "text-to-sql end-to-end question answering": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "end-to-end question answering answer selection": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "table question answering text-to-sql end-to-end question answering": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "text-to-sql end-to-end question answering answer selection": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "table question answering text-to-sql end-to-end question answering answer selection": ["SYNTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA"], "link prediction node classification": ["OpenGraph: Towards Open Graph Foundation Models"], "risk control for rag": ["Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework"], "factoid question answering": ["Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework"], "risk control for rag factoid question answering": ["Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework"], "math word problem": ["Learning to Paraphrase for Alignment with LLM Preference", "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "open-domain qa commonsense reasoning": ["Learning to Paraphrase for Alignment with LLM Preference"], "commonsense reasoning math word problem": ["Learning to Paraphrase for Alignment with LLM Preference"], "open-domain qa commonsense reasoning math word problem": ["Learning to Paraphrase for Alignment with LLM Preference"], "date understanding confidence calibration": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "commonsense reasoning gsm8k svamp": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "gsm8k svamp strategyqa": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "svamp strategyqa date understanding": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "strategyqa date understanding confidence calibration": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "arithmetic reasoning commonsense reasoning gsm8k svamp": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "commonsense reasoning gsm8k svamp strategyqa": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "gsm8k svamp strategyqa date understanding": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "svamp strategyqa date understanding confidence calibration": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "arithmetic reasoning commonsense reasoning gsm8k svamp strategyqa": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "commonsense reasoning gsm8k svamp strategyqa date understanding": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "gsm8k svamp strategyqa date understanding confidence calibration": ["Mirror-Consistency: Harnessing Inconsistency in Majority Voting"], "open-domain question answering RAG": ["Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts"], "in-image machine translation": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "text detection and recognition": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "text image translation": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "target text fusion": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "in-image machine translation text detection and recognition": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "text detection and recognition text image translation": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "text image translation target text fusion": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "in-image machine translation text detection and recognition text image translation": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "text detection and recognition text image translation target text fusion": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "in-image machine translation text detection and recognition text image translation target text fusion": ["AnyTrans: Translate AnyText in the Image with Large Scale Models"], "context compression LLMs": ["In-Context Former: Lightning-fast Compressing Context for Large Language Model"], "jailbreak": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "hidden state analysis": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "LLM safety jailbreak": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "jailbreak explainability": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "explainability alignment": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "alignment hidden state analysis": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "LLM safety jailbreak explainability": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "jailbreak explainability alignment": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "explainability alignment hidden state analysis": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "LLM safety jailbreak explainability alignment": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "jailbreak explainability alignment hidden state analysis": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "LLM safety jailbreak explainability alignment hidden state analysis": ["How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"], "multi-label few-shot intent detection": ["A Coarse-to-Fine Prototype Learning Approach for Multi-Label Few-Shot Intent Detection"], "syntax checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "subsumption of concepts or roles": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "instance checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "property characteristics probing": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "query answering": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "ontology satisfiability checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "syntax checking subsumption of concepts or roles": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "subsumption of concepts or roles instance checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "instance checking property characteristics probing": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "property characteristics probing query answering": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "query answering ontology satisfiability checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "syntax checking subsumption of concepts or roles instance checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "subsumption of concepts or roles instance checking property characteristics probing": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "instance checking property characteristics probing query answering": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "property characteristics probing query answering ontology satisfiability checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "syntax checking subsumption of concepts or roles instance checking property characteristics probing": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "subsumption of concepts or roles instance checking property characteristics probing query answering": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "instance checking property characteristics probing query answering ontology satisfiability checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "syntax checking subsumption of concepts or roles instance checking property characteristics probing query answering": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "subsumption of concepts or roles instance checking property characteristics probing query answering ontology satisfiability checking": ["Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study"], "medical question answering confidence elicitation": ["Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration"], "medical question answering confidence elicitation calibration": ["Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration"], "knowledge base evolution": ["EvOR: Evolving Retrieval for Code Generation"], "query evolution": ["EvOR: Evolving Retrieval for Code Generation"], "code generation RAG": ["EvOR: Evolving Retrieval for Code Generation"], "RAG knowledge base evolution": ["EvOR: Evolving Retrieval for Code Generation"], "knowledge base evolution query evolution": ["EvOR: Evolving Retrieval for Code Generation"], "code generation RAG knowledge base evolution": ["EvOR: Evolving Retrieval for Code Generation"], "RAG knowledge base evolution query evolution": ["EvOR: Evolving Retrieval for Code Generation"], "code generation RAG knowledge base evolution query evolution": ["EvOR: Evolving Retrieval for Code Generation"], "knowledge": ["Head-wise Shareable Attention for Large Language Models"], "reasoning natural language understanding": ["Head-wise Shareable Attention for Large Language Models", "StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "natural language understanding knowledge": ["Head-wise Shareable Attention for Large Language Models"], "reasoning natural language understanding knowledge": ["Head-wise Shareable Attention for Large Language Models"], "open domain qa": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "science": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "compositional datasets": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "open domain qa math": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "math science": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "science autonomous agents": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "autonomous agents question answering": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "question answering compositional datasets": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "open domain qa math science": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "math science autonomous agents": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "science autonomous agents question answering": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "autonomous agents question answering compositional datasets": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "open domain qa math science autonomous agents": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "math science autonomous agents question answering": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "science autonomous agents question answering compositional datasets": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "open domain qa math science autonomous agents question answering": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "math science autonomous agents question answering compositional datasets": ["Divide-or-Conquer? Which Part Should You Distill Your LLM?"], "sentiment analysis emotion prediction": ["Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models"], "text classification sentiment analysis emotion prediction": ["Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models"], "model inversion attack": ["Privacy Evaluation Benchmarks for NLP Models"], "attribute inference attack": ["Privacy Evaluation Benchmarks for NLP Models"], "model extraction attack": ["Privacy Evaluation Benchmarks for NLP Models"], "membership inference attack model inversion attack": ["Privacy Evaluation Benchmarks for NLP Models"], "model inversion attack attribute inference attack": ["Privacy Evaluation Benchmarks for NLP Models"], "attribute inference attack model extraction attack": ["Privacy Evaluation Benchmarks for NLP Models"], "membership inference attack model inversion attack attribute inference attack": ["Privacy Evaluation Benchmarks for NLP Models"], "model inversion attack attribute inference attack model extraction attack": ["Privacy Evaluation Benchmarks for NLP Models"], "membership inference attack model inversion attack attribute inference attack model extraction attack": ["Privacy Evaluation Benchmarks for NLP Models"], "multimodal entity alignment": ["MM-ChatAlign: A Novel Multimodal Reasoning Framework based on Large Language Models for Entity Alignment"], "computerized adaptive testing": ["Towards Explainable Computerized Adaptive Testing with Large Language Model"], "explainable question selection": ["Towards Explainable Computerized Adaptive Testing with Large Language Model"], "student ability estimation": ["Towards Explainable Computerized Adaptive Testing with Large Language Model"], "computerized adaptive testing explainable question selection": ["Towards Explainable Computerized Adaptive Testing with Large Language Model"], "explainable question selection student ability estimation": ["Towards Explainable Computerized Adaptive Testing with Large Language Model"], "computerized adaptive testing explainable question selection student ability estimation": ["Towards Explainable Computerized Adaptive Testing with Large Language Model"], "docqa": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "long document retrieval": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "multi-view indexing": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "content-aware indexing": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "docqa long document retrieval": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "long document retrieval multi-view indexing": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "multi-view indexing content-aware indexing": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "docqa long document retrieval multi-view indexing": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "long document retrieval multi-view indexing content-aware indexing": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "docqa long document retrieval multi-view indexing content-aware indexing": ["MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing"], "spoken question answering": ["PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems"], "multi-span question answering": ["Correct after Answer: Enhancing Multi-Span Question Answering with Post-Processing Method"], "social prediction": ["Are Large Language Models (LLMs) Good Social Predictors?"], "voting prediction": ["Are Large Language Models (LLMs) Good Social Predictors?"], "soc-prf prediction": ["Are Large Language Models (LLMs) Good Social Predictors?"], "low2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "high2low": ["Are Large Language Models (LLMs) Good Social Predictors?"], "high2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "social prediction voting prediction": ["Are Large Language Models (LLMs) Good Social Predictors?"], "voting prediction soc-prf prediction": ["Are Large Language Models (LLMs) Good Social Predictors?"], "soc-prf prediction low2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "low2high high2low": ["Are Large Language Models (LLMs) Good Social Predictors?"], "high2low high2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "social prediction voting prediction soc-prf prediction": ["Are Large Language Models (LLMs) Good Social Predictors?"], "voting prediction soc-prf prediction low2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "soc-prf prediction low2high high2low": ["Are Large Language Models (LLMs) Good Social Predictors?"], "low2high high2low high2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "social prediction voting prediction soc-prf prediction low2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "voting prediction soc-prf prediction low2high high2low": ["Are Large Language Models (LLMs) Good Social Predictors?"], "soc-prf prediction low2high high2low high2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "social prediction voting prediction soc-prf prediction low2high high2low": ["Are Large Language Models (LLMs) Good Social Predictors?"], "voting prediction soc-prf prediction low2high high2low high2high": ["Are Large Language Models (LLMs) Good Social Predictors?"], "text-to-speech synthesis": ["Bahasa Harmony: A Comprehensive Dataset for Bahasa Text-to-Speech Synthesis with Discrete Codec Modeling of EnGen-TTS"], "bitext retrieval": ["MINERS: Multilingual Language Models as Semantic Retrievers"], "retrieval-based classification": ["MINERS: Multilingual Language Models as Semantic Retrievers"], "icl classification": ["MINERS: Multilingual Language Models as Semantic Retrievers"], "bitext retrieval retrieval-based classification": ["MINERS: Multilingual Language Models as Semantic Retrievers"], "retrieval-based classification icl classification": ["MINERS: Multilingual Language Models as Semantic Retrievers"], "bitext retrieval retrieval-based classification icl classification": ["MINERS: Multilingual Language Models as Semantic Retrievers"], "boolean dense retrieval": ["BOOLQUESTIONS: Does Dense Retrieval Understand Boolean Logic in Language?"], "cross-lingual retrieval question answering": ["McCrolin: Multi-consistency Cross-lingual Training for Retrieval Question Answering"], "metric for robustness": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "non-adversarial perturbations": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "robustness evaluation metric for robustness": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "metric for robustness non-adversarial perturbations": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "non-adversarial perturbations LLM evaluation": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "LLM evaluation qa": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "qa classification": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "classification reading comprehension": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "robustness evaluation metric for robustness non-adversarial perturbations": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "metric for robustness non-adversarial perturbations LLM evaluation": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "non-adversarial perturbations LLM evaluation qa": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "LLM evaluation qa classification": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "qa classification reading comprehension": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "robustness evaluation metric for robustness non-adversarial perturbations LLM evaluation": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "metric for robustness non-adversarial perturbations LLM evaluation qa": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "non-adversarial perturbations LLM evaluation qa classification": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "LLM evaluation qa classification reading comprehension": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "robustness evaluation metric for robustness non-adversarial perturbations LLM evaluation qa": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "metric for robustness non-adversarial perturbations LLM evaluation qa classification": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "non-adversarial perturbations LLM evaluation qa classification reading comprehension": ["A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios"], "audio-visual question answering": ["Learning Musical Representations for Music Performance Question Answering", "SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering"], "music performance understanding": ["Learning Musical Representations for Music Performance Question Answering"], "audio-visual question answering music performance understanding": ["Learning Musical Representations for Music Performance Question Answering"], "news categorization": ["Transfer Learning for Text Classification via Model Risk Analysis"], "sentiment analysis news categorization": ["Transfer Learning for Text Classification via Model Risk Analysis"], "news categorization topic classification": ["Transfer Learning for Text Classification via Model Risk Analysis"], "text classification sentiment analysis news categorization": ["Transfer Learning for Text Classification via Model Risk Analysis"], "sentiment analysis news categorization topic classification": ["Transfer Learning for Text Classification via Model Risk Analysis"], "text classification sentiment analysis news categorization topic classification": ["Transfer Learning for Text Classification via Model Risk Analysis"], "robustness test": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "genetic attack": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "rag pipeline evaluation": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "robustness test genetic attack": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "genetic attack rag pipeline evaluation": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "rag pipeline evaluation question answering": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "robustness test genetic attack rag pipeline evaluation": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "genetic attack rag pipeline evaluation question answering": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "robustness test genetic attack rag pipeline evaluation question answering": ["Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations"], "mvbench": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "tempcompass": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "next-qa": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "video question answering mvbench": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "mvbench tempcompass": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "tempcompass next-qa": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "video question answering mvbench tempcompass": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "mvbench tempcompass next-qa": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "video question answering mvbench tempcompass next-qa": ["Enhancing Temporal Modeling of Video LLMs via Time Gating"], "sample complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "computational complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "planning task decomposition": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "task decomposition sample complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "sample complexity computational complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "computational complexity in-context learning": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "in-context learning fine-tuning": ["On the Empirical Complexity of Reasoning and Planning in LLMs", "Private prediction for large-scale synthetic text generation"], "reasoning planning task decomposition": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "planning task decomposition sample complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "task decomposition sample complexity computational complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "sample complexity computational complexity in-context learning": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "computational complexity in-context learning fine-tuning": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "reasoning planning task decomposition sample complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "planning task decomposition sample complexity computational complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "task decomposition sample complexity computational complexity in-context learning": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "sample complexity computational complexity in-context learning fine-tuning": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "reasoning planning task decomposition sample complexity computational complexity": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "planning task decomposition sample complexity computational complexity in-context learning": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "task decomposition sample complexity computational complexity in-context learning fine-tuning": ["On the Empirical Complexity of Reasoning and Planning in LLMs"], "spatial relationship understanding": ["Learning from Mistakes: Iterative Prompt Relabeling for Text-to-Image Diffusion Model Training"], "text-to-image generation spatial relationship understanding": ["Learning from Mistakes: Iterative Prompt Relabeling for Text-to-Image Diffusion Model Training"], "social reasoning": ["A Notion of Complexity for Theory of Mind via Discrete World Models", "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "theory of mind social reasoning": ["A Notion of Complexity for Theory of Mind via Discrete World Models"], "social reasoning question answering": ["A Notion of Complexity for Theory of Mind via Discrete World Models"], "theory of mind social reasoning question answering": ["A Notion of Complexity for Theory of Mind via Discrete World Models"], "personalized product search": ["Learning Dynamic Multi-attribute Interest for Personalized Product Search"], "metrics evaluation": ["Evaluating Automatic Metrics with Incremental Machine Translation Systems"], "a/b testing": ["Evaluating Automatic Metrics with Incremental Machine Translation Systems"], "machine translation metrics evaluation": ["Evaluating Automatic Metrics with Incremental Machine Translation Systems"], "metrics evaluation a/b testing": ["Evaluating Automatic Metrics with Incremental Machine Translation Systems"], "machine translation metrics evaluation a/b testing": ["Evaluating Automatic Metrics with Incremental Machine Translation Systems"], "embodied agent learning": ["LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble"], "reward estimation": ["LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble"], "embodied agent learning offline reinforcement learning": ["LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble"], "offline reinforcement learning reward estimation": ["LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble"], "embodied agent learning offline reinforcement learning reward estimation": ["LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble"], "natural language processing instruction following": ["Self-Renewal Prompt Optimizing with Implicit Reasoning", "Resilience of Large Language Models for Noisy Instructions"], "instruction following preference alignment": ["Self-Renewal Prompt Optimizing with Implicit Reasoning"], "preference alignment prompt optimization": ["Self-Renewal Prompt Optimizing with Implicit Reasoning"], "natural language processing instruction following preference alignment": ["Self-Renewal Prompt Optimizing with Implicit Reasoning"], "instruction following preference alignment prompt optimization": ["Self-Renewal Prompt Optimizing with Implicit Reasoning"], "natural language processing instruction following preference alignment prompt optimization": ["Self-Renewal Prompt Optimizing with Implicit Reasoning"], "target length generation task": ["RULER: A Model-Agnostic Method to Control Generated Length for Large Language Models"], "measuring gender-stereotypical reasoning in language models": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in machine translation systems": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "evaluating english and slavic masked lms": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "evaluating english generative lms": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "evaluating english-to-slavic machine translation systems": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in language models measuring gender-stereotypical reasoning in machine translation systems": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in machine translation systems evaluating english and slavic masked lms": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "evaluating english and slavic masked lms evaluating english generative lms": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "evaluating english generative lms evaluating english-to-slavic machine translation systems": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in language models measuring gender-stereotypical reasoning in machine translation systems evaluating english and slavic masked lms": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in machine translation systems evaluating english and slavic masked lms evaluating english generative lms": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "evaluating english and slavic masked lms evaluating english generative lms evaluating english-to-slavic machine translation systems": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in language models measuring gender-stereotypical reasoning in machine translation systems evaluating english and slavic masked lms evaluating english generative lms": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in machine translation systems evaluating english and slavic masked lms evaluating english generative lms evaluating english-to-slavic machine translation systems": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "measuring gender-stereotypical reasoning in language models measuring gender-stereotypical reasoning in machine translation systems evaluating english and slavic masked lms evaluating english generative lms evaluating english-to-slavic machine translation systems": ["Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling"], "linear text segmentation": ["Recent Trends in Linear Text Segmentation: A Survey"], "linear text segmentation topic segmentation": ["Recent Trends in Linear Text Segmentation: A Survey"], "topic segmentation discourse analysis": ["Recent Trends in Linear Text Segmentation: A Survey"], "linear text segmentation topic segmentation discourse analysis": ["Recent Trends in Linear Text Segmentation: A Survey"], "visual document understanding": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "structure-aware parsing": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "multi-grained text localization": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "visual document understanding structure-aware parsing": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "structure-aware parsing multi-grained text localization": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "multi-grained text localization document understanding": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "visual document understanding structure-aware parsing multi-grained text localization": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "structure-aware parsing multi-grained text localization document understanding": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "visual document understanding structure-aware parsing multi-grained text localization document understanding": ["mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"], "summarization text classification": ["LoRAN: Improved Low-Rank Adaptation by a Non-Linear Transformation"], "out-of-context knowledge reasoning": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "attribute reasoning": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "relation reasoning": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning", "Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "cross-lingual knowledge transfer": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "out-of-context knowledge reasoning attribute reasoning": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "attribute reasoning relation reasoning": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "relation reasoning cross-lingual knowledge transfer": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "out-of-context knowledge reasoning attribute reasoning relation reasoning": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "attribute reasoning relation reasoning cross-lingual knowledge transfer": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "out-of-context knowledge reasoning attribute reasoning relation reasoning cross-lingual knowledge transfer": ["Large Language Models are Limited in Out-of-Context Knowledge Reasoning"], "glue datasets": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "superglue datasets": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "glue datasets superglue datasets": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "superglue datasets text classification": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "text generation natural language understanding": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "glue datasets superglue datasets text classification": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "superglue datasets text classification text generation": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "text classification text generation natural language understanding": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "glue datasets superglue datasets text classification text generation": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "superglue datasets text classification text generation natural language understanding": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "glue datasets superglue datasets text classification text generation natural language understanding": ["BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks"], "few-shot named entity recognition": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "span detection": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "entity type classification": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "few-shot named entity recognition ner": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "ner span detection": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "span detection entity type classification": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "few-shot named entity recognition ner span detection": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "ner span detection entity type classification": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "few-shot named entity recognition ner span detection entity type classification": ["Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition"], "semantic textual similarity transfer learning": ["Scaling Sentence Embeddings with Large Language Models"], "fine-grained multimodal named entity recognition and grounding": ["Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding"], "resume scoring": ["JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models"], "resume scoring bias detection": ["JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models"], "bias detection gender bias analysis": ["JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models"], "resume scoring bias detection gender bias analysis": ["JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models"], "training dynamics analysis": ["Tending Towards Stability: Convergence Challenges in Small Language Models"], "language modeling training dynamics analysis": ["Tending Towards Stability: Convergence Challenges in Small Language Models"], "prompt generation": ["Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "red teaming prompt generation": ["Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "prompt generation LLM safety": ["Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "LLM safety adversarial attacks": ["Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "red teaming prompt generation LLM safety": ["Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "prompt generation LLM safety adversarial attacks": ["Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "red teaming prompt generation LLM safety adversarial attacks": ["Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming"], "financial market prediction": ["Modeling News Interactions and Influence for Financial Market Prediction"], "sequence-level knowledge distillation": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "long-tail learning": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "knowledge distillation sequence-level knowledge distillation": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "sequence-level knowledge distillation long-tail learning": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "long-tail learning natural language processing": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "natural language processing text classification": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation", "Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "question answering arithmetic": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "knowledge distillation sequence-level knowledge distillation long-tail learning": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "sequence-level knowledge distillation long-tail learning natural language processing": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "long-tail learning natural language processing text classification": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "natural language processing text classification question answering": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "text classification question answering arithmetic": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "knowledge distillation sequence-level knowledge distillation long-tail learning natural language processing": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "sequence-level knowledge distillation long-tail learning natural language processing text classification": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "long-tail learning natural language processing text classification question answering": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "natural language processing text classification question answering arithmetic": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "knowledge distillation sequence-level knowledge distillation long-tail learning natural language processing text classification": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "sequence-level knowledge distillation long-tail learning natural language processing text classification question answering": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "long-tail learning natural language processing text classification question answering arithmetic": ["Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"], "open-ended chart question answering": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "chart summarization": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "fact-checking with charts": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "chart question answering open-ended chart question answering": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "open-ended chart question answering chart summarization": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "chart summarization fact-checking with charts": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "fact-checking with charts chart-to-table": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "chart question answering open-ended chart question answering chart summarization": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "open-ended chart question answering chart summarization fact-checking with charts": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "chart summarization fact-checking with charts chart-to-table": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "chart question answering open-ended chart question answering chart summarization fact-checking with charts": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "open-ended chart question answering chart summarization fact-checking with charts chart-to-table": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "chart question answering open-ended chart question answering chart summarization fact-checking with charts chart-to-table": ["Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?"], "materials science": ["HoneyComb: A Flexible LLM-Based Agent System for Materials Science"], "materials science question answering": ["HoneyComb: A Flexible LLM-Based Agent System for Materials Science"], "diachronic semantic analysis": ["Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter"], "semantic shift detection": ["Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter"], "diachronic semantic analysis social media analysis": ["Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter"], "social media analysis semantic shift detection": ["Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter"], "diachronic semantic analysis social media analysis semantic shift detection": ["Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter"], "criminal court view generation": ["Divide and Conquer: Legal Concept-guided Criminal Court View Generation"], "legal judgments explanation": ["Divide and Conquer: Legal Concept-guided Criminal Court View Generation"], "criminal court view generation text summarization": ["Divide and Conquer: Legal Concept-guided Criminal Court View Generation"], "text summarization legal judgments explanation": ["Divide and Conquer: Legal Concept-guided Criminal Court View Generation"], "criminal court view generation text summarization legal judgments explanation": ["Divide and Conquer: Legal Concept-guided Criminal Court View Generation"], "data selection": ["Data Diversity Matters for Robust Instruction Tuning"], "dataset curation": ["Data Diversity Matters for Robust Instruction Tuning", "On Leakage of Code Generation Evaluation Datasets", "Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "data selection dataset curation": ["Data Diversity Matters for Robust Instruction Tuning"], "instruction tuning data selection dataset curation": ["Data Diversity Matters for Robust Instruction Tuning"], "grapheme-to-phoneme conversion": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "kasre-ezafe detection": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "homograph disambiguation": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "oov words handling": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "grapheme-to-phoneme conversion kasre-ezafe detection": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "kasre-ezafe detection homograph disambiguation": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "homograph disambiguation oov words handling": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "grapheme-to-phoneme conversion kasre-ezafe detection homograph disambiguation": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "kasre-ezafe detection homograph disambiguation oov words handling": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "grapheme-to-phoneme conversion kasre-ezafe detection homograph disambiguation oov words handling": ["GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion"], "question answering abstention": ["Characterizing LLM Abstention Behavior in Science QA with Context Perturbations"], "multiple-choice question analysis": ["Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning"], "commonsense reasoning multiple-choice question analysis": ["Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning"], "moral sentiment detection": ["Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "modeling annotator perspective": ["Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "hate speech detection moral sentiment detection": ["Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "moral sentiment detection modeling annotator perspective": ["Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "subjective nlp tasks hate speech detection moral sentiment detection": ["Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "hate speech detection moral sentiment detection modeling annotator perspective": ["Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "subjective nlp tasks hate speech detection moral sentiment detection modeling annotator perspective": ["Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation"], "english learning": ["EDEN: Empathetic Dialogues for English Learning"], "spoken conversation practice": ["EDEN: Empathetic Dialogues for English Learning"], "empathetic feedback": ["EDEN: Empathetic Dialogues for English Learning"], "chit-chat": ["EDEN: Empathetic Dialogues for English Learning"], "english learning spoken conversation practice": ["EDEN: Empathetic Dialogues for English Learning"], "spoken conversation practice empathetic feedback": ["EDEN: Empathetic Dialogues for English Learning"], "empathetic feedback grammar correction": ["EDEN: Empathetic Dialogues for English Learning"], "grammar correction chit-chat": ["EDEN: Empathetic Dialogues for English Learning"], "english learning spoken conversation practice empathetic feedback": ["EDEN: Empathetic Dialogues for English Learning"], "spoken conversation practice empathetic feedback grammar correction": ["EDEN: Empathetic Dialogues for English Learning"], "empathetic feedback grammar correction chit-chat": ["EDEN: Empathetic Dialogues for English Learning"], "english learning spoken conversation practice empathetic feedback grammar correction": ["EDEN: Empathetic Dialogues for English Learning"], "spoken conversation practice empathetic feedback grammar correction chit-chat": ["EDEN: Empathetic Dialogues for English Learning"], "english learning spoken conversation practice empathetic feedback grammar correction chit-chat": ["EDEN: Empathetic Dialogues for English Learning"], "etiological reasoning": ["Language Models Still Struggle to Zero-shot Reason about Time Series"], "context-aided forecasting": ["Language Models Still Struggle to Zero-shot Reason about Time Series"], "etiological reasoning question answering": ["Language Models Still Struggle to Zero-shot Reason about Time Series"], "question answering context-aided forecasting": ["Language Models Still Struggle to Zero-shot Reason about Time Series"], "etiological reasoning question answering context-aided forecasting": ["Language Models Still Struggle to Zero-shot Reason about Time Series"], "interactive decision-making": ["Enhancing Agent Learning through World Dynamics Modeling", "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking"], "game playing": ["Enhancing Agent Learning through World Dynamics Modeling", "Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "strategy learning": ["Enhancing Agent Learning through World Dynamics Modeling"], "language understanding interactive decision-making": ["Enhancing Agent Learning through World Dynamics Modeling"], "interactive decision-making game playing": ["Enhancing Agent Learning through World Dynamics Modeling"], "game playing strategy learning": ["Enhancing Agent Learning through World Dynamics Modeling"], "language understanding interactive decision-making game playing": ["Enhancing Agent Learning through World Dynamics Modeling"], "interactive decision-making game playing strategy learning": ["Enhancing Agent Learning through World Dynamics Modeling"], "language understanding interactive decision-making game playing strategy learning": ["Enhancing Agent Learning through World Dynamics Modeling"], "table qa": ["NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization"], "table qa fact verification": ["NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization"], "hallucination prevention": ["Zero-Resource Hallucination Prevention for Large Language Models"], "visual & language reasoning": ["Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals"], "reading comprehension paraphrase detection": ["Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals"], "paraphrase detection visual & language reasoning": ["Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals"], "natural language inference reading comprehension paraphrase detection": ["Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals"], "reading comprehension paraphrase detection visual & language reasoning": ["Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals"], "natural language inference reading comprehension paraphrase detection visual & language reasoning": ["Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals"], "chain-of-thought prompting": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "latent reasoning skill discovery": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "in-context learning chain-of-thought prompting": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "chain-of-thought prompting demonstration selection": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "demonstration selection latent reasoning skill discovery": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "in-context learning chain-of-thought prompting demonstration selection": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "chain-of-thought prompting demonstration selection latent reasoning skill discovery": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "in-context learning chain-of-thought prompting demonstration selection latent reasoning skill discovery": ["LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning"], "fine-grained image captioning": ["TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "zero-shot learning fine-grained image captioning": ["TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "fine-grained image captioning object detection": ["TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "image captioning zero-shot learning fine-grained image captioning": ["TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "zero-shot learning fine-grained image captioning object detection": ["TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "image captioning zero-shot learning fine-grained image captioning object detection": ["TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"], "case outcome classification": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases", "Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "allegation identification": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "violation identification": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "selective prediction": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "case outcome classification allegation identification": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "allegation identification violation identification": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "violation identification selective prediction": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "case outcome classification allegation identification violation identification": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "allegation identification violation identification selective prediction": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "case outcome classification allegation identification violation identification selective prediction": ["The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases"], "knowledge integration": ["InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration", "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "knowledge integration question answering": ["InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration"], "question answering relation classification": ["InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration"], "knowledge integration question answering relation classification": ["InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration"], "summarization consistency checking": ["SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization"], "factual consistency detection": ["SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization"], "natural language explanation": ["SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization"], "summarization consistency checking factual consistency detection": ["SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization"], "factual consistency detection natural language explanation": ["SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization"], "summarization consistency checking factual consistency detection natural language explanation": ["SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization"], "caption analysis": ["Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model"], "text-to-image generation caption analysis": ["Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model"], "shift cipher decoding": ["Deciphering the Factors Influencing the Efficacy of Chain-of-Thought: Probability, Memorization, and Noisy Reasoning"], "self-contradiction detection": ["Self-Contradictory Reasoning Evaluation and Detection"], "natural language inference reasoning evaluation": ["Self-Contradictory Reasoning Evaluation and Detection"], "reasoning evaluation self-contradiction detection": ["Self-Contradictory Reasoning Evaluation and Detection"], "self-contradiction detection question answering": ["Self-Contradictory Reasoning Evaluation and Detection"], "natural language inference reasoning evaluation self-contradiction detection": ["Self-Contradictory Reasoning Evaluation and Detection"], "reasoning evaluation self-contradiction detection question answering": ["Self-Contradictory Reasoning Evaluation and Detection"], "natural language inference reasoning evaluation self-contradiction detection question answering": ["Self-Contradictory Reasoning Evaluation and Detection"], "legal judgement prediction": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "echr task a": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "echr task b": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "case outcome classification legal judgement prediction": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "legal judgement prediction echr task a": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "echr task a echr task b": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "case outcome classification legal judgement prediction echr task a": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "legal judgement prediction echr task a echr task b": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "case outcome classification legal judgement prediction echr task a echr task b": ["Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases"], "decontextualization": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "error localization": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "claim decomposition": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "fact verification decontextualization": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "decontextualization error localization": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "error localization claim decomposition": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "fact verification decontextualization error localization": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "decontextualization error localization claim decomposition": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "fact verification decontextualization error localization claim decomposition": ["Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification"], "molecular source identification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular structure analysis": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular application understanding": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "corpus classification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "topic extraction": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension", "ROBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies"], "semantic consistency validation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "question answering molecular property prediction": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular property prediction molecular source identification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular source identification molecular structure analysis": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular structure analysis molecular application understanding": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular application understanding corpus classification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "corpus classification topic extraction": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "topic extraction answer generation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "answer generation semantic consistency validation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "question answering molecular property prediction molecular source identification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular property prediction molecular source identification molecular structure analysis": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular source identification molecular structure analysis molecular application understanding": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular structure analysis molecular application understanding corpus classification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular application understanding corpus classification topic extraction": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "corpus classification topic extraction answer generation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "topic extraction answer generation semantic consistency validation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "question answering molecular property prediction molecular source identification molecular structure analysis": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular property prediction molecular source identification molecular structure analysis molecular application understanding": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular source identification molecular structure analysis molecular application understanding corpus classification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular structure analysis molecular application understanding corpus classification topic extraction": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular application understanding corpus classification topic extraction answer generation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "corpus classification topic extraction answer generation semantic consistency validation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "question answering molecular property prediction molecular source identification molecular structure analysis molecular application understanding": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular property prediction molecular source identification molecular structure analysis molecular application understanding corpus classification": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular source identification molecular structure analysis molecular application understanding corpus classification topic extraction": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular structure analysis molecular application understanding corpus classification topic extraction answer generation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "molecular application understanding corpus classification topic extraction answer generation semantic consistency validation": ["MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension"], "bug detection": ["Sanitizing Large Language Models in Bug Detection with Data-Flow"], "addition": ["Scaling Behavior for Large Language Models regarding Numeral Systems: An Example using Pythia", "Skills-in-Context: Unlocking Compositionality in Large Language Models"], "multiplication": ["Scaling Behavior for Large Language Models regarding Numeral Systems: An Example using Pythia", "Skills-in-Context: Unlocking Compositionality in Large Language Models"], "addition multiplication": ["Scaling Behavior for Large Language Models regarding Numeral Systems: An Example using Pythia", "Skills-in-Context: Unlocking Compositionality in Large Language Models"], "scenario context generation": ["When and Where Did It Happen? An Encoder-Decoder Model to Identify Scenario Context"], "scenario context generation information extraction": ["When and Where Did It Happen? An Encoder-Decoder Model to Identify Scenario Context"], "incremental summarization": ["Enhancing Incremental Summarization with Structured Representations"], "long document summarization": ["Enhancing Incremental Summarization with Structured Representations", "LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "incremental summarization knowledge representation": ["Enhancing Incremental Summarization with Structured Representations"], "knowledge representation long document summarization": ["Enhancing Incremental Summarization with Structured Representations"], "incremental summarization knowledge representation long document summarization": ["Enhancing Incremental Summarization with Structured Representations"], "open-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "close-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "medical visual question answering image classification": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "image classification discriminative tasks": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "discriminative tasks generative tasks": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "generative tasks open-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "open-end qa close-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "medical visual question answering image classification discriminative tasks": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "image classification discriminative tasks generative tasks": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "discriminative tasks generative tasks open-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "generative tasks open-end qa close-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "medical visual question answering image classification discriminative tasks generative tasks": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "image classification discriminative tasks generative tasks open-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "discriminative tasks generative tasks open-end qa close-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "medical visual question answering image classification discriminative tasks generative tasks open-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "image classification discriminative tasks generative tasks open-end qa close-end qa": ["Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"], "multimodal emotion recognition in conversations": ["Multiple Knowledge-Enhanced Interactive Graph Network for Multimodal Conversational Emotion Recognition"], "hyper-parameter optimization in RAG": ["AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"], "counterfact": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "fever": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios gender": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios profession": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench epistemic reasoning": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench wikidata qa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "stanford sentiment treebank 2": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "question natural language inference": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "counterfact fever": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "fever bios gender": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios gender bios profession": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios profession truthfulqa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "truthfulqa bigbench epistemic reasoning": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench epistemic reasoning bigbench wikidata qa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench wikidata qa stanford sentiment treebank 2": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "stanford sentiment treebank 2 race": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "race question natural language inference": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "counterfact fever bios gender": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "fever bios gender bios profession": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios gender bios profession truthfulqa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios profession truthfulqa bigbench epistemic reasoning": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "truthfulqa bigbench epistemic reasoning bigbench wikidata qa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench epistemic reasoning bigbench wikidata qa stanford sentiment treebank 2": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench wikidata qa stanford sentiment treebank 2 race": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "stanford sentiment treebank 2 race question natural language inference": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "counterfact fever bios gender bios profession": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "fever bios gender bios profession truthfulqa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios gender bios profession truthfulqa bigbench epistemic reasoning": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios profession truthfulqa bigbench epistemic reasoning bigbench wikidata qa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "truthfulqa bigbench epistemic reasoning bigbench wikidata qa stanford sentiment treebank 2": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench epistemic reasoning bigbench wikidata qa stanford sentiment treebank 2 race": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench wikidata qa stanford sentiment treebank 2 race question natural language inference": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "counterfact fever bios gender bios profession truthfulqa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "fever bios gender bios profession truthfulqa bigbench epistemic reasoning": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios gender bios profession truthfulqa bigbench epistemic reasoning bigbench wikidata qa": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bios profession truthfulqa bigbench epistemic reasoning bigbench wikidata qa stanford sentiment treebank 2": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "truthfulqa bigbench epistemic reasoning bigbench wikidata qa stanford sentiment treebank 2 race": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "bigbench epistemic reasoning bigbench wikidata qa stanford sentiment treebank 2 race question natural language inference": ["Unleashing the Potential of Large Language Models through Spectral Modulation"], "semantic relatedness": ["LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization"], "intent classification news classification": ["LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization"], "news classification semantic relatedness": ["LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization"], "intent classification news classification semantic relatedness": ["LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization"], "extreme multi-label text classification": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "social networks": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "extreme multi-label text classification recommendation systems": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "recommendation systems social networks": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "social networks similarity search": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "extreme multi-label text classification recommendation systems social networks": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "recommendation systems social networks similarity search": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "extreme multi-label text classification recommendation systems social networks similarity search": ["QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware"], "summarization quality evaluation": ["UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs"], "mathematical question answering": ["Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data"], "argument recognition": ["Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data"], "program generation": ["Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data"], "mathematical question answering argument recognition": ["Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data"], "argument recognition program generation": ["Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data"], "mathematical question answering argument recognition program generation": ["Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data"], "chinese spelling check error detection": ["Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check"], "error detection error correction": ["Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check"], "chinese spelling check error detection error correction": ["Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check"], "long story qa": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long conversation memory": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story summarization": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "stacked news labeling": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "stacked typo detection": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "key-passage retrieval": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "table querying": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story qa long conversation memory": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long conversation memory long story summarization": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story summarization stacked news labeling": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "stacked news labeling stacked typo detection": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "stacked typo detection key-passage retrieval": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "key-passage retrieval table querying": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story qa long conversation memory long story summarization": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long conversation memory long story summarization stacked news labeling": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story summarization stacked news labeling stacked typo detection": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "stacked news labeling stacked typo detection key-passage retrieval": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "stacked typo detection key-passage retrieval table querying": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story qa long conversation memory long story summarization stacked news labeling": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long conversation memory long story summarization stacked news labeling stacked typo detection": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story summarization stacked news labeling stacked typo detection key-passage retrieval": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "stacked news labeling stacked typo detection key-passage retrieval table querying": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story qa long conversation memory long story summarization stacked news labeling stacked typo detection": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long conversation memory long story summarization stacked news labeling stacked typo detection key-passage retrieval": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "long story summarization stacked news labeling stacked typo detection key-passage retrieval table querying": ["CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models"], "personalized preference prediction": ["Guided Profile Generation Improves Personalization with LLMs"], "text paraphrasing": ["Guided Profile Generation Improves Personalization with LLMs"], "personalized preference prediction text paraphrasing": ["Guided Profile Generation Improves Personalization with LLMs"], "text paraphrasing dialogue response generation": ["Guided Profile Generation Improves Personalization with LLMs"], "personalized preference prediction text paraphrasing dialogue response generation": ["Guided Profile Generation Improves Personalization with LLMs"], "root cause analysis": ["MABC: Multi-Agent Blockchain-inspired Collaboration for Root Cause Analysis in Micro-Services Architecture"], "out-of-domain downstream tasks": ["Taking a Deep Breath: Enhancing Language Modeling of Large Language Models with Sentinel Tokens"], "language modeling out-of-domain downstream tasks": ["Taking a Deep Breath: Enhancing Language Modeling of Large Language Models with Sentinel Tokens"], "multimodal long-context processing": ["LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference"], "kv cache optimization": ["LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference"], "efficient inference": ["LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference"], "multimodal long-context processing kv cache optimization": ["LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference"], "kv cache optimization efficient inference": ["LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference"], "multimodal long-context processing kv cache optimization efficient inference": ["LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference"], "single-hop qa": ["OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs", "Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities"], "rag entity linking": ["OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs"], "entity linking single-hop qa": ["OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs"], "single-hop qa multi-hop qa": ["OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs", "Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities"], "rag entity linking single-hop qa": ["OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs"], "entity linking single-hop qa multi-hop qa": ["OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs"], "rag entity linking single-hop qa multi-hop qa": ["OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs"], "implicit pattern detection": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "expression calculation": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "boolean functions": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "code reading": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "implicit pattern detection expression calculation": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "expression calculation boolean functions": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "boolean functions relation reasoning": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "relation reasoning code reading": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "implicit pattern detection expression calculation boolean functions": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "expression calculation boolean functions relation reasoning": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "boolean functions relation reasoning code reading": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "implicit pattern detection expression calculation boolean functions relation reasoning": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "expression calculation boolean functions relation reasoning code reading": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "implicit pattern detection expression calculation boolean functions relation reasoning code reading": ["Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning"], "low-rank compression": ["Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization"], "emotion tagging": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "emotion recognition multimodal analysis": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "multimodal analysis dataset creation": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "dataset creation speech synthesis": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "speech synthesis emotion tagging": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "emotion recognition multimodal analysis dataset creation": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "multimodal analysis dataset creation speech synthesis": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "dataset creation speech synthesis emotion tagging": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "emotion recognition multimodal analysis dataset creation speech synthesis": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "multimodal analysis dataset creation speech synthesis emotion tagging": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "emotion recognition multimodal analysis dataset creation speech synthesis emotion tagging": ["Emosical: An Emotion-Annotated Musical Theatre Dataset"], "sentiment generation": ["Inference-Time Language Model Alignment via Integrated Value Guidance"], "sentiment generation summarization": ["Inference-Time Language Model Alignment via Integrated Value Guidance"], "sentiment generation summarization instruction following": ["Inference-Time Language Model Alignment via Integrated Value Guidance"], "classical chinese understanding": ["TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models"], "theory of mind  evaluation": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "negotiation": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "belief": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "desire": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "intention": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "theory of mind  evaluation negotiation": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "negotiation belief": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "belief desire": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "desire intention": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "theory of mind  evaluation negotiation belief": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "negotiation belief desire": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "belief desire intention": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "theory of mind  evaluation negotiation belief desire": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "negotiation belief desire intention": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "theory of mind  evaluation negotiation belief desire intention": ["NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding"], "audio generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "music generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "long-form music generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "hierarchical encoding": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "abstract-to-detail generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "audio generation music generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "music generation long-form music generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "long-form music generation hierarchical encoding": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "hierarchical encoding abstract-to-detail generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "audio generation music generation long-form music generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "music generation long-form music generation hierarchical encoding": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "long-form music generation hierarchical encoding abstract-to-detail generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "audio generation music generation long-form music generation hierarchical encoding": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "music generation long-form music generation hierarchical encoding abstract-to-detail generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "audio generation music generation long-form music generation hierarchical encoding abstract-to-detail generation": ["PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain"], "credibility enhancement": ["Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "conversational recommendation explanation generation": ["Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "explanation generation persuasion": ["Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "persuasion credibility enhancement": ["Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "conversational recommendation explanation generation persuasion": ["Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "explanation generation persuasion credibility enhancement": ["Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "conversational recommendation explanation generation persuasion credibility enhancement": ["Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"], "instruction fine-tuning continual learning": ["Revisiting Catastrophic Forgetting in Large Language Model Tuning"], "multilingual vision-language tasks": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visually grounded reasoning": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visual natural language inference": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visio-linguistic outlier detection": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "multilingual vision-language tasks visual question answering": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visual question answering visually grounded reasoning": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visually grounded reasoning visual natural language inference": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visual natural language inference visio-linguistic outlier detection": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visio-linguistic outlier detection image captioning": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "multilingual vision-language tasks visual question answering visually grounded reasoning": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visual question answering visually grounded reasoning visual natural language inference": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visually grounded reasoning visual natural language inference visio-linguistic outlier detection": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visual natural language inference visio-linguistic outlier detection image captioning": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "multilingual vision-language tasks visual question answering visually grounded reasoning visual natural language inference": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visual question answering visually grounded reasoning visual natural language inference visio-linguistic outlier detection": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visually grounded reasoning visual natural language inference visio-linguistic outlier detection image captioning": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "multilingual vision-language tasks visual question answering visually grounded reasoning visual natural language inference visio-linguistic outlier detection": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "visual question answering visually grounded reasoning visual natural language inference visio-linguistic outlier detection image captioning": ["M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks"], "emotion attribution": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "stereotype analysis": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "stigmatization assessment": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "religious representation": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "emotion attribution bias detection": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "bias detection stereotype analysis": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "stereotype analysis stigmatization assessment": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "stigmatization assessment religious representation": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "emotion attribution bias detection stereotype analysis": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "bias detection stereotype analysis stigmatization assessment": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "stereotype analysis stigmatization assessment religious representation": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "emotion attribution bias detection stereotype analysis stigmatization assessment": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "bias detection stereotype analysis stigmatization assessment religious representation": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "emotion attribution bias detection stereotype analysis stigmatization assessment religious representation": ["Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models"], "aspect-based sentiment classification": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis", "TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "absc": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "ae": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "joint": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "aspect extraction aspect-based sentiment classification": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "aspect-based sentiment classification absc": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "absc ae": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "ae joint": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "aspect extraction aspect-based sentiment classification absc": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "aspect-based sentiment classification absc ae": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "absc ae joint": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "aspect extraction aspect-based sentiment classification absc ae": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "aspect-based sentiment classification absc ae joint": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "aspect extraction aspect-based sentiment classification absc ae joint": ["Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis"], "table question answering fact verification": ["PROTRIX: Building Models for Planning and Reasoning over Tables with Sentence Context"], "detection": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "counter speech": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "detection explanation": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "explanation debiasing": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "debiasing counter speech": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "detection explanation debiasing": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "explanation debiasing counter speech": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "detection explanation debiasing counter speech": ["Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"], "news article generation": ["Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles"], "political bias analysis news article generation": ["Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles"], "news article generation text classification": ["Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles"], "political bias analysis news article generation text classification": ["Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles"], "open event extraction": ["OEE-CFC: A Dataset for Open Event Extraction from Chinese Financial Commentary"], "open event extraction event argument extraction": ["OEE-CFC: A Dataset for Open Event Extraction from Chinese Financial Commentary"], "long document classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "multi-class classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "long document classification binary classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "binary classification multi-class classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "multi-class classification multi-label classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "long document classification binary classification multi-class classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "binary classification multi-class classification multi-label classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "long document classification binary classification multi-class classification multi-label classification": ["Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"], "character description": ["BOOKWORM: A Dataset for Character Description and Analysis"], "character analysis": ["BOOKWORM: A Dataset for Character Description and Analysis"], "joint character description": ["BOOKWORM: A Dataset for Character Description and Analysis"], "character description character analysis": ["BOOKWORM: A Dataset for Character Description and Analysis"], "character analysis joint character description": ["BOOKWORM: A Dataset for Character Description and Analysis"], "character description character analysis joint character description": ["BOOKWORM: A Dataset for Character Description and Analysis"], "machine translation natural language understanding": ["Leveraging Grammar Induction for Language Understanding and Generation"], "natural language understanding glue": ["Leveraging Grammar Induction for Language Understanding and Generation"], "machine translation natural language understanding glue": ["Leveraging Grammar Induction for Language Understanding and Generation"], "hallucination mitigation question answering": ["SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully"], "summarization text completion": ["SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully"], "hallucination mitigation question answering summarization": ["SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully"], "question answering summarization text completion": ["SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully"], "hallucination mitigation question answering summarization text completion": ["SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully"], "language adaptation": ["RoQLlama: A Lightweight Romanian Adapted Language Model", "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "emotion detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model", "BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "dialect classification": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "satire detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "language adaptation question answering": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "question answering emotion detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "emotion detection dialect classification": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "dialect classification satire detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "satire detection text summarization": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "text summarization textual similarity": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "language adaptation question answering emotion detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "question answering emotion detection dialect classification": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "emotion detection dialect classification satire detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "dialect classification satire detection text summarization": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "satire detection text summarization textual similarity": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "language adaptation question answering emotion detection dialect classification": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "question answering emotion detection dialect classification satire detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "emotion detection dialect classification satire detection text summarization": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "dialect classification satire detection text summarization textual similarity": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "language adaptation question answering emotion detection dialect classification satire detection": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "question answering emotion detection dialect classification satire detection text summarization": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "emotion detection dialect classification satire detection text summarization textual similarity": ["RoQLlama: A Lightweight Romanian Adapted Language Model"], "speech question answering": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "english listening comprehension": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "instruction-independent multi-tasks": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech chain-of-thought": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech-to-text translation emotion recognition": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "emotion recognition speaker verification": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speaker verification speech question answering": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech question answering english listening comprehension": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "english listening comprehension instruction-independent multi-tasks": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "instruction-independent multi-tasks speech chain-of-thought": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "automatic speech recognition speech-to-text translation emotion recognition": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech-to-text translation emotion recognition speaker verification": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "emotion recognition speaker verification speech question answering": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speaker verification speech question answering english listening comprehension": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech question answering english listening comprehension instruction-independent multi-tasks": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "english listening comprehension instruction-independent multi-tasks speech chain-of-thought": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "automatic speech recognition speech-to-text translation emotion recognition speaker verification": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech-to-text translation emotion recognition speaker verification speech question answering": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "emotion recognition speaker verification speech question answering english listening comprehension": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speaker verification speech question answering english listening comprehension instruction-independent multi-tasks": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech question answering english listening comprehension instruction-independent multi-tasks speech chain-of-thought": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "automatic speech recognition speech-to-text translation emotion recognition speaker verification speech question answering": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speech-to-text translation emotion recognition speaker verification speech question answering english listening comprehension": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "emotion recognition speaker verification speech question answering english listening comprehension instruction-independent multi-tasks": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "speaker verification speech question answering english listening comprehension instruction-independent multi-tasks speech chain-of-thought": ["WavLLM: Towards Robust and Adaptive Speech Large Language Model"], "user feedback integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "emotion integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "demographic information integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "task-oriented dialogue document-grounded dialogue": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "document-grounded dialogue user feedback integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "user feedback integration emotion integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "emotion integration demographic information integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "demographic information integration factual consistency": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "factual consistency task completion": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "task-oriented dialogue document-grounded dialogue user feedback integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "document-grounded dialogue user feedback integration emotion integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "user feedback integration emotion integration demographic information integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "emotion integration demographic information integration factual consistency": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "demographic information integration factual consistency task completion": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "task-oriented dialogue document-grounded dialogue user feedback integration emotion integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "document-grounded dialogue user feedback integration emotion integration demographic information integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "user feedback integration emotion integration demographic information integration factual consistency": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "emotion integration demographic information integration factual consistency task completion": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "task-oriented dialogue document-grounded dialogue user feedback integration emotion integration demographic information integration": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "document-grounded dialogue user feedback integration emotion integration demographic information integration factual consistency": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "user feedback integration emotion integration demographic information integration factual consistency task completion": ["Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues"], "argument effectiveness style transfer": ["Improving Argument Effectiveness Across Ideologies using Instruction-tuned Large Language Models"], "long context understanding": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "single-doc qa": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "multi-doc qa": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "synthetic task": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "needle-in-a-haystack test": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "long context understanding single-doc qa": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "single-doc qa multi-doc qa": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "multi-doc qa summarization": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "few-shot learning synthetic task": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "synthetic task code completion": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "code completion needle-in-a-haystack test": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "long context understanding single-doc qa multi-doc qa": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "single-doc qa multi-doc qa summarization": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "multi-doc qa summarization few-shot learning": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "summarization few-shot learning synthetic task": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "few-shot learning synthetic task code completion": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "synthetic task code completion needle-in-a-haystack test": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "long context understanding single-doc qa multi-doc qa summarization": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "single-doc qa multi-doc qa summarization few-shot learning": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "multi-doc qa summarization few-shot learning synthetic task": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "summarization few-shot learning synthetic task code completion": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "few-shot learning synthetic task code completion needle-in-a-haystack test": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "long context understanding single-doc qa multi-doc qa summarization few-shot learning": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "single-doc qa multi-doc qa summarization few-shot learning synthetic task": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "multi-doc qa summarization few-shot learning synthetic task code completion": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "summarization few-shot learning synthetic task code completion needle-in-a-haystack test": ["KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches"], "evaluation of LLM-based agents": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "api manipulation": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool use capability assessment": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "requesting information": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "responding to tool returns": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "resolving dependency": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "evaluation of LLM-based agents api manipulation": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "api manipulation tool use capability assessment": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool use capability assessment planning": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "planning tool selection": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool selection requesting information": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "requesting information responding to tool returns": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "responding to tool returns resolving dependency": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "evaluation of LLM-based agents api manipulation tool use capability assessment": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "api manipulation tool use capability assessment planning": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool use capability assessment planning tool selection": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "planning tool selection requesting information": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool selection requesting information responding to tool returns": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "requesting information responding to tool returns resolving dependency": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "evaluation of LLM-based agents api manipulation tool use capability assessment planning": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "api manipulation tool use capability assessment planning tool selection": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool use capability assessment planning tool selection requesting information": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "planning tool selection requesting information responding to tool returns": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool selection requesting information responding to tool returns resolving dependency": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "evaluation of LLM-based agents api manipulation tool use capability assessment planning tool selection": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "api manipulation tool use capability assessment planning tool selection requesting information": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "tool use capability assessment planning tool selection requesting information responding to tool returns": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "planning tool selection requesting information responding to tool returns resolving dependency": ["An Evaluation Mechanism of LLM-based Agents on Manipulating APIs"], "multimodal mathematical reasoning": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "figure question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "textbook question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "multimodal mathematical reasoning visual question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "visual question answering figure question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "figure question answering geometry problem solving": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "geometry problem solving math word problem": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "math word problem textbook question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "multimodal mathematical reasoning visual question answering figure question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "visual question answering figure question answering geometry problem solving": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "figure question answering geometry problem solving math word problem": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "geometry problem solving math word problem textbook question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "multimodal mathematical reasoning visual question answering figure question answering geometry problem solving": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "visual question answering figure question answering geometry problem solving math word problem": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "figure question answering geometry problem solving math word problem textbook question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "multimodal mathematical reasoning visual question answering figure question answering geometry problem solving math word problem": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "visual question answering figure question answering geometry problem solving math word problem textbook question answering": ["Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models"], "fine-grained evaluation\\": ["Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation\\"], "instruction following fine-grained evaluation\\": ["Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation\\"], "vision-language navigation instruction following fine-grained evaluation\\": ["Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation\\"], "tool retrieval": ["Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval", "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models"], "machine unlearning": ["Rethinking Evaluation Methods for Machine Unlearning", "Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models"], "evaluation methods": ["Rethinking Evaluation Methods for Machine Unlearning"], "text classification machine unlearning": ["Rethinking Evaluation Methods for Machine Unlearning"], "machine unlearning evaluation methods": ["Rethinking Evaluation Methods for Machine Unlearning"], "text classification machine unlearning evaluation methods": ["Rethinking Evaluation Methods for Machine Unlearning"], "moral belief evaluation": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral choice scenarios": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "cultural comparison": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "gender bias detection": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework", "Evaluating Gender Bias of LLMs in Making Morality Judgements"], "moral reasoning": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral ranking": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral debate": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral belief evaluation LLMs": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "LLMs moral choice scenarios": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral choice scenarios cultural comparison": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "cultural comparison gender bias detection": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "gender bias detection moral reasoning": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral reasoning moral ranking": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral ranking moral debate": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral belief evaluation LLMs moral choice scenarios": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "LLMs moral choice scenarios cultural comparison": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral choice scenarios cultural comparison gender bias detection": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "cultural comparison gender bias detection moral reasoning": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "gender bias detection moral reasoning moral ranking": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral reasoning moral ranking moral debate": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral belief evaluation LLMs moral choice scenarios cultural comparison": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "LLMs moral choice scenarios cultural comparison gender bias detection": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral choice scenarios cultural comparison gender bias detection moral reasoning": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "cultural comparison gender bias detection moral reasoning moral ranking": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "gender bias detection moral reasoning moral ranking moral debate": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral belief evaluation LLMs moral choice scenarios cultural comparison gender bias detection": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "LLMs moral choice scenarios cultural comparison gender bias detection moral reasoning": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "moral choice scenarios cultural comparison gender bias detection moral reasoning moral ranking": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "cultural comparison gender bias detection moral reasoning moral ranking moral debate": ["Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"], "factual error correction": ["Knowledge Editing in Language Models via Adapted Direct Preference Optimization"], "knowledge editing language model alignment": ["Knowledge Editing in Language Models via Adapted Direct Preference Optimization"], "language model alignment factual error correction": ["Knowledge Editing in Language Models via Adapted Direct Preference Optimization"], "knowledge editing language model alignment factual error correction": ["Knowledge Editing in Language Models via Adapted Direct Preference Optimization"], "meta-prompting": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "information retrieval query generation": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "query generation task adaptation": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "task adaptation zero-shot learning": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "few-shot learning meta-prompting": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "information retrieval query generation task adaptation": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "query generation task adaptation zero-shot learning": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "task adaptation zero-shot learning few-shot learning": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "zero-shot learning few-shot learning meta-prompting": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "information retrieval query generation task adaptation zero-shot learning": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "query generation task adaptation zero-shot learning few-shot learning": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "task adaptation zero-shot learning few-shot learning meta-prompting": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "information retrieval query generation task adaptation zero-shot learning few-shot learning": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "query generation task adaptation zero-shot learning few-shot learning meta-prompting": ["Disentangling Questions from Query Generation for Task-Adaptive Retrieval"], "media storm detection": ["Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora"], "story rewriting": ["A Survey on Natural Language Counterfactual Generation"], "natural language inference question answering": ["A Survey on Natural Language Counterfactual Generation", "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation", "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "question answering story rewriting": ["A Survey on Natural Language Counterfactual Generation"], "story rewriting domain adaptation": ["A Survey on Natural Language Counterfactual Generation"], "domain adaptation relation extraction": ["A Survey on Natural Language Counterfactual Generation"], "relation extraction text classification": ["A Survey on Natural Language Counterfactual Generation"], "sentiment analysis natural language inference question answering": ["A Survey on Natural Language Counterfactual Generation", "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation"], "natural language inference question answering story rewriting": ["A Survey on Natural Language Counterfactual Generation"], "question answering story rewriting domain adaptation": ["A Survey on Natural Language Counterfactual Generation"], "story rewriting domain adaptation relation extraction": ["A Survey on Natural Language Counterfactual Generation"], "domain adaptation relation extraction text classification": ["A Survey on Natural Language Counterfactual Generation"], "sentiment analysis natural language inference question answering story rewriting": ["A Survey on Natural Language Counterfactual Generation"], "natural language inference question answering story rewriting domain adaptation": ["A Survey on Natural Language Counterfactual Generation"], "question answering story rewriting domain adaptation relation extraction": ["A Survey on Natural Language Counterfactual Generation"], "story rewriting domain adaptation relation extraction text classification": ["A Survey on Natural Language Counterfactual Generation"], "sentiment analysis natural language inference question answering story rewriting domain adaptation": ["A Survey on Natural Language Counterfactual Generation"], "natural language inference question answering story rewriting domain adaptation relation extraction": ["A Survey on Natural Language Counterfactual Generation"], "question answering story rewriting domain adaptation relation extraction text classification": ["A Survey on Natural Language Counterfactual Generation"], "gene function description": ["Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research"], "protein function inference": ["Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research"], "marker gene selection": ["Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research"], "gene function description protein function inference": ["Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research"], "protein function inference marker gene selection": ["Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research"], "gene function description protein function inference marker gene selection": ["Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research"], "multiple-choice questions multi-document question answering": ["QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism"], "long-context rag evaluation": ["LONG2RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall"], "long-form rag evaluation": ["LONG2RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall"], "key point recall metric": ["LONG2RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall"], "long-context rag evaluation long-form rag evaluation": ["LONG2RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall"], "long-form rag evaluation key point recall metric": ["LONG2RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall"], "long-context rag evaluation long-form rag evaluation key point recall metric": ["LONG2RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall"], "language development assessment": ["IndoCL: Benchmarking Indonesian Language Development Assessment"], "retrieval-augmented language models  enhancement": ["Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs"], "question answering retrieval-augmented language models  enhancement": ["Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs"], "media background checks generation": ["Generating Media Background Checks for Automated Source Critical Reasoning"], "LLM serving": ["In Defense of Structural Sparse Adapters for Concurrent LLM Serving"], "concept abstraction": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "concept concretization": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "common ancestor reasoning": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "multimodal reasoning visual reasoning": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models", "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "visual reasoning concept abstraction": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "concept abstraction concept concretization": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "concept concretization common ancestor reasoning": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "multimodal reasoning visual reasoning concept abstraction": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "visual reasoning concept abstraction concept concretization": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "concept abstraction concept concretization common ancestor reasoning": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "multimodal reasoning visual reasoning concept abstraction concept concretization": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "visual reasoning concept abstraction concept concretization common ancestor reasoning": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "multimodal reasoning visual reasoning concept abstraction concept concretization common ancestor reasoning": ["CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models"], "autonomous driving": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "human-centered driving": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "human-vehicle interaction": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "following user instructions": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "integrating human feedback": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "autonomous driving human-centered driving": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "human-centered driving human-vehicle interaction": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "human-vehicle interaction following user instructions": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "following user instructions integrating human feedback": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "autonomous driving human-centered driving human-vehicle interaction": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "human-centered driving human-vehicle interaction following user instructions": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "human-vehicle interaction following user instructions integrating human feedback": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "autonomous driving human-centered driving human-vehicle interaction following user instructions": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "human-centered driving human-vehicle interaction following user instructions integrating human feedback": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "autonomous driving human-centered driving human-vehicle interaction following user instructions integrating human feedback": ["Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models"], "cultural knowledge base construction": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural awareness evaluation": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "grounded evaluation": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural knowledge base construction cultural awareness evaluation": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural awareness evaluation language model fine-tuning": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "language model fine-tuning downstream task performance": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "downstream task performance grounded evaluation": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural knowledge base construction cultural awareness evaluation language model fine-tuning": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural awareness evaluation language model fine-tuning downstream task performance": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "language model fine-tuning downstream task performance grounded evaluation": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural knowledge base construction cultural awareness evaluation language model fine-tuning downstream task performance": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural awareness evaluation language model fine-tuning downstream task performance grounded evaluation": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "cultural knowledge base construction cultural awareness evaluation language model fine-tuning downstream task performance grounded evaluation": ["CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"], "parameter generation": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "api calling": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "tool selection parameter generation": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "parameter generation tool usage": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "tool usage api calling": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "tool selection parameter generation tool usage": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "parameter generation tool usage api calling": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "tool selection parameter generation tool usage api calling": ["TOOLVERIFIER: Generalization to New Tools via Self-Verification"], "20 questions game": ["Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain"], "question generation information seeking": ["Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain"], "information seeking 20 questions game": ["Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain"], "question generation information seeking 20 questions game": ["Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain"], "adversarial example generation": ["Adversarial Math Word Problem Generation"], "math word problem solving": ["Adversarial Math Word Problem Generation"], "adversarial example generation math word problem solving": ["Adversarial Math Word Problem Generation"], "math word problem solving LLM evaluation": ["Adversarial Math Word Problem Generation"], "adversarial example generation math word problem solving LLM evaluation": ["Adversarial Math Word Problem Generation"], "jailbreak defense LLM security": ["Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"], "receptive reframing of online discussions": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "promoting pro-social deliberation online": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "automated content moderation": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "reducing polarization": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "receptive reframing of online discussions promoting pro-social deliberation online": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "promoting pro-social deliberation online automated content moderation": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "automated content moderation reducing polarization": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "reducing polarization toxicity reduction": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "receptive reframing of online discussions promoting pro-social deliberation online automated content moderation": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "promoting pro-social deliberation online automated content moderation reducing polarization": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "automated content moderation reducing polarization toxicity reduction": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "receptive reframing of online discussions promoting pro-social deliberation online automated content moderation reducing polarization": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "promoting pro-social deliberation online automated content moderation reducing polarization toxicity reduction": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "receptive reframing of online discussions promoting pro-social deliberation online automated content moderation reducing polarization toxicity reduction": ["Promoting Constructive Deliberation: Reframing for Receptiveness"], "offensive content detection": ["Rater Cohesion and Quality from a Vicarious Perspective"], "rater agreement analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "vicarious annotation analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "demographic influence analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "rater quality assessment": ["Rater Cohesion and Quality from a Vicarious Perspective"], "offensive content detection rater agreement analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "rater agreement analysis vicarious annotation analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "vicarious annotation analysis demographic influence analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "demographic influence analysis rater quality assessment": ["Rater Cohesion and Quality from a Vicarious Perspective"], "offensive content detection rater agreement analysis vicarious annotation analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "rater agreement analysis vicarious annotation analysis demographic influence analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "vicarious annotation analysis demographic influence analysis rater quality assessment": ["Rater Cohesion and Quality from a Vicarious Perspective"], "offensive content detection rater agreement analysis vicarious annotation analysis demographic influence analysis": ["Rater Cohesion and Quality from a Vicarious Perspective"], "rater agreement analysis vicarious annotation analysis demographic influence analysis rater quality assessment": ["Rater Cohesion and Quality from a Vicarious Perspective"], "offensive content detection rater agreement analysis vicarious annotation analysis demographic influence analysis rater quality assessment": ["Rater Cohesion and Quality from a Vicarious Perspective"], "cooperation": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "competition": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "agent-based modeling": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "deliberate reasoning": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "social simulation cooperation": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "cooperation competition": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "competition agent-based modeling": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "agent-based modeling deliberate reasoning": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "social simulation cooperation competition": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "cooperation competition agent-based modeling": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "competition agent-based modeling deliberate reasoning": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "social simulation cooperation competition agent-based modeling": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "cooperation competition agent-based modeling deliberate reasoning": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "social simulation cooperation competition agent-based modeling deliberate reasoning": ["Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"], "transformer short-cutting": ["Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction"], "early exit prediction": ["Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction"], "transformer short-cutting early exit prediction": ["Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction"], "LLM authoring": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "copa generation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "validity assessment": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "LLM authoring commonsense reasoning": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "question answering copa generation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "copa generation consistency evaluation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "consistency evaluation validity assessment": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "LLM authoring commonsense reasoning question answering": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "commonsense reasoning question answering copa generation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "question answering copa generation consistency evaluation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "copa generation consistency evaluation validity assessment": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "LLM authoring commonsense reasoning question answering copa generation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "commonsense reasoning question answering copa generation consistency evaluation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "question answering copa generation consistency evaluation validity assessment": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "LLM authoring commonsense reasoning question answering copa generation consistency evaluation": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "commonsense reasoning question answering copa generation consistency evaluation validity assessment": ["From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items"], "response clarity evaluation": ["\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification"], "clarity classification": ["\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification"], "evasion detection": ["\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification"], "response clarity evaluation clarity classification": ["\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification"], "clarity classification evasion detection": ["\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification"], "response clarity evaluation clarity classification evasion detection": ["\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification"], "harmful fine-tuning attack  defense": ["Immunization against harmful fine-tuning attacks"], "merc": ["UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause"], "mecpe": ["UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause"], "merc mecpe": ["UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause"], "robustness improvement": ["CodeFort: Robust Training for Code Generation Models"], "code generation robustness improvement": ["CodeFort: Robust Training for Code Generation Models"], "rna secondary structure prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mrna degrade rate regression": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide variant": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide polymorphism": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mutation detection and repair": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "translation efficiency prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "gene expression prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "rna secondary structure prediction mrna degrade rate regression": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mrna degrade rate regression single nucleotide variant": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide variant single nucleotide polymorphism": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide polymorphism mutation detection and repair": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mutation detection and repair translation efficiency prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "translation efficiency prediction gene expression prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "rna secondary structure prediction mrna degrade rate regression single nucleotide variant": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mrna degrade rate regression single nucleotide variant single nucleotide polymorphism": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide variant single nucleotide polymorphism mutation detection and repair": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide polymorphism mutation detection and repair translation efficiency prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mutation detection and repair translation efficiency prediction gene expression prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "rna secondary structure prediction mrna degrade rate regression single nucleotide variant single nucleotide polymorphism": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mrna degrade rate regression single nucleotide variant single nucleotide polymorphism mutation detection and repair": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide variant single nucleotide polymorphism mutation detection and repair translation efficiency prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide polymorphism mutation detection and repair translation efficiency prediction gene expression prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "rna secondary structure prediction mrna degrade rate regression single nucleotide variant single nucleotide polymorphism mutation detection and repair": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "mrna degrade rate regression single nucleotide variant single nucleotide polymorphism mutation detection and repair translation efficiency prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "single nucleotide variant single nucleotide polymorphism mutation detection and repair translation efficiency prediction gene expression prediction": ["MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction"], "deliberation chain construction": ["\"Any Other Thoughts, Hedgehog?\u201d Linking Deliberation Chains in Collaborative Dialogues"], "question-answer generation": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "educational settings": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "conversational systems": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "question generation question-answer generation": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "question-answer generation data augmentation": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "data augmentation educational settings": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "educational settings conversational systems": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "question generation question-answer generation data augmentation": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "question-answer generation data augmentation educational settings": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "data augmentation educational settings conversational systems": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "question generation question-answer generation data augmentation educational settings": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "question-answer generation data augmentation educational settings conversational systems": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "question generation question-answer generation data augmentation educational settings conversational systems": ["Evaluation of Question Answer Generation for Portuguese: Insights and Datasets"], "complex instructions": ["Evolutionary Contrastive Distillation for Language Model Alignment"], "instruction-following complex instructions": ["Evolutionary Contrastive Distillation for Language Model Alignment"], "complex instructions language model alignment": ["Evolutionary Contrastive Distillation for Language Model Alignment"], "instruction-following complex instructions language model alignment": ["Evolutionary Contrastive Distillation for Language Model Alignment"], "negotiation strategy": ["A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies"], "human-compatible strategies": ["A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies"], "egalitarian outcomes": ["A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies"], "negotiation strategy human-compatible strategies": ["A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies"], "human-compatible strategies egalitarian outcomes": ["A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies"], "negotiation strategy human-compatible strategies egalitarian outcomes": ["A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies"], "community detection": ["Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media"], "bot detection": ["Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media"], "news media profiling": ["Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media"], "community detection bot detection": ["Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media"], "bot detection news media profiling": ["Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media"], "community detection bot detection news media profiling": ["Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media"], "annotation": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues", "Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "partner modeling": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "comprehension annotation": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "annotation partner modeling": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "partner modeling generation": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "comprehension annotation partner modeling": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "annotation partner modeling generation": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "comprehension annotation partner modeling generation": ["Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"], "length-of-stay prediction": ["When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?"], "diagnosis prediction mortality prediction": ["When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?"], "mortality prediction length-of-stay prediction": ["When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?"], "diagnosis prediction mortality prediction length-of-stay prediction": ["When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?"], "character recognition": ["Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts"], "visual question answering mathematical reasoning": ["Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts"], "mathematical reasoning character recognition": ["Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts"], "visual question answering mathematical reasoning character recognition": ["Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts"], "science question scoring": ["Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring"], "student answer assessment": ["Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring"], "rationale generation science question scoring": ["Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring"], "science question scoring student answer assessment": ["Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring"], "rationale generation science question scoring student answer assessment": ["Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring"], "musical lyrics translation": ["Sing it, Narrate it: Quality Musical Lyrics Translation"], "keyword mnemonics generation": ["Exploring Automated Keyword Mnemonics Generation with Large Language Models via Overgenerate-and-Rank"], "low-frequency word translation": ["Dual-teacher Knowledge Distillation for Low-frequency Word Translation"], "machine translation low-frequency word translation": ["Dual-teacher Knowledge Distillation for Low-frequency Word Translation"], "unsupervised sentence representation learning": ["A Simple Angle-based Approach for Contrastive Learning of Unsupervised Sentence Representation"], "legal knowledge": ["Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models"], "legal reasoning": ["Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models", "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration"], "korean bar exam": ["Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models"], "legal knowledge legal reasoning": ["Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models"], "legal reasoning korean bar exam": ["Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models"], "legal knowledge legal reasoning korean bar exam": ["Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models"], "ummt": ["Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs"], "ummt machine translation": ["Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs"], "chain-of-thought fine-tuning": ["Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach"], "subset selection": ["Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach"], "instruction tuning chain-of-thought fine-tuning": ["Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach"], "chain-of-thought fine-tuning subset selection": ["Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach"], "instruction tuning chain-of-thought fine-tuning subset selection": ["Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach"], "multiple-choice question answering reasoning": ["In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models"], "math problem standard alignment": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "standard verification": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "problem tagging": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "curriculum alignment evaluation": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "math pedagogy reasoning": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "math problem standard alignment standard verification": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "standard verification problem tagging": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "problem tagging curriculum alignment evaluation": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "curriculum alignment evaluation math pedagogy reasoning": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "math problem standard alignment standard verification problem tagging": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "standard verification problem tagging curriculum alignment evaluation": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "problem tagging curriculum alignment evaluation math pedagogy reasoning": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "math problem standard alignment standard verification problem tagging curriculum alignment evaluation": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "standard verification problem tagging curriculum alignment evaluation math pedagogy reasoning": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "math problem standard alignment standard verification problem tagging curriculum alignment evaluation math pedagogy reasoning": ["MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula"], "pronunciation reconstruction": ["Automatic Reconstruction of Ancient Chinese Pronunciations"], "temporal prediction": ["Automatic Reconstruction of Ancient Chinese Pronunciations"], "pronunciation reconstruction temporal prediction": ["Automatic Reconstruction of Ancient Chinese Pronunciations"], "cross-task generalization": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization", "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "task adaptation composition": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "module composition": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "cross-task generalization zero-shot learning": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "zero-shot learning task adaptation composition": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "task adaptation composition module composition": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "cross-task generalization zero-shot learning task adaptation composition": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "zero-shot learning task adaptation composition module composition": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "cross-task generalization zero-shot learning task adaptation composition module composition": ["Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"], "repository-level code tasks": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "retrieval-augmentation generation": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "long document summarization long document question answering": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "long document question answering repository-level code tasks": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "repository-level code tasks retrieval-augmentation generation": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "long document summarization long document question answering repository-level code tasks": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "long document question answering repository-level code tasks retrieval-augmentation generation": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "long document summarization long document question answering repository-level code tasks retrieval-augmentation generation": ["LongWanjuan: Towards Systematic Measurement for Long Text Quality"], "multi-domain machine translation": ["Large Language Model for Multi-Domain Translation: Benchmarking and Domain CoT Fine-tuning"], "clinical triage": ["TRIAGEAGENT: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage"], "emergency severity index  classification": ["TRIAGEAGENT: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage"], "clinical triage emergency severity index  classification": ["TRIAGEAGENT: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage"], "social media data selection": ["Generative Deduplication For Socia Media Data Selection"], "relationship disagreement decisions": ["Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts"], "relationship disagreement decisions bias evaluation": ["Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts"], "fact tracing": ["FASTTRACK: Reliable Fact Tracing via Clustering and LLM-Powered Evidence Validation"], "backdoor attack detection": ["PKAD: Pretrained Knowledge is All You Need to Detect and Mitigate Textual Backdoor Attacks"], "data poisoning defense": ["PKAD: Pretrained Knowledge is All You Need to Detect and Mitigate Textual Backdoor Attacks"], "backdoor attack detection data poisoning defense": ["PKAD: Pretrained Knowledge is All You Need to Detect and Mitigate Textual Backdoor Attacks"], "metaphor detection": ["Merely Judging Metaphor is Not Enough: Research on Reasonable Metaphor Detection", "EmbodiedBERT: Cognitively Informed Metaphor Detection Incorporating Sensorimotor Information"], "metaphor reasoning": ["Merely Judging Metaphor is Not Enough: Research on Reasonable Metaphor Detection"], "metaphor detection metaphor reasoning": ["Merely Judging Metaphor is Not Enough: Research on Reasonable Metaphor Detection"], "long-range dependencies": ["On the token distance modeling ability of higher RoPE attention dimension"], "long text comprehension": ["On the token distance modeling ability of higher RoPE attention dimension"], "long-range dependencies long text comprehension": ["On the token distance modeling ability of higher RoPE attention dimension"], "long text comprehension language modeling": ["On the token distance modeling ability of higher RoPE attention dimension"], "long-range dependencies long text comprehension language modeling": ["On the token distance modeling ability of higher RoPE attention dimension"], "byzantine attack defense": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "malicious client detection": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "federated learning byzantine attack defense": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "byzantine attack defense malicious client detection": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "malicious client detection natural language processing": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "federated learning byzantine attack defense malicious client detection": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "byzantine attack defense malicious client detection natural language processing": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "malicious client detection natural language processing text classification": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "federated learning byzantine attack defense malicious client detection natural language processing": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "byzantine attack defense malicious client detection natural language processing text classification": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "federated learning byzantine attack defense malicious client detection natural language processing text classification": ["Enhancing Byzantine-Resistant Aggregations with Client Embedding"], "aspect-term sentiment analysis": ["Exploiting Careful Design of SVM Solution for Aspect-term Sentiment Analysis"], "few-shot relation classification": ["Learning to Generate Rules for Realistic Few-Shot Relation Classification: An Encoder-Decoder Approach"], "rule generation": ["Learning to Generate Rules for Realistic Few-Shot Relation Classification: An Encoder-Decoder Approach"], "few-shot relation classification rule generation": ["Learning to Generate Rules for Realistic Few-Shot Relation Classification: An Encoder-Decoder Approach"], "chart understanding visual reasoning": ["Plot Twist: Multimodal Models Don't Comprehend Simple Chart Details"], "visual reasoning question answering": ["Plot Twist: Multimodal Models Don't Comprehend Simple Chart Details"], "chart understanding visual reasoning question answering": ["Plot Twist: Multimodal Models Don't Comprehend Simple Chart Details"], "offensive speech detection": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "generalizable offensive content detection": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "cross-dataset generalization": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "explainable decisions for content moderation": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "offensive speech detection hate speech detection": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "hate speech detection generalizable offensive content detection": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "generalizable offensive content detection cross-dataset generalization": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "cross-dataset generalization explainable decisions for content moderation": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "offensive speech detection hate speech detection generalizable offensive content detection": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "hate speech detection generalizable offensive content detection cross-dataset generalization": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "generalizable offensive content detection cross-dataset generalization explainable decisions for content moderation": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "offensive speech detection hate speech detection generalizable offensive content detection cross-dataset generalization": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "hate speech detection generalizable offensive content detection cross-dataset generalization explainable decisions for content moderation": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "offensive speech detection hate speech detection generalizable offensive content detection cross-dataset generalization explainable decisions for content moderation": ["HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"], "offensive language detection bias mitigation": ["Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases"], "multistep numerical reasoning": ["Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option"], "multistep numerical reasoning tool selection": ["Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option"], "nlidb security": ["SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases"], "data leakage detection": ["SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases"], "nlidb security data leakage detection": ["SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases"], "knowledge injection LLMs": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "LLMs programming": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "programming mathematics": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "mathematics code generation": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "code generation question answering": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "knowledge injection LLMs programming": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "LLMs programming mathematics": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "programming mathematics code generation": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "mathematics code generation question answering": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "knowledge injection LLMs programming mathematics": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "LLMs programming mathematics code generation": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "programming mathematics code generation question answering": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "knowledge injection LLMs programming mathematics code generation": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "LLMs programming mathematics code generation question answering": ["Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection"], "mathematical reasoning calibration": ["Self-Consistency Boosts Calibration for Math Reasoning"], "instruction tuning knowledge distillation": ["Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning"], "medical translation": ["On Creating an English-Thai Code-switched Machine Translation in Medical Domain"], "machine translation code-switching": ["On Creating an English-Thai Code-switched Machine Translation in Medical Domain"], "code-switching medical translation": ["On Creating an English-Thai Code-switched Machine Translation in Medical Domain"], "machine translation code-switching medical translation": ["On Creating an English-Thai Code-switched Machine Translation in Medical Domain"], "cognitive dynamics assessment": ["CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models"], "ethical evaluation": ["Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "toxicity detection LLMs  evaluation": ["Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "LLMs  evaluation bias mitigation": ["Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "bias mitigation ethical evaluation": ["Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "toxicity detection LLMs  evaluation bias mitigation": ["Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "LLMs  evaluation bias mitigation ethical evaluation": ["Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "toxicity detection LLMs  evaluation bias mitigation ethical evaluation": ["Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"], "political discourse analysis": ["Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter"], "twitter analysis": ["Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter"], "political discourse analysis twitter analysis": ["Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter"], "twitter analysis stance detection": ["Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter"], "political discourse analysis twitter analysis stance detection": ["Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter"], "table structure recognition": ["UniTabNet: Bridging Vision and Language Models for Enhanced Table Structure Recognition"], "code-switching evaluation metric": ["PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition"], "speech recognition code-switching evaluation metric": ["PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition"], "multiword expression analysis": ["A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations"], "named entity analysis": ["A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations"], "machine translation error analysis multiword expression analysis": ["A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations"], "multiword expression analysis named entity analysis": ["A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations"], "machine translation error analysis multiword expression analysis named entity analysis": ["A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations"], "multiple choice questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "code understanding": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "true or false questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "language modeling passkey retrieval": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "passkey retrieval sentiment classification": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "reading comprehension text classification": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "text classification multiple choice questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "multiple choice questions math problems": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "math problems code understanding": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "code understanding true or false questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "language modeling passkey retrieval sentiment classification": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "passkey retrieval sentiment classification reading comprehension": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "sentiment classification reading comprehension text classification": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "reading comprehension text classification multiple choice questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "text classification multiple choice questions math problems": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "multiple choice questions math problems code understanding": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "math problems code understanding true or false questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "language modeling passkey retrieval sentiment classification reading comprehension": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "passkey retrieval sentiment classification reading comprehension text classification": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "sentiment classification reading comprehension text classification multiple choice questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "reading comprehension text classification multiple choice questions math problems": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "text classification multiple choice questions math problems code understanding": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "multiple choice questions math problems code understanding true or false questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "language modeling passkey retrieval sentiment classification reading comprehension text classification": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "passkey retrieval sentiment classification reading comprehension text classification multiple choice questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "sentiment classification reading comprehension text classification multiple choice questions math problems": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "reading comprehension text classification multiple choice questions math problems code understanding": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "text classification multiple choice questions math problems code understanding true or false questions": ["SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models"], "api call generation": [" FANTAstic SEquences and Where to Find Them: Faithful and Efficient API Call Generation through State-tracked Constrained Decoding and Reranking "], "geometric reasoning": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "self-correction": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models", "E2CL: Exploration-based Error Correction Learning for Embodied Agents", "LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "role specialization": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "geometric reasoning problem-solving": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "problem-solving tool usage": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "tool usage spatial reasoning": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "spatial reasoning instruction following": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "instruction following self-correction": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "self-correction collaboration": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "collaboration role specialization": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "geometric reasoning problem-solving tool usage": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "problem-solving tool usage spatial reasoning": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "tool usage spatial reasoning instruction following": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "spatial reasoning instruction following self-correction": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "instruction following self-correction collaboration": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "self-correction collaboration role specialization": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "geometric reasoning problem-solving tool usage spatial reasoning": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "problem-solving tool usage spatial reasoning instruction following": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "tool usage spatial reasoning instruction following self-correction": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "spatial reasoning instruction following self-correction collaboration": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "instruction following self-correction collaboration role specialization": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "geometric reasoning problem-solving tool usage spatial reasoning instruction following": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "problem-solving tool usage spatial reasoning instruction following self-correction": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "tool usage spatial reasoning instruction following self-correction collaboration": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "spatial reasoning instruction following self-correction collaboration role specialization": ["Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"], "arc-c": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "recognizing textual entailment": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "corpus of linguistic acceptability": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "siqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "oqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "arc-c recognizing textual entailment": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "recognizing textual entailment corpus of linguistic acceptability": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "corpus of linguistic acceptability scienceqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "openbookqa winogrande": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "winogrande hellaswag": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "hellaswag siqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "siqa oqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "arc-c recognizing textual entailment corpus of linguistic acceptability": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "recognizing textual entailment corpus of linguistic acceptability scienceqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "corpus of linguistic acceptability scienceqa commonsenseqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "commonsenseqa openbookqa winogrande": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "openbookqa winogrande hellaswag": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "winogrande hellaswag siqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "hellaswag siqa oqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "arc-c recognizing textual entailment corpus of linguistic acceptability scienceqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "recognizing textual entailment corpus of linguistic acceptability scienceqa commonsenseqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "corpus of linguistic acceptability scienceqa commonsenseqa openbookqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "scienceqa commonsenseqa openbookqa winogrande": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "commonsenseqa openbookqa winogrande hellaswag": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "openbookqa winogrande hellaswag siqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "winogrande hellaswag siqa oqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "arc-c recognizing textual entailment corpus of linguistic acceptability scienceqa commonsenseqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "recognizing textual entailment corpus of linguistic acceptability scienceqa commonsenseqa openbookqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "corpus of linguistic acceptability scienceqa commonsenseqa openbookqa winogrande": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "scienceqa commonsenseqa openbookqa winogrande hellaswag": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "commonsenseqa openbookqa winogrande hellaswag siqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "openbookqa winogrande hellaswag siqa oqa": ["AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models"], "causal effect identification": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "frontdoor adjustment set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "maximal root set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-forest": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-tree": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-component": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "markov equivalent class": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "d-separation": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "markov blanket": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "causal effect identification backdoor adjustment set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "backdoor adjustment set frontdoor adjustment set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "frontdoor adjustment set maximal root set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "maximal root set c-forest": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-forest c-tree": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-tree c-component": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-component markov equivalent class": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "markov equivalent class d-separation": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "d-separation markov blanket": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "causal effect identification backdoor adjustment set frontdoor adjustment set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "backdoor adjustment set frontdoor adjustment set maximal root set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "frontdoor adjustment set maximal root set c-forest": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "maximal root set c-forest c-tree": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-forest c-tree c-component": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-tree c-component markov equivalent class": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-component markov equivalent class d-separation": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "markov equivalent class d-separation markov blanket": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "causal effect identification backdoor adjustment set frontdoor adjustment set maximal root set": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "backdoor adjustment set frontdoor adjustment set maximal root set c-forest": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "frontdoor adjustment set maximal root set c-forest c-tree": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "maximal root set c-forest c-tree c-component": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-forest c-tree c-component markov equivalent class": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-tree c-component markov equivalent class d-separation": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-component markov equivalent class d-separation markov blanket": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "causal effect identification backdoor adjustment set frontdoor adjustment set maximal root set c-forest": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "backdoor adjustment set frontdoor adjustment set maximal root set c-forest c-tree": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "frontdoor adjustment set maximal root set c-forest c-tree c-component": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "maximal root set c-forest c-tree c-component markov equivalent class": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-forest c-tree c-component markov equivalent class d-separation": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "c-tree c-component markov equivalent class d-separation markov blanket": ["CLEAR: Can Language Models Really Understand Causal Graphs?"], "generative language models": ["PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning"], "instruction-following knowledge distillation": ["PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning"], "knowledge distillation generative language models": ["PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning"], "generative language models model compression": ["PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning"], "instruction-following knowledge distillation generative language models": ["PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning"], "knowledge distillation generative language models model compression": ["PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning"], "instruction-following knowledge distillation generative language models model compression": ["PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning"], "video metaphor captioning": ["Unveiling the Invisible: Captioning Videos with Metaphors"], "winogrande answer generation": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande question modification object": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "qasc topic word to generate related fact": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winowhy reason plausibility detection": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "snli classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli entailment classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli contradiction classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "gap classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "squad2.0: answerable unanswerable question classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "inverse causal relationship": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande answer generation winogrande question modification object": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande question modification object qasc topic word to generate related fact": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "qasc topic word to generate related fact winowhy reason plausibility detection": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winowhy reason plausibility detection snli classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "snli classification mnli entailment classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli entailment classification mnli contradiction classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli contradiction classification gap classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "gap classification squad2.0: answerable unanswerable question classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "squad2.0: answerable unanswerable question classification inverse causal relationship": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande answer generation winogrande question modification object qasc topic word to generate related fact": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande question modification object qasc topic word to generate related fact winowhy reason plausibility detection": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "qasc topic word to generate related fact winowhy reason plausibility detection snli classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winowhy reason plausibility detection snli classification mnli entailment classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "snli classification mnli entailment classification mnli contradiction classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli entailment classification mnli contradiction classification gap classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli contradiction classification gap classification squad2.0: answerable unanswerable question classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "gap classification squad2.0: answerable unanswerable question classification inverse causal relationship": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande answer generation winogrande question modification object qasc topic word to generate related fact winowhy reason plausibility detection": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande question modification object qasc topic word to generate related fact winowhy reason plausibility detection snli classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "qasc topic word to generate related fact winowhy reason plausibility detection snli classification mnli entailment classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winowhy reason plausibility detection snli classification mnli entailment classification mnli contradiction classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "snli classification mnli entailment classification mnli contradiction classification gap classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli entailment classification mnli contradiction classification gap classification squad2.0: answerable unanswerable question classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli contradiction classification gap classification squad2.0: answerable unanswerable question classification inverse causal relationship": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande answer generation winogrande question modification object qasc topic word to generate related fact winowhy reason plausibility detection snli classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winogrande question modification object qasc topic word to generate related fact winowhy reason plausibility detection snli classification mnli entailment classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "qasc topic word to generate related fact winowhy reason plausibility detection snli classification mnli entailment classification mnli contradiction classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "winowhy reason plausibility detection snli classification mnli entailment classification mnli contradiction classification gap classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "snli classification mnli entailment classification mnli contradiction classification gap classification squad2.0: answerable unanswerable question classification": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "mnli entailment classification mnli contradiction classification gap classification squad2.0: answerable unanswerable question classification inverse causal relationship": ["How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?"], "ripple effect mitigation": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "knowledge editing ripple effect mitigation": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "ripple effect mitigation multi-hop question answering": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "multi-hop question answering in-context learning": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "in-context learning chain-of-thought reasoning": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "knowledge editing ripple effect mitigation multi-hop question answering": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "ripple effect mitigation multi-hop question answering in-context learning": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "multi-hop question answering in-context learning chain-of-thought reasoning": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "knowledge editing ripple effect mitigation multi-hop question answering in-context learning": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "ripple effect mitigation multi-hop question answering in-context learning chain-of-thought reasoning": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "knowledge editing ripple effect mitigation multi-hop question answering in-context learning chain-of-thought reasoning": ["RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning"], "machine-generated text detection": ["Authorship Obfuscation in Multilingual Machine-Generated Text Detection", "Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection", "Detecting Machine-Generated Long-Form Content with Latent-Space Variables"], "machine-generated text detection authorship obfuscation": ["Authorship Obfuscation in Multilingual Machine-Generated Text Detection"], "authorship obfuscation adversarial robustness": ["Authorship Obfuscation in Multilingual Machine-Generated Text Detection"], "machine-generated text detection authorship obfuscation adversarial robustness": ["Authorship Obfuscation in Multilingual Machine-Generated Text Detection"], "citation prediction": ["Comparing Edge-based and Node-based Methods on a Citation Prediction Task"], "entailment classification": ["DADEE: Unsupervised Domain Adaptation in Early Exit PLMS"], "sentiment analysis entailment classification": ["DADEE: Unsupervised Domain Adaptation in Early Exit PLMS"], "entailment classification natural language inference": ["DADEE: Unsupervised Domain Adaptation in Early Exit PLMS"], "sentiment analysis entailment classification natural language inference": ["DADEE: Unsupervised Domain Adaptation in Early Exit PLMS"], "model pruning LLMs": ["LaCo: Large Language Model Pruning via Layer Collapse"], "discourse parsing link prediction": ["Llamipa: An Incremental Discourse Parser"], "link prediction relation prediction": ["Llamipa: An Incremental Discourse Parser"], "discourse parsing link prediction relation prediction": ["Llamipa: An Incremental Discourse Parser"], "language to action": ["Nebula: A Discourse-Aware Minecraft Builder"], "instruction execution": ["Nebula: A Discourse-Aware Minecraft Builder"], "dialogue understanding": ["Nebula: A Discourse-Aware Minecraft Builder", "Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?"], "shape construction": ["Nebula: A Discourse-Aware Minecraft Builder"], "location description": ["Nebula: A Discourse-Aware Minecraft Builder"], "language to action instruction execution": ["Nebula: A Discourse-Aware Minecraft Builder"], "instruction execution dialogue understanding": ["Nebula: A Discourse-Aware Minecraft Builder"], "dialogue understanding shape construction": ["Nebula: A Discourse-Aware Minecraft Builder"], "shape construction location description": ["Nebula: A Discourse-Aware Minecraft Builder"], "language to action instruction execution dialogue understanding": ["Nebula: A Discourse-Aware Minecraft Builder"], "instruction execution dialogue understanding shape construction": ["Nebula: A Discourse-Aware Minecraft Builder"], "dialogue understanding shape construction location description": ["Nebula: A Discourse-Aware Minecraft Builder"], "language to action instruction execution dialogue understanding shape construction": ["Nebula: A Discourse-Aware Minecraft Builder"], "instruction execution dialogue understanding shape construction location description": ["Nebula: A Discourse-Aware Minecraft Builder"], "language to action instruction execution dialogue understanding shape construction location description": ["Nebula: A Discourse-Aware Minecraft Builder"], "biomedical language models": ["Improving Referring Ability for Biomedical Language Models"], "intra-sample referring ability": ["Improving Referring Ability for Biomedical Language Models"], "inter-sample referring ability": ["Improving Referring Ability for Biomedical Language Models"], "continual pre-training biomedical language models": ["Improving Referring Ability for Biomedical Language Models"], "biomedical language models intra-sample referring ability": ["Improving Referring Ability for Biomedical Language Models"], "intra-sample referring ability inter-sample referring ability": ["Improving Referring Ability for Biomedical Language Models"], "continual pre-training biomedical language models intra-sample referring ability": ["Improving Referring Ability for Biomedical Language Models"], "biomedical language models intra-sample referring ability inter-sample referring ability": ["Improving Referring Ability for Biomedical Language Models"], "continual pre-training biomedical language models intra-sample referring ability inter-sample referring ability": ["Improving Referring Ability for Biomedical Language Models"], "document segmentation": ["LumberChunker: Long-Form Narrative Document Segmentation"], "document segmentation RAG": ["LumberChunker: Long-Form Narrative Document Segmentation"], "RAG question answering": ["LumberChunker: Long-Form Narrative Document Segmentation"], "document segmentation RAG question answering": ["LumberChunker: Long-Form Narrative Document Segmentation"], "derivation generation": ["Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions"], "continual finetuning": ["Unlocking Continual Learning Abilities in Language Models"], "continual learning continual finetuning": ["Unlocking Continual Learning Abilities in Language Models"], "continual finetuning continual pre-training": ["Unlocking Continual Learning Abilities in Language Models"], "continual learning continual finetuning continual pre-training": ["Unlocking Continual Learning Abilities in Language Models"], "scientific rigour analysis": ["On the Rigour of Scientific Writing: Criteria, Analysis, and Insights"], "rigour criteria identification": ["On the Rigour of Scientific Writing: Criteria, Analysis, and Insights"], "scientific writing assessment": ["On the Rigour of Scientific Writing: Criteria, Analysis, and Insights"], "scientific rigour analysis rigour criteria identification": ["On the Rigour of Scientific Writing: Criteria, Analysis, and Insights"], "rigour criteria identification scientific writing assessment": ["On the Rigour of Scientific Writing: Criteria, Analysis, and Insights"], "scientific rigour analysis rigour criteria identification scientific writing assessment": ["On the Rigour of Scientific Writing: Criteria, Analysis, and Insights"], "multimedia event extraction": ["MMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling"], "event argument extraction multimedia event extraction": ["MMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling"], "iterative preference learning": ["Not All Preference Pairs Are Created Equal: A Recipe for Annotation-Efficient Iterative Preference Learning"], "annotation efficiency": ["Not All Preference Pairs Are Created Equal: A Recipe for Annotation-Efficient Iterative Preference Learning"], "iterative preference learning annotation efficiency": ["Not All Preference Pairs Are Created Equal: A Recipe for Annotation-Efficient Iterative Preference Learning"], "cross-lingual phrase retrieval": ["Cross-lingual Contextualized Phrase Retrieval"], "cross-lingual phrase retrieval machine translation": ["Cross-lingual Contextualized Phrase Retrieval"], "long video understanding": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "spatial-temporal reasoning": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "long video understanding question answering": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "question answering spatial-temporal reasoning": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "spatial-temporal reasoning zero-shot learning": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "long video understanding question answering spatial-temporal reasoning": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "question answering spatial-temporal reasoning zero-shot learning": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "long video understanding question answering spatial-temporal reasoning zero-shot learning": ["VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs"], "context sensitivity analysis": ["Efficiently Computing Susceptibility to Context in Language Models"], "language model evaluation context sensitivity analysis": ["Efficiently Computing Susceptibility to Context in Language Models"], "esg sentence extraction": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "esg sentence classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "multiclass classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "esg sentence extraction esg sentence classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "esg sentence classification multiclass classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "multiclass classification binary classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "esg sentence extraction esg sentence classification multiclass classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "esg sentence classification multiclass classification binary classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "esg sentence extraction esg sentence classification multiclass classification binary classification": ["ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases"], "arithmetic problem solving": ["Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information"], "commonsense reasoning arithmetic problem solving": ["Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information"], "mathematical reasoning commonsense reasoning arithmetic problem solving": ["Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information"], "meme summarization": ["Hope 'The Paragraph Guy' explains the rest : Introducing MeSum, the Meme Summarizer"], "multimodal meme understanding": ["Hope 'The Paragraph Guy' explains the rest : Introducing MeSum, the Meme Summarizer"], "meme summarization multimodal meme understanding": ["Hope 'The Paragraph Guy' explains the rest : Introducing MeSum, the Meme Summarizer"], "first-order logic translation": ["Learning Semantic Structure through First-Order-Logic Translation"], "question answering first-order logic translation": ["Learning Semantic Structure through First-Order-Logic Translation"], "heuristic learning": ["A Training Data Recipe to Accelerate A* Search with Large Language Models\\"], "coreset selection\\": ["A Training Data Recipe to Accelerate A* Search with Large Language Models\\"], "heuristic learning coreset selection\\": ["A Training Data Recipe to Accelerate A* Search with Large Language Models\\"], "analogical reasoning": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "ai evaluation": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "analogical reasoning problem-solving": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "problem-solving multiple-choice question generation": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "multiple-choice question generation ai evaluation": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "analogical reasoning problem-solving multiple-choice question generation": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "problem-solving multiple-choice question generation ai evaluation": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "analogical reasoning problem-solving multiple-choice question generation ai evaluation": ["From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions"], "meeting summarization": ["What's under the hood: Investigating Automatic Metrics on Meeting Summarization"], "automatic metric evaluation": ["What's under the hood: Investigating Automatic Metrics on Meeting Summarization"], "meeting summarization automatic metric evaluation": ["What's under the hood: Investigating Automatic Metrics on Meeting Summarization"], "automatic metric evaluation error analysis": ["What's under the hood: Investigating Automatic Metrics on Meeting Summarization"], "meeting summarization automatic metric evaluation error analysis": ["What's under the hood: Investigating Automatic Metrics on Meeting Summarization"], "self-distillation": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "model stacking": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "natural language understanding cross-lingual transfer": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "cross-lingual transfer self-distillation": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "self-distillation model stacking": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "model stacking machine translation": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "natural language understanding cross-lingual transfer self-distillation": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "cross-lingual transfer self-distillation model stacking": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "self-distillation model stacking machine translation": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "natural language understanding cross-lingual transfer self-distillation model stacking": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "cross-lingual transfer self-distillation model stacking machine translation": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "natural language understanding cross-lingual transfer self-distillation model stacking machine translation": ["Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages"], "rhetoric classification": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "form classification": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "content classification": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays", "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "component extraction": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "rhetoric generation": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "rhetoric classification form classification": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "form classification content classification": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "content classification component extraction": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "component extraction rhetoric generation": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "rhetoric classification form classification content classification": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "form classification content classification component extraction": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "content classification component extraction rhetoric generation": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "rhetoric classification form classification content classification component extraction": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "form classification content classification component extraction rhetoric generation": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "rhetoric classification form classification content classification component extraction rhetoric generation": ["CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays"], "text classification span prediction": ["An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference"], "span prediction summarization": ["An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference"], "summarization natural language inference": ["An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference"], "text classification span prediction summarization": ["An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference"], "span prediction summarization natural language inference": ["An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference"], "text classification span prediction summarization natural language inference": ["An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference"], "weakness detection": ["AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "weakness detection instruction-following": ["AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "instruction-following mathematics": ["AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "mathematics coding": ["AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "weakness detection instruction-following mathematics": ["AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "instruction-following mathematics coding": ["AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "weakness detection instruction-following mathematics coding": ["AUTODETECT: Towards a Unified Framework for Automated Weakness Detection in Large Language Models"], "LLMs  personalization": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "knowledge preservation": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "general alignment": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "LLMs  personalization preference optimization": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "preference optimization knowledge preservation": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "knowledge preservation general alignment": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "LLMs  personalization preference optimization knowledge preservation": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "preference optimization knowledge preservation general alignment": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "LLMs  personalization preference optimization knowledge preservation general alignment": ["BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization"], "cross-lingual proper noun recognition": ["Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models"], "automatic speech recognition cross-lingual proper noun recognition": ["Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models"], "cross-lingual proper noun recognition error correction": ["Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models"], "automatic speech recognition cross-lingual proper noun recognition error correction": ["Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models"], "clinical ner": ["Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting"], "named entity recognition clinical ner": ["Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting"], "clinical ner few-shot learning": ["Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting"], "named entity recognition clinical ner few-shot learning": ["Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting"], "tts": ["STTATTS: Unified Speech-To-Text And Text-To-Speech Model"], "voice conversion": ["STTATTS: Unified Speech-To-Text And Text-To-Speech Model"], "asr tts": ["STTATTS: Unified Speech-To-Text And Text-To-Speech Model"], "tts voice conversion": ["STTATTS: Unified Speech-To-Text And Text-To-Speech Model"], "asr tts voice conversion": ["STTATTS: Unified Speech-To-Text And Text-To-Speech Model"], "uncertainty quantification natural language generation": ["ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees"], "LLM-assisted candidate selection": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "cognitive bias detection": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "attraction effect": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "human resources": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "LLM-assisted candidate selection cognitive bias detection": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "cognitive bias detection attraction effect": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "attraction effect human resources": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "LLM-assisted candidate selection cognitive bias detection attraction effect": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "cognitive bias detection attraction effect human resources": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "LLM-assisted candidate selection cognitive bias detection attraction effect human resources": ["Irrelevant Alternatives Bias Large Language Model Hiring Decisions"], "patronizing and condescending language detection": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "implicit toxicity detection": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "bilingual model development": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "patronizing and condescending language detection implicit toxicity detection": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "implicit toxicity detection bilingual model development": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "bilingual model development bias detection": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "patronizing and condescending language detection implicit toxicity detection bilingual model development": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "implicit toxicity detection bilingual model development bias detection": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "patronizing and condescending language detection implicit toxicity detection bilingual model development bias detection": ["PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"], "trustworthiness": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "legal": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "reasoning trustworthiness": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "trustworthiness legal": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "legal medical question answering": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "reasoning trustworthiness legal": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "trustworthiness legal medical question answering": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "reasoning trustworthiness legal medical question answering": ["MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"], "argument component classification": ["CEAMC: Corpus and Empirical Study of Argument Analysis in Education via LLMs"], "instruction augmentation": ["Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "instruction augmentation code completion": ["Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "code completion mathematics": ["Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "mathematics commonsense reasoning": ["Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "instruction augmentation code completion mathematics": ["Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "code completion mathematics commonsense reasoning": ["Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "instruction augmentation code completion mathematics commonsense reasoning": ["Ada-Instruct: Adapting Instruction Generators for Complex Reasoning"], "non-factoid question answering evaluation": ["LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs"], "multilingual math reasoning": ["Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations"], "toxic language detection": ["SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists"], "sentiment analysis toxic language detection": ["SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists"], "story/recipe generation": ["LongForm: Effective Instruction Tuning with Reverse Instructions"], "text generation instruction following": ["LongForm: Effective Instruction Tuning with Reverse Instructions", "Achieving Stronger Generation via Simple Contrastive Tuning"], "instruction following story/recipe generation": ["LongForm: Effective Instruction Tuning with Reverse Instructions"], "story/recipe generation long-form question answering": ["LongForm: Effective Instruction Tuning with Reverse Instructions"], "text generation instruction following story/recipe generation": ["LongForm: Effective Instruction Tuning with Reverse Instructions"], "instruction following story/recipe generation long-form question answering": ["LongForm: Effective Instruction Tuning with Reverse Instructions"], "text generation instruction following story/recipe generation long-form question answering": ["LongForm: Effective Instruction Tuning with Reverse Instructions"], "graph counterfactual explanation": ["Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction"], "molecular property prediction graph counterfactual explanation": ["Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction"], "knowledge utilization": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "memorization": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "comprehension and application": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "creation": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "individual evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "group evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "trustworthy LLMs": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge utilization knowledge evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge evolution memorization": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "memorization comprehension and application": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "comprehension and application creation": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "creation individual evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "individual evolution group evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "group evolution trustworthy LLMs": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge utilization knowledge evolution memorization": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge evolution memorization comprehension and application": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "memorization comprehension and application creation": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "comprehension and application creation individual evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "creation individual evolution group evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "individual evolution group evolution trustworthy LLMs": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge utilization knowledge evolution memorization comprehension and application": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge evolution memorization comprehension and application creation": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "memorization comprehension and application creation individual evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "comprehension and application creation individual evolution group evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "creation individual evolution group evolution trustworthy LLMs": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge utilization knowledge evolution memorization comprehension and application creation": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "knowledge evolution memorization comprehension and application creation individual evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "memorization comprehension and application creation individual evolution group evolution": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "comprehension and application creation individual evolution group evolution trustworthy LLMs": ["Knowledge Mechanisms in Large Language Models: A Survey and Perspective"], "synthetic retrieval": ["LONGHEADS: Multi-Head Attention is Secretly a Long Context Processor"], "long context benchmark": ["LONGHEADS: Multi-Head Attention is Secretly a Long Context Processor"], "language modeling synthetic retrieval": ["LONGHEADS: Multi-Head Attention is Secretly a Long Context Processor"], "synthetic retrieval long context benchmark": ["LONGHEADS: Multi-Head Attention is Secretly a Long Context Processor"], "language modeling synthetic retrieval long context benchmark": ["LONGHEADS: Multi-Head Attention is Secretly a Long Context Processor"], "linguistic feature extraction": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "motivational interviewing  response type classification": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "text complexity measurement": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "templated utterance detection": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "natural language processing linguistic feature extraction": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "linguistic feature extraction sentiment analysis": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "sentiment analysis motivational interviewing  response type classification": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "motivational interviewing  response type classification text complexity measurement": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "text complexity measurement templated utterance detection": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "natural language processing linguistic feature extraction sentiment analysis": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "linguistic feature extraction sentiment analysis motivational interviewing  response type classification": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "sentiment analysis motivational interviewing  response type classification text complexity measurement": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "motivational interviewing  response type classification text complexity measurement templated utterance detection": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "natural language processing linguistic feature extraction sentiment analysis motivational interviewing  response type classification": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "linguistic feature extraction sentiment analysis motivational interviewing  response type classification text complexity measurement": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "sentiment analysis motivational interviewing  response type classification text complexity measurement templated utterance detection": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "natural language processing linguistic feature extraction sentiment analysis motivational interviewing  response type classification text complexity measurement": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "linguistic feature extraction sentiment analysis motivational interviewing  response type classification text complexity measurement templated utterance detection": ["Crisis counselor language and perceived genuine concern in crisis conversations"], "sentence simplification": ["Edit-Constrained Decoding for Sentence Simplification", "Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "belief generation": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "annotation generation": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "generation toxicity detection": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "toxicity detection stigma detection": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "stigma detection belief generation": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "annotation generation toxicity detection": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "generation toxicity detection stigma detection": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "toxicity detection stigma detection belief generation": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "annotation generation toxicity detection stigma detection": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "generation toxicity detection stigma detection belief generation": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "annotation generation toxicity detection stigma detection belief generation": ["Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas"], "model variation detection": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "model developer detection": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "machine-generated text detection authorship attribution": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "authorship attribution model variation detection": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "model variation detection model developer detection": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "machine-generated text detection authorship attribution model variation detection": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "authorship attribution model variation detection model developer detection": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "machine-generated text detection authorship attribution model variation detection model developer detection": ["Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection"], "sst-2 mrpc": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models", "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "qqp mnli": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "rte glue": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "sst-2 mrpc qqp": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "mrpc qqp mnli": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "qqp mnli qnli": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "qnli rte glue": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "sst-2 mrpc qqp mnli": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "mrpc qqp mnli qnli": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "qqp mnli qnli rte": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "mnli qnli rte glue": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "sst-2 mrpc qqp mnli qnli": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "mrpc qqp mnli qnli rte": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "qqp mnli qnli rte glue": ["Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models"], "LLM detection text classification": ["On the Generalization of Training-based ChatGPT Detection Methods"], "synthetic text generation": ["Private prediction for large-scale synthetic text generation"], "structured data generation": ["Private prediction for large-scale synthetic text generation"], "synthetic text generation differential privacy": ["Private prediction for large-scale synthetic text generation"], "differential privacy in-context learning": ["Private prediction for large-scale synthetic text generation"], "fine-tuning structured data generation": ["Private prediction for large-scale synthetic text generation"], "synthetic text generation differential privacy in-context learning": ["Private prediction for large-scale synthetic text generation"], "differential privacy in-context learning fine-tuning": ["Private prediction for large-scale synthetic text generation"], "in-context learning fine-tuning structured data generation": ["Private prediction for large-scale synthetic text generation"], "synthetic text generation differential privacy in-context learning fine-tuning": ["Private prediction for large-scale synthetic text generation"], "differential privacy in-context learning fine-tuning structured data generation": ["Private prediction for large-scale synthetic text generation"], "synthetic text generation differential privacy in-context learning fine-tuning structured data generation": ["Private prediction for large-scale synthetic text generation"], "abuse detection": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "transliteration": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sentiment analysis abuse detection": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "abuse detection sarcasm detection": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sarcasm detection fake news detection": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "fake news detection topic classification": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "topic classification part-of-speech tagging": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "part-of-speech tagging named-entity recognition": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "named-entity recognition question answering": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "summarization paraphrasing": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "paraphrasing transliteration": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "transliteration translation": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "translation ai assistant": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sentiment analysis abuse detection sarcasm detection": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "abuse detection sarcasm detection fake news detection": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sarcasm detection fake news detection topic classification": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "fake news detection topic classification part-of-speech tagging": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "topic classification part-of-speech tagging named-entity recognition": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "part-of-speech tagging named-entity recognition question answering": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "named-entity recognition question answering summarization": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "question answering summarization paraphrasing": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "summarization paraphrasing transliteration": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "paraphrasing transliteration translation": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "transliteration translation ai assistant": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sentiment analysis abuse detection sarcasm detection fake news detection": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "abuse detection sarcasm detection fake news detection topic classification": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sarcasm detection fake news detection topic classification part-of-speech tagging": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "fake news detection topic classification part-of-speech tagging named-entity recognition": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "topic classification part-of-speech tagging named-entity recognition question answering": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "part-of-speech tagging named-entity recognition question answering summarization": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "named-entity recognition question answering summarization paraphrasing": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "question answering summarization paraphrasing transliteration": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "summarization paraphrasing transliteration translation": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "paraphrasing transliteration translation ai assistant": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sentiment analysis abuse detection sarcasm detection fake news detection topic classification": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "abuse detection sarcasm detection fake news detection topic classification part-of-speech tagging": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "sarcasm detection fake news detection topic classification part-of-speech tagging named-entity recognition": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "fake news detection topic classification part-of-speech tagging named-entity recognition question answering": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "topic classification part-of-speech tagging named-entity recognition question answering summarization": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "part-of-speech tagging named-entity recognition question answering summarization paraphrasing": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "named-entity recognition question answering summarization paraphrasing transliteration": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "question answering summarization paraphrasing transliteration translation": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "summarization paraphrasing transliteration translation ai assistant": ["Generalists vs. Specialists: Evaluating Large Language Models for Urdu"], "alignment labeling": ["Improving Multi-Agent Debate with Sparse Communication Topology"], "reasoning factuality": ["Improving Multi-Agent Debate with Sparse Communication Topology"], "factuality multimodal reasoning": ["Improving Multi-Agent Debate with Sparse Communication Topology"], "multimodal reasoning alignment labeling": ["Improving Multi-Agent Debate with Sparse Communication Topology"], "reasoning factuality multimodal reasoning": ["Improving Multi-Agent Debate with Sparse Communication Topology"], "factuality multimodal reasoning alignment labeling": ["Improving Multi-Agent Debate with Sparse Communication Topology"], "reasoning factuality multimodal reasoning alignment labeling": ["Improving Multi-Agent Debate with Sparse Communication Topology"], "evidence retrieval": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "multi-stage reranking": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "fact verification evidence retrieval": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "evidence retrieval multi-stage reranking": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "multi-stage reranking open-domain question answering": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "fact verification evidence retrieval multi-stage reranking": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "evidence retrieval multi-stage reranking open-domain question answering": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "fact verification evidence retrieval multi-stage reranking open-domain question answering": ["Evidence Retrieval for Fact Verification using Multi-stage Reranking"], "code generation verification": ["Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision"], "math problem solving code generation verification": ["Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision"], "language understanding commonsense reasoning": ["MUSCLE: A Model Update Strategy for Compatible LLM Evolution"], "math reasoning dialogue summarization": ["MUSCLE: A Model Update Strategy for Compatible LLM Evolution"], "language understanding commonsense reasoning math reasoning": ["MUSCLE: A Model Update Strategy for Compatible LLM Evolution"], "commonsense reasoning math reasoning dialogue summarization": ["MUSCLE: A Model Update Strategy for Compatible LLM Evolution"], "language understanding commonsense reasoning math reasoning dialogue summarization": ["MUSCLE: A Model Update Strategy for Compatible LLM Evolution"], "event-keyed summarization": ["Event-Keyed Summarization"], "controllable summarization": ["Event-Keyed Summarization"], "event-keyed summarization summarization": ["Event-Keyed Summarization"], "summarization event extraction": ["Event-Keyed Summarization"], "event extraction controllable summarization": ["Event-Keyed Summarization"], "event-keyed summarization summarization event extraction": ["Event-Keyed Summarization"], "summarization event extraction controllable summarization": ["Event-Keyed Summarization"], "event-keyed summarization summarization event extraction controllable summarization": ["Event-Keyed Summarization"], "multiple-choice question-and-answer": ["The Effect of Sampling Temperature on Problem Solving in Large Language Models"], "multiple-choice question-and-answer problem-solving": ["The Effect of Sampling Temperature on Problem Solving in Large Language Models"], "rhetorical role labeling": ["HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents"], "market comment generation": ["Demonstration Selection Strategies for Numerical Time Series Data-to-Text"], "line graph-to-text": ["Demonstration Selection Strategies for Numerical Time Series Data-to-Text"], "market comment generation line graph-to-text": ["Demonstration Selection Strategies for Numerical Time Series Data-to-Text"], "sentence embedding evaluation": ["ALIGN-SIM: A Task-Free Test Bed for Evaluating and Interpreting Sentence Embeddings through Semantic Similarity Alignment"], "parameter-efficient fine-tuning glue": ["BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models"], "parameter-efficient fine-tuning glue superglue": ["BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models"], "reasoning question answering": ["In-Context Learning with Iterative Demonstration Selection"], "question answering topic classification": ["In-Context Learning with Iterative Demonstration Selection"], "reasoning question answering topic classification": ["In-Context Learning with Iterative Demonstration Selection"], "nlp explainability": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "task analysis": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "dataset evaluation": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "nlp explainability human-ai collaboration": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "human-ai collaboration decision-making": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "decision-making task analysis": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "task analysis dataset evaluation": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "nlp explainability human-ai collaboration decision-making": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "human-ai collaboration decision-making task analysis": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "decision-making task analysis dataset evaluation": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "nlp explainability human-ai collaboration decision-making task analysis": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "human-ai collaboration decision-making task analysis dataset evaluation": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "nlp explainability human-ai collaboration decision-making task analysis dataset evaluation": ["On Evaluating Explanation Utility for Human-AI Decision Making in NLP"], "hierarchical topic modeling": ["Unsupervised Hierarchical Topic Modeling via Anchor Word Clustering and Path Guidance"], "topic modeling hierarchical topic modeling": ["Unsupervised Hierarchical Topic Modeling via Anchor Word Clustering and Path Guidance"], "embedding stealing detection": ["GuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack"], "watermarking embedding stealing detection": ["GuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack"], "model evaluation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs", "CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "lazy learning mitigation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "visual question answering multimodal learning": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "multimodal learning model evaluation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "model evaluation error analysis": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "error analysis lazy learning mitigation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "visual question answering multimodal learning model evaluation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "multimodal learning model evaluation error analysis": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "model evaluation error analysis lazy learning mitigation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "visual question answering multimodal learning model evaluation error analysis": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "multimodal learning model evaluation error analysis lazy learning mitigation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "visual question answering multimodal learning model evaluation error analysis lazy learning mitigation": ["Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs"], "intent discovery": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery", "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "ood intent discovery": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "open intent discovery": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "intent discovery ood intent discovery": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "ood intent discovery open intent discovery": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "open intent discovery contrastive learning": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "contrastive learning clustering": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "intent discovery ood intent discovery open intent discovery": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "ood intent discovery open intent discovery contrastive learning": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "open intent discovery contrastive learning clustering": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "intent discovery ood intent discovery open intent discovery contrastive learning": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "ood intent discovery open intent discovery contrastive learning clustering": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "intent discovery ood intent discovery open intent discovery contrastive learning clustering": ["Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery"], "commonsense reasoning mMLu": ["RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization"], "mMLu visual instruction tuning": ["RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization"], "commonsense reasoning mMLu visual instruction tuning": ["RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization"], "confusing charge prediction": ["Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration"], "confusing charge prediction legal reasoning": ["Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration"], "key-value pairs retrieval": ["Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell"], "long-context question answering key-value pairs retrieval": ["Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell"], "key-value pairs retrieval multi-document question answering": ["Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell"], "long-context question answering key-value pairs retrieval multi-document question answering": ["Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell"], "embodied environment alignment": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-feedback": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "action prediction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents", "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding", "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft", "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "speculative inference": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "embodied environment alignment error correction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "error correction self-feedback": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-feedback self-correction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-correction task planning": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "task planning action prediction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "action prediction feedback generation": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "feedback generation speculative inference": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "embodied environment alignment error correction self-feedback": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "error correction self-feedback self-correction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-feedback self-correction task planning": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-correction task planning action prediction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "task planning action prediction feedback generation": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "action prediction feedback generation speculative inference": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "embodied environment alignment error correction self-feedback self-correction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "error correction self-feedback self-correction task planning": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-feedback self-correction task planning action prediction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-correction task planning action prediction feedback generation": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "task planning action prediction feedback generation speculative inference": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "embodied environment alignment error correction self-feedback self-correction task planning": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "error correction self-feedback self-correction task planning action prediction": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-feedback self-correction task planning action prediction feedback generation": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "self-correction task planning action prediction feedback generation speculative inference": ["E2CL: Exploration-based Error Correction Learning for Embodied Agents"], "counter-narrative generation": ["Contextualized Graph Representations for Generating Counter-Narratives against Hate Speech"], "temporal knowledge graph forecasting": ["Modeling Historical Relevant and Local Frequency Context for Representation-Based Temporal Knowledge Graph Forecasting"], "aspect sentiment quad prediction": ["An Instruction Tuning-Based Contrastive Learning Framework for Aspect Sentiment Quad Prediction with Implicit Aspects and Opinions", "Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?", "Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis"], "proactive engagement": ["MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "vision-language models proactive engagement": ["MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "proactive engagement question answering": ["MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "question answering human-ai interaction": ["MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "vision-language models proactive engagement question answering": ["MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "proactive engagement question answering human-ai interaction": ["MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "vision-language models proactive engagement question answering human-ai interaction": ["MACAROON: Training Vision-Language Models To Be Your Engaged Partners"], "multi-domain neural machine translation": ["ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation"], "knowledge transfer": ["ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation", "Data-Centric AI in the Age of Large Language Models"], "multi-domain neural machine translation continual learning": ["ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation"], "continual learning knowledge transfer": ["ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation"], "multi-domain neural machine translation continual learning knowledge transfer": ["ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation"], "document embedding": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "topic coherence": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "inference time reduction": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "topic modeling document embedding": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "document embedding topic coherence": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "topic coherence inference time reduction": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "topic modeling document embedding topic coherence": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "document embedding topic coherence inference time reduction": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "topic modeling document embedding topic coherence inference time reduction": ["NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"], "real-world instruction handling": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "model-based evaluation": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "instruction following constraint satisfaction": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "constraint satisfaction real-world instruction handling": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "real-world instruction handling model-based evaluation": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "model-based evaluation self-correction": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "instruction following constraint satisfaction real-world instruction handling": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "constraint satisfaction real-world instruction handling model-based evaluation": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "real-world instruction handling model-based evaluation self-correction": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "instruction following constraint satisfaction real-world instruction handling model-based evaluation": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "constraint satisfaction real-world instruction handling model-based evaluation self-correction": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "instruction following constraint satisfaction real-world instruction handling model-based evaluation self-correction": ["LLM Self-Correction with DECRIM: DECOMPOSE, CRITIQUE, AND REFINE for Enhanced Following of Instructions with Multiple Constraints"], "target aspect sentiment detection": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect category sentiment analysis": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment quad prediction aspect sentiment triplet extraction": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment triplet extraction target aspect sentiment detection": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "target aspect sentiment detection aspect opinion pair extraction": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect opinion pair extraction aspect category sentiment analysis": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment quad prediction aspect sentiment triplet extraction target aspect sentiment detection": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment triplet extraction target aspect sentiment detection aspect opinion pair extraction": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "target aspect sentiment detection aspect opinion pair extraction aspect category sentiment analysis": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment quad prediction aspect sentiment triplet extraction target aspect sentiment detection aspect opinion pair extraction": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment triplet extraction target aspect sentiment detection aspect opinion pair extraction aspect category sentiment analysis": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "aspect sentiment quad prediction aspect sentiment triplet extraction target aspect sentiment detection aspect opinion pair extraction aspect category sentiment analysis": ["Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?"], "fine-grained headline hallucination detection": ["Multilingual Fine-Grained News Headline Hallucination Detection"], "text hierarchy generation": ["PE: A Poincare Explanation Method for Fast Text Hierarchy Generation"], "hierarchical attribution": ["PE: A Poincare Explanation Method for Fast Text Hierarchy Generation"], "feature interaction modeling": ["PE: A Poincare Explanation Method for Fast Text Hierarchy Generation"], "text hierarchy generation hierarchical attribution": ["PE: A Poincare Explanation Method for Fast Text Hierarchy Generation"], "hierarchical attribution feature interaction modeling": ["PE: A Poincare Explanation Method for Fast Text Hierarchy Generation"], "text hierarchy generation hierarchical attribution feature interaction modeling": ["PE: A Poincare Explanation Method for Fast Text Hierarchy Generation"], "mathematical reasoning preference learning": ["Step-level Value Preference Optimization for Mathematical Reasoning"], "preference learning reinforcement learning from human feedback": ["Step-level Value Preference Optimization for Mathematical Reasoning"], "reinforcement learning from human feedback fine-tuning": ["Step-level Value Preference Optimization for Mathematical Reasoning"], "mathematical reasoning preference learning reinforcement learning from human feedback": ["Step-level Value Preference Optimization for Mathematical Reasoning"], "preference learning reinforcement learning from human feedback fine-tuning": ["Step-level Value Preference Optimization for Mathematical Reasoning"], "mathematical reasoning preference learning reinforcement learning from human feedback fine-tuning": ["Step-level Value Preference Optimization for Mathematical Reasoning"], "situational awareness": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "environment perception": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situation comprehension": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "future projection": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "forecast": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situational awareness environment perception": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "environment perception situation comprehension": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situation comprehension future projection": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "future projection evaluation": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "evaluation forecast": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situational awareness environment perception situation comprehension": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "environment perception situation comprehension future projection": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situation comprehension future projection evaluation": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "future projection evaluation forecast": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situational awareness environment perception situation comprehension future projection": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "environment perception situation comprehension future projection evaluation": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situation comprehension future projection evaluation forecast": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "situational awareness environment perception situation comprehension future projection evaluation": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "environment perception situation comprehension future projection evaluation forecast": ["Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis"], "dialogue-to-image retrieval": ["Balancing Visual Context Understanding in Dialogue for Image Retrieval", "STARK: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge"], "language model": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "language model factual knowledge": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "factual knowledge hallucination analysis": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "hallucination analysis hallucination mitigation": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "hallucination mitigation open-domain question answering": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "language model factual knowledge hallucination analysis": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "factual knowledge hallucination analysis hallucination mitigation": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "hallucination analysis hallucination mitigation open-domain question answering": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "language model factual knowledge hallucination analysis hallucination mitigation": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "factual knowledge hallucination analysis hallucination mitigation open-domain question answering": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "language model factual knowledge hallucination analysis hallucination mitigation open-domain question answering": ["Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations"], "fairness evaluation": ["A Study of Implicit Ranking Unfairness in Large Language Models", "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "ranking fairness evaluation": ["A Study of Implicit Ranking Unfairness in Large Language Models"], "fairness evaluation data augmentation": ["A Study of Implicit Ranking Unfairness in Large Language Models"], "ranking fairness evaluation data augmentation": ["A Study of Implicit Ranking Unfairness in Large Language Models"], "multilingual LLMs evaluation": ["Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models"], "cross-lingual transferability": ["Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models"], "language modeling quality": ["Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models"], "multilingual LLMs evaluation cross-lingual transferability": ["Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models"], "cross-lingual transferability language modeling quality": ["Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models"], "multilingual LLMs evaluation cross-lingual transferability language modeling quality": ["Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models"], "theorem retrieval": ["A Semantic Search Engine for Mathlib4"], "formal to informal translation": ["A Semantic Search Engine for Mathlib4"], "semantic search theorem retrieval": ["A Semantic Search Engine for Mathlib4"], "theorem retrieval query augmentation": ["A Semantic Search Engine for Mathlib4"], "query augmentation formal to informal translation": ["A Semantic Search Engine for Mathlib4"], "semantic search theorem retrieval query augmentation": ["A Semantic Search Engine for Mathlib4"], "theorem retrieval query augmentation formal to informal translation": ["A Semantic Search Engine for Mathlib4"], "semantic search theorem retrieval query augmentation formal to informal translation": ["A Semantic Search Engine for Mathlib4"], "dynamic benchmarking": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "outdated knowledge detection": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "fact verification knowledge updating": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "knowledge updating dynamic benchmarking": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "dynamic benchmarking temporal reasoning": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "temporal reasoning LLM evaluation": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "LLM evaluation outdated knowledge detection": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "fact verification knowledge updating dynamic benchmarking": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "knowledge updating dynamic benchmarking temporal reasoning": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "dynamic benchmarking temporal reasoning LLM evaluation": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "temporal reasoning LLM evaluation outdated knowledge detection": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "fact verification knowledge updating dynamic benchmarking temporal reasoning": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "knowledge updating dynamic benchmarking temporal reasoning LLM evaluation": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "dynamic benchmarking temporal reasoning LLM evaluation outdated knowledge detection": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "fact verification knowledge updating dynamic benchmarking temporal reasoning LLM evaluation": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "knowledge updating dynamic benchmarking temporal reasoning LLM evaluation outdated knowledge detection": ["DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs"], "dialogue policy learning": ["Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "dialogue state tracking dialogue policy learning": ["Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "dialogue policy learning response generation": ["Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "task-oriented dialogue dialogue state tracking dialogue policy learning": ["Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "dialogue state tracking dialogue policy learning response generation": ["Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "task-oriented dialogue dialogue state tracking dialogue policy learning response generation": ["Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue"], "negotiation dialogues": ["Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues"], "norm remediation": ["Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues"], "negotiation dialogues social intelligence": ["Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues"], "social intelligence norm remediation": ["Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues"], "negotiation dialogues social intelligence norm remediation": ["Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues"], "screenwriting": ["HOLLMWOOD: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing"], "entity alignment": ["Advancing Cross-Lingual Entity Alignment with Large Language Models: Tailored Sample Segmentation and Zero-Shot Prompts", "NALA: an Effective and Interpretable Entity Alignment Method"], "unsupervised domain adaptation": ["Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction"], "emotion-cause pair extraction unsupervised domain adaptation": ["Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction"], "question difficulty estimation": ["Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation"], "question difficulty estimation natural language processing": ["Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation"], "natural language processing language understanding": ["Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation"], "question difficulty estimation natural language processing language understanding": ["Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation"], "LLMs alignment": ["Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models without Preference Data", "Better Alignment with Instruction Back-and-Forth Translation"], "reinforcement learning from human feedback LLMs alignment": ["Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models without Preference Data"], "activation scaling": ["Activation Scaling for Steering and Interpreting Language Models"], "model intervention": ["Activation Scaling for Steering and Interpreting Language Models"], "factual recall": ["Activation Scaling for Steering and Interpreting Language Models"], "indirect object identification": ["Activation Scaling for Steering and Interpreting Language Models"], "language model steering mechanistic interpretability": ["Activation Scaling for Steering and Interpreting Language Models"], "mechanistic interpretability activation scaling": ["Activation Scaling for Steering and Interpreting Language Models"], "activation scaling model intervention": ["Activation Scaling for Steering and Interpreting Language Models"], "model intervention factual recall": ["Activation Scaling for Steering and Interpreting Language Models"], "factual recall indirect object identification": ["Activation Scaling for Steering and Interpreting Language Models"], "language model steering mechanistic interpretability activation scaling": ["Activation Scaling for Steering and Interpreting Language Models"], "mechanistic interpretability activation scaling model intervention": ["Activation Scaling for Steering and Interpreting Language Models"], "activation scaling model intervention factual recall": ["Activation Scaling for Steering and Interpreting Language Models"], "model intervention factual recall indirect object identification": ["Activation Scaling for Steering and Interpreting Language Models"], "language model steering mechanistic interpretability activation scaling model intervention": ["Activation Scaling for Steering and Interpreting Language Models"], "mechanistic interpretability activation scaling model intervention factual recall": ["Activation Scaling for Steering and Interpreting Language Models"], "activation scaling model intervention factual recall indirect object identification": ["Activation Scaling for Steering and Interpreting Language Models"], "language model steering mechanistic interpretability activation scaling model intervention factual recall": ["Activation Scaling for Steering and Interpreting Language Models"], "mechanistic interpretability activation scaling model intervention factual recall indirect object identification": ["Activation Scaling for Steering and Interpreting Language Models"], "cross-modal integration of speech and text": ["LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models"], "spoken dialog": ["LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models"], "speech-text translation": ["LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models"], "cross-modal integration of speech and text spoken dialog": ["LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models"], "spoken dialog speech-text translation": ["LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models"], "cross-modal integration of speech and text spoken dialog speech-text translation": ["LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models"], "schema linking": ["DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models"], "sql generation": ["DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models"], "text-to-sql schema linking": ["DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models"], "schema linking sql generation": ["DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models"], "text-to-sql schema linking sql generation": ["DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models"], "semantic text similarity": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity recognition named entity disambiguation": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity disambiguation question answering": ["MedINST: Meta Dataset of Biomedical Instructions"], "question answering relation extraction": ["MedINST: Meta Dataset of Biomedical Instructions"], "relation extraction coreference resolution": ["MedINST: Meta Dataset of Biomedical Instructions"], "coreference resolution textual entailment": ["MedINST: Meta Dataset of Biomedical Instructions"], "textual entailment semantic text similarity": ["MedINST: Meta Dataset of Biomedical Instructions"], "semantic text similarity text classification": ["MedINST: Meta Dataset of Biomedical Instructions"], "text classification event extraction": ["MedINST: Meta Dataset of Biomedical Instructions"], "event extraction translation": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity recognition named entity disambiguation question answering": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity disambiguation question answering relation extraction": ["MedINST: Meta Dataset of Biomedical Instructions"], "question answering relation extraction coreference resolution": ["MedINST: Meta Dataset of Biomedical Instructions"], "relation extraction coreference resolution textual entailment": ["MedINST: Meta Dataset of Biomedical Instructions"], "coreference resolution textual entailment semantic text similarity": ["MedINST: Meta Dataset of Biomedical Instructions"], "textual entailment semantic text similarity text classification": ["MedINST: Meta Dataset of Biomedical Instructions"], "semantic text similarity text classification event extraction": ["MedINST: Meta Dataset of Biomedical Instructions"], "text classification event extraction translation": ["MedINST: Meta Dataset of Biomedical Instructions"], "event extraction translation summarization": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity recognition named entity disambiguation question answering relation extraction": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity disambiguation question answering relation extraction coreference resolution": ["MedINST: Meta Dataset of Biomedical Instructions"], "question answering relation extraction coreference resolution textual entailment": ["MedINST: Meta Dataset of Biomedical Instructions"], "relation extraction coreference resolution textual entailment semantic text similarity": ["MedINST: Meta Dataset of Biomedical Instructions"], "coreference resolution textual entailment semantic text similarity text classification": ["MedINST: Meta Dataset of Biomedical Instructions"], "textual entailment semantic text similarity text classification event extraction": ["MedINST: Meta Dataset of Biomedical Instructions"], "semantic text similarity text classification event extraction translation": ["MedINST: Meta Dataset of Biomedical Instructions"], "text classification event extraction translation summarization": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity recognition named entity disambiguation question answering relation extraction coreference resolution": ["MedINST: Meta Dataset of Biomedical Instructions"], "named entity disambiguation question answering relation extraction coreference resolution textual entailment": ["MedINST: Meta Dataset of Biomedical Instructions"], "question answering relation extraction coreference resolution textual entailment semantic text similarity": ["MedINST: Meta Dataset of Biomedical Instructions"], "relation extraction coreference resolution textual entailment semantic text similarity text classification": ["MedINST: Meta Dataset of Biomedical Instructions"], "coreference resolution textual entailment semantic text similarity text classification event extraction": ["MedINST: Meta Dataset of Biomedical Instructions"], "textual entailment semantic text similarity text classification event extraction translation": ["MedINST: Meta Dataset of Biomedical Instructions"], "semantic text similarity text classification event extraction translation summarization": ["MedINST: Meta Dataset of Biomedical Instructions"], "compositional visual question answering": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "external knowledge-dependent image question answering": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "visual question answering compositional visual question answering": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "compositional visual question answering external knowledge-dependent image question answering": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "external knowledge-dependent image question answering visual grounding": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "visual question answering compositional visual question answering external knowledge-dependent image question answering": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "compositional visual question answering external knowledge-dependent image question answering visual grounding": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "visual question answering compositional visual question answering external knowledge-dependent image question answering visual grounding": ["PropTest: Automatic Property Testing for Improved Visual Programming"], "news topic classification": ["BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers", "TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance", "AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "toxicity detection sentiment classification": ["BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers"], "sentiment classification news topic classification": ["BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers"], "toxicity detection sentiment classification news topic classification": ["BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers"], "chart-to-code generation": ["Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts"], "code template generation": ["Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts"], "chart-to-code generation data visualization": ["Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts"], "data visualization code template generation": ["Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts"], "chart-to-code generation data visualization code template generation": ["Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts"], "multimodal time series prediction": ["Financial Forecasting from Textual and Tabular Time Series"], "financial forecasting": ["Financial Forecasting from Textual and Tabular Time Series"], "earnings surprise prediction": ["Financial Forecasting from Textual and Tabular Time Series"], "multimodal time series prediction financial forecasting": ["Financial Forecasting from Textual and Tabular Time Series"], "financial forecasting earnings surprise prediction": ["Financial Forecasting from Textual and Tabular Time Series"], "multimodal time series prediction financial forecasting earnings surprise prediction": ["Financial Forecasting from Textual and Tabular Time Series"], "visual question answering knowledge-based vqa": ["Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA", "Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective"], "knowledge-based vqa question generation": ["Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA"], "visual question answering knowledge-based vqa question generation": ["Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA"], "ontology completion": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "rule prediction": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "ontology completion rule prediction": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "rule prediction benchmark creation": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "benchmark creation model evaluation": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "ontology completion rule prediction benchmark creation": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "rule prediction benchmark creation model evaluation": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "ontology completion rule prediction benchmark creation model evaluation": ["CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules"], "sentiment transfer": ["Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout"], "topic transfer": ["Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout"], "text style transfer sentiment transfer": ["Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout"], "sentiment transfer topic transfer": ["Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout"], "text style transfer sentiment transfer topic transfer": ["Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout"], "weak-to-strong learning": ["Weak-to-Strong Reasoning"], "reasoning mathematical reasoning": ["Weak-to-Strong Reasoning"], "mathematical reasoning weak-to-strong learning": ["Weak-to-Strong Reasoning"], "reasoning mathematical reasoning weak-to-strong learning": ["Weak-to-Strong Reasoning"], "glue benchmark: sst-2": ["Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation"], "glue benchmark: sst-2 qnli": ["Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation"], "mnli qqp": ["Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation"], "glue benchmark: sst-2 qnli mnli": ["Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation"], "qnli mnli qqp": ["Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation"], "glue benchmark: sst-2 qnli mnli qqp": ["Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation"], "hallucination benchmark generation": ["AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for Vision-Language Models"], "hallucination benchmark generation visual question answering": ["AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for Vision-Language Models"], "on-demand keyphrase generation": ["METAKP: On-Demand Keyphrase Generation"], "goal relevance assessment": ["METAKP: On-Demand Keyphrase Generation"], "keyphrase generation on-demand keyphrase generation": ["METAKP: On-Demand Keyphrase Generation"], "on-demand keyphrase generation goal relevance assessment": ["METAKP: On-Demand Keyphrase Generation"], "keyphrase generation on-demand keyphrase generation goal relevance assessment": ["METAKP: On-Demand Keyphrase Generation"], "public-speaking style transfer": ["PSST: A Benchmark for Evaluation-driven Text Public-Speaking Style Transfer"], "question answering multi-hop reasoning": ["TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation"], "paraphrase": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "open domain dialogue": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "paraphrase question generation": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "question generation open domain dialogue": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "open domain dialogue text simplification": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "paraphrase question generation open domain dialogue": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "question generation open domain dialogue text simplification": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "paraphrase question generation open domain dialogue text simplification": ["Enable Fast Sampling for Seq2Seq Text Diffusion"], "text summarization human preference alignment": ["ALIGNSUM: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference"], "masked-character prediction": ["CHIRON: Rich Character Representations in Long-Form Narratives"], "story analysis": ["CHIRON: Rich Character Representations in Long-Form Narratives"], "character-centricity inference": ["CHIRON: Rich Character Representations in Long-Form Narratives"], "masked-character prediction story analysis": ["CHIRON: Rich Character Representations in Long-Form Narratives"], "story analysis character-centricity inference": ["CHIRON: Rich Character Representations in Long-Form Narratives"], "masked-character prediction story analysis character-centricity inference": ["CHIRON: Rich Character Representations in Long-Form Narratives"], "question answering single-hop qa": ["Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities"], "question answering single-hop qa multi-hop qa": ["Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities"], "infrared image understanding": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "multi-modal LLMs": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "phrase grounding": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "infrared image understanding multi-modal LLMs": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "multi-modal LLMs image-text retrieval": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "image-text retrieval phrase grounding": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "phrase grounding visual question answering": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "image captioning instruction following": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "infrared image understanding multi-modal LLMs image-text retrieval": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "multi-modal LLMs image-text retrieval phrase grounding": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "image-text retrieval phrase grounding visual question answering": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "phrase grounding visual question answering image captioning": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "visual question answering image captioning instruction following": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "infrared image understanding multi-modal LLMs image-text retrieval phrase grounding": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "multi-modal LLMs image-text retrieval phrase grounding visual question answering": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "image-text retrieval phrase grounding visual question answering image captioning": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "phrase grounding visual question answering image captioning instruction following": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "infrared image understanding multi-modal LLMs image-text retrieval phrase grounding visual question answering": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "multi-modal LLMs image-text retrieval phrase grounding visual question answering image captioning": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "image-text retrieval phrase grounding visual question answering image captioning instruction following": ["Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models"], "neural architecture search": ["LPZero: Language Model Zero-cost Proxy Search from Zero"], "language model optimization": ["LPZero: Language Model Zero-cost Proxy Search from Zero"], "neural architecture search language model optimization": ["LPZero: Language Model Zero-cost Proxy Search from Zero"], "language model optimization downstream task performance": ["LPZero: Language Model Zero-cost Proxy Search from Zero"], "neural architecture search language model optimization downstream task performance": ["LPZero: Language Model Zero-cost Proxy Search from Zero"], "phrase similarity identification": ["Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models"], "semantic relatedness estimation": ["Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models"], "contextual phrase understanding": ["Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models"], "phrase similarity identification semantic relatedness estimation": ["Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models"], "semantic relatedness estimation contextual phrase understanding": ["Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models"], "phrase similarity identification semantic relatedness estimation contextual phrase understanding": ["Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models"], "in-context alignment": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "knowledge-based tasks": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "tool-use tasks": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "multi-turn dialogues": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context learning in-context alignment": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context alignment knowledge-based tasks": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "knowledge-based tasks tool-use tasks": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "tool-use tasks multi-turn dialogues": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "multi-turn dialogues instruction following": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context learning in-context alignment knowledge-based tasks": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context alignment knowledge-based tasks tool-use tasks": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "knowledge-based tasks tool-use tasks multi-turn dialogues": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "tool-use tasks multi-turn dialogues instruction following": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context learning in-context alignment knowledge-based tasks tool-use tasks": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context alignment knowledge-based tasks tool-use tasks multi-turn dialogues": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "knowledge-based tasks tool-use tasks multi-turn dialogues instruction following": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context learning in-context alignment knowledge-based tasks tool-use tasks multi-turn dialogues": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "in-context alignment knowledge-based tasks tool-use tasks multi-turn dialogues instruction following": ["How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"], "question duplicate detection": ["Variational Language Concepts for Interpreting Foundation Language Models"], "interpretability paraphrase identification": ["Variational Language Concepts for Interpreting Foundation Language Models"], "paraphrase identification textual entailment": ["Variational Language Concepts for Interpreting Foundation Language Models", "Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity"], "textual entailment semantic textual similarity": ["Variational Language Concepts for Interpreting Foundation Language Models"], "semantic textual similarity question duplicate detection": ["Variational Language Concepts for Interpreting Foundation Language Models"], "interpretability paraphrase identification textual entailment": ["Variational Language Concepts for Interpreting Foundation Language Models"], "paraphrase identification textual entailment semantic textual similarity": ["Variational Language Concepts for Interpreting Foundation Language Models"], "textual entailment semantic textual similarity question duplicate detection": ["Variational Language Concepts for Interpreting Foundation Language Models"], "interpretability paraphrase identification textual entailment semantic textual similarity": ["Variational Language Concepts for Interpreting Foundation Language Models"], "paraphrase identification textual entailment semantic textual similarity question duplicate detection": ["Variational Language Concepts for Interpreting Foundation Language Models"], "interpretability paraphrase identification textual entailment semantic textual similarity question duplicate detection": ["Variational Language Concepts for Interpreting Foundation Language Models"], "panel sequence detection": ["Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga dataset and Its Challenging Tasks"], "author's intention generation": ["Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga dataset and Its Challenging Tasks"], "panel sequence detection author's intention generation": ["Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga dataset and Its Challenging Tasks"], "author's intention generation description generation": ["Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga dataset and Its Challenging Tasks"], "panel sequence detection author's intention generation description generation": ["Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga dataset and Its Challenging Tasks"], "social bias evaluation benchmark": ["TWBias: A Benchmark for Assessing Social Bias in Traditional Chinese Large Language Models through a Taiwan Cultural Lens"], "text classification machine reading comprehension": ["Unlocking the Potential of Model Merging for Low-Resource Languages"], "machine reading comprehension response selection": ["Unlocking the Potential of Model Merging for Low-Resource Languages"], "response selection math reasoning": ["Unlocking the Potential of Model Merging for Low-Resource Languages"], "text classification machine reading comprehension response selection": ["Unlocking the Potential of Model Merging for Low-Resource Languages"], "machine reading comprehension response selection math reasoning": ["Unlocking the Potential of Model Merging for Low-Resource Languages"], "text classification machine reading comprehension response selection math reasoning": ["Unlocking the Potential of Model Merging for Low-Resource Languages"], "query reformulation": ["PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "LLM alignment query reformulation": ["PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "query reformulation harMLessness": ["PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "harMLessness helpfulness": ["PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "LLM alignment query reformulation harMLessness": ["PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "query reformulation harMLessness helpfulness": ["PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "LLM alignment query reformulation harMLessness helpfulness": ["PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness"], "grounding": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "segmentation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "medical report generation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "vqa grounding": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "grounding segmentation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "segmentation classification": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "classification medical report generation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "medical report generation RAG": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "vqa grounding segmentation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "grounding segmentation classification": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "segmentation classification medical report generation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "classification medical report generation RAG": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "vqa grounding segmentation classification": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "grounding segmentation classification medical report generation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "segmentation classification medical report generation RAG": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "vqa grounding segmentation classification medical report generation": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "grounding segmentation classification medical report generation RAG": ["MMedAgent: Learning to Use Medical Tools with Multi-modal Agent"], "temporal knowledge graph reasoning knowledge graph completion": ["SALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning"], "multilingual reasoning chain-of-thought reasoning": ["Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping"], "evaluation of attitudes": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "opinions": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "and values  in LLMs": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "survey and analysis of related research": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "identification of challenges and opportunities": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "evaluation of attitudes opinions": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "opinions and values  in LLMs": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "and values  in LLMs survey and analysis of related research": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "survey and analysis of related research identification of challenges and opportunities": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "evaluation of attitudes opinions and values  in LLMs": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "opinions and values  in LLMs survey and analysis of related research": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "and values  in LLMs survey and analysis of related research identification of challenges and opportunities": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "evaluation of attitudes opinions and values  in LLMs survey and analysis of related research": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "opinions and values  in LLMs survey and analysis of related research identification of challenges and opportunities": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "evaluation of attitudes opinions and values  in LLMs survey and analysis of related research identification of challenges and opportunities": ["The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models"], "low-resource machine translation": ["Low-Resource Machine Translation through the Lens of Personalized Federated Learning"], "argument quality assessment": ["Can Language Models Recognize Convincing Arguments?"], "stance prediction": ["Can Language Models Recognize Convincing Arguments?"], "persuasiveness detection": ["Can Language Models Recognize Convincing Arguments?"], "argument quality assessment stance prediction": ["Can Language Models Recognize Convincing Arguments?"], "stance prediction persuasiveness detection": ["Can Language Models Recognize Convincing Arguments?"], "argument quality assessment stance prediction persuasiveness detection": ["Can Language Models Recognize Convincing Arguments?"], "knowledge exploration": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "scientific literature summarization": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "hierarchical topic organization": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "exploratory search": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "knowledge exploration scientific literature summarization": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "scientific literature summarization hierarchical topic organization": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "hierarchical topic organization exploratory search": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "knowledge exploration scientific literature summarization hierarchical topic organization": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "scientific literature summarization hierarchical topic organization exploratory search": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "knowledge exploration scientific literature summarization hierarchical topic organization exploratory search": ["Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature"], "abstractive proposition segmentation": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "text segmentation": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "abstractive proposition segmentation text segmentation": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "text segmentation few-shot learning": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "few-shot learning domain generalization": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "abstractive proposition segmentation text segmentation few-shot learning": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "text segmentation few-shot learning domain generalization": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "abstractive proposition segmentation text segmentation few-shot learning domain generalization": ["Scalable and Domain-General Abstractive Proposition Segmentation"], "few-shot transfer learning": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "multi-task learning few-shot transfer learning": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "few-shot transfer learning text classification": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "natural language inference semantic textual similarity": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "semantic textual similarity paraphrase detection": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "paraphrase detection coreference resolution": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "coreference resolution question answering": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "question answering word sense disambiguation": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "multi-task learning few-shot transfer learning text classification": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "few-shot transfer learning text classification natural language inference": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "text classification natural language inference semantic textual similarity": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "natural language inference semantic textual similarity paraphrase detection": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "semantic textual similarity paraphrase detection coreference resolution": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "paraphrase detection coreference resolution question answering": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "coreference resolution question answering word sense disambiguation": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "multi-task learning few-shot transfer learning text classification natural language inference": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "few-shot transfer learning text classification natural language inference semantic textual similarity": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "text classification natural language inference semantic textual similarity paraphrase detection": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "natural language inference semantic textual similarity paraphrase detection coreference resolution": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "semantic textual similarity paraphrase detection coreference resolution question answering": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "paraphrase detection coreference resolution question answering word sense disambiguation": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "multi-task learning few-shot transfer learning text classification natural language inference semantic textual similarity": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "few-shot transfer learning text classification natural language inference semantic textual similarity paraphrase detection": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "text classification natural language inference semantic textual similarity paraphrase detection coreference resolution": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "natural language inference semantic textual similarity paraphrase detection coreference resolution question answering": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "semantic textual similarity paraphrase detection coreference resolution question answering word sense disambiguation": ["Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention"], "knowledge filtering": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "invalid reasoning reduction": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "commonsense reasoning knowledge integration": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "knowledge integration knowledge filtering": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "knowledge filtering invalid reasoning reduction": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "commonsense reasoning knowledge integration knowledge filtering": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "knowledge integration knowledge filtering invalid reasoning reduction": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "commonsense reasoning knowledge integration knowledge filtering invalid reasoning reduction": ["LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning"], "rationale alignment diagnosis": ["Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals"], "automated essay scoring rationale alignment diagnosis": ["Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals"], "LLM alignment instruction following": ["TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"], "instruction following conversational ai": ["TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"], "conversational ai preference learning": ["TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"], "LLM alignment instruction following conversational ai": ["TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"], "instruction following conversational ai preference learning": ["TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"], "LLM alignment instruction following conversational ai preference learning": ["TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"], "answer sentence selection": ["Datasets for Multilingual Answer Sentence Selection"], "answer sentence selection question answering": ["Datasets for Multilingual Answer Sentence Selection"], "abstractive text summarization": ["Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization"], "abstractive text summarization active learning": ["Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization"], "supnatinst": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "drop": ["Achieving Stronger Generation via Simple Contrastive Tuning", "LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "instruction following supnatinst": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "supnatinst drop": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "drop alpacaeval": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "text generation instruction following supnatinst": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "instruction following supnatinst drop": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "supnatinst drop alpacaeval": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "text generation instruction following supnatinst drop": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "instruction following supnatinst drop alpacaeval": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "text generation instruction following supnatinst drop alpacaeval": ["Achieving Stronger Generation via Simple Contrastive Tuning"], "geopolitical analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "relationship extraction": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "labeling": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "event prediction dataset creation": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "dataset creation natural language processing": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "natural language processing text analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "text analysis geopolitical analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "geopolitical analysis relationship extraction": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "relationship extraction labeling": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "labeling benchmark": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "event prediction dataset creation natural language processing": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "dataset creation natural language processing text analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "natural language processing text analysis geopolitical analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "text analysis geopolitical analysis relationship extraction": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "geopolitical analysis relationship extraction labeling": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "relationship extraction labeling benchmark": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "event prediction dataset creation natural language processing text analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "dataset creation natural language processing text analysis geopolitical analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "natural language processing text analysis geopolitical analysis relationship extraction": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "text analysis geopolitical analysis relationship extraction labeling": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "geopolitical analysis relationship extraction labeling benchmark": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "event prediction dataset creation natural language processing text analysis geopolitical analysis": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "dataset creation natural language processing text analysis geopolitical analysis relationship extraction": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "natural language processing text analysis geopolitical analysis relationship extraction labeling": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "text analysis geopolitical analysis relationship extraction labeling benchmark": ["Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling"], "evaluation benchmark creation": ["DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models"], "hallucination detection dialogue generation": ["DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models"], "dialogue generation evaluation benchmark creation": ["DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models"], "hallucination detection dialogue generation evaluation benchmark creation": ["DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models"], "document-level simplification": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "grade-specific simplification": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "text simplification document-level simplification": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "document-level simplification grade-specific simplification": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "grade-specific simplification multi-agent collaboration": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "text simplification document-level simplification grade-specific simplification": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "document-level simplification grade-specific simplification multi-agent collaboration": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "text simplification document-level simplification grade-specific simplification multi-agent collaboration": ["ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models"], "out-of-scope intent detection": ["Class Name Guided Out-of-Scope Intent Classification"], "out-of-scope intent detection intent classification": ["Class Name Guided Out-of-Scope Intent Classification"], "benchmark decontamination": ["Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation"], "LLM evaluation benchmark decontamination": ["Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation"], "zero-shot tts": ["MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech"], "cross-lingual tts": ["MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech"], "speech style transfer": ["MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech"], "zero-shot tts cross-lingual tts": ["MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech"], "cross-lingual tts speech style transfer": ["MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech"], "zero-shot tts cross-lingual tts speech style transfer": ["MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech"], "islamic studies": ["ROBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies"], "hadith analysis": ["ROBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies"], "topic extraction islamic studies": ["ROBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies"], "islamic studies hadith analysis": ["ROBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies"], "topic extraction islamic studies hadith analysis": ["ROBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies"], "semantic textual similarity paraphrase identification": ["Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity"], "semantic textual similarity paraphrase identification textual entailment": ["Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity"], "emotion recognition in conversations": ["DetectiveNN: Imitating Human Emotional Reasoning with a Recall-Detect-Predict Framework for Emotion Recognition in Conversations", "PFA-ERC: Psuedo-Future Augmented Dynamic Emotion Recognition in Conversations"], "calibration error evaluation": ["On Diversified Preferences of Large Language Model Alignment"], "reward modeling LLM alignment": ["On Diversified Preferences of Large Language Model Alignment"], "LLM alignment calibration error evaluation": ["On Diversified Preferences of Large Language Model Alignment"], "calibration error evaluation multi-objective optimization": ["On Diversified Preferences of Large Language Model Alignment"], "reward modeling LLM alignment calibration error evaluation": ["On Diversified Preferences of Large Language Model Alignment"], "LLM alignment calibration error evaluation multi-objective optimization": ["On Diversified Preferences of Large Language Model Alignment"], "reward modeling LLM alignment calibration error evaluation multi-objective optimization": ["On Diversified Preferences of Large Language Model Alignment"], "nli": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "text similarity": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "acceptability": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "nli sentiment analysis": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "sentiment analysis text similarity": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "text similarity paraphrase detection": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "paraphrase detection question answering": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "question answering acceptability": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "nli sentiment analysis text similarity": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "sentiment analysis text similarity paraphrase detection": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "text similarity paraphrase detection question answering": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "paraphrase detection question answering acceptability": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "nli sentiment analysis text similarity paraphrase detection": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "sentiment analysis text similarity paraphrase detection question answering": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "text similarity paraphrase detection question answering acceptability": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "nli sentiment analysis text similarity paraphrase detection question answering": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "sentiment analysis text similarity paraphrase detection question answering acceptability": ["LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters"], "generative commonsense reasoning": ["Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning"], "generative commonsense reasoning text generation": ["Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning"], "text generation in-context learning": ["Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning"], "generative commonsense reasoning text generation in-context learning": ["Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning"], "ai-generated code detection": ["CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "code generation watermarking": ["CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "watermarking intellectual property protection": ["CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "intellectual property protection ai-generated code detection": ["CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "code generation watermarking intellectual property protection": ["CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "watermarking intellectual property protection ai-generated code detection": ["CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "code generation watermarking intellectual property protection ai-generated code detection": ["CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"], "fake news detection sentiment analysis": ["StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation"], "fake news detection sentiment analysis natural language inference": ["StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation"], "fake news detection sentiment analysis natural language inference question answering": ["StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation"], "idiom translation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "context-aware translation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "idiom translation context-aware translation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "context-aware translation data generation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "data generation prompt engineering": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "prompt engineering evaluation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "idiom translation context-aware translation data generation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "context-aware translation data generation prompt engineering": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "data generation prompt engineering evaluation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "idiom translation context-aware translation data generation prompt engineering": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "context-aware translation data generation prompt engineering evaluation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "idiom translation context-aware translation data generation prompt engineering evaluation": ["Creative and Context-Aware Translation of East Asian Idioms with GPT-4"], "task assignment": ["Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions"], "bias detection bias mitigation": ["Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "Cognitive Bias in Decision-Making with LLMs", "Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "bias mitigation multi-agent interaction": ["Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions"], "multi-agent interaction task assignment": ["Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions"], "bias detection bias mitigation multi-agent interaction": ["Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions"], "bias mitigation multi-agent interaction task assignment": ["Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions"], "bias detection bias mitigation multi-agent interaction task assignment": ["Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions"], "causal discovery sentiment analysis": ["Do LLMs Think Fast and Slow? A Causal Study on Sentiment Analysis"], "qa evaluation": ["PEDANTS: Cheap but Effective and Interpretable Answer Equivalence"], "answer correctness assessment": ["PEDANTS: Cheap but Effective and Interpretable Answer Equivalence"], "qa evaluation answer correctness assessment": ["PEDANTS: Cheap but Effective and Interpretable Answer Equivalence"], "judicial decision-making": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "court debate simulation": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "legal resources retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "precedent retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "judgement prediction": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "legal articles generation": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "judicial decision-making court debate simulation": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "court debate simulation legal resources retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "legal resources retrieval case analysis": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "case analysis precedent retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "precedent retrieval judgement prediction": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "judgement prediction legal articles generation": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "judicial decision-making court debate simulation legal resources retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "court debate simulation legal resources retrieval case analysis": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "legal resources retrieval case analysis precedent retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "case analysis precedent retrieval judgement prediction": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "precedent retrieval judgement prediction legal articles generation": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "judicial decision-making court debate simulation legal resources retrieval case analysis": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "court debate simulation legal resources retrieval case analysis precedent retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "legal resources retrieval case analysis precedent retrieval judgement prediction": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "case analysis precedent retrieval judgement prediction legal articles generation": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "judicial decision-making court debate simulation legal resources retrieval case analysis precedent retrieval": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "court debate simulation legal resources retrieval case analysis precedent retrieval judgement prediction": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "legal resources retrieval case analysis precedent retrieval judgement prediction legal articles generation": ["AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"], "knowledge editing generalization": ["Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models"], "generalization locality": ["Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models"], "locality language modeling": ["Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models"], "knowledge editing generalization locality": ["Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models"], "generalization locality language modeling": ["Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models"], "knowledge editing generalization locality language modeling": ["Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models"], "explainability language models": ["Improving LLM Attributions with Randomized Path-Integration"], "language models attribution": ["Improving LLM Attributions with Randomized Path-Integration"], "explainability language models attribution": ["Improving LLM Attributions with Randomized Path-Integration"], "factuality evaluation long-form text generation": ["VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation"], "long-form text generation claim verification": ["VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation"], "factuality evaluation long-form text generation claim verification": ["VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation"], "code debugging": ["Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging"], "socratic questioning": ["Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging"], "multi-turn dialogue": ["Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging", "Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "code debugging socratic questioning": ["Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging"], "socratic questioning multi-turn dialogue": ["Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging"], "code debugging socratic questioning multi-turn dialogue": ["Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging"], "aspect-based sentiment classification news topic classification": ["TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "news topic classification question type classification": ["TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "aspect-based sentiment classification news topic classification question type classification": ["TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "news topic classification question type classification emotion classification": ["TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "aspect-based sentiment classification news topic classification question type classification emotion classification": ["TUTOR-ICL: Guiding Large Language Models for Improved In-Context Learning Performance"], "conversation redirection measurement": ["Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy"], "mental health therapy analysis": ["Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy"], "patient-therapist relationship dynamics": ["Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy"], "conversation redirection measurement mental health therapy analysis": ["Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy"], "mental health therapy analysis patient-therapist relationship dynamics": ["Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy"], "conversation redirection measurement mental health therapy analysis patient-therapist relationship dynamics": ["Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy"], "LLM explainability": ["LLM Explainability via Attributive Masking Learning"], "masking learning": ["LLM Explainability via Attributive Masking Learning"], "LLM explainability attribution": ["LLM Explainability via Attributive Masking Learning"], "attribution masking learning": ["LLM Explainability via Attributive Masking Learning"], "LLM explainability attribution masking learning": ["LLM Explainability via Attributive Masking Learning"], "deception detection": ["How Entangled is Factuality and Deception in German?"], "deception detection fact verification": ["How Entangled is Factuality and Deception in German?"], "fact verification natural language inference": ["How Entangled is Factuality and Deception in German?"], "deception detection fact verification natural language inference": ["How Entangled is Factuality and Deception in German?"], "news recommendation": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation", "Efficient Pointwise-Pairwise Learning-to-Rank for News Recommendation"], "multi-aspect recommendation": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "diversification": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "metric-based learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "news recommendation multi-aspect recommendation": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "multi-aspect recommendation personalization": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "personalization diversification": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "diversification metric-based learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "metric-based learning transfer learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "news recommendation multi-aspect recommendation personalization": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "multi-aspect recommendation personalization diversification": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "personalization diversification metric-based learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "diversification metric-based learning transfer learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "news recommendation multi-aspect recommendation personalization diversification": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "multi-aspect recommendation personalization diversification metric-based learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "personalization diversification metric-based learning transfer learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "news recommendation multi-aspect recommendation personalization diversification metric-based learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "multi-aspect recommendation personalization diversification metric-based learning transfer learning": ["Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"], "counter narrative generation": ["A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation"], "counter narrative generation evaluation": ["A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation"], "evaluation hate speech mitigation": ["A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation"], "counter narrative generation evaluation hate speech mitigation": ["A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation"], "iterative feedback": ["Enhancing Tool Retrieval with Iterative Feedback from Large Language Models"], "tool retrieval iterative feedback": ["Enhancing Tool Retrieval with Iterative Feedback from Large Language Models"], "ambiguity detection": ["Detecting Temporal Ambiguity in Questions"], "temporal ambiguity detection": ["Detecting Temporal Ambiguity in Questions"], "question answering ambiguity detection": ["Detecting Temporal Ambiguity in Questions"], "ambiguity detection temporal ambiguity detection": ["Detecting Temporal Ambiguity in Questions"], "question answering ambiguity detection temporal ambiguity detection": ["Detecting Temporal Ambiguity in Questions"], "wikitext-2": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language understanding text summarization": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "text summarization natural language generation": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language generation complex reasoning": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "complex reasoning glue benchmark": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "glue benchmark gsm8k": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "gsm8k wikitext-2": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "wikitext-2 commonsense reasoning": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language understanding text summarization natural language generation": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "text summarization natural language generation complex reasoning": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language generation complex reasoning glue benchmark": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "complex reasoning glue benchmark gsm8k": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "glue benchmark gsm8k wikitext-2": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "gsm8k wikitext-2 commonsense reasoning": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language understanding text summarization natural language generation complex reasoning": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "text summarization natural language generation complex reasoning glue benchmark": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language generation complex reasoning glue benchmark gsm8k": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "complex reasoning glue benchmark gsm8k wikitext-2": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "glue benchmark gsm8k wikitext-2 commonsense reasoning": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language understanding text summarization natural language generation complex reasoning glue benchmark": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "text summarization natural language generation complex reasoning glue benchmark gsm8k": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "natural language generation complex reasoning glue benchmark gsm8k wikitext-2": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "complex reasoning glue benchmark gsm8k wikitext-2 commonsense reasoning": ["LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation"], "unintentional human activity understanding": ["Navigating Hallucinations for Reasoning of Unintentional Activities"], "unintentional human activity understanding reasoning": ["Navigating Hallucinations for Reasoning of Unintentional Activities"], "reasoning zero-shot learning": ["Navigating Hallucinations for Reasoning of Unintentional Activities"], "unintentional human activity understanding reasoning zero-shot learning": ["Navigating Hallucinations for Reasoning of Unintentional Activities"], "self-anthropomorphism analysis": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "human-robot interaction": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "dialogue systems self-anthropomorphism analysis": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "self-anthropomorphism analysis dataset creation": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "dataset creation human-robot interaction": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "dialogue systems self-anthropomorphism analysis dataset creation": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "self-anthropomorphism analysis dataset creation human-robot interaction": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "dialogue systems self-anthropomorphism analysis dataset creation human-robot interaction": ["From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues"], "multiple-choice question generation distractor generation": ["DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking"], "feedback learning": ["ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline"], "math problem solving language understanding": ["ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline"], "language understanding feedback learning": ["ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline"], "feedback learning LLM alignment": ["ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline"], "math problem solving language understanding feedback learning": ["ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline"], "language understanding feedback learning LLM alignment": ["ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline"], "math problem solving language understanding feedback learning LLM alignment": ["ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline"], "on-device deployment": ["MobileQuant: Mobile-friendly Quantization for On-device Language Models"], "quantization language models": ["MobileQuant: Mobile-friendly Quantization for On-device Language Models"], "language models on-device deployment": ["MobileQuant: Mobile-friendly Quantization for On-device Language Models"], "quantization language models on-device deployment": ["MobileQuant: Mobile-friendly Quantization for On-device Language Models"], "intergroup bias detection": ["Do they mean 'us'? Interpreting Referring Expression variation under Intergroup Bias"], "referring expression tagging": ["Do they mean 'us'? Interpreting Referring Expression variation under Intergroup Bias"], "intergroup bias detection referring expression tagging": ["Do they mean 'us'? Interpreting Referring Expression variation under Intergroup Bias"], "LLMs-generated content detection": ["A Survey on Detection of LLMs-Generated Content"], "reasoning in the wild": ["Can LLMs Reason in the Wild with Programs?"], "tactic identification": ["Can LLMs Reason in the Wild with Programs?"], "multi-formalism reasoning": ["Can LLMs Reason in the Wild with Programs?"], "hybrid problem solving": ["Can LLMs Reason in the Wild with Programs?"], "reasoning in the wild program synthesis": ["Can LLMs Reason in the Wild with Programs?"], "program synthesis tactic identification": ["Can LLMs Reason in the Wild with Programs?"], "tactic identification multi-formalism reasoning": ["Can LLMs Reason in the Wild with Programs?"], "multi-formalism reasoning hybrid problem solving": ["Can LLMs Reason in the Wild with Programs?"], "reasoning in the wild program synthesis tactic identification": ["Can LLMs Reason in the Wild with Programs?"], "program synthesis tactic identification multi-formalism reasoning": ["Can LLMs Reason in the Wild with Programs?"], "tactic identification multi-formalism reasoning hybrid problem solving": ["Can LLMs Reason in the Wild with Programs?"], "reasoning in the wild program synthesis tactic identification multi-formalism reasoning": ["Can LLMs Reason in the Wild with Programs?"], "program synthesis tactic identification multi-formalism reasoning hybrid problem solving": ["Can LLMs Reason in the Wild with Programs?"], "reasoning in the wild program synthesis tactic identification multi-formalism reasoning hybrid problem solving": ["Can LLMs Reason in the Wild with Programs?"], "cross-modality safety alignment": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "text unlearning": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "cross-modality safety alignment text unlearning": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "text unlearning vision-language models": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "vision-language models safety alignment": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "cross-modality safety alignment text unlearning vision-language models": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "text unlearning vision-language models safety alignment": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "cross-modality safety alignment text unlearning vision-language models safety alignment": ["Can Textual Unlearning Solve Cross-Modality Safety Alignment?"], "prompt refinement": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "robustness evaluation on instruction perturbation": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "glue cola": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "newspop": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "ag news": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "imdb": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "dbpedia": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "emotion": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "tweet offensive": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "prompt refinement robustness evaluation on instruction perturbation": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "robustness evaluation on instruction perturbation glue cola": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "glue cola newspop": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "newspop ag news": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "ag news imdb": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "imdb dbpedia": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "dbpedia emotion": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "emotion tweet offensive": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "prompt refinement robustness evaluation on instruction perturbation glue cola": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "robustness evaluation on instruction perturbation glue cola newspop": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "glue cola newspop ag news": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "newspop ag news imdb": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "ag news imdb dbpedia": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "imdb dbpedia emotion": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "dbpedia emotion tweet offensive": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "prompt refinement robustness evaluation on instruction perturbation glue cola newspop": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "robustness evaluation on instruction perturbation glue cola newspop ag news": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "glue cola newspop ag news imdb": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "newspop ag news imdb dbpedia": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "ag news imdb dbpedia emotion": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "imdb dbpedia emotion tweet offensive": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "prompt refinement robustness evaluation on instruction perturbation glue cola newspop ag news": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "robustness evaluation on instruction perturbation glue cola newspop ag news imdb": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "glue cola newspop ag news imdb dbpedia": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "newspop ag news imdb dbpedia emotion": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "ag news imdb dbpedia emotion tweet offensive": ["Monotonic Paraphrasing Improves Generalization of Language Model Prompting"], "text style transfer machine translation": ["MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization"], "biomedical summarization": ["Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries"], "faithfulness evaluation reasoning evaluation": ["Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries"], "reasoning evaluation biomedical summarization": ["Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries"], "faithfulness evaluation reasoning evaluation biomedical summarization": ["Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries"], "cross-lingual nli": ["Pruning Multilingual Large Language Models for Multilingual Inference"], "multilingual amazon review corpus": ["Pruning Multilingual Large Language Models for Multilingual Inference"], "cross-lingual nli multilingual amazon review corpus": ["Pruning Multilingual Large Language Models for Multilingual Inference"], "video rst parsing": ["Video Discourse Parsing and Its Application to Multimodal Summarization: A Dataset and Baseline Approaches"], "multimodal summarization": ["Video Discourse Parsing and Its Application to Multimodal Summarization: A Dataset and Baseline Approaches"], "video rst parsing multimodal summarization": ["Video Discourse Parsing and Its Application to Multimodal Summarization: A Dataset and Baseline Approaches"], "language modeling summarization": ["Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding"], "summarization code completion": ["Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding"], "code completion question answering": ["Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding"], "language modeling summarization code completion": ["Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding"], "summarization code completion question answering": ["Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding"], "language modeling summarization code completion question answering": ["Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding"], "zero-shot medical image diagnosis": ["VPL: Visual Proxy Learning Framework for Zero-Shot Medical Image Diagnosis"], "medical image classification": ["VPL: Visual Proxy Learning Framework for Zero-Shot Medical Image Diagnosis", "Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models"], "zero-shot medical image diagnosis medical image classification": ["VPL: Visual Proxy Learning Framework for Zero-Shot Medical Image Diagnosis"], "sign language generation": ["Word-Conditioned 3D American Sign Language Motion Generation"], "3d motion synthesis": ["Word-Conditioned 3D American Sign Language Motion Generation"], "text-to-sign conversion": ["Word-Conditioned 3D American Sign Language Motion Generation"], "image-to-sign conversion": ["Word-Conditioned 3D American Sign Language Motion Generation"], "sign language synthesis": ["Word-Conditioned 3D American Sign Language Motion Generation"], "sign language production": ["Word-Conditioned 3D American Sign Language Motion Generation"], "sign language generation 3d motion synthesis": ["Word-Conditioned 3D American Sign Language Motion Generation"], "3d motion synthesis text-to-sign conversion": ["Word-Conditioned 3D American Sign Language Motion Generation"], "text-to-sign conversion image-to-sign conversion": ["Word-Conditioned 3D American Sign Language Motion Generation"], "image-to-sign conversion sign language synthesis": ["Word-Conditioned 3D American Sign Language Motion Generation"], "sign language synthesis sign language production": ["Word-Conditioned 3D American Sign Language Motion Generation"], "sign language generation 3d motion synthesis text-to-sign conversion": ["Word-Conditioned 3D American Sign Language Motion Generation"], "3d motion synthesis text-to-sign conversion image-to-sign conversion": ["Word-Conditioned 3D American Sign Language Motion Generation"], "text-to-sign conversion image-to-sign conversion sign language synthesis": ["Word-Conditioned 3D American Sign Language Motion Generation"], "image-to-sign conversion sign language synthesis sign language production": ["Word-Conditioned 3D American Sign Language Motion Generation"], "sign language generation 3d motion synthesis text-to-sign conversion image-to-sign conversion": ["Word-Conditioned 3D American Sign Language Motion Generation"], "3d motion synthesis text-to-sign conversion image-to-sign conversion sign language synthesis": ["Word-Conditioned 3D American Sign Language Motion Generation"], "text-to-sign conversion image-to-sign conversion sign language synthesis sign language production": ["Word-Conditioned 3D American Sign Language Motion Generation"], "sign language generation 3d motion synthesis text-to-sign conversion image-to-sign conversion sign language synthesis": ["Word-Conditioned 3D American Sign Language Motion Generation"], "3d motion synthesis text-to-sign conversion image-to-sign conversion sign language synthesis sign language production": ["Word-Conditioned 3D American Sign Language Motion Generation"], "LLM-based agent safety": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "agent constitution adherence": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "risk mitigation": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "LLM-based agent safety agent constitution adherence": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "agent constitution adherence task planning": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "task planning risk mitigation": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "risk mitigation helpfulness enhancement": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "LLM-based agent safety agent constitution adherence task planning": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "agent constitution adherence task planning risk mitigation": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "task planning risk mitigation helpfulness enhancement": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "LLM-based agent safety agent constitution adherence task planning risk mitigation": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "agent constitution adherence task planning risk mitigation helpfulness enhancement": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "LLM-based agent safety agent constitution adherence task planning risk mitigation helpfulness enhancement": ["TrustAgent: Towards Safe and Trustworthy LLM-based Agents"], "community similarity": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "content similarity": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "opinion similarity": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "cross-platform comparison": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "community similarity content similarity": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "content similarity opinion similarity": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "opinion similarity cross-platform comparison": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "community similarity content similarity opinion similarity": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "content similarity opinion similarity cross-platform comparison": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "community similarity content similarity opinion similarity cross-platform comparison": ["Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity"], "complex query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "statistics query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "constraint query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "knowledge graph reasoning complex query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "complex query answering numerical reasoning": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "numerical reasoning entity prediction": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "entity prediction statistics query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "statistics query answering constraint query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "knowledge graph reasoning complex query answering numerical reasoning": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "complex query answering numerical reasoning entity prediction": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "numerical reasoning entity prediction statistics query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "entity prediction statistics query answering constraint query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "knowledge graph reasoning complex query answering numerical reasoning entity prediction": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "complex query answering numerical reasoning entity prediction statistics query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "numerical reasoning entity prediction statistics query answering constraint query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "knowledge graph reasoning complex query answering numerical reasoning entity prediction statistics query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "complex query answering numerical reasoning entity prediction statistics query answering constraint query answering": ["CNEQ: Incorporating numbers into Knowledge Graph Reasoning"], "industrial applications": ["StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "natural language understanding domain-specific knowledge": ["StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "domain-specific knowledge industrial applications": ["StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "reasoning natural language understanding domain-specific knowledge": ["StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "natural language understanding domain-specific knowledge industrial applications": ["StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "reasoning natural language understanding domain-specific knowledge industrial applications": ["StraGo: Harnessing Strategic Guidance for Prompt Optimization"], "combinatorial reasoning": ["Learning to Plan by Updating Natural Language"], "mathematical reasoning causal reasoning": ["Learning to Plan by Updating Natural Language"], "causal reasoning logical reasoning": ["Learning to Plan by Updating Natural Language"], "symbolic reasoning combinatorial reasoning": ["Learning to Plan by Updating Natural Language"], "mathematical reasoning causal reasoning logical reasoning": ["Learning to Plan by Updating Natural Language"], "causal reasoning logical reasoning symbolic reasoning": ["Learning to Plan by Updating Natural Language"], "logical reasoning symbolic reasoning combinatorial reasoning": ["Learning to Plan by Updating Natural Language"], "mathematical reasoning causal reasoning logical reasoning symbolic reasoning": ["Learning to Plan by Updating Natural Language"], "causal reasoning logical reasoning symbolic reasoning combinatorial reasoning": ["Learning to Plan by Updating Natural Language"], "mathematical reasoning causal reasoning logical reasoning symbolic reasoning combinatorial reasoning": ["Learning to Plan by Updating Natural Language"], "circuit analysis": ["On the Similarity of Circuits across Languages: A Case Study on the Subject-verb Agreement Task"], "subject-verb agreement circuit analysis": ["On the Similarity of Circuits across Languages: A Case Study on the Subject-verb Agreement Task"], "LLM personalization evaluation": ["Can LLM be a Personalized Judge?"], "personalized judge reliability": ["Can LLM be a Personalized Judge?"], "LLM personalization evaluation personalized judge reliability": ["Can LLM be a Personalized Judge?"], "multi-choice vqa": ["Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models"], "visual question answering multi-choice vqa": ["Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models"], "automated paper reviewing": ["Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis"], "consistency testing": ["Knowledge-based Consistency Testing of Large Language Models"], "knowledge gap analysis": ["Knowledge-based Consistency Testing of Large Language Models"], "consistency testing knowledge gap analysis": ["Knowledge-based Consistency Testing of Large Language Models"], "knowledge gap analysis LLM evaluation": ["Knowledge-based Consistency Testing of Large Language Models"], "consistency testing knowledge gap analysis LLM evaluation": ["Knowledge-based Consistency Testing of Large Language Models"], "forward reaction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "retrosynthesis": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "reaction type classification": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "reagent selection": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "yield prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "condition prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "forward reaction retrosynthesis": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "retrosynthesis reaction type classification": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "reaction type classification reagent selection": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "reagent selection yield prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "yield prediction condition prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "forward reaction retrosynthesis reaction type classification": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "retrosynthesis reaction type classification reagent selection": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "reaction type classification reagent selection yield prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "reagent selection yield prediction condition prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "forward reaction retrosynthesis reaction type classification reagent selection": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "retrosynthesis reaction type classification reagent selection yield prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "reaction type classification reagent selection yield prediction condition prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "forward reaction retrosynthesis reaction type classification reagent selection yield prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "retrosynthesis reaction type classification reagent selection yield prediction condition prediction": ["PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"], "element list generation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element grounding": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "action space generation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "page navigation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element list generation element grounding": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element grounding action space generation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "action space generation action prediction": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "action prediction vqa": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "vqa page navigation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element list generation element grounding action space generation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element grounding action space generation action prediction": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "action space generation action prediction vqa": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "action prediction vqa page navigation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element list generation element grounding action space generation action prediction": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element grounding action space generation action prediction vqa": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "action space generation action prediction vqa page navigation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element list generation element grounding action space generation action prediction vqa": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "element grounding action space generation action prediction vqa page navigation": ["MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding"], "schema-driven extraction": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "structured data extraction": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "information extraction table understanding": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "table understanding schema-driven extraction": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "schema-driven extraction structured data extraction": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "information extraction table understanding schema-driven extraction": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "table understanding schema-driven extraction structured data extraction": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "information extraction table understanding schema-driven extraction structured data extraction": ["Schema-Driven Information Extraction from Heterogeneous Tables"], "definition bias measurement": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "bias-aware fine-tuning": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "task-specific bias mitigation": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "relation extraction definition bias measurement": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "definition bias measurement bias-aware fine-tuning": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "bias-aware fine-tuning task-specific bias mitigation": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "named entity recognition relation extraction definition bias measurement": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "relation extraction definition bias measurement bias-aware fine-tuning": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "definition bias measurement bias-aware fine-tuning task-specific bias mitigation": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "named entity recognition relation extraction definition bias measurement bias-aware fine-tuning": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "relation extraction definition bias measurement bias-aware fine-tuning task-specific bias mitigation": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "named entity recognition relation extraction definition bias measurement bias-aware fine-tuning task-specific bias mitigation": ["Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases"], "nl2code": ["PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning"], "table-based question answering": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based fact verification": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-to-text": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "column type & relation classification": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based question answering table-based fact verification": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based fact verification table-to-text": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-to-text text-to-sql": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "text-to-sql column type & relation classification": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based question answering table-based fact verification table-to-text": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based fact verification table-to-text text-to-sql": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-to-text text-to-sql column type & relation classification": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based question answering table-based fact verification table-to-text text-to-sql": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based fact verification table-to-text text-to-sql column type & relation classification": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "table-based question answering table-based fact verification table-to-text text-to-sql column type & relation classification": ["TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning"], "coreset selection": ["In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models"], "coreset selection instruction finetuning": ["In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models"], "negotiation outcome prediction": ["How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models"], "personality trait analysis": ["How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models"], "negotiation outcome prediction personality trait analysis": ["How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models"], "live commentary generation": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "open-domain setting": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "live commentary generation video understanding": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "video understanding open-domain setting": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "open-domain setting spatial reasoning": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "spatial reasoning question answering": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "live commentary generation video understanding open-domain setting": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "video understanding open-domain setting spatial reasoning": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "open-domain setting spatial reasoning question answering": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "live commentary generation video understanding open-domain setting spatial reasoning": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "video understanding open-domain setting spatial reasoning question answering": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "live commentary generation video understanding open-domain setting spatial reasoning question answering": ["Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation"], "task-oriented dialogue systems": ["Learning to Match Representations is Better for End-to-End Task-Oriented Dialog System"], "safety detection in LLM responses": ["ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors"], "vlm probing": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "toxicity analysis": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "bias level assessment": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "vlm probing bias detection": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "bias detection sentiment analysis": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "sentiment analysis toxicity analysis": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "toxicity analysis bias level assessment": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "vlm probing bias detection sentiment analysis": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "bias detection sentiment analysis toxicity analysis": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "sentiment analysis toxicity analysis bias level assessment": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "vlm probing bias detection sentiment analysis toxicity analysis": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "bias detection sentiment analysis toxicity analysis bias level assessment": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "vlm probing bias detection sentiment analysis toxicity analysis bias level assessment": ["BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"], "perplexity": ["MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition"], "zero-shot classification language understanding": ["MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition"], "language understanding language generation": ["MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition"], "language generation perplexity": ["MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition"], "zero-shot classification language understanding language generation": ["MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition"], "language understanding language generation perplexity": ["MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition"], "zero-shot classification language understanding language generation perplexity": ["MoE-I2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition"], "multimodal misinformation detection": ["Multimodal Misinformation Detection by Learning from Synthetic Data with Multimodal LLMs"], "flores": ["Exploring Design Choices for Building Language-Specific LLMs"], "xlsum": ["Exploring Design Choices for Building Language-Specific LLMs"], "MLama": ["Exploring Design Choices for Building Language-Specific LLMs"], "headline generation": ["Exploring Design Choices for Building Language-Specific LLMs"], "flores xlsum": ["Exploring Design Choices for Building Language-Specific LLMs"], "xlsum MLama": ["Exploring Design Choices for Building Language-Specific LLMs"], "MLama sentiment analysis": ["Exploring Design Choices for Building Language-Specific LLMs"], "sentiment analysis xstorycloze": ["Exploring Design Choices for Building Language-Specific LLMs"], "xnli machine translation": ["Exploring Design Choices for Building Language-Specific LLMs"], "machine translation headline generation": ["Exploring Design Choices for Building Language-Specific LLMs"], "headline generation knowledge probing": ["Exploring Design Choices for Building Language-Specific LLMs"], "knowledge probing causal reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "causal reasoning commonsense reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "flores xlsum MLama": ["Exploring Design Choices for Building Language-Specific LLMs"], "xlsum MLama sentiment analysis": ["Exploring Design Choices for Building Language-Specific LLMs"], "MLama sentiment analysis xstorycloze": ["Exploring Design Choices for Building Language-Specific LLMs"], "sentiment analysis xstorycloze xnli": ["Exploring Design Choices for Building Language-Specific LLMs"], "xstorycloze xnli machine translation": ["Exploring Design Choices for Building Language-Specific LLMs"], "xnli machine translation headline generation": ["Exploring Design Choices for Building Language-Specific LLMs"], "machine translation headline generation knowledge probing": ["Exploring Design Choices for Building Language-Specific LLMs"], "headline generation knowledge probing causal reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "knowledge probing causal reasoning commonsense reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "flores xlsum MLama sentiment analysis": ["Exploring Design Choices for Building Language-Specific LLMs"], "xlsum MLama sentiment analysis xstorycloze": ["Exploring Design Choices for Building Language-Specific LLMs"], "MLama sentiment analysis xstorycloze xnli": ["Exploring Design Choices for Building Language-Specific LLMs"], "sentiment analysis xstorycloze xnli machine translation": ["Exploring Design Choices for Building Language-Specific LLMs"], "xstorycloze xnli machine translation headline generation": ["Exploring Design Choices for Building Language-Specific LLMs"], "xnli machine translation headline generation knowledge probing": ["Exploring Design Choices for Building Language-Specific LLMs"], "machine translation headline generation knowledge probing causal reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "headline generation knowledge probing causal reasoning commonsense reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "flores xlsum MLama sentiment analysis xstorycloze": ["Exploring Design Choices for Building Language-Specific LLMs"], "xlsum MLama sentiment analysis xstorycloze xnli": ["Exploring Design Choices for Building Language-Specific LLMs"], "MLama sentiment analysis xstorycloze xnli machine translation": ["Exploring Design Choices for Building Language-Specific LLMs"], "sentiment analysis xstorycloze xnli machine translation headline generation": ["Exploring Design Choices for Building Language-Specific LLMs"], "xstorycloze xnli machine translation headline generation knowledge probing": ["Exploring Design Choices for Building Language-Specific LLMs"], "xnli machine translation headline generation knowledge probing causal reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "machine translation headline generation knowledge probing causal reasoning commonsense reasoning": ["Exploring Design Choices for Building Language-Specific LLMs"], "federated learning privacy protection": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "privacy protection quantization": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "quantization parameter-efficient fine-tuning": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "parameter-efficient fine-tuning text generation": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "federated learning privacy protection quantization": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "privacy protection quantization parameter-efficient fine-tuning": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "quantization parameter-efficient fine-tuning text generation": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "federated learning privacy protection quantization parameter-efficient fine-tuning": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "privacy protection quantization parameter-efficient fine-tuning text generation": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "federated learning privacy protection quantization parameter-efficient fine-tuning text generation": ["Promoting Data and Model Privacy in Federated Learning through Quantized LoRA"], "intended target identification": ["Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation"], "anomia assistance": ["Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation"], "intended target identification anomia assistance": ["Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation"], "financial question answering": ["Fine-tuning Smaller Language Models for Question Answering over Financial Documents"], "financial question answering numerical reasoning": ["Fine-tuning Smaller Language Models for Question Answering over Financial Documents"], "medical dialogue": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical terminology standardization": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical entity recognition": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "image analysis": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "discharge instruction": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "examination education": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical trial criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query intent criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query query relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query title relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical dialog generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical question answering medical dialogue": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical dialogue clinical terminology standardization": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical terminology standardization medical entity recognition": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical entity recognition report generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "report generation image analysis": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "image analysis discharge instruction": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "discharge instruction examination education": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "examination education clinical trial criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical trial criterion semantic textual similarity": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "semantic textual similarity information retrieval": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "information retrieval query intent criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query intent criterion query query relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query query relevance query title relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query title relevance medical dialog generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical question answering medical dialogue clinical terminology standardization": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical dialogue clinical terminology standardization medical entity recognition": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical terminology standardization medical entity recognition report generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical entity recognition report generation image analysis": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "report generation image analysis discharge instruction": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "image analysis discharge instruction examination education": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "discharge instruction examination education clinical trial criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "examination education clinical trial criterion semantic textual similarity": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical trial criterion semantic textual similarity information retrieval": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "semantic textual similarity information retrieval query intent criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "information retrieval query intent criterion query query relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query intent criterion query query relevance query title relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query query relevance query title relevance medical dialog generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical question answering medical dialogue clinical terminology standardization medical entity recognition": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical dialogue clinical terminology standardization medical entity recognition report generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical terminology standardization medical entity recognition report generation image analysis": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical entity recognition report generation image analysis discharge instruction": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "report generation image analysis discharge instruction examination education": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "image analysis discharge instruction examination education clinical trial criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "discharge instruction examination education clinical trial criterion semantic textual similarity": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "examination education clinical trial criterion semantic textual similarity information retrieval": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical trial criterion semantic textual similarity information retrieval query intent criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "semantic textual similarity information retrieval query intent criterion query query relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "information retrieval query intent criterion query query relevance query title relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "query intent criterion query query relevance query title relevance medical dialog generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical question answering medical dialogue clinical terminology standardization medical entity recognition report generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical dialogue clinical terminology standardization medical entity recognition report generation image analysis": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical terminology standardization medical entity recognition report generation image analysis discharge instruction": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "medical entity recognition report generation image analysis discharge instruction examination education": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "report generation image analysis discharge instruction examination education clinical trial criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "image analysis discharge instruction examination education clinical trial criterion semantic textual similarity": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "discharge instruction examination education clinical trial criterion semantic textual similarity information retrieval": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "examination education clinical trial criterion semantic textual similarity information retrieval query intent criterion": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "clinical trial criterion semantic textual similarity information retrieval query intent criterion query query relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "semantic textual similarity information retrieval query intent criterion query query relevance query title relevance": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "information retrieval query intent criterion query query relevance query title relevance medical dialog generation": ["MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"], "reward modeling rlhf": ["Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "rlhf language modeling": ["Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "language modeling preference learning": ["Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "reward modeling rlhf language modeling": ["Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "rlhf language modeling preference learning": ["Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "reward modeling rlhf language modeling preference learning": ["Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"], "code membership inference": ["Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models"], "unauthorized code use detection": ["Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models"], "code membership inference unauthorized code use detection": ["Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models"], "logic grid puzzle": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "information essentiality": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "minute mysteries qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "hotpot qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "wiki hop": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "narrative qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "logic grid puzzle information essentiality": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "information essentiality aqua": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "aqua minute mysteries qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "minute mysteries qa coin flip": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "coin flip hotpot qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "hotpot qa wiki hop": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "wiki hop narrative qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "logic grid puzzle information essentiality aqua": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "information essentiality aqua minute mysteries qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "aqua minute mysteries qa coin flip": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "minute mysteries qa coin flip hotpot qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "coin flip hotpot qa wiki hop": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "hotpot qa wiki hop narrative qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "logic grid puzzle information essentiality aqua minute mysteries qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "information essentiality aqua minute mysteries qa coin flip": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "aqua minute mysteries qa coin flip hotpot qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "minute mysteries qa coin flip hotpot qa wiki hop": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "coin flip hotpot qa wiki hop narrative qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "logic grid puzzle information essentiality aqua minute mysteries qa coin flip": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "information essentiality aqua minute mysteries qa coin flip hotpot qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "aqua minute mysteries qa coin flip hotpot qa wiki hop": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "minute mysteries qa coin flip hotpot qa wiki hop narrative qa": ["Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication"], "tool execution": ["Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "action calibration": ["Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "task planning tool execution": ["Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "tool execution action calibration": ["Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "tool learning task planning tool execution": ["Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "task planning tool execution action calibration": ["Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "tool learning task planning tool execution action calibration": ["Learning to Use Tools via Cooperative and Interactive Agents with Large Language Models"], "statute retrieval": ["STARD: A Chinese Statute Retrieval Dataset Derived from Real-life Queries by Non-professionals"], "hallucination mitigation visual understanding": ["What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models"], "visual understanding reasoning": ["What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models"], "hallucination mitigation visual understanding reasoning": ["What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models"], "materials entity recognition": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "paragraph classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "synthesis action retrieval": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "materials entity recognition relation classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "relation classification event argument extraction": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "event argument extraction paragraph classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "paragraph classification synthesis action retrieval": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "synthesis action retrieval sentence classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "sentence classification slot filling": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "slot filling named entity recognition": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "materials entity recognition relation classification event argument extraction": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "relation classification event argument extraction paragraph classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "event argument extraction paragraph classification synthesis action retrieval": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "paragraph classification synthesis action retrieval sentence classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "synthesis action retrieval sentence classification slot filling": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "sentence classification slot filling named entity recognition": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "materials entity recognition relation classification event argument extraction paragraph classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "relation classification event argument extraction paragraph classification synthesis action retrieval": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "event argument extraction paragraph classification synthesis action retrieval sentence classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "paragraph classification synthesis action retrieval sentence classification slot filling": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "synthesis action retrieval sentence classification slot filling named entity recognition": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "materials entity recognition relation classification event argument extraction paragraph classification synthesis action retrieval": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "relation classification event argument extraction paragraph classification synthesis action retrieval sentence classification": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "event argument extraction paragraph classification synthesis action retrieval sentence classification slot filling": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "paragraph classification synthesis action retrieval sentence classification slot filling named entity recognition": ["MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science"], "document structure parsing": ["PDF-to-Tree: Parsing PDF Text Blocks into a Tree"], "meme offensive detection": ["Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes"], "multimodal classification": ["Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes"], "meme offensive detection multimodal classification": ["Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes"], "multimodal classification interpretability": ["Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes"], "meme offensive detection multimodal classification interpretability": ["Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes"], "knowledge removal": ["Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models"], "machine unlearning multilingual language models": ["Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models"], "multilingual language models knowledge removal": ["Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models"], "machine unlearning multilingual language models knowledge removal": ["Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models"], "emotion-cause pair extraction in conversations": ["Enhancing Emotion-Cause Pair Extraction in Conversations via Center Event Detection and Reasoning"], "center event detection": ["Enhancing Emotion-Cause Pair Extraction in Conversations via Center Event Detection and Reasoning"], "emotion-cause pair extraction in conversations center event detection": ["Enhancing Emotion-Cause Pair Extraction in Conversations via Center Event Detection and Reasoning"], "medical image classification medical visual question answering": ["Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models"], "automatic post-editing": ["Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "automatic post-editing quality estimation": ["Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "quality estimation multilingual machine translation": ["Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "multilingual machine translation domain adaptation": ["Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "automatic post-editing quality estimation multilingual machine translation": ["Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "quality estimation multilingual machine translation domain adaptation": ["Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "automatic post-editing quality estimation multilingual machine translation domain adaptation": ["Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"], "certified robustness": ["CERT-ED: Certifiably Robust Text Classification for Edit Distance"], "text classification certified robustness": ["CERT-ED: Certifiably Robust Text Classification for Edit Distance"], "proactive agent planning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "clarification need prediction": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "clarification question generation": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "agent planning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning", "FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "proactive agent planning clarification need prediction": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "clarification need prediction clarification question generation": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "clarification question generation tool learning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "tool learning agent planning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "proactive agent planning clarification need prediction clarification question generation": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "clarification need prediction clarification question generation tool learning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "clarification question generation tool learning agent planning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "proactive agent planning clarification need prediction clarification question generation tool learning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "clarification need prediction clarification question generation tool learning agent planning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "proactive agent planning clarification need prediction clarification question generation tool learning agent planning": ["Ask-before-Plan: Proactive Language Agents for Real-World Planning"], "constraints following": ["From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models"], "instruction following constraints following": ["From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models"], "constraints following generalization": ["From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models"], "instruction following constraints following generalization": ["From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models"], "workflow-guided planning": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "task solving": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "workflow-guided planning agent planning": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "agent planning benchmarking": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "benchmarking task solving": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "task solving tool utilization": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "tool utilization multi-agent collaboration": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "workflow-guided planning agent planning benchmarking": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "agent planning benchmarking task solving": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "benchmarking task solving tool utilization": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "task solving tool utilization multi-agent collaboration": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "workflow-guided planning agent planning benchmarking task solving": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "agent planning benchmarking task solving tool utilization": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "benchmarking task solving tool utilization multi-agent collaboration": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "workflow-guided planning agent planning benchmarking task solving tool utilization": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "agent planning benchmarking task solving tool utilization multi-agent collaboration": ["FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"], "mental disorder classification": ["Mental Disorder Classification via Temporal Representation of Text"], "speech comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "hotword detection": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "keyword comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "intent identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "sound comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "caption retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "event retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech comparison dialogue response generation": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "dialogue response generation hotword detection": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "hotword detection speech identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech identification keyword comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "keyword comparison intent identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "intent identification story generation": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "story generation sound comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "sound comparison caption retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "caption retrieval event retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "event retrieval event detection": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech comparison dialogue response generation hotword detection": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "dialogue response generation hotword detection speech identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "hotword detection speech identification keyword comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech identification keyword comparison intent identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "keyword comparison intent identification story generation": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "intent identification story generation sound comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "story generation sound comparison caption retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "sound comparison caption retrieval event retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "caption retrieval event retrieval event detection": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech comparison dialogue response generation hotword detection speech identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "dialogue response generation hotword detection speech identification keyword comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "hotword detection speech identification keyword comparison intent identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech identification keyword comparison intent identification story generation": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "keyword comparison intent identification story generation sound comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "intent identification story generation sound comparison caption retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "story generation sound comparison caption retrieval event retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "sound comparison caption retrieval event retrieval event detection": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech comparison dialogue response generation hotword detection speech identification keyword comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "dialogue response generation hotword detection speech identification keyword comparison intent identification": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "hotword detection speech identification keyword comparison intent identification story generation": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "speech identification keyword comparison intent identification story generation sound comparison": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "keyword comparison intent identification story generation sound comparison caption retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "intent identification story generation sound comparison caption retrieval event retrieval": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "story generation sound comparison caption retrieval event retrieval event detection": ["Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models"], "multimodal procedural planning": ["Multimodal Procedural Planning via Dual Text-Image Prompting"], "paraphrase identification reading comprehension": ["Functionality learning through specification instructions"], "reading comprehension hate speech detection": ["Functionality learning through specification instructions"], "sentiment analysis paraphrase identification reading comprehension": ["Functionality learning through specification instructions"], "paraphrase identification reading comprehension hate speech detection": ["Functionality learning through specification instructions"], "sentiment analysis paraphrase identification reading comprehension hate speech detection": ["Functionality learning through specification instructions"], "lexical constraint": ["DICTDIS: Dictionary Constrained Disambiguation for Improved NMT"], "neural machine translation lexical constraint": ["DICTDIS: Dictionary Constrained Disambiguation for Improved NMT"], "lexical constraint disambiguation": ["DICTDIS: Dictionary Constrained Disambiguation for Improved NMT"], "neural machine translation lexical constraint disambiguation": ["DICTDIS: Dictionary Constrained Disambiguation for Improved NMT"], "code efficiency judgment": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "code refinement": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "regression": ["Rethinking Code Refinement: Learning to Judge Code Efficiency", "Regression-aware Inference with LLMs"], "code efficiency judgment code refinement": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "code refinement classification": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "classification regression": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "code efficiency judgment code refinement classification": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "code refinement classification regression": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "code efficiency judgment code refinement classification regression": ["Rethinking Code Refinement: Learning to Judge Code Efficiency"], "long-context classification": ["Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability"], "classification in-context learning": ["Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability"], "in-context learning long-context classification": ["Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability"], "classification in-context learning long-context classification": ["Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability"], "in-context editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "one-hop editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "stubborn knowledge editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "knowledge editing in-context editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "in-context editing multi-hop question answering": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "multi-hop question answering one-hop editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "one-hop editing stubborn knowledge editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "knowledge editing in-context editing multi-hop question answering": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "in-context editing multi-hop question answering one-hop editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "multi-hop question answering one-hop editing stubborn knowledge editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "knowledge editing in-context editing multi-hop question answering one-hop editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "in-context editing multi-hop question answering one-hop editing stubborn knowledge editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "knowledge editing in-context editing multi-hop question answering one-hop editing stubborn knowledge editing": ["Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities"], "news summarization factual consistency": ["Improving Factual Consistency of News Summarization by Contrastive Preference Optimization"], "egocentric video understanding": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "attribute recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object state recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object localization": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding", "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "functional reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "egocentric video understanding video captioning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video captioning video question answering": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video question answering object recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object recognition attribute recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "attribute recognition object state recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object state recognition object localization": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object localization spatial reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "spatial reasoning functional reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "functional reasoning world knowledge": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "egocentric video understanding video captioning video question answering": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video captioning video question answering object recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video question answering object recognition attribute recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object recognition attribute recognition object state recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "attribute recognition object state recognition object localization": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object state recognition object localization spatial reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object localization spatial reasoning functional reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "spatial reasoning functional reasoning world knowledge": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "egocentric video understanding video captioning video question answering object recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video captioning video question answering object recognition attribute recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video question answering object recognition attribute recognition object state recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object recognition attribute recognition object state recognition object localization": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "attribute recognition object state recognition object localization spatial reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object state recognition object localization spatial reasoning functional reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object localization spatial reasoning functional reasoning world knowledge": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "egocentric video understanding video captioning video question answering object recognition attribute recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video captioning video question answering object recognition attribute recognition object state recognition": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "video question answering object recognition attribute recognition object state recognition object localization": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object recognition attribute recognition object state recognition object localization spatial reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "attribute recognition object state recognition object localization spatial reasoning functional reasoning": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "object state recognition object localization spatial reasoning functional reasoning world knowledge": ["ALANAVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding"], "cross-platform analysis": ["Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias"], "topic modeling bias mitigation": ["Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias"], "bias mitigation cross-platform analysis": ["Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias"], "topic modeling bias mitigation cross-platform analysis": ["Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias"], "event factuality detection": ["MAVEN-FACT: A Large-scale Event Factuality Detection Dataset"], "collaborative building": ["Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft"], "action prediction code generation": ["Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft"], "code generation collaborative building": ["Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft"], "action prediction code generation collaborative building": ["Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft"], "aspect-category-opinion-sentiment": ["Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis"], "aspect-based sentiment analysis aspect sentiment quad prediction": ["Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis"], "aspect sentiment quad prediction aspect-category-opinion-sentiment": ["Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis"], "aspect-based sentiment analysis aspect sentiment quad prediction aspect-category-opinion-sentiment": ["Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis"], "arcc": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm-plus": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "bbh": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement", "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "factual knowledge mathematical reasoning": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mathematical reasoning coding": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "coding mMLu": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mMLu arcc": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "arcc gsm8k": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm8k gsm-plus": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm-plus mbpp": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mbpp humaneval": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "humaneval bbh": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "factual knowledge mathematical reasoning coding": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mathematical reasoning coding mMLu": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "coding mMLu arcc": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mMLu arcc gsm8k": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "arcc gsm8k gsm-plus": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm8k gsm-plus mbpp": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm-plus mbpp humaneval": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mbpp humaneval bbh": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "factual knowledge mathematical reasoning coding mMLu": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mathematical reasoning coding mMLu arcc": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "coding mMLu arcc gsm8k": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mMLu arcc gsm8k gsm-plus": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "arcc gsm8k gsm-plus mbpp": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm8k gsm-plus mbpp humaneval": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm-plus mbpp humaneval bbh": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "factual knowledge mathematical reasoning coding mMLu arcc": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mathematical reasoning coding mMLu arcc gsm8k": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "coding mMLu arcc gsm8k gsm-plus": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "mMLu arcc gsm8k gsm-plus mbpp": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "arcc gsm8k gsm-plus mbpp humaneval": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "gsm8k gsm-plus mbpp humaneval bbh": ["LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement"], "relation extraction named entity recognition": ["ITER: Iterative Transformer-based Entity Recognition and Relation Extraction"], "donation solicitation": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "health intervention": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "persuasion donation solicitation": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "donation solicitation recommendation systems": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "recommendation systems health intervention": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "persuasion donation solicitation recommendation systems": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "donation solicitation recommendation systems health intervention": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "persuasion donation solicitation recommendation systems health intervention": ["Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval"], "fact knowledge memorization": ["Scaling Laws for Fact Memorization of Large Language Models"], "redundant fact memorization": ["Scaling Laws for Fact Memorization of Large Language Models"], "generalization on unseen facts": ["Scaling Laws for Fact Memorization of Large Language Models"], "fact knowledge memorization scaling laws analysis": ["Scaling Laws for Fact Memorization of Large Language Models"], "scaling laws analysis redundant fact memorization": ["Scaling Laws for Fact Memorization of Large Language Models"], "redundant fact memorization generalization on unseen facts": ["Scaling Laws for Fact Memorization of Large Language Models"], "fact knowledge memorization scaling laws analysis redundant fact memorization": ["Scaling Laws for Fact Memorization of Large Language Models"], "scaling laws analysis redundant fact memorization generalization on unseen facts": ["Scaling Laws for Fact Memorization of Large Language Models"], "fact knowledge memorization scaling laws analysis redundant fact memorization generalization on unseen facts": ["Scaling Laws for Fact Memorization of Large Language Models"], "sentence retrieval": ["Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment"], "sentence retrieval text classification": ["Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment"], "text classification sequence labeling": ["Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment"], "sentence retrieval text classification sequence labeling": ["Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment"], "data cleaning": ["Leveraging Web-Crawled Data for High-Quality Fine-Tuning"], "mathematical reasoning data cleaning": ["Leveraging Web-Crawled Data for High-Quality Fine-Tuning"], "data cleaning fine-tuning": ["Leveraging Web-Crawled Data for High-Quality Fine-Tuning"], "mathematical reasoning data cleaning fine-tuning": ["Leveraging Web-Crawled Data for High-Quality Fine-Tuning"], "counter-argument logical structure analysis": ["Designing Logic Pattern Templates for Counter-Argument Logical Structure Analysis"], "counter-argument logical structure analysis template selection": ["Designing Logic Pattern Templates for Counter-Argument Logical Structure Analysis"], "counter-argument logical structure analysis template selection slot filling": ["Designing Logic Pattern Templates for Counter-Argument Logical Structure Analysis"], "language modeling model compression": ["Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs", "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models"], "model compression zero-shot learning": ["Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs"], "quantization language modeling model compression": ["Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs"], "language modeling model compression zero-shot learning": ["Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs"], "quantization language modeling model compression zero-shot learning": ["Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs"], "multiple choice question answering": ["Using LLMs to Simulate Students' Responses to Exam Questions", "Downstream Trade-offs of a Family of Text Watermarks", "Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models"], "multiple choice question answering student simulation": ["Using LLMs to Simulate Students' Responses to Exam Questions"], "heart sound diagnosis": ["HSDreport: Heart Sound Diagnosis with Echocardiography Reports"], "catastrophic neglect repair": ["Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement"], "text-to-image generation catastrophic neglect repair": ["Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement"], "visual speech translation": ["Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing"], "visual speech recognition visual speech translation": ["Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing"], "visual speech translation multi-task learning": ["Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing"], "visual speech recognition visual speech translation multi-task learning": ["Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing"], "multi-document conditional reasoning": ["MDCR: A Dataset for Multi-Document Conditional Reasoning"], "optimization": ["MDCR: A Dataset for Multi-Document Conditional Reasoning"], "multi-document conditional reasoning question answering": ["MDCR: A Dataset for Multi-Document Conditional Reasoning"], "question answering optimization": ["MDCR: A Dataset for Multi-Document Conditional Reasoning"], "multi-document conditional reasoning question answering optimization": ["MDCR: A Dataset for Multi-Document Conditional Reasoning"], "psychometric": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "game theory": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "social decision-making": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "persona-based analysis": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "reasoning psychometric": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "psychometric game theory": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "game theory social decision-making": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "social decision-making persona-based analysis": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "reasoning psychometric game theory": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "psychometric game theory social decision-making": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "game theory social decision-making persona-based analysis": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "reasoning psychometric game theory social decision-making": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "psychometric game theory social decision-making persona-based analysis": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "reasoning psychometric game theory social decision-making persona-based analysis": ["Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure"], "commonsense reasoning zero-shot learning": ["Zero-shot Commonsense Reasoning over Machine Imagination"], "zero-shot learning natural language understanding": ["Zero-shot Commonsense Reasoning over Machine Imagination"], "natural language understanding visual question answering": ["Zero-shot Commonsense Reasoning over Machine Imagination"], "commonsense reasoning zero-shot learning natural language understanding": ["Zero-shot Commonsense Reasoning over Machine Imagination"], "zero-shot learning natural language understanding visual question answering": ["Zero-shot Commonsense Reasoning over Machine Imagination"], "commonsense reasoning zero-shot learning natural language understanding visual question answering": ["Zero-shot Commonsense Reasoning over Machine Imagination"], "multimodal aspect term extraction": ["Vanessa : Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis"], "multimodal aspect-based sentiment classification": ["Vanessa : Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis"], "mabsa": ["Vanessa : Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis"], "multimodal aspect term extraction multimodal aspect-based sentiment classification": ["Vanessa : Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis"], "multimodal aspect-based sentiment classification mabsa": ["Vanessa : Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis"], "multimodal aspect term extraction multimodal aspect-based sentiment classification mabsa": ["Vanessa : Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis"], "binary code similarity detection": ["Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants"], "function variant recognition": ["Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants"], "binary code similarity detection adversarial training": ["Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants"], "adversarial training function variant recognition": ["Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants"], "binary code similarity detection adversarial training function variant recognition": ["Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants"], "nutrition counseling dataset creation": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "LLM performance analysis": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "nutrition counseling dataset creation human-ai collaboration": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "human-ai collaboration safety evaluation": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "safety evaluation text quality evaluation": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "text quality evaluation LLM performance analysis": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "nutrition counseling dataset creation human-ai collaboration safety evaluation": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "human-ai collaboration safety evaluation text quality evaluation": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "safety evaluation text quality evaluation LLM performance analysis": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "nutrition counseling dataset creation human-ai collaboration safety evaluation text quality evaluation": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "human-ai collaboration safety evaluation text quality evaluation LLM performance analysis": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "nutrition counseling dataset creation human-ai collaboration safety evaluation text quality evaluation LLM performance analysis": ["Ask the experts: Sourcing a high-quality nutrition counseling dataset through Human-AI collaboration"], "multimodal dialogue summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "code-mixed data": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "image summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "hinting": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "multimodal dialogue summarization code-mixed data": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "code-mixed data healthcare": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "healthcare text summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "text summarization image summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "image summarization hinting": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "multimodal dialogue summarization code-mixed data healthcare": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "code-mixed data healthcare text summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "healthcare text summarization image summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "text summarization image summarization hinting": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "multimodal dialogue summarization code-mixed data healthcare text summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "code-mixed data healthcare text summarization image summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "healthcare text summarization image summarization hinting": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "multimodal dialogue summarization code-mixed data healthcare text summarization image summarization": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "code-mixed data healthcare text summarization image summarization hinting": ["HealthAlignSumm: Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"], "nl2code generation": ["Revisiting the Impact of Pursuing Modularity for Code Generation"], "code modularity assessment": ["Revisiting the Impact of Pursuing Modularity for Code Generation"], "nl2code generation code modularity assessment": ["Revisiting the Impact of Pursuing Modularity for Code Generation"], "length-control summarization": ["A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers"], "text summarization length-control summarization": ["A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers"], "visual storytelling evaluation": ["Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition"], "gender identity classification": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "probing": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "corpus creation": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "representation analysis": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "gender identity classification probing": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "probing corpus creation": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "corpus creation bias detection": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "bias detection representation analysis": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "gender identity classification probing corpus creation": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "probing corpus creation bias detection": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "corpus creation bias detection representation analysis": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "gender identity classification probing corpus creation bias detection": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "probing corpus creation bias detection representation analysis": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "gender identity classification probing corpus creation bias detection representation analysis": ["Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing"], "language models instruction following": ["A Recipe to Train Powerful Romanian LLMs with English Instructions"], "instruction following translation": ["A Recipe to Train Powerful Romanian LLMs with English Instructions"], "translation benchmarking": ["A Recipe to Train Powerful Romanian LLMs with English Instructions"], "language models instruction following translation": ["A Recipe to Train Powerful Romanian LLMs with English Instructions"], "instruction following translation benchmarking": ["A Recipe to Train Powerful Romanian LLMs with English Instructions"], "language models instruction following translation benchmarking": ["A Recipe to Train Powerful Romanian LLMs with English Instructions"], "online language processing": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "neurobiological research": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "human prediction mechanism": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "language modeling online language processing": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "online language processing cognitive modeling": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "cognitive modeling neurobiological research": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "neurobiological research human prediction mechanism": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "language modeling online language processing cognitive modeling": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "online language processing cognitive modeling neurobiological research": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "cognitive modeling neurobiological research human prediction mechanism": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "language modeling online language processing cognitive modeling neurobiological research": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "online language processing cognitive modeling neurobiological research human prediction mechanism": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "language modeling online language processing cognitive modeling neurobiological research human prediction mechanism": ["Generalized Measures of Anticipation and Responsivity in Online Language Processing"], "counter-response generation": ["Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling"], "troll classification": ["Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling"], "response strategy recommendation": ["Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling"], "counter-response generation troll classification": ["Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling"], "troll classification response strategy recommendation": ["Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling"], "counter-response generation troll classification response strategy recommendation": ["Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling"], "issue detection": ["SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "dialogue evaluation LLM evaluation": ["SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "LLM evaluation issue detection": ["SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "issue detection natural language generation": ["SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "dialogue evaluation LLM evaluation issue detection": ["SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "LLM evaluation issue detection natural language generation": ["SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "dialogue evaluation LLM evaluation issue detection natural language generation": ["SODA-EVAL: Open-Domain Dialogue Evaluation in the age of LLMs"], "dialog summarization": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "editing for attribution": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "question knowledge alignment": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "consistency actuality qa": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "qa dialog summarization": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "dialog summarization text generation": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "text generation editing for attribution": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "editing for attribution question knowledge alignment": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "question knowledge alignment task-oriented dialog": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "task-oriented dialog classification": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "classification knowledge-intensive tasks": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "knowledge-intensive tasks consistency actuality qa": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "qa dialog summarization text generation": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "dialog summarization text generation editing for attribution": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "text generation editing for attribution question knowledge alignment": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "editing for attribution question knowledge alignment task-oriented dialog": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "question knowledge alignment task-oriented dialog classification": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "task-oriented dialog classification knowledge-intensive tasks": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "classification knowledge-intensive tasks consistency actuality qa": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "qa dialog summarization text generation editing for attribution": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "dialog summarization text generation editing for attribution question knowledge alignment": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "text generation editing for attribution question knowledge alignment task-oriented dialog": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "editing for attribution question knowledge alignment task-oriented dialog classification": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "question knowledge alignment task-oriented dialog classification knowledge-intensive tasks": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "task-oriented dialog classification knowledge-intensive tasks consistency actuality qa": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "qa dialog summarization text generation editing for attribution question knowledge alignment": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "dialog summarization text generation editing for attribution question knowledge alignment task-oriented dialog": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "text generation editing for attribution question knowledge alignment task-oriented dialog classification": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "editing for attribution question knowledge alignment task-oriented dialog classification knowledge-intensive tasks": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "question knowledge alignment task-oriented dialog classification knowledge-intensive tasks consistency actuality qa": ["A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models"], "constituency parsing": ["Predicting generalization performance with correctness discriminators"], "semantic parsing part-of-speech tagging": ["Predicting generalization performance with correctness discriminators"], "part-of-speech tagging constituency parsing": ["Predicting generalization performance with correctness discriminators"], "semantic parsing part-of-speech tagging constituency parsing": ["Predicting generalization performance with correctness discriminators"], "q&a": ["FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models"], "reading comprehension text summarization": ["FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models"], "text summarization q&a": ["FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models"], "reading comprehension text summarization q&a": ["FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models"], "nlp systems evaluation": ["Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks"], "benchmarking nlp systems evaluation": ["Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks"], "multi-session conversation": ["Mixed-Session Conversation with Egocentric Memory"], "egocentric memory": ["Mixed-Session Conversation with Egocentric Memory"], "dialogue generation memory management": ["Mixed-Session Conversation with Egocentric Memory"], "memory management multi-session conversation": ["Mixed-Session Conversation with Egocentric Memory"], "multi-session conversation egocentric memory": ["Mixed-Session Conversation with Egocentric Memory"], "dialogue generation memory management multi-session conversation": ["Mixed-Session Conversation with Egocentric Memory"], "memory management multi-session conversation egocentric memory": ["Mixed-Session Conversation with Egocentric Memory"], "dialogue generation memory management multi-session conversation egocentric memory": ["Mixed-Session Conversation with Egocentric Memory"], "question answering dataset generation": ["CSLM: A Framework for Question Answering Dataset Generation through Collaborative Small Language Models"], "text edition": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "insertion": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "reversal": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "text edition identification": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "identification insertion": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "insertion reversal": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "reversal counting": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "text edition identification insertion": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "identification insertion reversal": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "insertion reversal counting": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "text edition identification insertion reversal": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "identification insertion reversal counting": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "text edition identification insertion reversal counting": ["Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?"], "LLMs  security": ["Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection"], "jailbreak attacks LLMs  security": ["Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection"], "self-detection": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "self-detection LLMs": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "LLMs natural language processing": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "natural language inference commonsense question answering": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "self-detection LLMs natural language processing": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "LLMs natural language processing sentiment analysis": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "natural language processing sentiment analysis natural language inference": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "sentiment analysis natural language inference commonsense question answering": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "self-detection LLMs natural language processing sentiment analysis": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "LLMs natural language processing sentiment analysis natural language inference": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "natural language processing sentiment analysis natural language inference commonsense question answering": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "self-detection LLMs natural language processing sentiment analysis natural language inference": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "LLMs natural language processing sentiment analysis natural language inference commonsense question answering": ["Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection"], "easy read text segmentation": ["Automating Easy Read Text Segmentation"], "data-centric benchmarks": ["Data-Centric AI in the Age of Large Language Models"], "data curation": ["Data-Centric AI in the Age of Large Language Models", "LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"], "data attribution": ["Data-Centric AI in the Age of Large Language Models"], "inference contextualization": ["Data-Centric AI in the Age of Large Language Models"], "data-centric benchmarks data curation": ["Data-Centric AI in the Age of Large Language Models"], "data curation data attribution": ["Data-Centric AI in the Age of Large Language Models"], "data attribution knowledge transfer": ["Data-Centric AI in the Age of Large Language Models"], "knowledge transfer inference contextualization": ["Data-Centric AI in the Age of Large Language Models"], "data-centric benchmarks data curation data attribution": ["Data-Centric AI in the Age of Large Language Models"], "data curation data attribution knowledge transfer": ["Data-Centric AI in the Age of Large Language Models"], "data attribution knowledge transfer inference contextualization": ["Data-Centric AI in the Age of Large Language Models"], "data-centric benchmarks data curation data attribution knowledge transfer": ["Data-Centric AI in the Age of Large Language Models"], "data curation data attribution knowledge transfer inference contextualization": ["Data-Centric AI in the Age of Large Language Models"], "data-centric benchmarks data curation data attribution knowledge transfer inference contextualization": ["Data-Centric AI in the Age of Large Language Models"], "math word problem generation": ["MATHWELL: Generating Educational Math Word Problems Using Teacher Annotations"], "instruction following error correction": ["Resilience of Large Language Models for Noisy Instructions"], "error correction noise robustness": ["Resilience of Large Language Models for Noisy Instructions"], "natural language processing instruction following error correction": ["Resilience of Large Language Models for Noisy Instructions"], "instruction following error correction noise robustness": ["Resilience of Large Language Models for Noisy Instructions"], "natural language processing instruction following error correction noise robustness": ["Resilience of Large Language Models for Noisy Instructions"], "ensemble of LLMs": ["LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"], "ensemble of LLMs question answering": ["LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"], "ensemble of LLMs question answering code generation": ["LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"], "question answering code generation summarization": ["LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"], "ensemble of LLMs question answering code generation summarization": ["LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity"], "object replacement": ["Creative Problem Solving in Large Language and Vision Models \u2013 What Would it Take?"], "cross-lingual question answering": ["Cross-Lingual Multi-Hop Knowledge Editing"], "knowledge editing cross-lingual question answering": ["Cross-Lingual Multi-Hop Knowledge Editing"], "cross-lingual question answering multi-hop reasoning": ["Cross-Lingual Multi-Hop Knowledge Editing"], "knowledge editing cross-lingual question answering multi-hop reasoning": ["Cross-Lingual Multi-Hop Knowledge Editing"], "gui navigation": ["Android in the Zoo: Chain-of-Action-Thought for GUI Agents"], "self-recognition assessment in lms": ["Self-Recognition in Language Models"], "math word problems": ["Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning", "Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths"], "math word problems question answering": ["Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning"], "language phylogeny reconstruction": ["The Shape of Word Embeddings: Quantifying Non-Isometry With Topological Data Analysis"], "non-isometry quantification": ["The Shape of Word Embeddings: Quantifying Non-Isometry With Topological Data Analysis"], "language phylogeny reconstruction non-isometry quantification": ["The Shape of Word Embeddings: Quantifying Non-Isometry With Topological Data Analysis"], "unlearning evaluation": ["Towards Robust Evaluation of Unlearning in LLMs via Data Transformations"], "data transformation": ["Towards Robust Evaluation of Unlearning in LLMs via Data Transformations"], "unlearning evaluation data transformation": ["Towards Robust Evaluation of Unlearning in LLMs via Data Transformations"], "quantity-aware ranking": ["Numbers Matter! Bringing Quantity-awareness to Retrieval Systems"], "quantity-aware ranking information retrieval": ["Numbers Matter! Bringing Quantity-awareness to Retrieval Systems"], "multi-modal dialogue": ["STARK: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge"], "persona-grounded conversation": ["STARK: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge"], "multi-modal dialogue persona-grounded conversation": ["STARK: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge"], "persona-grounded conversation dialogue-to-image retrieval": ["STARK: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge"], "multi-modal dialogue persona-grounded conversation dialogue-to-image retrieval": ["STARK: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge"], "subjectivity classification": ["Dual-Phase Accelerated Prompt Optimization"], "salient translation": ["Dual-Phase Accelerated Prompt Optimization", "Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "sentiment classification topic classification": ["Dual-Phase Accelerated Prompt Optimization"], "topic classification question answering": ["Dual-Phase Accelerated Prompt Optimization"], "question answering subjectivity classification": ["Dual-Phase Accelerated Prompt Optimization"], "subjectivity classification logical inference": ["Dual-Phase Accelerated Prompt Optimization"], "logical inference paraphrasing": ["Dual-Phase Accelerated Prompt Optimization"], "paraphrasing disambiguation": ["Dual-Phase Accelerated Prompt Optimization"], "disambiguation salient translation": ["Dual-Phase Accelerated Prompt Optimization"], "salient translation geometric shapes": ["Dual-Phase Accelerated Prompt Optimization"], "sentiment classification topic classification question answering": ["Dual-Phase Accelerated Prompt Optimization"], "topic classification question answering subjectivity classification": ["Dual-Phase Accelerated Prompt Optimization"], "question answering subjectivity classification logical inference": ["Dual-Phase Accelerated Prompt Optimization"], "subjectivity classification logical inference paraphrasing": ["Dual-Phase Accelerated Prompt Optimization"], "logical inference paraphrasing disambiguation": ["Dual-Phase Accelerated Prompt Optimization"], "paraphrasing disambiguation salient translation": ["Dual-Phase Accelerated Prompt Optimization"], "disambiguation salient translation geometric shapes": ["Dual-Phase Accelerated Prompt Optimization"], "sentiment classification topic classification question answering subjectivity classification": ["Dual-Phase Accelerated Prompt Optimization"], "topic classification question answering subjectivity classification logical inference": ["Dual-Phase Accelerated Prompt Optimization"], "question answering subjectivity classification logical inference paraphrasing": ["Dual-Phase Accelerated Prompt Optimization"], "subjectivity classification logical inference paraphrasing disambiguation": ["Dual-Phase Accelerated Prompt Optimization"], "logical inference paraphrasing disambiguation salient translation": ["Dual-Phase Accelerated Prompt Optimization"], "paraphrasing disambiguation salient translation geometric shapes": ["Dual-Phase Accelerated Prompt Optimization"], "sentiment classification topic classification question answering subjectivity classification logical inference": ["Dual-Phase Accelerated Prompt Optimization"], "topic classification question answering subjectivity classification logical inference paraphrasing": ["Dual-Phase Accelerated Prompt Optimization"], "question answering subjectivity classification logical inference paraphrasing disambiguation": ["Dual-Phase Accelerated Prompt Optimization"], "subjectivity classification logical inference paraphrasing disambiguation salient translation": ["Dual-Phase Accelerated Prompt Optimization"], "logical inference paraphrasing disambiguation salient translation geometric shapes": ["Dual-Phase Accelerated Prompt Optimization"], "anomaly": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "distribution": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "correlation": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "determine range": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "order": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "filter": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "extremum": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "cluster": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "reasoning anomaly": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "anomaly distribution": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "distribution correlation": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "correlation determine range": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "determine range order": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "order filter": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "filter retrieval": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "retrieval extremum": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "extremum cluster": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "reasoning anomaly distribution": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "anomaly distribution correlation": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "distribution correlation determine range": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "correlation determine range order": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "determine range order filter": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "order filter retrieval": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "filter retrieval extremum": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "retrieval extremum cluster": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "reasoning anomaly distribution correlation": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "anomaly distribution correlation determine range": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "distribution correlation determine range order": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "correlation determine range order filter": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "determine range order filter retrieval": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "order filter retrieval extremum": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "filter retrieval extremum cluster": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "reasoning anomaly distribution correlation determine range": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "anomaly distribution correlation determine range order": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "distribution correlation determine range order filter": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "correlation determine range order filter retrieval": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "determine range order filter retrieval extremum": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "order filter retrieval extremum cluster": ["ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering"], "cross-cultural communication": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "pragmatic reasoning": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "codenames duet\\": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "cross-cultural communication pragmatic reasoning": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "pragmatic reasoning game playing": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "game playing codenames duet\\": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "cross-cultural communication pragmatic reasoning game playing": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "pragmatic reasoning game playing codenames duet\\": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "cross-cultural communication pragmatic reasoning game playing codenames duet\\": ["Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication\\"], "media-level political bias": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level factuality": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "article-level political bias": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "article-level factuality": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "joint modeling at article-level": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level political bias media-level factuality": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level factuality article-level political bias": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "article-level political bias article-level factuality": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "article-level factuality joint modeling at article-level": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level political bias media-level factuality article-level political bias": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level factuality article-level political bias article-level factuality": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "article-level political bias article-level factuality joint modeling at article-level": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level political bias media-level factuality article-level political bias article-level factuality": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level factuality article-level political bias article-level factuality joint modeling at article-level": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "media-level political bias media-level factuality article-level political bias article-level factuality joint modeling at article-level": ["SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles"], "topic-following": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "rule-following": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "dialogue systems topic-following": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "topic-following instruction tuning": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "instruction tuning safety alignment": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "safety alignment content moderation": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "content moderation rule-following": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "dialogue systems topic-following instruction tuning": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "topic-following instruction tuning safety alignment": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "instruction tuning safety alignment content moderation": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "safety alignment content moderation rule-following": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "dialogue systems topic-following instruction tuning safety alignment": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "topic-following instruction tuning safety alignment content moderation": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "instruction tuning safety alignment content moderation rule-following": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "dialogue systems topic-following instruction tuning safety alignment content moderation": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "topic-following instruction tuning safety alignment content moderation rule-following": ["CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"], "zero-shot cross-lingual stance detection": ["An LLM-Enabled Knowledge Elicitation and Retrieval Framework for Zero-Shot Cross-Lingual Stance Identification"], "evaluation fine-tuning": ["TuringQ: Benchmarking AI Comprehension in Theory of Computation"], "question answering evaluation fine-tuning": ["TuringQ: Benchmarking AI Comprehension in Theory of Computation"], "document summarization": ["Learning to Refine with Fine-Grained Natural Language Feedback"], "factual consistency refinement": ["Learning to Refine with Fine-Grained Natural Language Feedback"], "document summarization factual consistency refinement": ["Learning to Refine with Fine-Grained Natural Language Feedback"], "education disparity": ["Implicit Personalization in Language Models: A Systematic Study"], "echo chamber": ["Implicit Personalization in Language Models: A Systematic Study"], "cultural adaptation education disparity": ["Implicit Personalization in Language Models: A Systematic Study"], "education disparity echo chamber": ["Implicit Personalization in Language Models: A Systematic Study"], "cultural adaptation education disparity echo chamber": ["Implicit Personalization in Language Models: A Systematic Study"], "predicate-argument structure analysis": ["When the Misidentified Adverbial Phrase Functions as a Complement"], "syntactic parsing": ["When the Misidentified Adverbial Phrase Functions as a Complement"], "predicate-argument structure analysis syntactic parsing": ["When the Misidentified Adverbial Phrase Functions as a Complement"], "syntactic parsing semantic role labeling": ["When the Misidentified Adverbial Phrase Functions as a Complement"], "predicate-argument structure analysis syntactic parsing semantic role labeling": ["When the Misidentified Adverbial Phrase Functions as a Complement"], "table summarization": ["Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization"], "knowledge mining": ["Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization"], "table summarization knowledge mining": ["Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization"], "pairwise ranking information retrieval": ["Few-shot Prompting for Pairwise Ranking: An Effective Non-Parametric Retrieval Model"], "arithmetic reasoning self-training": ["Self-training Language Models for Arithmetic Reasoning"], "pptc robustness evaluation": ["PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion"], "software version robustness": ["PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion"], "pptc robustness evaluation adversarial robustness": ["PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion"], "adversarial robustness software version robustness": ["PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion"], "pptc robustness evaluation adversarial robustness software version robustness": ["PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion"], "LLM deployment": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "weight-only quantization": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "mixed-type matrix multiplication": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "kernel optimization": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "LLM deployment weight-only quantization": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "weight-only quantization mixed-type matrix multiplication": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "mixed-type matrix multiplication kernel optimization": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "LLM deployment weight-only quantization mixed-type matrix multiplication": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "weight-only quantization mixed-type matrix multiplication kernel optimization": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "LLM deployment weight-only quantization mixed-type matrix multiplication kernel optimization": ["Fast Matrix Multiplications for Lookup Table-Quantized LLMs"], "out-of-distribution detection": ["Distance-aware Calibration for Pre-trained Language Models", "Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression", "CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text"], "text classification calibration": ["Distance-aware Calibration for Pre-trained Language Models"], "calibration out-of-distribution detection": ["Distance-aware Calibration for Pre-trained Language Models"], "text classification calibration out-of-distribution detection": ["Distance-aware Calibration for Pre-trained Language Models"], "drug name interchangeability": ["Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks"], "medical question answering robustness evaluation": ["Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks"], "robustness evaluation drug name interchangeability": ["Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks"], "medical question answering robustness evaluation drug name interchangeability": ["Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks"], "artificial error generation": ["To Err Is Human, but Llamas Can Learn It Too"], "grammatical error correction artificial error generation": ["To Err Is Human, but Llamas Can Learn It Too"], "procedural text comprehension": ["PizzaCommonSense: Learning to Model Commonsense Reasoning about Intermediate Steps in Cooking Recipes"], "input-output prediction": ["PizzaCommonSense: Learning to Model Commonsense Reasoning about Intermediate Steps in Cooking Recipes"], "procedural text comprehension commonsense reasoning": ["PizzaCommonSense: Learning to Model Commonsense Reasoning about Intermediate Steps in Cooking Recipes"], "commonsense reasoning input-output prediction": ["PizzaCommonSense: Learning to Model Commonsense Reasoning about Intermediate Steps in Cooking Recipes"], "procedural text comprehension commonsense reasoning input-output prediction": ["PizzaCommonSense: Learning to Model Commonsense Reasoning about Intermediate Steps in Cooking Recipes"], "discourse dependency parsing": ["Enhancing Discourse Dependency Parsing with Sentence Dependency Parsing: A Unified Generative Method Based on Code Representation"], "sentence-level dependency parsing": ["Enhancing Discourse Dependency Parsing with Sentence Dependency Parsing: A Unified Generative Method Based on Code Representation"], "discourse dependency parsing sentence-level dependency parsing": ["Enhancing Discourse Dependency Parsing with Sentence Dependency Parsing: A Unified Generative Method Based on Code Representation"], "rag robustness evaluation": ["\"Knowing When You Don't Know\u201d: A Multilingual Relevance Assessment Dataset for Robust Retrieval-Augmented Generation"], "dialogue state tracking zero-shot learning": ["Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking"], "zero-shot learning data generation": ["Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking"], "dialogue state tracking zero-shot learning data generation": ["Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking"], "multi-attribute controllable text generation": ["TARA: Token-level Attribute Relation Adaptation for Multi-Attribute Controllable Text Generation"], "multi-hop fact verification": ["Denoising Rationalization for Multi-hop Fact Verification via Multi-granular Explainer"], "rationalization": ["Denoising Rationalization for Multi-hop Fact Verification via Multi-granular Explainer"], "multi-hop fact verification rationalization": ["Denoising Rationalization for Multi-hop Fact Verification via Multi-granular Explainer"], "lay definition generation": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "knowledge gap reduction": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "lay definition generation text simplification": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "text simplification data augmentation": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "data augmentation knowledge gap reduction": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "knowledge gap reduction human-ai collaboration": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "lay definition generation text simplification data augmentation": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "text simplification data augmentation knowledge gap reduction": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "data augmentation knowledge gap reduction human-ai collaboration": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "lay definition generation text simplification data augmentation knowledge gap reduction": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "text simplification data augmentation knowledge gap reduction human-ai collaboration": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "lay definition generation text simplification data augmentation knowledge gap reduction human-ai collaboration": ["README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP"], "knowledge-grounded dialogue summarization": ["Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts"], "summarization natural language generation": ["Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts"], "knowledge-grounded dialogue summarization natural language generation": ["Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts"], "LLM evaluation bias detection": ["Cognitive Bias in Decision-Making with LLMs"], "LLM evaluation bias detection bias mitigation": ["Cognitive Bias in Decision-Making with LLMs"], "problem-oriented segmentation & retrieval": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "conversation structure analysis": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "discourse segmentation": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "joint task modeling": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "education application": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "language analysis": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "time management": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "problem-oriented segmentation & retrieval conversation structure analysis": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "conversation structure analysis discourse segmentation": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "discourse segmentation information retrieval": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "information retrieval joint task modeling": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "joint task modeling education application": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "education application language analysis": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "language analysis time management": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "problem-oriented segmentation & retrieval conversation structure analysis discourse segmentation": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "conversation structure analysis discourse segmentation information retrieval": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "discourse segmentation information retrieval joint task modeling": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "information retrieval joint task modeling education application": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "joint task modeling education application language analysis": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "education application language analysis time management": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "problem-oriented segmentation & retrieval conversation structure analysis discourse segmentation information retrieval": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "conversation structure analysis discourse segmentation information retrieval joint task modeling": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "discourse segmentation information retrieval joint task modeling education application": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "information retrieval joint task modeling education application language analysis": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "joint task modeling education application language analysis time management": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "problem-oriented segmentation & retrieval conversation structure analysis discourse segmentation information retrieval joint task modeling": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "conversation structure analysis discourse segmentation information retrieval joint task modeling education application": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "discourse segmentation information retrieval joint task modeling education application language analysis": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "information retrieval joint task modeling education application language analysis time management": ["Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"], "long document processing": ["Can't Remember Details in Long Documents? You Need Some R&R"], "question answering long document processing": ["Can't Remember Details in Long Documents? You Need Some R&R"], "long document processing in-context retrieval": ["Can't Remember Details in Long Documents? You Need Some R&R"], "in-context retrieval prompt engineering": ["Can't Remember Details in Long Documents? You Need Some R&R"], "question answering long document processing in-context retrieval": ["Can't Remember Details in Long Documents? You Need Some R&R"], "long document processing in-context retrieval prompt engineering": ["Can't Remember Details in Long Documents? You Need Some R&R"], "question answering long document processing in-context retrieval prompt engineering": ["Can't Remember Details in Long Documents? You Need Some R&R"], "relevance classification": ["HUMVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid"], "category classification": ["HUMVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid"], "relevance classification category classification": ["HUMVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid"], "quotation attribution": ["Improving Quotation Attribution with Fictional Character Embeddings"], "text classification robustness analysis": ["Robust Text Classification: Analyzing Prototype-Based Networks"], "robustness analysis adversarial attack": ["Robust Text Classification: Analyzing Prototype-Based Networks"], "text classification robustness analysis adversarial attack": ["Robust Text Classification: Analyzing Prototype-Based Networks"], "agent-based reasoning": ["GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "long-context question answering multi-hop reasoning": ["GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "multi-hop reasoning knowledge graph reasoning": ["GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "knowledge graph reasoning agent-based reasoning": ["GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "long-context question answering multi-hop reasoning knowledge graph reasoning": ["GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "multi-hop reasoning knowledge graph reasoning agent-based reasoning": ["GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "long-context question answering multi-hop reasoning knowledge graph reasoning agent-based reasoning": ["GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"], "pairwise preference judgment analysis": ["Compare without Despair: Reliable Preference Evaluation with Generation SEPARABILITY"], "LLM evaluation pairwise preference judgment analysis": ["Compare without Despair: Reliable Preference Evaluation with Generation SEPARABILITY"], "instructeval": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-1k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-a": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-c": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-r": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-v2": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-sketch": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "stylized-imagenet": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "squad drop": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "drop gsm8k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "gsm8k instructeval": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "instructeval imagenet-1k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-1k imagenet-a": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-a imagenet-c": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-c imagenet-r": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-r imagenet-v2": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-v2 imagenet-sketch": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-sketch stylized-imagenet": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "superglue squad drop": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "squad drop gsm8k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "drop gsm8k instructeval": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "gsm8k instructeval imagenet-1k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "instructeval imagenet-1k imagenet-a": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-1k imagenet-a imagenet-c": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-a imagenet-c imagenet-r": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-c imagenet-r imagenet-v2": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-r imagenet-v2 imagenet-sketch": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-v2 imagenet-sketch stylized-imagenet": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "superglue squad drop gsm8k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "squad drop gsm8k instructeval": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "drop gsm8k instructeval imagenet-1k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "gsm8k instructeval imagenet-1k imagenet-a": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "instructeval imagenet-1k imagenet-a imagenet-c": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-1k imagenet-a imagenet-c imagenet-r": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-a imagenet-c imagenet-r imagenet-v2": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-c imagenet-r imagenet-v2 imagenet-sketch": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-r imagenet-v2 imagenet-sketch stylized-imagenet": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "superglue squad drop gsm8k instructeval": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "squad drop gsm8k instructeval imagenet-1k": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "drop gsm8k instructeval imagenet-1k imagenet-a": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "gsm8k instructeval imagenet-1k imagenet-a imagenet-c": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "instructeval imagenet-1k imagenet-a imagenet-c imagenet-r": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-1k imagenet-a imagenet-c imagenet-r imagenet-v2": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-a imagenet-c imagenet-r imagenet-v2 imagenet-sketch": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "imagenet-c imagenet-r imagenet-v2 imagenet-sketch stylized-imagenet": ["LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning"], "low-precision sparse parameter-efficient fine-tuning of large pre-trained models": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "model adaptation": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "boolean questions": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "physical interaction question answering": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "simple variations on arithmetic math word problems": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "low-precision sparse parameter-efficient fine-tuning of large pre-trained models model adaptation": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "model adaptation language understanding": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "language understanding code generation": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "code generation math reasoning": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "commonsense reasoning boolean questions": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "boolean questions physical interaction question answering": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "physical interaction question answering simple variations on arithmetic math word problems": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "low-precision sparse parameter-efficient fine-tuning of large pre-trained models model adaptation language understanding": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "model adaptation language understanding code generation": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "language understanding code generation math reasoning": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "code generation math reasoning commonsense reasoning": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "math reasoning commonsense reasoning boolean questions": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "commonsense reasoning boolean questions physical interaction question answering": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "boolean questions physical interaction question answering simple variations on arithmetic math word problems": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "low-precision sparse parameter-efficient fine-tuning of large pre-trained models model adaptation language understanding code generation": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "model adaptation language understanding code generation math reasoning": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "language understanding code generation math reasoning commonsense reasoning": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "code generation math reasoning commonsense reasoning boolean questions": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "math reasoning commonsense reasoning boolean questions physical interaction question answering": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "commonsense reasoning boolean questions physical interaction question answering simple variations on arithmetic math word problems": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "low-precision sparse parameter-efficient fine-tuning of large pre-trained models model adaptation language understanding code generation math reasoning": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "model adaptation language understanding code generation math reasoning commonsense reasoning": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "language understanding code generation math reasoning commonsense reasoning boolean questions": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "code generation math reasoning commonsense reasoning boolean questions physical interaction question answering": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "math reasoning commonsense reasoning boolean questions physical interaction question answering simple variations on arithmetic math word problems": ["SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models"], "language modeling dialogue generation": ["Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "dialogue generation backdoor attack": ["Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "backdoor attack multi-turn dialogue": ["Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "language modeling dialogue generation backdoor attack": ["Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "dialogue generation backdoor attack multi-turn dialogue": ["Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "language modeling dialogue generation backdoor attack multi-turn dialogue": ["Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers"], "factual question answering": ["InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "factual question answering commonsense reasoning": ["InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "reading comprehension hallucination detection": ["InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "factual question answering commonsense reasoning reading comprehension": ["InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "commonsense reasoning reading comprehension hallucination detection": ["InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "factual question answering commonsense reasoning reading comprehension hallucination detection": ["InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States"], "text classification data augmentation": ["All You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification"], "parts of speech analysis": ["Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation"], "text-to-image generation adversarial attacks": ["Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation"], "adversarial attacks parts of speech analysis": ["Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation"], "text-to-image generation adversarial attacks parts of speech analysis": ["Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation"], "curriculum learning": ["Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "LLM alignment preference optimization": ["Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "preference optimization curriculum learning": ["Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "curriculum learning direct preference optimization": ["Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "LLM alignment preference optimization curriculum learning": ["Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "preference optimization curriculum learning direct preference optimization": ["Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "LLM alignment preference optimization curriculum learning direct preference optimization": ["Enhancing Alignment using Curriculum Learning & Ranked Preferences"], "multi-target summarization": ["Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach"], "semantic coherence": ["Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach"], "cross-lingual summarization multi-target summarization": ["Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach"], "multi-target summarization semantic coherence": ["Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach"], "cross-lingual summarization multi-target summarization semantic coherence": ["Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach"], "tabular data": ["TAB2TEXT - A framework for deep learning with tabular data"], "text data": ["TAB2TEXT - A framework for deep learning with tabular data"], "prediction": ["TAB2TEXT - A framework for deep learning with tabular data"], "tabular data text data": ["TAB2TEXT - A framework for deep learning with tabular data"], "text data prediction": ["TAB2TEXT - A framework for deep learning with tabular data"], "tabular data text data prediction": ["TAB2TEXT - A framework for deep learning with tabular data"], "multimodal RAG": ["Synthetic Multimodal Question Generation"], "multimodal RAG question answering": ["Synthetic Multimodal Question Generation"], "question answering synthetic data generation": ["Synthetic Multimodal Question Generation"], "multimodal RAG question answering synthetic data generation": ["Synthetic Multimodal Question Generation"], "molecule retrieval": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecule captioning": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecular binary and multi-class classification": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecule retrieval molecule captioning": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecule captioning molecular binary and multi-class classification": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecular binary and multi-class classification molecular property prediction": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecule retrieval molecule captioning molecular binary and multi-class classification": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecule captioning molecular binary and multi-class classification molecular property prediction": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "molecule retrieval molecule captioning molecular binary and multi-class classification molecular property prediction": ["Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures"], "context ranking": ["HyQE: Ranking Contexts with Hypothetical Query Embeddings"], "context ranking information retrieval": ["HyQE: Ranking Contexts with Hypothetical Query Embeddings"], "model merging safety alignment": ["Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "safety alignment natural language processing": ["Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "natural language processing LLM alignment": ["Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "model merging safety alignment natural language processing": ["Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "safety alignment natural language processing LLM alignment": ["Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "model merging safety alignment natural language processing LLM alignment": ["Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"], "habitat reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "affordance reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "habitat reasoning affordance reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "affordance reasoning visual reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "visual reasoning multimodal reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "habitat reasoning affordance reasoning visual reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "affordance reasoning visual reasoning multimodal reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "habitat reasoning affordance reasoning visual reasoning multimodal reasoning": ["Large Language Models Are Challenged by Habitat-Centered Reasoning"], "fact-checking misinformation detection": ["How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"], "misinformation detection toxicity detection": ["How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"], "toxicity detection stance detection": ["How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"], "fact-checking misinformation detection toxicity detection": ["How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"], "misinformation detection toxicity detection stance detection": ["How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"], "fact-checking misinformation detection toxicity detection stance detection": ["How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"], "cultural awareness": ["Benchmarking Machine Translation with Cultural Awareness"], "machine translation cultural awareness": ["Benchmarking Machine Translation with Cultural Awareness"], "single-turn dialogue": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "single-turn dialogue sentence simplification": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "sentence simplification extractive question answering": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "extractive question answering commonsense reasoning": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "commonsense reasoning natural language inference": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "single-turn dialogue sentence simplification extractive question answering": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "sentence simplification extractive question answering commonsense reasoning": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "extractive question answering commonsense reasoning natural language inference": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "single-turn dialogue sentence simplification extractive question answering commonsense reasoning": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "sentence simplification extractive question answering commonsense reasoning natural language inference": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "single-turn dialogue sentence simplification extractive question answering commonsense reasoning natural language inference": ["Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?"], "text generation knowledge distillation": ["Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "knowledge distillation speculative decoding": ["Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "speculative decoding language modeling": ["Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "text generation knowledge distillation speculative decoding": ["Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "knowledge distillation speculative decoding language modeling": ["Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "text generation knowledge distillation speculative decoding language modeling": ["Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation"], "intent detection data augmentation": ["Generate then Refine: Data Augmentation for Zero-shot Intent Detection"], "data augmentation zero-shot learning": ["Generate then Refine: Data Augmentation for Zero-shot Intent Detection"], "intent detection data augmentation zero-shot learning": ["Generate then Refine: Data Augmentation for Zero-shot Intent Detection"], "relation extraction zero-shot learning": ["Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"], "zero-shot learning prompting": ["Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"], "relation extraction zero-shot learning prompting": ["Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"], "document information extraction": ["\u201cWhat is the value of {templates}?\u201d Rethinking Document Information Extraction Datasets for LLMs"], "key information extraction": ["\u201cWhat is the value of {templates}?\u201d Rethinking Document Information Extraction Datasets for LLMs", "AliGATr: Graph-based layout generation for form understanding"], "document information extraction key information extraction": ["\u201cWhat is the value of {templates}?\u201d Rethinking Document Information Extraction Datasets for LLMs"], "key information extraction visual question answering": ["\u201cWhat is the value of {templates}?\u201d Rethinking Document Information Extraction Datasets for LLMs"], "document information extraction key information extraction visual question answering": ["\u201cWhat is the value of {templates}?\u201d Rethinking Document Information Extraction Datasets for LLMs"], "evaluating language models": ["What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models"], "knowledge probing evaluating language models": ["What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models"], "evaluating language models fact recall": ["What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models"], "knowledge probing evaluating language models fact recall": ["What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models"], "benchmark contamination analysis": ["On Leakage of Code Generation Evaluation Datasets"], "code generation benchmark contamination analysis": ["On Leakage of Code Generation Evaluation Datasets"], "benchmark contamination analysis dataset curation": ["On Leakage of Code Generation Evaluation Datasets"], "code generation benchmark contamination analysis dataset curation": ["On Leakage of Code Generation Evaluation Datasets"], "traumatic event detection": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "cross-domain transferability": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "identification of trauma mechanisms": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "traumatic event detection cross-domain transferability": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "cross-domain transferability identification of trauma mechanisms": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "identification of trauma mechanisms binary classification": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "traumatic event detection cross-domain transferability identification of trauma mechanisms": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "cross-domain transferability identification of trauma mechanisms binary classification": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "traumatic event detection cross-domain transferability identification of trauma mechanisms binary classification": ["The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"], "casual judgement": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "boolean expressions evaluation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "snarks": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "reasoning casual judgement": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "casual judgement boolean expressions evaluation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "boolean expressions evaluation object counting": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "object counting snarks": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "snarks disambiguation qa": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "disambiguation qa movie recommendation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "movie recommendation date understanding": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "date understanding salient translation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "reasoning casual judgement boolean expressions evaluation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "casual judgement boolean expressions evaluation object counting": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "boolean expressions evaluation object counting snarks": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "object counting snarks disambiguation qa": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "snarks disambiguation qa movie recommendation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "disambiguation qa movie recommendation date understanding": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "movie recommendation date understanding salient translation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "reasoning casual judgement boolean expressions evaluation object counting": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "casual judgement boolean expressions evaluation object counting snarks": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "boolean expressions evaluation object counting snarks disambiguation qa": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "object counting snarks disambiguation qa movie recommendation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "snarks disambiguation qa movie recommendation date understanding": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "disambiguation qa movie recommendation date understanding salient translation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "reasoning casual judgement boolean expressions evaluation object counting snarks": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "casual judgement boolean expressions evaluation object counting snarks disambiguation qa": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "boolean expressions evaluation object counting snarks disambiguation qa movie recommendation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "object counting snarks disambiguation qa movie recommendation date understanding": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "snarks disambiguation qa movie recommendation date understanding salient translation": ["Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework"], "region description": ["V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization"], "visual question answering region description": ["V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization"], "region description object hallucination detection": ["V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization"], "visual question answering region description object hallucination detection": ["V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization"], "multimodal scientific asr": ["Exploring the Potential of Multimodal LLM with Knowledge-Intensive Multimodal ASR"], "backtranslation": ["Better Alignment with Instruction Back-and-Forth Translation"], "alignment synthetic data generation": ["Better Alignment with Instruction Back-and-Forth Translation"], "synthetic data generation backtranslation": ["Better Alignment with Instruction Back-and-Forth Translation"], "instruction tuning LLMs alignment": ["Better Alignment with Instruction Back-and-Forth Translation"], "LLMs alignment synthetic data generation": ["Better Alignment with Instruction Back-and-Forth Translation"], "alignment synthetic data generation backtranslation": ["Better Alignment with Instruction Back-and-Forth Translation"], "instruction tuning LLMs alignment synthetic data generation": ["Better Alignment with Instruction Back-and-Forth Translation"], "LLMs alignment synthetic data generation backtranslation": ["Better Alignment with Instruction Back-and-Forth Translation"], "instruction tuning LLMs alignment synthetic data generation backtranslation": ["Better Alignment with Instruction Back-and-Forth Translation"], "key information extraction relation extraction": ["AliGATr: Graph-based layout generation for form understanding"], "attribute control": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "detoxification attribute control": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "attribute control language modeling": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "language modeling toxicity detection": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "toxicity detection text generation": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "detoxification attribute control language modeling": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "attribute control language modeling toxicity detection": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "language modeling toxicity detection text generation": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "detoxification attribute control language modeling toxicity detection": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "attribute control language modeling toxicity detection text generation": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "detoxification attribute control language modeling toxicity detection text generation": ["Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"], "scientific diagram generation": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "diagram refinement": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "human-computer interaction": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "scientific diagram generation diagram refinement": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "diagram refinement information extraction": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "information extraction code generation": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "code generation human-computer interaction": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "scientific diagram generation diagram refinement information extraction": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "diagram refinement information extraction code generation": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "information extraction code generation human-computer interaction": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "scientific diagram generation diagram refinement information extraction code generation": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "diagram refinement information extraction code generation human-computer interaction": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "scientific diagram generation diagram refinement information extraction code generation human-computer interaction": ["SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement"], "authorship transfer": ["TINYSTYLER: Efficient Few-Shot Text Style Transfer with Authorship Embeddings"], "formality transfer": ["TINYSTYLER: Efficient Few-Shot Text Style Transfer with Authorship Embeddings"], "text style transfer authorship transfer": ["TINYSTYLER: Efficient Few-Shot Text Style Transfer with Authorship Embeddings"], "authorship transfer formality transfer": ["TINYSTYLER: Efficient Few-Shot Text Style Transfer with Authorship Embeddings"], "text style transfer authorship transfer formality transfer": ["TINYSTYLER: Efficient Few-Shot Text Style Transfer with Authorship Embeddings"], "emphasis understanding": ["Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?"], "implication modeling": ["Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?"], "emphasis understanding dialogue understanding": ["Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?"], "dialogue understanding implication modeling": ["Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?"], "emphasis understanding dialogue understanding implication modeling": ["Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?"], "multilingual fidelity": ["Why do LLaVA Vision-Language Models Reply to Images in English?"], "visual question answering multilingual fidelity": ["Why do LLaVA Vision-Language Models Reply to Images in English?"], "toxicity mitigation": ["Preference Tuning For Toxicity Mitigation Generalizes Across Languages"], "cross-lingual generalization": ["Preference Tuning For Toxicity Mitigation Generalizes Across Languages"], "toxicity mitigation cross-lingual generalization": ["Preference Tuning For Toxicity Mitigation Generalizes Across Languages"], "calibration long-form generation": ["Calibrating Long-form Generations from Large Language Models"], "calibration long-form generation question answering": ["Calibrating Long-form Generations from Large Language Models"], "calibration long-form generation question answering summarization": ["Calibrating Long-form Generations from Large Language Models"], "multimodal recommendation": ["Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation"], "representation learning": ["Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation"], "sequential recommendation multimodal recommendation": ["Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation"], "multimodal recommendation representation learning": ["Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation"], "sequential recommendation multimodal recommendation representation learning": ["Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation"], "language modeling quantization": ["Exploring Quantization for Efficient Pre-Training of Transformer Language Models"], "quantization pre-training": ["Exploring Quantization for Efficient Pre-Training of Transformer Language Models"], "language modeling quantization pre-training": ["Exploring Quantization for Efficient Pre-Training of Transformer Language Models"], "video-text alignment": ["Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding"], "story understanding": ["Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding"], "video-text alignment story understanding": ["Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding"], "story understanding multilingual learning": ["Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding"], "video-text alignment story understanding multilingual learning": ["Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding"], "visual perception evaluation": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "multi-level perception analysis": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "benchmark construction": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "visual perception evaluation multi-level perception analysis": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "multi-level perception analysis image understanding": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "image understanding benchmark construction": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "visual perception evaluation multi-level perception analysis image understanding": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "multi-level perception analysis image understanding benchmark construction": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "visual perception evaluation multi-level perception analysis image understanding benchmark construction": ["MVP-Bench: Can Large Vision\u2013Language Models Conduct Multi-level Visual Perception Like Humans?"], "topic coherence evaluation": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "hierarchical topic reduction": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "topic modeling topic coherence evaluation": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "topic coherence evaluation topic segmentation": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "topic segmentation hierarchical topic reduction": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "topic modeling topic coherence evaluation topic segmentation": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "topic coherence evaluation topic segmentation hierarchical topic reduction": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "topic modeling topic coherence evaluation topic segmentation hierarchical topic reduction": ["Topic Modeling: Contextual Token Embeddings Are All You Need"], "mt-bench": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback", "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "rewardbench": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "mt-bench rewardbench": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "rewardbench model alignment": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "model alignment preference optimization": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "preference optimization reinforcement learning from human feedback": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "mt-bench rewardbench model alignment": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "rewardbench model alignment preference optimization": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "model alignment preference optimization reinforcement learning from human feedback": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "mt-bench rewardbench model alignment preference optimization": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "rewardbench model alignment preference optimization reinforcement learning from human feedback": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "mt-bench rewardbench model alignment preference optimization reinforcement learning from human feedback": ["Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback"], "instruction tuning machine translation": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "machine translation news topic classification": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "news topic classification sentiment analysis": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "question answering part-of-speech tagging": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "named entity recognition summarization": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "instruction tuning machine translation news topic classification": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "machine translation news topic classification sentiment analysis": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "news topic classification sentiment analysis question answering": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "sentiment analysis question answering part-of-speech tagging": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "question answering part-of-speech tagging named entity recognition": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "part-of-speech tagging named entity recognition summarization": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "instruction tuning machine translation news topic classification sentiment analysis": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "machine translation news topic classification sentiment analysis question answering": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "news topic classification sentiment analysis question answering part-of-speech tagging": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "sentiment analysis question answering part-of-speech tagging named entity recognition": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "question answering part-of-speech tagging named entity recognition summarization": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "instruction tuning machine translation news topic classification sentiment analysis question answering": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "machine translation news topic classification sentiment analysis question answering part-of-speech tagging": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "news topic classification sentiment analysis question answering part-of-speech tagging named entity recognition": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "sentiment analysis question answering part-of-speech tagging named entity recognition summarization": ["AFRIINSTRUCT: Instruction Tuning of African Languages for Diverse Tasks"], "open-domain dialogue response generation": ["LLMs as Collaborator: Demands-Guided Collaborative Retrieval-Augmented Generation for Commonsense Knowledge-Grounded Open-Domain Dialogue Systems"], "commonsense knowledge-grounded response generation": ["LLMs as Collaborator: Demands-Guided Collaborative Retrieval-Augmented Generation for Commonsense Knowledge-Grounded Open-Domain Dialogue Systems"], "open-domain dialogue response generation commonsense knowledge-grounded response generation": ["LLMs as Collaborator: Demands-Guided Collaborative Retrieval-Augmented Generation for Commonsense Knowledge-Grounded Open-Domain Dialogue Systems"], "evidence attribution": ["ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs"], "claim detection": ["ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs"], "fact verification evidence attribution": ["ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs"], "evidence attribution claim detection": ["ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs"], "fact verification evidence attribution claim detection": ["ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs"], "text generation language modeling": ["Empirical Prior for Text Autoencoders"], "pedagogical alignment of LLMs": ["Pedagogical Alignment of Large Language Models"], "preference dataset creation": ["Pedagogical Alignment of Large Language Models"], "performance evaluation of lhp algorithms": ["Pedagogical Alignment of Large Language Models"], "pedagogical alignment of LLMs preference dataset creation": ["Pedagogical Alignment of Large Language Models"], "preference dataset creation performance evaluation of lhp algorithms": ["Pedagogical Alignment of Large Language Models"], "pedagogical alignment of LLMs preference dataset creation performance evaluation of lhp algorithms": ["Pedagogical Alignment of Large Language Models"], "question generation evaluation metric": ["Reference-based Metrics Disprove Themselves in Question Generation"], "scoring": ["Regression-aware Inference with LLMs"], "relevance scoring": ["Regression-aware Inference with LLMs"], "time series prediction": ["Regression-aware Inference with LLMs"], "listwise ranking": ["Regression-aware Inference with LLMs"], "us amazon reviews": ["Regression-aware Inference with LLMs"], "regression scoring": ["Regression-aware Inference with LLMs"], "scoring relevance scoring": ["Regression-aware Inference with LLMs"], "relevance scoring sentiment analysis": ["Regression-aware Inference with LLMs"], "sentiment analysis time series prediction": ["Regression-aware Inference with LLMs"], "time series prediction arithmetic tasks": ["Regression-aware Inference with LLMs"], "arithmetic tasks listwise ranking": ["Regression-aware Inference with LLMs"], "listwise ranking semantic textual similarity": ["Regression-aware Inference with LLMs"], "semantic textual similarity us amazon reviews": ["Regression-aware Inference with LLMs"], "us amazon reviews triviaqa": ["Regression-aware Inference with LLMs"], "regression scoring relevance scoring": ["Regression-aware Inference with LLMs"], "scoring relevance scoring sentiment analysis": ["Regression-aware Inference with LLMs"], "relevance scoring sentiment analysis time series prediction": ["Regression-aware Inference with LLMs"], "sentiment analysis time series prediction arithmetic tasks": ["Regression-aware Inference with LLMs"], "time series prediction arithmetic tasks listwise ranking": ["Regression-aware Inference with LLMs"], "arithmetic tasks listwise ranking semantic textual similarity": ["Regression-aware Inference with LLMs"], "listwise ranking semantic textual similarity us amazon reviews": ["Regression-aware Inference with LLMs"], "semantic textual similarity us amazon reviews triviaqa": ["Regression-aware Inference with LLMs"], "regression scoring relevance scoring sentiment analysis": ["Regression-aware Inference with LLMs"], "scoring relevance scoring sentiment analysis time series prediction": ["Regression-aware Inference with LLMs"], "relevance scoring sentiment analysis time series prediction arithmetic tasks": ["Regression-aware Inference with LLMs"], "sentiment analysis time series prediction arithmetic tasks listwise ranking": ["Regression-aware Inference with LLMs"], "time series prediction arithmetic tasks listwise ranking semantic textual similarity": ["Regression-aware Inference with LLMs"], "arithmetic tasks listwise ranking semantic textual similarity us amazon reviews": ["Regression-aware Inference with LLMs"], "listwise ranking semantic textual similarity us amazon reviews triviaqa": ["Regression-aware Inference with LLMs"], "regression scoring relevance scoring sentiment analysis time series prediction": ["Regression-aware Inference with LLMs"], "scoring relevance scoring sentiment analysis time series prediction arithmetic tasks": ["Regression-aware Inference with LLMs"], "relevance scoring sentiment analysis time series prediction arithmetic tasks listwise ranking": ["Regression-aware Inference with LLMs"], "sentiment analysis time series prediction arithmetic tasks listwise ranking semantic textual similarity": ["Regression-aware Inference with LLMs"], "time series prediction arithmetic tasks listwise ranking semantic textual similarity us amazon reviews": ["Regression-aware Inference with LLMs"], "arithmetic tasks listwise ranking semantic textual similarity us amazon reviews triviaqa": ["Regression-aware Inference with LLMs"], "nl2gql": ["R\u00b3-NL2GQL: A Model Coordination and Knowledge Graph Alignment Approach for NL2GQL"], "time-sensitive question answering": ["Updating Large Language Models' Memories with Time Constraints", "Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering"], "knowledge editing time-sensitive question answering": ["Updating Large Language Models' Memories with Time Constraints"], "social iqa": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "winograde": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "question answering openbookqa": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "piqa social iqa": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "social iqa boolq": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "boolq winograde": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "winograde hellaswag": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "hellaswag arc-easy": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "question answering openbookqa piqa": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "openbookqa piqa social iqa": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "piqa social iqa boolq": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "social iqa boolq winograde": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "boolq winograde hellaswag": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "winograde hellaswag arc-easy": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "hellaswag arc-easy arc-challenge": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "question answering openbookqa piqa social iqa": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "openbookqa piqa social iqa boolq": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "piqa social iqa boolq winograde": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "social iqa boolq winograde hellaswag": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "boolq winograde hellaswag arc-easy": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "winograde hellaswag arc-easy arc-challenge": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "question answering openbookqa piqa social iqa boolq": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "openbookqa piqa social iqa boolq winograde": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "piqa social iqa boolq winograde hellaswag": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "social iqa boolq winograde hellaswag arc-easy": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "boolq winograde hellaswag arc-easy arc-challenge": ["DLORA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"], "jailbreak detection": ["Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models"], "multimodal LLMs": ["Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models"], "information security": ["Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models"], "jailbreak detection multimodal LLMs": ["Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models"], "multimodal LLMs information security": ["Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models"], "jailbreak detection multimodal LLMs information security": ["Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models"], "data poisoning": ["Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions"], "text summarization adversarial attack": ["Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions"], "adversarial attack data poisoning": ["Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions"], "text summarization adversarial attack data poisoning": ["Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions"], "sanskrit word segmentation": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "vedic sanskrit dependency parsing": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "lemmatization": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "morphosyntactic tagging": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "sanskrit word segmentation vedic sanskrit dependency parsing": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "vedic sanskrit dependency parsing ocr post-correction": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "ocr post-correction lemmatization": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "lemmatization morphosyntactic tagging": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "sanskrit word segmentation vedic sanskrit dependency parsing ocr post-correction": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "vedic sanskrit dependency parsing ocr post-correction lemmatization": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "ocr post-correction lemmatization morphosyntactic tagging": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "sanskrit word segmentation vedic sanskrit dependency parsing ocr post-correction lemmatization": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "vedic sanskrit dependency parsing ocr post-correction lemmatization morphosyntactic tagging": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "sanskrit word segmentation vedic sanskrit dependency parsing ocr post-correction lemmatization morphosyntactic tagging": ["One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"], "open-domain long-form text generation": ["ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation"], "lfqa": ["ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation"], "odsum": ["ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation"], "open-domain long-form text generation lfqa": ["ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation"], "lfqa odsum": ["ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation"], "open-domain long-form text generation lfqa odsum": ["ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation"], "text correction": ["Aligners: Decoupling LLMs and Alignment"], "ethical alignment": ["Aligners: Decoupling LLMs and Alignment"], "factuality alignment": ["Aligners: Decoupling LLMs and Alignment"], "helpfulness alignment": ["Aligners: Decoupling LLMs and Alignment"], "LLM alignment text correction": ["Aligners: Decoupling LLMs and Alignment"], "text correction synthetic data generation": ["Aligners: Decoupling LLMs and Alignment"], "synthetic data generation ethical alignment": ["Aligners: Decoupling LLMs and Alignment"], "ethical alignment factuality alignment": ["Aligners: Decoupling LLMs and Alignment"], "factuality alignment helpfulness alignment": ["Aligners: Decoupling LLMs and Alignment"], "LLM alignment text correction synthetic data generation": ["Aligners: Decoupling LLMs and Alignment"], "text correction synthetic data generation ethical alignment": ["Aligners: Decoupling LLMs and Alignment"], "synthetic data generation ethical alignment factuality alignment": ["Aligners: Decoupling LLMs and Alignment"], "ethical alignment factuality alignment helpfulness alignment": ["Aligners: Decoupling LLMs and Alignment"], "LLM alignment text correction synthetic data generation ethical alignment": ["Aligners: Decoupling LLMs and Alignment"], "text correction synthetic data generation ethical alignment factuality alignment": ["Aligners: Decoupling LLMs and Alignment"], "synthetic data generation ethical alignment factuality alignment helpfulness alignment": ["Aligners: Decoupling LLMs and Alignment"], "LLM alignment text correction synthetic data generation ethical alignment factuality alignment": ["Aligners: Decoupling LLMs and Alignment"], "text correction synthetic data generation ethical alignment factuality alignment helpfulness alignment": ["Aligners: Decoupling LLMs and Alignment"], "complex instruction following": ["TOWER: Tree Organized Weighting for Evaluating Complex Instructions"], "LLM evaluation complex instruction following": ["TOWER: Tree Organized Weighting for Evaluating Complex Instructions"], "medical entity disambiguation": ["Extractive Medical Entity Disambiguation with Memory Mechanism and Memorized Entity Information"], "fine-tuning quantization": ["QEFT: Quantization for Efficient Fine-Tuning of LLMs"], "fine-tuning quantization inference": ["QEFT: Quantization for Efficient Fine-Tuning of LLMs"], "commaqa-e": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "dynamic programming": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "scan": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "folio": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "last letter concatenation addition": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "multiplication commaqa-e": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "commaqa-e dynamic programming": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "dynamic programming gsm8k": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "math rte": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "rte scan": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "scan folio": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "last letter concatenation addition multiplication": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "addition multiplication commaqa-e": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "multiplication commaqa-e dynamic programming": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "commaqa-e dynamic programming gsm8k": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "dynamic programming gsm8k math": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "gsm8k math rte": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "math rte scan": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "rte scan folio": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "last letter concatenation addition multiplication commaqa-e": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "addition multiplication commaqa-e dynamic programming": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "multiplication commaqa-e dynamic programming gsm8k": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "commaqa-e dynamic programming gsm8k math": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "dynamic programming gsm8k math rte": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "gsm8k math rte scan": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "math rte scan folio": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "last letter concatenation addition multiplication commaqa-e dynamic programming": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "addition multiplication commaqa-e dynamic programming gsm8k": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "multiplication commaqa-e dynamic programming gsm8k math": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "commaqa-e dynamic programming gsm8k math rte": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "dynamic programming gsm8k math rte scan": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "gsm8k math rte scan folio": ["Skills-in-Context: Unlocking Compositionality in Large Language Models"], "disease diagnosis": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "fairness in ai": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "healthcare applications": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "disease diagnosis bias detection": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "bias mitigation fairness in ai": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "fairness in ai healthcare applications": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "disease diagnosis bias detection bias mitigation": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "bias detection bias mitigation fairness in ai": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "bias mitigation fairness in ai healthcare applications": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "disease diagnosis bias detection bias mitigation fairness in ai": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "bias detection bias mitigation fairness in ai healthcare applications": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "disease diagnosis bias detection bias mitigation fairness in ai healthcare applications": ["Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models"], "data analysis": ["BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "benchmarking evaluation": ["BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "evaluation data analysis": ["BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "data analysis scientific discovery": ["BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "benchmarking evaluation data analysis": ["BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "evaluation data analysis scientific discovery": ["BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "benchmarking evaluation data analysis scientific discovery": ["BLADE: Benchmarking Language Model Agents for Data-Driven Science"], "phone recognition": ["Phonetic and Lexical Discovery of Canine Vocalization"], "word discovery": ["Phonetic and Lexical Discovery of Canine Vocalization"], "semantics discovery": ["Phonetic and Lexical Discovery of Canine Vocalization"], "phone recognition word discovery": ["Phonetic and Lexical Discovery of Canine Vocalization"], "word discovery semantics discovery": ["Phonetic and Lexical Discovery of Canine Vocalization"], "phone recognition word discovery semantics discovery": ["Phonetic and Lexical Discovery of Canine Vocalization"], "multi-lingual text-to-speech": ["Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech"], "low-resource text-to-speech": ["Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech"], "multi-lingual text-to-speech low-resource text-to-speech": ["Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech"], "opinion prediction": ["Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks"], "LLM alignment human behavior simulation": ["Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks"], "human behavior simulation opinion prediction": ["Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks"], "LLM alignment human behavior simulation opinion prediction": ["Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks"], "short-form generation": ["Downstream Trade-offs of a Family of Text Watermarks"], "classification multiple choice question answering": ["Downstream Trade-offs of a Family of Text Watermarks"], "multiple choice question answering short-form generation": ["Downstream Trade-offs of a Family of Text Watermarks"], "short-form generation long-form generation": ["Downstream Trade-offs of a Family of Text Watermarks"], "classification multiple choice question answering short-form generation": ["Downstream Trade-offs of a Family of Text Watermarks"], "multiple choice question answering short-form generation long-form generation": ["Downstream Trade-offs of a Family of Text Watermarks"], "classification multiple choice question answering short-form generation long-form generation": ["Downstream Trade-offs of a Family of Text Watermarks"], "table question answering multimodal reasoning": ["Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "visual reasoning knowledge-aware reasoning": ["Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "table question answering multimodal reasoning visual reasoning": ["Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "multimodal reasoning visual reasoning knowledge-aware reasoning": ["Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "table question answering multimodal reasoning visual reasoning knowledge-aware reasoning": ["Knowledge-Aware Reasoning over Multimodal Semi-structured Tables"], "multilingual qa": ["Representational Isomorphism and Alignment of Multilingual Large Language Models"], "semantic textual similarity cross-lingual retrieval": ["Representational Isomorphism and Alignment of Multilingual Large Language Models"], "cross-lingual retrieval machine translation": ["Representational Isomorphism and Alignment of Multilingual Large Language Models"], "machine translation multilingual qa": ["Representational Isomorphism and Alignment of Multilingual Large Language Models"], "semantic textual similarity cross-lingual retrieval machine translation": ["Representational Isomorphism and Alignment of Multilingual Large Language Models"], "cross-lingual retrieval machine translation multilingual qa": ["Representational Isomorphism and Alignment of Multilingual Large Language Models"], "semantic textual similarity cross-lingual retrieval machine translation multilingual qa": ["Representational Isomorphism and Alignment of Multilingual Large Language Models"], "story generation long-form story generation": ["SWAG: Storytelling With Action Guidance"], "extreme multi-label learning": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "product categorization": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "medical records coding": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "document tagging": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "multi-label classification extreme multi-label learning": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "extreme multi-label learning text classification": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "text classification product categorization": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "product categorization medical records coding": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "medical records coding document tagging": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "multi-label classification extreme multi-label learning text classification": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "extreme multi-label learning text classification product categorization": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "text classification product categorization medical records coding": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "product categorization medical records coding document tagging": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "multi-label classification extreme multi-label learning text classification product categorization": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "extreme multi-label learning text classification product categorization medical records coding": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "text classification product categorization medical records coding document tagging": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "multi-label classification extreme multi-label learning text classification product categorization medical records coding": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "extreme multi-label learning text classification product categorization medical records coding document tagging": ["Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems"], "personalized question generation": ["Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting"], "open-domain dialogue": ["Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting"], "personalized question generation open-domain dialogue": ["Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting"], "multimodal dialogue response generation": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "vision-language understanding visual question answering": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "visual question answering multimodal dialogue response generation": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "multimodal dialogue response generation object localization": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "object localization social reasoning": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "social reasoning fine-grained perception": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "vision-language understanding visual question answering multimodal dialogue response generation": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "visual question answering multimodal dialogue response generation object localization": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "multimodal dialogue response generation object localization social reasoning": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "object localization social reasoning fine-grained perception": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "vision-language understanding visual question answering multimodal dialogue response generation object localization": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "visual question answering multimodal dialogue response generation object localization social reasoning": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "multimodal dialogue response generation object localization social reasoning fine-grained perception": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "vision-language understanding visual question answering multimodal dialogue response generation object localization social reasoning": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "visual question answering multimodal dialogue response generation object localization social reasoning fine-grained perception": ["Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM"], "relation identification": ["LLM as a metric critic for low resource relation identification"], "co-evolution": ["LLM as a metric critic for low resource relation identification"], "relation identification low-resource learning": ["LLM as a metric critic for low resource relation identification"], "low-resource learning prompt optimization": ["LLM as a metric critic for low resource relation identification"], "prompt optimization co-evolution": ["LLM as a metric critic for low resource relation identification"], "relation identification low-resource learning prompt optimization": ["LLM as a metric critic for low resource relation identification"], "low-resource learning prompt optimization co-evolution": ["LLM as a metric critic for low resource relation identification"], "relation identification low-resource learning prompt optimization co-evolution": ["LLM as a metric critic for low resource relation identification"], "target-driven recommendation dialogues": ["Experience as Source for Anticipation and Planning: Experiential Policy Learning for Target-driven Recommendation Dialogues"], "fact-checking evaluation": ["Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers"], "fact-checking evaluation benchmark": ["Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-Checkers"], "popqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "pubqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "bio": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "alce-asqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "2wikimultihopqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "popqa triviaqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "triviaqa pubqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "pubqa bio": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "bio alce-asqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "alce-asqa hotpotqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "hotpotqa musique": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "musique 2wikimultihopqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "popqa triviaqa pubqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "triviaqa pubqa bio": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "pubqa bio alce-asqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "bio alce-asqa hotpotqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "alce-asqa hotpotqa musique": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "hotpotqa musique 2wikimultihopqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "popqa triviaqa pubqa bio": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "triviaqa pubqa bio alce-asqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "pubqa bio alce-asqa hotpotqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "bio alce-asqa hotpotqa musique": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "alce-asqa hotpotqa musique 2wikimultihopqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "popqa triviaqa pubqa bio alce-asqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "triviaqa pubqa bio alce-asqa hotpotqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "pubqa bio alce-asqa hotpotqa musique": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "bio alce-asqa hotpotqa musique 2wikimultihopqa": ["OPEN-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models"], "psychological counseling": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "cbt technique application": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "dialogue generation psychological counseling": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "psychological counseling dataset creation": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "dataset creation cbt technique application": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "dialogue generation psychological counseling dataset creation": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "psychological counseling dataset creation cbt technique application": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "dialogue generation psychological counseling dataset creation cbt technique application": ["CACTUS: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory"], "layout generation": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "text-to-layout": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "graphic design": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "layout generation text-to-layout": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "text-to-layout image generation": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "image generation graphic design": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "layout generation text-to-layout image generation": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "text-to-layout image generation graphic design": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "layout generation text-to-layout image generation graphic design": ["TextLap: Customizing Language Models for Text-to-Layout Planning"], "ontology building": ["Data-driven Coreference-based Ontology Building"], "long-form question answering conversational question answering": ["Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision"], "conversational question answering RAG": ["Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision"], "long-form question answering conversational question answering RAG": ["Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision"], "pairwise argument ranking": ["Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking"], "few-shot image classification": ["Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP"], "few-shot image classification image retrieval": ["Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP"], "context adaptation": ["DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models"], "question answering knowledge conflict analysis": ["DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models"], "knowledge conflict analysis context adaptation": ["DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models"], "question answering knowledge conflict analysis context adaptation": ["DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models"], "parallel data creation": ["LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification"], "text detoxification data augmentation": ["LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification"], "data augmentation parallel data creation": ["LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification"], "text detoxification data augmentation parallel data creation": ["LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification"], "human label variation": ["\u201cSeeing the Big through the Small\u201d: Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?"], "natural language inference human label variation": ["\u201cSeeing the Big through the Small\u201d: Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?"], "human-ai conversation analysis": ["Language Models in Dialogue: Conversational Maxims for Human-AI Interactions"], "maxim evaluation": ["Language Models in Dialogue: Conversational Maxims for Human-AI Interactions"], "conversation quality assessment": ["Language Models in Dialogue: Conversational Maxims for Human-AI Interactions"], "human-ai conversation analysis maxim evaluation": ["Language Models in Dialogue: Conversational Maxims for Human-AI Interactions"], "maxim evaluation conversation quality assessment": ["Language Models in Dialogue: Conversational Maxims for Human-AI Interactions"], "human-ai conversation analysis maxim evaluation conversation quality assessment": ["Language Models in Dialogue: Conversational Maxims for Human-AI Interactions"], "multi-hop question answering knowledge graph integration": ["LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments"], "knowledge graph integration knowledge editing": ["LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments"], "multi-hop question answering knowledge graph integration knowledge editing": ["LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments"], "preference alignment summarization": ["Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness"], "summarization dialogue": ["Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness"], "preference alignment summarization dialogue": ["Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness"], "adversarial interview": ["Mitigating Hallucination in Fictional Character Role-Play"], "open ended interview": ["Mitigating Hallucination in Fictional Character Role-Play"], "dialogue completion": ["Mitigating Hallucination in Fictional Character Role-Play"], "scene grounded interview": ["Mitigating Hallucination in Fictional Character Role-Play"], "adversarial interview open ended interview": ["Mitigating Hallucination in Fictional Character Role-Play"], "open ended interview dialogue completion": ["Mitigating Hallucination in Fictional Character Role-Play"], "dialogue completion scene grounded interview": ["Mitigating Hallucination in Fictional Character Role-Play"], "adversarial interview open ended interview dialogue completion": ["Mitigating Hallucination in Fictional Character Role-Play"], "open ended interview dialogue completion scene grounded interview": ["Mitigating Hallucination in Fictional Character Role-Play"], "adversarial interview open ended interview dialogue completion scene grounded interview": ["Mitigating Hallucination in Fictional Character Role-Play"], "ironic reply generation": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "age-specific model building": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "ironic reply generation linguistic analysis": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "linguistic analysis human evaluation": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "human evaluation age-specific model building": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "ironic reply generation linguistic analysis human evaluation": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "linguistic analysis human evaluation age-specific model building": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "ironic reply generation linguistic analysis human evaluation age-specific model building": ["I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models"], "conversational engagement enhancement": ["Minimal Yet Big Impact: How AI Agent Back-channeling Enhances Conversational Engagement through Conversation Persistence and Context Richness"], "span annotation": ["Large Language Models for Propaganda Span Annotation"], "propaganda detection span annotation": ["Large Language Models for Propaganda Span Annotation"], "original prompt reconstruction": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "cot reasoning": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "prompt compression original prompt reconstruction": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "original prompt reconstruction text summarization": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "text summarization multi-hop qa": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "multi-hop qa cot reasoning": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "prompt compression original prompt reconstruction text summarization": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "original prompt reconstruction text summarization multi-hop qa": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "text summarization multi-hop qa cot reasoning": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "prompt compression original prompt reconstruction text summarization multi-hop qa": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "original prompt reconstruction text summarization multi-hop qa cot reasoning": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "prompt compression original prompt reconstruction text summarization multi-hop qa cot reasoning": ["Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"], "prompt sensitivity index": ["POSIX: A Prompt Sensitivity Index For Large Language Models"], "LLMs evaluation": ["POSIX: A Prompt Sensitivity Index For Large Language Models"], "prompt sensitivity index LLMs evaluation": ["POSIX: A Prompt Sensitivity Index For Large Language Models"], "role-playing agents": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "personality assessment": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "decision simulation": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "role-playing agents language models": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "language models personality assessment": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "personality assessment decision simulation": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "role-playing agents language models personality assessment": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "language models personality assessment decision simulation": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "role-playing agents language models personality assessment decision simulation": ["Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"], "leaderboard generation": ["LEGOBENCH: Scientific Leaderboard Generation Benchmark"], "ranking papers": ["LEGOBENCH: Scientific Leaderboard Generation Benchmark"], "leaderboard generation ranking papers": ["LEGOBENCH: Scientific Leaderboard Generation Benchmark"], "legal question answering": ["H-LegalKI: A Hierarchical Legal Knowledge Integration Framework for Legal Community Question Answering"], "factual inconsistency detection in summaries": ["Identifying Factual Inconsistencies in Summaries: Grounding LLM Inference via Task Taxonomy"], "long-range dependency modeling": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "length extrapolation": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "downstream evaluation": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "time series modeling": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "language modeling long-range dependency modeling": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "long-range dependency modeling length extrapolation": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "length extrapolation downstream evaluation": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "downstream evaluation time series modeling": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "language modeling long-range dependency modeling length extrapolation": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "long-range dependency modeling length extrapolation downstream evaluation": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "length extrapolation downstream evaluation time series modeling": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "language modeling long-range dependency modeling length extrapolation downstream evaluation": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "long-range dependency modeling length extrapolation downstream evaluation time series modeling": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "language modeling long-range dependency modeling length extrapolation downstream evaluation time series modeling": ["Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning"], "back-transliteration": ["BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "back-transliteration sentiment analysis": ["BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "sentiment analysis offensive language detection": ["BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "offensive language detection emotion detection": ["BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "back-transliteration sentiment analysis offensive language detection": ["BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "sentiment analysis offensive language detection emotion detection": ["BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "back-transliteration sentiment analysis offensive language detection emotion detection": ["BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla"], "empathic similarity assessment": ["Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs"], "narrative classification": ["EU DisinfoTest: a Benchmark for Evaluating Language Models' Ability to Detect Disinformation Narratives"], "disinformation detection narrative classification": ["EU DisinfoTest: a Benchmark for Evaluating Language Models' Ability to Detect Disinformation Narratives"], "narrative classification zero-shot classification": ["EU DisinfoTest: a Benchmark for Evaluating Language Models' Ability to Detect Disinformation Narratives"], "disinformation detection narrative classification zero-shot classification": ["EU DisinfoTest: a Benchmark for Evaluating Language Models' Ability to Detect Disinformation Narratives"], "biomedical text processing": ["Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models"], "classification summarization": ["Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models"], "summarization biomedical text processing": ["Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models"], "classification summarization biomedical text processing": ["Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models"], "in-context learning code completion": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "code completion summarization": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "question answering RAG in-context learning": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "RAG in-context learning code completion": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "in-context learning code completion summarization": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "code completion summarization few-shot learning": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "question answering RAG in-context learning code completion": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "RAG in-context learning code completion summarization": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "in-context learning code completion summarization few-shot learning": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "question answering RAG in-context learning code completion summarization": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "RAG in-context learning code completion summarization few-shot learning": ["From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression"], "multimodal sentiment analysis": ["Knowledge-Guided Dynamic Modality Attention Fusion Framework for Multimodal Sentiment Analysis"], "machine translation data curation": ["LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"], "data curation instruction fine-tuning": ["LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"], "machine translation data curation instruction fine-tuning": ["LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation"], "document-grounded dialogue systems": ["SARCAT: Generative Span-Act Guided Response Generation Using Copy-Enhanced Target Augmentation"], "response generation document-grounded dialogue systems": ["SARCAT: Generative Span-Act Guided Response Generation Using Copy-Enhanced Target Augmentation"], "neural machine translation gender bias mitigation": ["Does Context Help Mitigate Gender Bias in Neural Machine Translation?"], "meta-evaluation summarization": ["A Critical Look at Meta-evaluating Summarisation Evaluation Metrics"], "hate speech": ["LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study"], "natural language inference hate speech": ["LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study"], "sentiment analysis natural language inference hate speech": ["LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study"], "entity classification": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "linguistic acceptability": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "sentiment analysis content classification": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "content classification entity classification": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "entity classification paraphrase identification": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "paraphrase identification natural language inference": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "question answering linguistic acceptability": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "sentiment analysis content classification entity classification": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "content classification entity classification paraphrase identification": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "entity classification paraphrase identification natural language inference": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "paraphrase identification natural language inference question answering": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "natural language inference question answering linguistic acceptability": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "sentiment analysis content classification entity classification paraphrase identification": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "content classification entity classification paraphrase identification natural language inference": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "entity classification paraphrase identification natural language inference question answering": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "paraphrase identification natural language inference question answering linguistic acceptability": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "sentiment analysis content classification entity classification paraphrase identification natural language inference": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "content classification entity classification paraphrase identification natural language inference question answering": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "entity classification paraphrase identification natural language inference question answering linguistic acceptability": ["Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"], "trope prediction in movie synopses": ["Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses"], "synthetic data analysis": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "pattern overfitting mitigation": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "instruction-following capability enhancement": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "output distribution correction": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "LLM training": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "synthetic data analysis pattern overfitting mitigation": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "pattern overfitting mitigation instruction-following capability enhancement": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "instruction-following capability enhancement output distribution correction": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "output distribution correction LLM unlearning": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "LLM unlearning LLM training": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "synthetic data analysis pattern overfitting mitigation instruction-following capability enhancement": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "pattern overfitting mitigation instruction-following capability enhancement output distribution correction": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "instruction-following capability enhancement output distribution correction LLM unlearning": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "output distribution correction LLM unlearning LLM training": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "synthetic data analysis pattern overfitting mitigation instruction-following capability enhancement output distribution correction": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "pattern overfitting mitigation instruction-following capability enhancement output distribution correction LLM unlearning": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "instruction-following capability enhancement output distribution correction LLM unlearning LLM training": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "synthetic data analysis pattern overfitting mitigation instruction-following capability enhancement output distribution correction LLM unlearning": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "pattern overfitting mitigation instruction-following capability enhancement output distribution correction LLM unlearning LLM training": ["Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models"], "out-of-distribution detection hallucination detection": ["CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text"], "hallucination detection text classification": ["CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text"], "out-of-distribution detection hallucination detection text classification": ["CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text"], "ambiguity identification": ["CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "natural language inference disambiguation": ["CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "disambiguation ambiguity identification": ["CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "ambiguity identification multi-label classification": ["CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "natural language inference disambiguation ambiguity identification": ["CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "disambiguation ambiguity identification multi-label classification": ["CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "natural language inference disambiguation ambiguity identification multi-label classification": ["CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models"], "simplicity assessment": ["ARTS: Assessing Readability & Text Simplicity"], "text simplification evaluation": ["ARTS: Assessing Readability & Text Simplicity"], "simplicity assessment dataset creation": ["ARTS: Assessing Readability & Text Simplicity"], "dataset creation readability assessment": ["ARTS: Assessing Readability & Text Simplicity"], "readability assessment text simplification evaluation": ["ARTS: Assessing Readability & Text Simplicity"], "simplicity assessment dataset creation readability assessment": ["ARTS: Assessing Readability & Text Simplicity"], "dataset creation readability assessment text simplification evaluation": ["ARTS: Assessing Readability & Text Simplicity"], "simplicity assessment dataset creation readability assessment text simplification evaluation": ["ARTS: Assessing Readability & Text Simplicity"], "free text generation": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "data-to-text conversion": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "consistency evaluation summarization": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "summarization free text generation": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "free text generation data-to-text conversion": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "consistency evaluation summarization free text generation": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "summarization free text generation data-to-text conversion": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "consistency evaluation summarization free text generation data-to-text conversion": ["AXCEL: Automated eXplainable Consistency Evaluation using LLMS"], "webshop interactive decision-making": ["Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking"], "alfworld webshop interactive decision-making": ["Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking"], "meta-learning model selection": ["Characterizing Text Datasets with Psycholinguistic Features"], "text classification meta-learning model selection": ["Characterizing Text Datasets with Psycholinguistic Features"], "lexical entailment recognition": ["Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition"], "quarel": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning", "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "quarel strategyqa": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "strategyqa openbookqa": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "openbookqa qasc": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "qasc gsm8k": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "gsm8k causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "causal understanding natural language reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "natural language reasoning mathematical reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "commonsense reasoning causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "quarel strategyqa openbookqa": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "strategyqa openbookqa qasc": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "openbookqa qasc gsm8k": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "qasc gsm8k causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "gsm8k causal understanding natural language reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "causal understanding natural language reasoning mathematical reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "natural language reasoning mathematical reasoning commonsense reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "mathematical reasoning commonsense reasoning causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "quarel strategyqa openbookqa qasc": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "strategyqa openbookqa qasc gsm8k": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "openbookqa qasc gsm8k causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "qasc gsm8k causal understanding natural language reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "gsm8k causal understanding natural language reasoning mathematical reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "causal understanding natural language reasoning mathematical reasoning commonsense reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "natural language reasoning mathematical reasoning commonsense reasoning causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "quarel strategyqa openbookqa qasc gsm8k": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "strategyqa openbookqa qasc gsm8k causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "openbookqa qasc gsm8k causal understanding natural language reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "qasc gsm8k causal understanding natural language reasoning mathematical reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "gsm8k causal understanding natural language reasoning mathematical reasoning commonsense reasoning": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "causal understanding natural language reasoning mathematical reasoning commonsense reasoning causal understanding": ["Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"], "knowledge detection": ["Self-training Large Language Models through Knowledge Detection"], "self-training knowledge detection": ["Self-training Large Language Models through Knowledge Detection"], "knowledge detection hallucination reduction": ["Self-training Large Language Models through Knowledge Detection"], "hallucination reduction catastrophic forgetting mitigation": ["Self-training Large Language Models through Knowledge Detection"], "self-training knowledge detection hallucination reduction": ["Self-training Large Language Models through Knowledge Detection"], "knowledge detection hallucination reduction catastrophic forgetting mitigation": ["Self-training Large Language Models through Knowledge Detection"], "self-training knowledge detection hallucination reduction catastrophic forgetting mitigation": ["Self-training Large Language Models through Knowledge Detection"], "pico extraction": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "named-entity recognition pico extraction": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "pico extraction relation extraction": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "document classification question answering": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "named-entity recognition pico extraction relation extraction": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "pico extraction relation extraction document classification": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "relation extraction document classification question answering": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "named-entity recognition pico extraction relation extraction document classification": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "pico extraction relation extraction document classification question answering": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "named-entity recognition pico extraction relation extraction document classification question answering": ["VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models"], "decoding strategy": ["Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation"], "text generation open-ended generation": ["Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation"], "open-ended generation decoding strategy": ["Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation"], "text generation open-ended generation decoding strategy": ["Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation"], "pos tagging ner": ["SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models"], "ner natural language inference": ["SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models"], "pos tagging ner natural language inference": ["SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models"], "manual data labeling": ["Re-examining Sexism and Misogyny Classification with Annotator Attitudes"], "automated classification": ["Re-examining Sexism and Misogyny Classification with Annotator Attitudes"], "gender-based violence  detection": ["Re-examining Sexism and Misogyny Classification with Annotator Attitudes"], "manual data labeling automated classification": ["Re-examining Sexism and Misogyny Classification with Annotator Attitudes"], "automated classification gender-based violence  detection": ["Re-examining Sexism and Misogyny Classification with Annotator Attitudes"], "manual data labeling automated classification gender-based violence  detection": ["Re-examining Sexism and Misogyny Classification with Annotator Attitudes"], "persona": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "objective tasks": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "LLM prompting": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "prompting persona": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "persona objective tasks": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "LLM prompting persona": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "prompting persona objective tasks": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "LLM prompting persona objective tasks": ["When \"A Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models"], "knowledge grounded visual reasoning": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "perceptual visual reasoning": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "iconqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "vizwiz": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "flickr30k": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "visual reasoning knowledge grounded visual reasoning": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "knowledge grounded visual reasoning perceptual visual reasoning": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "perceptual visual reasoning scienceqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "scienceqa iconqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "iconqa vizwiz": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "vizwiz flickr30k": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "visual reasoning knowledge grounded visual reasoning perceptual visual reasoning": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "knowledge grounded visual reasoning perceptual visual reasoning scienceqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "perceptual visual reasoning scienceqa iconqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "scienceqa iconqa vizwiz": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "iconqa vizwiz flickr30k": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "visual reasoning knowledge grounded visual reasoning perceptual visual reasoning scienceqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "knowledge grounded visual reasoning perceptual visual reasoning scienceqa iconqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "perceptual visual reasoning scienceqa iconqa vizwiz": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "scienceqa iconqa vizwiz flickr30k": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "visual reasoning knowledge grounded visual reasoning perceptual visual reasoning scienceqa iconqa": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "knowledge grounded visual reasoning perceptual visual reasoning scienceqa iconqa vizwiz": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "perceptual visual reasoning scienceqa iconqa vizwiz flickr30k": ["Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"], "automatic speech recognition bias analysis": ["Modeling Gender and Dialect Bias in Automatic Speech Recognition"], "value consistency measurement": ["Are Large Language Models Consistent over Value-laden Questions?"], "value consistency measurement LLM evaluation": ["Are Large Language Models Consistent over Value-laden Questions?"], "machine translation error explanation": ["XTOWER: A Multilingual LLM for Explaining and Correcting Translation Errors"], "machine translation error correction": ["XTOWER: A Multilingual LLM for Explaining and Correcting Translation Errors"], "machine translation error explanation machine translation error correction": ["XTOWER: A Multilingual LLM for Explaining and Correcting Translation Errors"], "multi-modal machine translation": ["LAMBDA: Large Language Model-Based Data Augmentation for Multi-Modal Machine Translation"], "privacy evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "canary attacks": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "classification coreference resolution": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "coreference resolution mention detection": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "mention detection fairness evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "fairness evaluation privacy evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "privacy evaluation canary attacks": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "text generation classification coreference resolution": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "classification coreference resolution mention detection": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "coreference resolution mention detection fairness evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "mention detection fairness evaluation privacy evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "fairness evaluation privacy evaluation canary attacks": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "text generation classification coreference resolution mention detection": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "classification coreference resolution mention detection fairness evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "coreference resolution mention detection fairness evaluation privacy evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "mention detection fairness evaluation privacy evaluation canary attacks": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "text generation classification coreference resolution mention detection fairness evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "classification coreference resolution mention detection fairness evaluation privacy evaluation": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "coreference resolution mention detection fairness evaluation privacy evaluation canary attacks": ["Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"], "dialogue act recognition": ["Dual Process Masking for Dialogue Act Recognition"], "text-to-image knowledge editing": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "evaluation criterion": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "prompt editing": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "text-to-image knowledge editing dataset curation": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "dataset curation evaluation criterion": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "evaluation criterion prompt editing": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "text-to-image knowledge editing dataset curation evaluation criterion": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "dataset curation evaluation criterion prompt editing": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "text-to-image knowledge editing dataset curation evaluation criterion prompt editing": ["Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion"], "human preference alignment reinforcement learning from human feedback": ["DEFT: Distribution-guided Efficient Fine-Tuning for Human Alignment"], "kv cache compression": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "zero-shot tasks": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "language modeling kv cache compression": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "kv cache compression zero-shot tasks": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "zero-shot tasks perplexity evaluation": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "perplexity evaluation language generation": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "language modeling kv cache compression zero-shot tasks": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "kv cache compression zero-shot tasks perplexity evaluation": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "zero-shot tasks perplexity evaluation language generation": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "language modeling kv cache compression zero-shot tasks perplexity evaluation": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "kv cache compression zero-shot tasks perplexity evaluation language generation": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "language modeling kv cache compression zero-shot tasks perplexity evaluation language generation": ["Eigen Attention: Attention in Low-Rank Space for KV Cache Compression"], "natural language understanding question answering": ["ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning"], "truthfulness evaluation": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "knowledge and reasoning": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "language modeling text classification": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "text classification bias evaluation": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "bias evaluation toxicity detection": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "toxicity detection truthfulness evaluation": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "truthfulness evaluation summarization": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "instruction following knowledge and reasoning": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "language modeling text classification bias evaluation": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "text classification bias evaluation toxicity detection": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "bias evaluation toxicity detection truthfulness evaluation": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "toxicity detection truthfulness evaluation summarization": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "truthfulness evaluation summarization instruction following": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "summarization instruction following knowledge and reasoning": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "language modeling text classification bias evaluation toxicity detection": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "text classification bias evaluation toxicity detection truthfulness evaluation": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "bias evaluation toxicity detection truthfulness evaluation summarization": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "toxicity detection truthfulness evaluation summarization instruction following": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "truthfulness evaluation summarization instruction following knowledge and reasoning": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "language modeling text classification bias evaluation toxicity detection truthfulness evaluation": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "text classification bias evaluation toxicity detection truthfulness evaluation summarization": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "bias evaluation toxicity detection truthfulness evaluation summarization instruction following": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "toxicity detection truthfulness evaluation summarization instruction following knowledge and reasoning": ["Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression"], "nl-to-code": ["One-to-many testing for code generation from (just) natural language"], "mbpp adaptation": ["One-to-many testing for code generation from (just) natural language"], "evaluation of code generation models": ["One-to-many testing for code generation from (just) natural language"], "code generation nl-to-code": ["One-to-many testing for code generation from (just) natural language"], "nl-to-code mbpp adaptation": ["One-to-many testing for code generation from (just) natural language"], "mbpp adaptation evaluation of code generation models": ["One-to-many testing for code generation from (just) natural language"], "code generation nl-to-code mbpp adaptation": ["One-to-many testing for code generation from (just) natural language"], "nl-to-code mbpp adaptation evaluation of code generation models": ["One-to-many testing for code generation from (just) natural language"], "code generation nl-to-code mbpp adaptation evaluation of code generation models": ["One-to-many testing for code generation from (just) natural language"], "scientific literature understanding": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models", "Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "multi-document reasoning": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "question answering scientific literature understanding": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "scientific literature understanding multi-modal reasoning": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "multi-modal reasoning multi-document reasoning": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "question answering scientific literature understanding multi-modal reasoning": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "scientific literature understanding multi-modal reasoning multi-document reasoning": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "question answering scientific literature understanding multi-modal reasoning multi-document reasoning": ["M3SCIQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models"], "LLM agent reasoning": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "action inference": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "context operationalization": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "distraction handling": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "LLM agent reasoning action inference": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "action inference context operationalization": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "context operationalization distraction handling": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "LLM agent reasoning action inference context operationalization": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "action inference context operationalization distraction handling": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "LLM agent reasoning action inference context operationalization distraction handling": ["Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction"], "document generation": ["Knowledge-Centric Templatic Views of Documents"], "templatic view generation": ["Knowledge-Centric Templatic Views of Documents"], "document generation templatic view generation": ["Knowledge-Centric Templatic Views of Documents"], "templatic view generation evaluation": ["Knowledge-Centric Templatic Views of Documents"], "document generation templatic view generation evaluation": ["Knowledge-Centric Templatic Views of Documents"], "aspect category extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "sentiment polarity classification": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "implicit opinion extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect-based sentiment analysis aspect category extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect category extraction opinion extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "opinion extraction sentiment polarity classification": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "sentiment polarity classification implicit opinion extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect-based sentiment analysis aspect category extraction opinion extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect category extraction opinion extraction sentiment polarity classification": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "opinion extraction sentiment polarity classification implicit opinion extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect-based sentiment analysis aspect category extraction opinion extraction sentiment polarity classification": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect category extraction opinion extraction sentiment polarity classification implicit opinion extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "aspect-based sentiment analysis aspect category extraction opinion extraction sentiment polarity classification implicit opinion extraction": ["Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction"], "LLM steering": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "error resolution": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "program debugging": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "code generation LLM steering": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "LLM steering error resolution": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "error resolution human-ai collaboration": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "human-ai collaboration program debugging": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "code generation LLM steering error resolution": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "LLM steering error resolution human-ai collaboration": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "error resolution human-ai collaboration program debugging": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "code generation LLM steering error resolution human-ai collaboration": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "LLM steering error resolution human-ai collaboration program debugging": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "code generation LLM steering error resolution human-ai collaboration program debugging": ["Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation"], "turn-taking prediction": ["Large Language Models Know What To Say But Not When to Speak"], "transition relevance place  prediction": ["Large Language Models Know What To Say But Not When to Speak"], "turn-taking prediction transition relevance place  prediction": ["Large Language Models Know What To Say But Not When to Speak"], "essay fluency grading": ["Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method"], "wrong sentence rewriting": ["Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method"], "essay fluency grading error type identification": ["Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method"], "error type identification wrong sentence rewriting": ["Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method"], "essay fluency grading error type identification wrong sentence rewriting": ["Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method"], "common sense understanding": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "memorization avoidance": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "reasoning truthfulness": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "truthfulness common sense understanding": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "common sense understanding hallucination detection": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "hallucination detection memorization avoidance": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "reasoning truthfulness common sense understanding": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "truthfulness common sense understanding hallucination detection": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "common sense understanding hallucination detection memorization avoidance": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "reasoning truthfulness common sense understanding hallucination detection": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "truthfulness common sense understanding hallucination detection memorization avoidance": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "reasoning truthfulness common sense understanding hallucination detection memorization avoidance": ["Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning"], "malgorithm identification": ["MalAlgoQA: Pedagogical Evaluation of Counterfactual Reasoning in Large Language Models and Implications for AI in Education"], "poetic form detection": ["Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets"], "model patching": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "skill addition": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "instruction tuning model patching": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "model patching skill addition": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "skill addition scientific literature understanding": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "scientific literature understanding safety": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "safety coding": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "instruction tuning model patching skill addition": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "model patching skill addition scientific literature understanding": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "skill addition scientific literature understanding safety": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "scientific literature understanding safety coding": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "instruction tuning model patching skill addition scientific literature understanding": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "model patching skill addition scientific literature understanding safety": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "skill addition scientific literature understanding safety coding": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "instruction tuning model patching skill addition scientific literature understanding safety": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "model patching skill addition scientific literature understanding safety coding": ["Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging"], "fluency assessment": ["To Ask LLMs about English Grammaticality, Prompt Them in a Different Language"], "grammatical error correction question answering": ["To Ask LLMs about English Grammaticality, Prompt Them in a Different Language"], "question answering fluency assessment": ["To Ask LLMs about English Grammaticality, Prompt Them in a Different Language"], "grammatical error correction question answering fluency assessment": ["To Ask LLMs about English Grammaticality, Prompt Them in a Different Language"], "short-text topic modeling": ["Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs"], "topic modeling short-text topic modeling": ["Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs"], "short-text topic modeling text classification": ["Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs"], "topic modeling short-text topic modeling text classification": ["Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs"], "unlabeled attachment score": ["Targeted Multilingual Adaptation for Low-resource Language Families"], "part-of-speech tagging unlabeled attachment score": ["Targeted Multilingual Adaptation for Low-resource Language Families"], "multi-label intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "intent span extraction": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "coarse-grained intent labeling": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "fine-grained intent labeling": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "non-primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "multi-label intent detection intent span extraction": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "intent span extraction coarse-grained intent labeling": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "coarse-grained intent labeling fine-grained intent labeling": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "fine-grained intent labeling primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "primary intent detection non-primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "multi-label intent detection intent span extraction coarse-grained intent labeling": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "intent span extraction coarse-grained intent labeling fine-grained intent labeling": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "coarse-grained intent labeling fine-grained intent labeling primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "fine-grained intent labeling primary intent detection non-primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "multi-label intent detection intent span extraction coarse-grained intent labeling fine-grained intent labeling": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "intent span extraction coarse-grained intent labeling fine-grained intent labeling primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "coarse-grained intent labeling fine-grained intent labeling primary intent detection non-primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "multi-label intent detection intent span extraction coarse-grained intent labeling fine-grained intent labeling primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "intent span extraction coarse-grained intent labeling fine-grained intent labeling primary intent detection non-primary intent detection": ["A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"], "indicxtreme classification": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "indicxtreme classification summarization": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "summarization question-answering": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "question-answering machine translation": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "machine translation mathematical reasoning": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "indicxtreme classification summarization question-answering": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "summarization question-answering machine translation": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "question-answering machine translation mathematical reasoning": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "indicxtreme classification summarization question-answering machine translation": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "summarization question-answering machine translation mathematical reasoning": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "indicxtreme classification summarization question-answering machine translation mathematical reasoning": ["Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMS"], "vision-language retrieval": ["Advancing Vision-Language Models with Adapter Ensemble Strategies"], "author diarization": ["Who Wrote When? Author Diarization in Social Media Discussions"], "graph generation": ["Controlled Transformation of Text-Attributed Graphs"], "graph translation": ["Controlled Transformation of Text-Attributed Graphs"], "taxonomy creation": ["Controlled Transformation of Text-Attributed Graphs"], "graph generation graph translation": ["Controlled Transformation of Text-Attributed Graphs"], "graph translation data augmentation": ["Controlled Transformation of Text-Attributed Graphs"], "data augmentation taxonomy creation": ["Controlled Transformation of Text-Attributed Graphs"], "graph generation graph translation data augmentation": ["Controlled Transformation of Text-Attributed Graphs"], "graph translation data augmentation taxonomy creation": ["Controlled Transformation of Text-Attributed Graphs"], "graph generation graph translation data augmentation taxonomy creation": ["Controlled Transformation of Text-Attributed Graphs"], "legal consequence identification": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "checkworthiness assessment": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "election law violation detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "privacy regulation breach detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "misinformation detection legal consequence identification": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "legal consequence identification checkworthiness assessment": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "checkworthiness assessment hate speech detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "hate speech detection election law violation detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "election law violation detection privacy regulation breach detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "misinformation detection legal consequence identification checkworthiness assessment": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "legal consequence identification checkworthiness assessment hate speech detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "checkworthiness assessment hate speech detection election law violation detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "hate speech detection election law violation detection privacy regulation breach detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "misinformation detection legal consequence identification checkworthiness assessment hate speech detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "legal consequence identification checkworthiness assessment hate speech detection election law violation detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "checkworthiness assessment hate speech detection election law violation detection privacy regulation breach detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "misinformation detection legal consequence identification checkworthiness assessment hate speech detection election law violation detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "legal consequence identification checkworthiness assessment hate speech detection election law violation detection privacy regulation breach detection": ["Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"], "depression identification": ["CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models"], "anxiety identification": ["CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models"], "depression identification anxiety identification": ["CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models"], "predicate inference": ["Explicit Inductive Inference using Large Language Models"], "knowledge graph question answering subgraph retrieval": ["Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA"], "subgraph retrieval RAG": ["Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA"], "knowledge graph question answering subgraph retrieval RAG": ["Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA"], "morality judgement": ["Evaluating Gender Bias of LLMs in Making Morality Judgements"], "gender bias detection morality judgement": ["Evaluating Gender Bias of LLMs in Making Morality Judgements"], "sts-b": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mnli sst-2": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mrpc cola": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "cola qnli": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "qnli qqp": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "qqp rte": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "rte sts-b": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mnli sst-2 mrpc": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "sst-2 mrpc cola": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mrpc cola qnli": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "cola qnli qqp": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "qnli qqp rte": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "qqp rte sts-b": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mnli sst-2 mrpc cola": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "sst-2 mrpc cola qnli": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mrpc cola qnli qqp": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "cola qnli qqp rte": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "qnli qqp rte sts-b": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mnli sst-2 mrpc cola qnli": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "sst-2 mrpc cola qnli qqp": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "mrpc cola qnli qqp rte": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "cola qnli qqp rte sts-b": ["A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune"], "source selection in news": ["Explaining Mixtures of Sources in News Articles"], "harmful tweet detection": ["LLM generated responses to mitigate the impact of hate speech"], "counter-speech generation": ["LLM generated responses to mitigate the impact of hate speech"], "user engagement reduction": ["LLM generated responses to mitigate the impact of hate speech"], "harmful tweet detection counter-speech generation": ["LLM generated responses to mitigate the impact of hate speech"], "counter-speech generation user engagement reduction": ["LLM generated responses to mitigate the impact of hate speech"], "harmful tweet detection counter-speech generation user engagement reduction": ["LLM generated responses to mitigate the impact of hate speech"], "cross-lingual lexical alignment": ["Locally Measuring Cross-lingual Lexical Alignment: A Domain and Word Level Perspective"], "multivent-g dataset creation": ["Grounding Partially-Defined Events in Multimodal Data"], "partially-defined event extraction": ["Grounding Partially-Defined Events in Multimodal Data"], "text span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "temporal span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "spatial span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "multivent-g dataset creation partially-defined event extraction": ["Grounding Partially-Defined Events in Multimodal Data"], "partially-defined event extraction text span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "text span retrieval temporal span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "temporal span retrieval spatial span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "multivent-g dataset creation partially-defined event extraction text span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "partially-defined event extraction text span retrieval temporal span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "text span retrieval temporal span retrieval spatial span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "multivent-g dataset creation partially-defined event extraction text span retrieval temporal span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "partially-defined event extraction text span retrieval temporal span retrieval spatial span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "multivent-g dataset creation partially-defined event extraction text span retrieval temporal span retrieval spatial span retrieval": ["Grounding Partially-Defined Events in Multimodal Data"], "multilingual LLMs": ["How Does Quantization Affect Multilingual LLMs?"], "performance evaluation": ["How Does Quantization Affect Multilingual LLMs?"], "quantization multilingual LLMs": ["How Does Quantization Affect Multilingual LLMs?"], "multilingual LLMs performance evaluation": ["How Does Quantization Affect Multilingual LLMs?"], "quantization multilingual LLMs performance evaluation": ["How Does Quantization Affect Multilingual LLMs?"], "document-to-presentation": ["Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution"], "non-linear narrative generation": ["Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution"], "content attribution": ["Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution"], "document-to-presentation non-linear narrative generation": ["Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution"], "non-linear narrative generation content attribution": ["Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution"], "document-to-presentation non-linear narrative generation content attribution": ["Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution"], "alzheimer's disease detection": ["Domain Adaptation via Prompt Learning for Alzheimer's Detection"], "reward model specification": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning with ai feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "policy training": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning reward model specification": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reward model specification value alignment": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "value alignment reinforcement learning from human feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning from human feedback reinforcement learning with ai feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning with ai feedback policy training": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning reward model specification value alignment": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reward model specification value alignment reinforcement learning from human feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "value alignment reinforcement learning from human feedback reinforcement learning with ai feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning from human feedback reinforcement learning with ai feedback policy training": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning reward model specification value alignment reinforcement learning from human feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reward model specification value alignment reinforcement learning from human feedback reinforcement learning with ai feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "value alignment reinforcement learning from human feedback reinforcement learning with ai feedback policy training": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reinforcement learning reward model specification value alignment reinforcement learning from human feedback reinforcement learning with ai feedback": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "reward model specification value alignment reinforcement learning from human feedback reinforcement learning with ai feedback policy training": ["Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models"], "preference labeling": ["On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization"], "reward model training preference labeling": ["On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization"], "preference labeling LLM alignment": ["On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization"], "reward model training preference labeling LLM alignment": ["On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization"], "metaphor and multi-word expression": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "text refinement": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "rule explanation and definitions": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "i'rab": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "grammatical error correction metaphor and multi-word expression": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "metaphor and multi-word expression text refinement": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "text refinement rule explanation and definitions": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "rule explanation and definitions i'rab": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "grammatical error correction metaphor and multi-word expression text refinement": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "metaphor and multi-word expression text refinement rule explanation and definitions": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "text refinement rule explanation and definitions i'rab": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "grammatical error correction metaphor and multi-word expression text refinement rule explanation and definitions": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "metaphor and multi-word expression text refinement rule explanation and definitions i'rab": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "grammatical error correction metaphor and multi-word expression text refinement rule explanation and definitions i'rab": ["Gazelle: An Instruction Dataset for Arabic Writing Assistance"], "open-ended question answering": ["Extrinsic Evaluation of Cultural Competence in Large Language Models"], "text generation open-ended question answering": ["Extrinsic Evaluation of Cultural Competence in Large Language Models"], "open-ended question answering story generation": ["Extrinsic Evaluation of Cultural Competence in Large Language Models"], "text generation open-ended question answering story generation": ["Extrinsic Evaluation of Cultural Competence in Large Language Models"], "training data filtering": ["BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "machine translation evaluation quality estimation": ["BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "quality estimation hallucination detection": ["BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "hallucination detection training data filtering": ["BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "machine translation evaluation quality estimation hallucination detection": ["BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "quality estimation hallucination detection training data filtering": ["BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "machine translation evaluation quality estimation hallucination detection training data filtering": ["BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"], "multi-label sequential sentence classification": ["Multi-label Sequential Sentence Classification via Large Language Model"], "user simulation": ["Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants"], "conversational task assistant": ["Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants"], "user simulation conversational task assistant": ["Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants"], "data contamination mitigation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "multiple-choice tasks": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "variable perturbation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "benchmark language model evaluation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "language model evaluation data contamination mitigation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "data contamination mitigation mathematical reasoning": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "mathematical reasoning question answering": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "question answering multiple-choice tasks": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "multiple-choice tasks commonsense reasoning": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "commonsense reasoning variable perturbation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "variable perturbation generalization": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "benchmark language model evaluation data contamination mitigation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "language model evaluation data contamination mitigation mathematical reasoning": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "data contamination mitigation mathematical reasoning question answering": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "mathematical reasoning question answering multiple-choice tasks": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "question answering multiple-choice tasks commonsense reasoning": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "multiple-choice tasks commonsense reasoning variable perturbation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "commonsense reasoning variable perturbation generalization": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "benchmark language model evaluation data contamination mitigation mathematical reasoning": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "language model evaluation data contamination mitigation mathematical reasoning question answering": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "data contamination mitigation mathematical reasoning question answering multiple-choice tasks": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "mathematical reasoning question answering multiple-choice tasks commonsense reasoning": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "question answering multiple-choice tasks commonsense reasoning variable perturbation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "multiple-choice tasks commonsense reasoning variable perturbation generalization": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "benchmark language model evaluation data contamination mitigation mathematical reasoning question answering": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "language model evaluation data contamination mitigation mathematical reasoning question answering multiple-choice tasks": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "data contamination mitigation mathematical reasoning question answering multiple-choice tasks commonsense reasoning": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "mathematical reasoning question answering multiple-choice tasks commonsense reasoning variable perturbation": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "question answering multiple-choice tasks commonsense reasoning variable perturbation generalization": ["VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation"], "gloss2text translation": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "label smoothing": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "gloss2text translation sign language translation": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "sign language translation data augmentation": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "data augmentation label smoothing": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "gloss2text translation sign language translation data augmentation": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "sign language translation data augmentation label smoothing": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "gloss2text translation sign language translation data augmentation label smoothing": ["Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing"], "conversation generation": ["Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations"], "conversation generation question answering": ["Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations"], "question answering hallucination mitigation": ["Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations"], "conversation generation question answering hallucination mitigation": ["Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations"], "continual learning language model adaptation": ["Gradient Localization Improves Lifelong Pretraining of Language Models"], "language model adaptation knowledge probing": ["Gradient Localization Improves Lifelong Pretraining of Language Models"], "continual learning language model adaptation knowledge probing": ["Gradient Localization Improves Lifelong Pretraining of Language Models"], "temporal knowledge retention": ["Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models"], "temporal knowledge retention temporal reasoning": ["Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models"], "temporal reasoning multiple choice question answering": ["Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models"], "temporal knowledge retention temporal reasoning multiple choice question answering": ["Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models"], "language modeling translation": ["Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models"], "translation named entity recognition": ["Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models"], "language modeling translation named entity recognition": ["Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models"], "long-form factuality evaluation": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "factual precision improvement": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "fine-grained alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "sentence-level alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "language model alignment long-form factuality evaluation": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "long-form factuality evaluation factual precision improvement": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "factual precision improvement helpfulness maintenance": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "helpfulness maintenance fine-grained alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "fine-grained alignment sentence-level alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "language model alignment long-form factuality evaluation factual precision improvement": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "long-form factuality evaluation factual precision improvement helpfulness maintenance": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "factual precision improvement helpfulness maintenance fine-grained alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "helpfulness maintenance fine-grained alignment sentence-level alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "language model alignment long-form factuality evaluation factual precision improvement helpfulness maintenance": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "long-form factuality evaluation factual precision improvement helpfulness maintenance fine-grained alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "factual precision improvement helpfulness maintenance fine-grained alignment sentence-level alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "language model alignment long-form factuality evaluation factual precision improvement helpfulness maintenance fine-grained alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "long-form factuality evaluation factual precision improvement helpfulness maintenance fine-grained alignment sentence-level alignment": ["FACTALIGN: Long-form Factuality Alignment of Large Language Models"], "few-shot adaptation": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "cross-task generalization few-shot adaptation": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "few-shot adaptation natural language understanding": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "natural language understanding text classification": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "cross-task generalization few-shot adaptation natural language understanding": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "few-shot adaptation natural language understanding text classification": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "natural language understanding text classification question answering": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "text classification question answering natural language inference": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "cross-task generalization few-shot adaptation natural language understanding text classification": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "few-shot adaptation natural language understanding text classification question answering": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "natural language understanding text classification question answering natural language inference": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "cross-task generalization few-shot adaptation natural language understanding text classification question answering": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "few-shot adaptation natural language understanding text classification question answering natural language inference": ["HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation"], "natural language inference sentiment analysis topic classification": ["Inference and Verbalization Functions During In-Context Learning"], "ai-generated news detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "multimodal detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "image-only detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "text-only detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "ai-generated news detection multimodal detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "multimodal detection image-only detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "image-only detection text-only detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "ai-generated news detection multimodal detection image-only detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "multimodal detection image-only detection text-only detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "ai-generated news detection multimodal detection image-only detection text-only detection": ["MiRAGeNews: Multimodal Realistic AI-Generated News Detection"], "knowledge-based vqa multi-hop reasoning": ["Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective"], "visual question answering knowledge-based vqa multi-hop reasoning": ["Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective"], "knowledge reasoning in-context learning": ["Large Language Models are In-context Teachers for Knowledge Reasoning"], "in-context learning medical question answering": ["Large Language Models are In-context Teachers for Knowledge Reasoning"], "medical question answering commonsense reasoning": ["Large Language Models are In-context Teachers for Knowledge Reasoning"], "knowledge reasoning in-context learning medical question answering": ["Large Language Models are In-context Teachers for Knowledge Reasoning"], "in-context learning medical question answering commonsense reasoning": ["Large Language Models are In-context Teachers for Knowledge Reasoning"], "knowledge reasoning in-context learning medical question answering commonsense reasoning": ["Large Language Models are In-context Teachers for Knowledge Reasoning"], "social acceptance": ["SOCIALGAZE: Improving the Integration of Human Social Norms in Large Language Models"], "judgement": ["SOCIALGAZE: Improving the Integration of Human Social Norms in Large Language Models"], "social acceptance judgement": ["SOCIALGAZE: Improving the Integration of Human Social Norms in Large Language Models"], "judgement rationale generation": ["SOCIALGAZE: Improving the Integration of Human Social Norms in Large Language Models"], "social acceptance judgement rationale generation": ["SOCIALGAZE: Improving the Integration of Human Social Norms in Large Language Models"], "temporal graph generation": ["NARRATIVE-OF-THOUGHT: Improving Temporal Reasoning of Large Language Models via Recounted Narratives"], "temporal reasoning temporal graph generation": ["NARRATIVE-OF-THOUGHT: Improving Temporal Reasoning of Large Language Models via Recounted Narratives"], "self-exploration": ["Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "web navigation intent discovery": ["Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "intent discovery self-exploration": ["Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "self-exploration action prediction": ["Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "web navigation intent discovery self-exploration": ["Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "intent discovery self-exploration action prediction": ["Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "web navigation intent discovery self-exploration action prediction": ["Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents"], "brain ct report generation": ["See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning"], "inference rule classification": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "single-step derivation reasoning": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "proof generation": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "out-of-domain generalization": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "logical reasoning inference rule classification": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "inference rule classification single-step derivation reasoning": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "single-step derivation reasoning proof generation": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "proof generation out-of-domain generalization": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "logical reasoning inference rule classification single-step derivation reasoning": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "inference rule classification single-step derivation reasoning proof generation": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "single-step derivation reasoning proof generation out-of-domain generalization": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "logical reasoning inference rule classification single-step derivation reasoning proof generation": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "inference rule classification single-step derivation reasoning proof generation out-of-domain generalization": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "logical reasoning inference rule classification single-step derivation reasoning proof generation out-of-domain generalization": ["P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains"], "personalized integrative negotiation": ["TRIP NEGOTIATOR: A Travel Persona-aware Reinforced Dialogue Generation Model for Personalized Integrative Negotiation in Tourism"], "personalized integrative negotiation dialogue generation": ["TRIP NEGOTIATOR: A Travel Persona-aware Reinforced Dialogue Generation Model for Personalized Integrative Negotiation in Tourism"], "conditional question answering": ["Chain of Condition: Construct, Verify and Solve Conditions for Conditional Question Answering"], "LLM role-playing": ["Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization"], "LLM personalization": ["Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization"], "personality evaluation": ["Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization"], "LLM role-playing LLM personalization": ["Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization"], "LLM personalization personality evaluation": ["Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization"], "LLM role-playing LLM personalization personality evaluation": ["Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization"], "harmful content detection data augmentation": ["ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "data augmentation text classification": ["ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "text classification synthetic data generation": ["ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "harmful content detection data augmentation text classification": ["ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "data augmentation text classification synthetic data generation": ["ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "harmful content detection data augmentation text classification synthetic data generation": ["ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"], "steganography": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "covert communication": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "information hiding": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "LLM biasing": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "steganography covert communication": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "covert communication information hiding": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "information hiding LLM biasing": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "steganography covert communication information hiding": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "covert communication information hiding LLM biasing": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "steganography covert communication information hiding LLM biasing": ["Look Who's Talking Now: Covert Channels From Biased LLMs"], "social norm identification": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "community value quantification": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "norm evolution tracking": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "social interaction analysis": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "social norm identification community value quantification": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "community value quantification norm evolution tracking": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "norm evolution tracking social interaction analysis": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "social norm identification community value quantification norm evolution tracking": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "community value quantification norm evolution tracking social interaction analysis": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "social norm identification community value quantification norm evolution tracking social interaction analysis": ["VALUESCOPE: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"], "citation intention classification": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "task relation learning": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "readout function": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "citation intention classification multi-task learning": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "multi-task learning task relation learning": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "task relation learning readout function": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "citation intention classification multi-task learning task relation learning": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "multi-task learning task relation learning readout function": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "citation intention classification multi-task learning task relation learning readout function": ["Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification"], "visual entailment": ["TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "visual question answering visual entailment": ["TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "visual entailment image-text retrieval": ["TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "image-text retrieval image captioning": ["TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "visual question answering visual entailment image-text retrieval": ["TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "visual entailment image-text retrieval image captioning": ["TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "visual question answering visual entailment image-text retrieval image captioning": ["TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling"], "science-based exam questions": ["Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths"], "math word problems science-based exam questions": ["Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths"], "language agent prompts": ["Uncertainty Calibration for Tool-Using Language Agents"], "tool execution traces": ["Uncertainty Calibration for Tool-Using Language Agents"], "tool use language agent prompts": ["Uncertainty Calibration for Tool-Using Language Agents"], "language agent prompts tool execution traces": ["Uncertainty Calibration for Tool-Using Language Agents"], "tool execution traces calibration": ["Uncertainty Calibration for Tool-Using Language Agents"], "tool use language agent prompts tool execution traces": ["Uncertainty Calibration for Tool-Using Language Agents"], "language agent prompts tool execution traces calibration": ["Uncertainty Calibration for Tool-Using Language Agents"], "tool use language agent prompts tool execution traces calibration": ["Uncertainty Calibration for Tool-Using Language Agents"], "personalized video comment generation": ["Personalized Video Comment Generation"], "algebraic problem solving": ["Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?"], "math problem solving algebraic problem solving": ["Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?"], "abstractive question answering": ["MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures"], "logic understanding": ["MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures"], "medical question answering abstractive question answering": ["MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures"], "abstractive question answering logic understanding": ["MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures"], "medical question answering abstractive question answering logic understanding": ["MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures"], "length control": ["PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness"], "copy and paste": ["PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness"], "length control copy and paste": ["PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness"], "automated evaluation": ["SedarEval: Automated Evaluation using Self-Adaptive Rubrics"], "LLM evaluation automated evaluation": ["SedarEval: Automated Evaluation using Self-Adaptive Rubrics"], "automated evaluation benchmark creation": ["SedarEval: Automated Evaluation using Self-Adaptive Rubrics"], "LLM evaluation automated evaluation benchmark creation": ["SedarEval: Automated Evaluation using Self-Adaptive Rubrics"], "knowledge capability": ["Towards One-to-Many Visual Question Answering"], "visual attribute recognition": ["Towards One-to-Many Visual Question Answering"], "scene comprehension": ["Towards One-to-Many Visual Question Answering"], "visual question answering knowledge capability": ["Towards One-to-Many Visual Question Answering"], "knowledge capability visual attribute recognition": ["Towards One-to-Many Visual Question Answering"], "visual attribute recognition scene comprehension": ["Towards One-to-Many Visual Question Answering"], "visual question answering knowledge capability visual attribute recognition": ["Towards One-to-Many Visual Question Answering"], "knowledge capability visual attribute recognition scene comprehension": ["Towards One-to-Many Visual Question Answering"], "visual question answering knowledge capability visual attribute recognition scene comprehension": ["Towards One-to-Many Visual Question Answering"], "event-event causal relation extraction": ["Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering"], "causal relation classification": ["Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering"], "event-event causal relation extraction event causality identification": ["Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering"], "event causality identification causal relation classification": ["Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering"], "event-event causal relation extraction event causality identification causal relation classification": ["Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering"], "medical chat": ["BiMediX: Bilingual Medical Mixture of Experts LLM"], "open question answering": ["BiMediX: Bilingual Medical Mixture of Experts LLM"], "medical chat open question answering": ["BiMediX: Bilingual Medical Mixture of Experts LLM"], "open question answering multiple-choice question answering": ["BiMediX: Bilingual Medical Mixture of Experts LLM"], "medical chat open question answering multiple-choice question answering": ["BiMediX: Bilingual Medical Mixture of Experts LLM"], "image captioning vqa": ["Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design"], "vqa cross-modal retrieval": ["Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design"], "image captioning vqa cross-modal retrieval": ["Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design"], "natural logic inference": ["Zero-Shot Fact Verification via Natural Logic and Large Language Models"], "fact verification natural logic inference": ["Zero-Shot Fact Verification via Natural Logic and Large Language Models"], "natural logic inference question answering": ["Zero-Shot Fact Verification via Natural Logic and Large Language Models"], "fact verification natural logic inference question answering": ["Zero-Shot Fact Verification via Natural Logic and Large Language Models"], "artificial text detection": ["Robust AI-Generated Text Detection by Restricted Embeddings"], "cross-domain atd": ["Robust AI-Generated Text Detection by Restricted Embeddings"], "cross-generator atd": ["Robust AI-Generated Text Detection by Restricted Embeddings"], "artificial text detection cross-domain atd": ["Robust AI-Generated Text Detection by Restricted Embeddings"], "cross-domain atd cross-generator atd": ["Robust AI-Generated Text Detection by Restricted Embeddings"], "artificial text detection cross-domain atd cross-generator atd": ["Robust AI-Generated Text Detection by Restricted Embeddings"], "spam detection": ["CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack"], "sentiment analysis toxicity detection": ["CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack"], "toxicity detection spam detection": ["CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack"], "sentiment analysis toxicity detection spam detection": ["CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack"], "math reasoning instruction tuning": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "instruction tuning mt-bench": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "mt-bench mMLu": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "mMLu bbh": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "commonsense reasoning math reasoning instruction tuning": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "math reasoning instruction tuning mt-bench": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "instruction tuning mt-bench mMLu": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "mt-bench mMLu bbh": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "commonsense reasoning math reasoning instruction tuning mt-bench": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "math reasoning instruction tuning mt-bench mMLu": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "instruction tuning mt-bench mMLu bbh": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "commonsense reasoning math reasoning instruction tuning mt-bench mMLu": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "math reasoning instruction tuning mt-bench mMLu bbh": ["MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning"], "political bias detection": ["LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models"], "political bias detection value alignment": ["LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models"], "value alignment opinion mining": ["LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models"], "political bias detection value alignment opinion mining": ["LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models"], "information-seeking dialogue": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "factuality improvement": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "zero-shot domain transfer": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "behavioural tuning": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "information-seeking dialogue factuality improvement": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "factuality improvement hallucination mitigation": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "hallucination mitigation zero-shot domain transfer": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "zero-shot domain transfer behavioural tuning": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "information-seeking dialogue factuality improvement hallucination mitigation": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "factuality improvement hallucination mitigation zero-shot domain transfer": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "hallucination mitigation zero-shot domain transfer behavioural tuning": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "information-seeking dialogue factuality improvement hallucination mitigation zero-shot domain transfer": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "factuality improvement hallucination mitigation zero-shot domain transfer behavioural tuning": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "information-seeking dialogue factuality improvement hallucination mitigation zero-shot domain transfer behavioural tuning": ["Dial BEINFO for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning"], "active retrieval": ["Unified Active Retrieval for Retrieval Augmented Generation"], "active retrieval RAG": ["Unified Active Retrieval for Retrieval Augmented Generation"], "RAG classification": ["Unified Active Retrieval for Retrieval Augmented Generation"], "active retrieval RAG classification": ["Unified Active Retrieval for Retrieval Augmented Generation"], "language adaptation continual learning": ["Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "continual learning model merging": ["Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "model merging transfer learning": ["Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "language adaptation continual learning model merging": ["Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "continual learning model merging transfer learning": ["Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "language adaptation continual learning model merging transfer learning": ["Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"], "quantization LLMs": ["ATQ: Activation Transformation for Weight-Activation Quantization of Large Language Models"], "knowledge verification": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "eliciting preference": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "knowledge to application": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "applying to knowing": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "knowledge verification eliciting preference": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "eliciting preference knowledge to application": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "knowledge to application applying to knowing": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "knowledge verification eliciting preference knowledge to application": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "eliciting preference knowledge to application applying to knowing": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"], "knowledge verification eliciting preference knowledge to application applying to knowing": ["To Know or Not to Know? Analyzing Self-Consistency of Large Language Models under Ambiguity"]};

    window.addEventListener('DOMContentLoaded', () => {
        const plotDiv = document.querySelector(".plotly-graph-div");

        const titleBox = document.createElement("div");
        titleBox.id = "titleBox";
        titleBox.style.width = "90%";
        titleBox.style.maxHeight = "300px";
        titleBox.style.margin = "20px auto";
        titleBox.style.border = "1px solid gray";
        titleBox.style.overflowY = "scroll";
        titleBox.style.padding = "10px";
        titleBox.style.fontSize = "16px";
        document.body.appendChild(titleBox);

        plotDiv.on('plotly_click', function(data) {
            const label = data.points[0].x.toLowerCase();
            const titles = ngramMap[label] || [];
            titleBox.innerHTML = "<b>" + label + "</b><br><br>" + titles.map((t, i) => (i+1) + ". " + t).join("<br>");
        });
    });
    </script>
    </body></html>
